############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=10 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 26281432.000000 in 189.89s 
Iter 2...	Training loss: 21091028.000000 in 123.07s 
Iter 3...	Training loss: 12288160.000000 in 121.69s 
Iter 4...	Training loss: 4905480.000000 in 122.27s 
Iter 5...	Training loss: 1577427.500000 in 124.73s 
Top-1 Recall: 0.180371 Precision: 0.180371 NDCG: 0.180371 HR: 0.180371
Top-5 Recall: 0.291114 Precision: 0.058223 NDCG: 0.236543 HR: 0.291114
Top-10 Recall: 0.405836 Precision: 0.040584 NDCG: 0.273180 HR: 0.405836
Eval costs: 1.529045 s
Iter 6...	Training loss: 560482.812500 in 119.81s 
Iter 7...	Training loss: 288709.375000 in 123.65s 
Iter 8...	Training loss: 214200.718750 in 121.30s 
Iter 9...	Training loss: 192182.812500 in 123.23s 
Iter 10...	Training loss: 183301.718750 in 124.08s 
Top-1 Recall: 0.204907 Precision: 0.204907 NDCG: 0.204907 HR: 0.204907
Top-5 Recall: 0.390584 Precision: 0.078117 NDCG: 0.298162 HR: 0.390584
Top-10 Recall: 0.548408 Precision: 0.054841 NDCG: 0.349032 HR: 0.548408
Eval costs: 1.551123 s
Iter 11...	Training loss: 177920.125000 in 126.10s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 26161074.000000 in 125.37s 
Iter 2...	Training loss: 21099960.000000 in 121.94s 
Iter 3...	Training loss: 12282601.000000 in 121.77s 
Iter 4...	Training loss: 4969125.500000 in 119.94s 
Iter 5...	Training loss: 1587497.375000 in 120.73s 
Top-1 Recall: 0.177056 Precision: 0.177056 NDCG: 0.177056 HR: 0.177056
Top-5 Recall: 0.295756 Precision: 0.059151 NDCG: 0.237989 HR: 0.295756
Top-10 Recall: 0.404509 Precision: 0.040451 NDCG: 0.272732 HR: 0.404509
Eval costs: 1.509214 s
Iter 6...	Training loss: 562409.375000 in 123.10s 
Iter 7...	Training loss: 291035.156250 in 122.98s 
Iter 8...	Training loss: 216908.546875 in 122.57s 
Iter 9...	Training loss: 192184.390625 in 122.81s 
Iter 10...	Training loss: 183229.031250 in 121.70s 
Top-1 Recall: 0.211538 Precision: 0.211538 NDCG: 0.211538 HR: 0.211538
Top-5 Recall: 0.394562 Precision: 0.078912 NDCG: 0.302916 HR: 0.394562
Top-10 Recall: 0.547745 Precision: 0.054775 NDCG: 0.352214 HR: 0.547745
Eval costs: 1.520072 s
Iter 11...	Training loss: 178630.656250 in 120.21s 
Iter 12...	Training loss: 174271.953125 in 151.00s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 26174286.000000 in 143.90s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=64 
############################################### 
n_negative=20  
batch_size=512 
############################################### 
n_negative=20  
batch_size=512 
############################################### 
n_negative=20  
batch_size=512 
############################################### 
n_negative=20  
batch_size=512 
