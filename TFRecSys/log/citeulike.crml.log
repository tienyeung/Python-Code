############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 3004574.750000  in 3.56s 
Iter 2...	Training loss: 2826746.250000  in 3.51s 
Iter 3...	Training loss: 2731502.250000  in 3.51s 
Iter 4...	Training loss: 2651180.750000  in 3.52s 
Iter 5...	Training loss: 2576896.000000  in 3.51s 
Top-1 Recall: 0.003523 Precision: 0.003523 NDCG: 0.003523 HR: 0.003523
Top-5 Recall: 0.015729 Precision: 0.003146 NDCG: 0.009898 HR: 0.015729
Top-10 Recall: 0.025544 Precision: 0.002554 NDCG: 0.013085 HR: 0.025544
Eval costs: 0.974410 s
Iter 6...	Training loss: 2501586.250000  in 3.52s 
Iter 7...	Training loss: 2419641.500000  in 3.52s 
Iter 8...	Training loss: 2324490.500000  in 3.50s 
Iter 9...	Training loss: 2211963.500000  in 3.51s 
Iter 10...	Training loss: 2072568.250000  in 3.51s 
Top-1 Recall: 0.009186 Precision: 0.009186 NDCG: 0.009186 HR: 0.009186
Top-5 Recall: 0.027180 Precision: 0.005436 NDCG: 0.018255 HR: 0.027180
Top-10 Recall: 0.038883 Precision: 0.003888 NDCG: 0.022011 HR: 0.038883
Eval costs: 0.917908 s
Iter 11...	Training loss: 1898070.875000  in 3.60s 
Iter 12...	Training loss: 1687893.625000  in 3.53s 
Iter 13...	Training loss: 1448630.375000  in 3.51s 
Iter 14...	Training loss: 1207537.250000  in 3.54s 
Iter 15...	Training loss: 983948.062500  in 3.51s 
Top-1 Recall: 0.017994 Precision: 0.017994 NDCG: 0.017994 HR: 0.017994
Top-5 Recall: 0.053857 Precision: 0.010771 NDCG: 0.036117 HR: 0.053857
Top-10 Recall: 0.075249 Precision: 0.007525 NDCG: 0.043015 HR: 0.075249
Eval costs: 0.952084 s
Iter 16...	Training loss: 795319.437500  in 3.53s 
Iter 17...	Training loss: 643100.625000  in 3.49s 
Iter 18...	Training loss: 524755.812500  in 3.52s 
Iter 19...	Training loss: 432475.281250  in 3.58s 
Iter 20...	Training loss: 358820.218750  in 3.52s 
Top-1 Recall: 0.021643 Precision: 0.021643 NDCG: 0.021643 HR: 0.021643
Top-5 Recall: 0.066566 Precision: 0.013313 NDCG: 0.044550 HR: 0.066566
Top-10 Recall: 0.091481 Precision: 0.009148 NDCG: 0.052552 HR: 0.091481
Eval costs: 0.967654 s
Iter 21...	Training loss: 301204.156250  in 3.65s 
Iter 22...	Training loss: 258397.265625  in 3.50s 
Iter 23...	Training loss: 223555.406250  in 3.51s 
Iter 24...	Training loss: 194360.843750  in 3.57s 
Iter 25...	Training loss: 169488.609375  in 3.55s 
Top-1 Recall: 0.022398 Precision: 0.022398 NDCG: 0.022398 HR: 0.022398
Top-5 Recall: 0.069586 Precision: 0.013917 NDCG: 0.046152 HR: 0.069586
Top-10 Recall: 0.093872 Precision: 0.009387 NDCG: 0.054047 HR: 0.093872
Eval costs: 1.058543 s
Iter 26...	Training loss: 150107.593750  in 3.56s 
Iter 27...	Training loss: 132352.843750  in 3.69s 
Iter 28...	Training loss: 121089.265625  in 3.53s 
Iter 29...	Training loss: 107487.312500  in 3.53s 
Iter 30...	Training loss: 99467.640625  in 3.54s 
Top-1 Recall: 0.021140 Precision: 0.021140 NDCG: 0.021140 HR: 0.021140
Top-5 Recall: 0.069334 Precision: 0.013867 NDCG: 0.045353 HR: 0.069334
Top-10 Recall: 0.098779 Precision: 0.009878 NDCG: 0.054846 HR: 0.098779
Eval costs: 0.984163 s
Iter 31...	Training loss: 90269.218750  in 3.52s 
Iter 32...	Training loss: 82527.734375  in 3.53s 
Iter 33...	Training loss: 76079.164062  in 3.52s 
Iter 34...	Training loss: 69432.195312  in 3.63s 
Iter 35...	Training loss: 64691.363281  in 3.52s 
Top-1 Recall: 0.022147 Precision: 0.022147 NDCG: 0.022147 HR: 0.022147
Top-5 Recall: 0.067950 Precision: 0.013590 NDCG: 0.045680 HR: 0.067950
Top-10 Recall: 0.098150 Precision: 0.009815 NDCG: 0.055410 HR: 0.098150
Eval costs: 0.987997 s
Iter 36...	Training loss: 59071.222656  in 3.51s 
Iter 37...	Training loss: 56266.863281  in 3.50s 
Iter 38...	Training loss: 52143.000000  in 3.50s 
Iter 39...	Training loss: 48279.191406  in 3.52s 
Iter 40...	Training loss: 45360.289062  in 3.57s 
Top-1 Recall: 0.021518 Precision: 0.021518 NDCG: 0.021518 HR: 0.021518
Top-5 Recall: 0.069586 Precision: 0.013917 NDCG: 0.045993 HR: 0.069586
Top-10 Recall: 0.099157 Precision: 0.009916 NDCG: 0.055468 HR: 0.099157
Eval costs: 1.069462 s
Iter 41...	Training loss: 43630.347656  in 3.53s 
Iter 42...	Training loss: 40185.832031  in 3.52s 
Iter 43...	Training loss: 37858.917969  in 3.51s 
Iter 44...	Training loss: 36721.035156  in 3.61s 
Iter 45...	Training loss: 33392.214844  in 3.54s 
Top-1 Recall: 0.022776 Precision: 0.022776 NDCG: 0.022776 HR: 0.022776
Top-5 Recall: 0.069838 Precision: 0.013968 NDCG: 0.046640 HR: 0.069838
Top-10 Recall: 0.099031 Precision: 0.009903 NDCG: 0.055972 HR: 0.099031
Eval costs: 0.989918 s
Iter 46...	Training loss: 32354.300781  in 3.52s 
Iter 47...	Training loss: 30709.964844  in 3.51s 
Iter 48...	Training loss: 29147.900391  in 3.54s 
Iter 49...	Training loss: 28337.484375  in 3.52s 
Iter 50...	Training loss: 26296.869141  in 3.59s 
Top-1 Recall: 0.022650 Precision: 0.022650 NDCG: 0.022650 HR: 0.022650
Top-5 Recall: 0.070467 Precision: 0.014093 NDCG: 0.047152 HR: 0.070467
Top-10 Recall: 0.099786 Precision: 0.009979 NDCG: 0.056630 HR: 0.099786
Eval costs: 0.991853 s
Iter 51...	Training loss: 26066.789062  in 3.53s 
Iter 52...	Training loss: 23753.175781  in 3.57s 
Iter 53...	Training loss: 22582.738281  in 3.55s 
Iter 54...	Training loss: 21665.646484  in 3.58s 
Iter 55...	Training loss: 21536.968750  in 3.54s 
Top-1 Recall: 0.024160 Precision: 0.024160 NDCG: 0.024160 HR: 0.024160
Top-5 Recall: 0.070844 Precision: 0.014169 NDCG: 0.047837 HR: 0.070844
Top-10 Recall: 0.100415 Precision: 0.010042 NDCG: 0.057367 HR: 0.100415
Eval costs: 1.071390 s
Iter 56...	Training loss: 20630.156250  in 3.59s 
Iter 57...	Training loss: 19010.390625  in 3.52s 
Iter 58...	Training loss: 18937.605469  in 3.56s 
Iter 59...	Training loss: 18124.941406  in 3.59s 
Iter 60...	Training loss: 17536.990234  in 3.52s 
Top-1 Recall: 0.022902 Precision: 0.022902 NDCG: 0.022902 HR: 0.022902
Top-5 Recall: 0.071222 Precision: 0.014244 NDCG: 0.047568 HR: 0.071222
Top-10 Recall: 0.097647 Precision: 0.009765 NDCG: 0.056071 HR: 0.097647
Eval costs: 0.994114 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 357657.500000 (60271.085999, 297386.393799) in 4.13s 
Iter 2...	Training loss: 324915.062500 (45730.940445, 279184.160889) in 3.87s 
Iter 3...	Training loss: 304295.906250 (34659.772110, 269636.135254) in 3.92s 
Iter 4...	Training loss: 288725.625000 (27110.536701, 261615.087891) in 4.00s 
Iter 5...	Training loss: 254150.718750 (0.000000, 254150.738892) in 3.62s 
Top-1 Recall: 0.004782 Precision: 0.004782 NDCG: 0.004782 HR: 0.004782
Top-5 Recall: 0.017239 Precision: 0.003448 NDCG: 0.011090 HR: 0.017239
Top-10 Recall: 0.025041 Precision: 0.002504 NDCG: 0.013603 HR: 0.025041
Eval costs: 0.885996 s
Iter 6...	Training loss: 283155.812500 (36275.047283, 246880.800415) in 4.23s 
Iter 7...	Training loss: 253924.781250 (15154.003124, 238770.790283) in 3.89s 
Iter 8...	Training loss: 242228.187500 (12873.306503, 229354.876099) in 3.93s 
Iter 9...	Training loss: 228916.968750 (10617.700815, 218299.271118) in 4.01s 
Iter 10...	Training loss: 213350.140625 (8573.269630, 204776.872925) in 3.92s 
Top-1 Recall: 0.009563 Precision: 0.009563 NDCG: 0.009563 HR: 0.009563
Top-5 Recall: 0.027558 Precision: 0.005512 NDCG: 0.018731 HR: 0.027558
Top-10 Recall: 0.038505 Precision: 0.003851 NDCG: 0.022272 HR: 0.038505
Eval costs: 0.928200 s
Iter 11...	Training loss: 194905.421875 (6809.151243, 188096.258789) in 3.93s 
Iter 12...	Training loss: 173233.015625 (5334.051728, 167898.962891) in 3.88s 
Iter 13...	Training loss: 149650.500000 (4185.570964, 145464.933838) in 3.88s 
Iter 14...	Training loss: 125950.468750 (3357.111426, 122593.365417) in 3.98s 
Iter 15...	Training loss: 104498.289062 (2841.501535, 101656.788086) in 3.93s 
Top-1 Recall: 0.019630 Precision: 0.019630 NDCG: 0.019630 HR: 0.019630
Top-5 Recall: 0.051466 Precision: 0.010293 NDCG: 0.036335 HR: 0.051466
Top-10 Recall: 0.079653 Precision: 0.007965 NDCG: 0.045487 HR: 0.079653
Eval costs: 0.963272 s
Iter 16...	Training loss: 85694.148438 (2579.314396, 83114.829712) in 3.94s 
Iter 17...	Training loss: 70910.765625 (2495.857590, 68414.908508) in 3.90s 
Iter 18...	Training loss: 58802.871094 (2534.510486, 56268.360077) in 3.93s 
Iter 19...	Training loss: 49440.636719 (2643.819874, 46796.814026) in 3.94s 
Iter 20...	Training loss: 42497.460938 (2798.221753, 39699.237823) in 3.88s 
Top-1 Recall: 0.022776 Precision: 0.022776 NDCG: 0.022776 HR: 0.022776
Top-5 Recall: 0.066063 Precision: 0.013213 NDCG: 0.044636 HR: 0.066063
Top-10 Recall: 0.091481 Precision: 0.009148 NDCG: 0.052855 HR: 0.091481
Eval costs: 0.980734 s
Iter 21...	Training loss: 36559.269531 (2974.441682, 33584.829544) in 3.90s 
Iter 22...	Training loss: 31963.912109 (3162.783812, 28801.127777) in 3.97s 
Iter 23...	Training loss: 28541.082031 (3366.419251, 25174.664291) in 3.94s 
Iter 24...	Training loss: 25760.685547 (3570.055428, 22190.631088) in 3.92s 
Iter 25...	Training loss: 23469.291016 (3784.138022, 19685.154045) in 3.96s 
Top-1 Recall: 0.022524 Precision: 0.022524 NDCG: 0.022524 HR: 0.022524
Top-5 Recall: 0.067573 Precision: 0.013515 NDCG: 0.045331 HR: 0.067573
Top-10 Recall: 0.095759 Precision: 0.009576 NDCG: 0.054462 HR: 0.095759
Eval costs: 0.993109 s
Iter 26...	Training loss: 21344.591797 (4001.206830, 17343.384773) in 3.89s 
Iter 27...	Training loss: 19923.726562 (4206.593852, 15717.131401) in 3.97s 
Iter 28...	Training loss: 18761.876953 (4427.794705, 14334.082741) in 3.89s 
Iter 29...	Training loss: 17527.906250 (4626.388528, 12901.517792) in 3.91s 
Iter 30...	Training loss: 11699.379883 (0.000000, 11699.381042) in 3.61s 
Top-1 Recall: 0.022650 Precision: 0.022650 NDCG: 0.022650 HR: 0.022650
Top-5 Recall: 0.069083 Precision: 0.013817 NDCG: 0.046437 HR: 0.069083
Top-10 Recall: 0.096389 Precision: 0.009639 NDCG: 0.055259 HR: 0.096389
Eval costs: 1.085957 s
Iter 31...	Training loss: 18891.515625 (8185.875643, 10705.640491) in 4.21s 
Iter 32...	Training loss: 15039.511719 (5210.233977, 9829.279137) in 3.92s 
Iter 33...	Training loss: 14482.775391 (5400.369343, 9082.405777) in 3.97s 
Iter 34...	Training loss: 13952.005859 (5601.879836, 8350.125957) in 3.89s 
Iter 35...	Training loss: 13664.851562 (5786.359263, 7878.491421) in 3.88s 
Top-1 Recall: 0.023153 Precision: 0.023153 NDCG: 0.023153 HR: 0.023153
Top-5 Recall: 0.067573 Precision: 0.013515 NDCG: 0.045793 HR: 0.067573
Top-10 Recall: 0.095885 Precision: 0.009589 NDCG: 0.054870 HR: 0.095885
Eval costs: 1.085012 s
Iter 36...	Training loss: 13262.096680 (5991.930368, 7270.165890) in 3.91s 
Iter 37...	Training loss: 12985.193359 (6188.734229, 6796.459473) in 3.88s 
Iter 38...	Training loss: 12681.458008 (6362.500537, 6318.956841) in 3.94s 
Iter 39...	Training loss: 12493.781250 (6551.261850, 5942.519829) in 3.89s 
Iter 40...	Training loss: 12527.046875 (6735.261380, 5791.785240) in 3.89s 
Top-1 Recall: 0.024412 Precision: 0.024412 NDCG: 0.024412 HR: 0.024412
Top-5 Recall: 0.068705 Precision: 0.013741 NDCG: 0.046798 HR: 0.068705
Top-10 Recall: 0.095130 Precision: 0.009513 NDCG: 0.055321 HR: 0.095130
Eval costs: 1.087387 s
Iter 41...	Training loss: 12318.394531 (6898.687889, 5419.706055) in 3.89s 
Iter 42...	Training loss: 11935.936523 (7077.552202, 4858.384773) in 3.93s 
Iter 43...	Training loss: 12020.568359 (7245.934467, 4774.633829) in 3.93s 
Iter 44...	Training loss: 11940.808594 (7429.651176, 4511.156553) in 4.01s 
Iter 45...	Training loss: 11847.378906 (7602.278145, 4245.100876) in 3.88s 
Top-1 Recall: 0.023028 Precision: 0.023028 NDCG: 0.023028 HR: 0.023028
Top-5 Recall: 0.069586 Precision: 0.013917 NDCG: 0.046810 HR: 0.069586
Top-10 Recall: 0.095256 Precision: 0.009526 NDCG: 0.055129 HR: 0.095256
Eval costs: 1.002743 s
Iter 46...	Training loss: 11832.236328 (7767.681707, 4064.553810) in 3.97s 
Iter 47...	Training loss: 11826.987305 (7936.537729, 3890.449633) in 3.93s 
Iter 48...	Training loss: 11812.437500 (8116.575775, 3695.862024) in 3.88s 
Iter 49...	Training loss: 11841.514648 (8282.472296, 3559.042507) in 3.96s 
Iter 50...	Training loss: 3316.900146 (0.000000, 3316.900092) in 3.59s 
Top-1 Recall: 0.022902 Precision: 0.022902 NDCG: 0.022902 HR: 0.022902
Top-5 Recall: 0.068579 Precision: 0.013716 NDCG: 0.046377 HR: 0.068579
Top-10 Recall: 0.097647 Precision: 0.009765 NDCG: 0.055775 HR: 0.097647
Eval costs: 1.004600 s
Iter 51...	Training loss: 17766.628906 (14468.838450, 3297.790116) in 4.23s 
Iter 52...	Training loss: 11865.650391 (8763.314558, 3102.335599) in 3.88s 
Iter 53...	Training loss: 11911.517578 (8948.709734, 2962.807552) in 3.89s 
Iter 54...	Training loss: 11947.990234 (9125.778360, 2822.211108) in 3.94s 
Iter 55...	Training loss: 11966.740234 (9282.463659, 2684.276568) in 3.90s 
Top-1 Recall: 0.023783 Precision: 0.023783 NDCG: 0.023783 HR: 0.023783
Top-5 Recall: 0.068957 Precision: 0.013791 NDCG: 0.046865 HR: 0.068957
Top-10 Recall: 0.097647 Precision: 0.009765 NDCG: 0.056040 HR: 0.097647
Eval costs: 1.004249 s
Iter 56...	Training loss: 12048.171875 (9443.089581, 2605.081493) in 3.96s 
Iter 57...	Training loss: 2466.679443 (0.000000, 2466.679186) in 3.57s 
Iter 58...	Training loss: 18833.121094 (16466.899910, 2366.223039) in 4.22s 
Iter 59...	Training loss: 12180.282227 (9895.109056, 2285.172838) in 3.91s 
Iter 60...	Training loss: 12320.802734 (10050.331251, 2270.471346) in 3.96s 
Top-1 Recall: 0.024034 Precision: 0.024034 NDCG: 0.024034 HR: 0.024034
Top-5 Recall: 0.069083 Precision: 0.013817 NDCG: 0.046682 HR: 0.069083
Top-10 Recall: 0.097899 Precision: 0.009790 NDCG: 0.055869 HR: 0.097899
Eval costs: 1.005157 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 369434.656250 (60301.143524, 309133.535889) in 4.13s 
Iter 2...	Training loss: 331036.250000 (45750.723824, 285285.520508) in 3.90s 
Iter 3...	Training loss: 308244.218750 (34524.229946, 273719.971436) in 3.89s 
Iter 4...	Training loss: 291612.156250 (26637.971897, 264974.191528) in 4.01s 
Iter 5...	Training loss: 278537.968750 (21425.414982, 257112.547363) in 3.91s 
Top-1 Recall: 0.005033 Precision: 0.005033 NDCG: 0.005033 HR: 0.005033
Top-5 Recall: 0.017365 Precision: 0.003473 NDCG: 0.011529 HR: 0.017365
Top-10 Recall: 0.025922 Precision: 0.002592 NDCG: 0.014255 HR: 0.025922
Eval costs: 0.878555 s
Iter 6...	Training loss: 267116.687500 (17659.696606, 249457.011475) in 4.00s 
Iter 7...	Training loss: 255858.125000 (14638.995636, 241219.130371) in 3.91s 
Iter 8...	Training loss: 243943.265625 (12082.447508, 231860.809937) in 3.92s 
Iter 9...	Training loss: 230499.000000 (9859.235559, 220639.762695) in 3.97s 
Iter 10...	Training loss: 206837.921875 (0.000000, 206837.920654) in 3.59s 
Top-1 Recall: 0.009689 Precision: 0.009689 NDCG: 0.009689 HR: 0.009689
Top-5 Recall: 0.029445 Precision: 0.005889 NDCG: 0.019815 HR: 0.029445
Top-10 Recall: 0.042154 Precision: 0.004215 NDCG: 0.023952 HR: 0.042154
Eval costs: 0.917830 s
Iter 11...	Training loss: 202496.843750 (11613.155318, 190883.692505) in 4.23s 
Iter 12...	Training loss: 176075.343750 (5078.918309, 170996.426880) in 3.88s 
Iter 13...	Training loss: 152817.781250 (4000.608041, 148817.168335) in 3.94s 
Iter 14...	Training loss: 128870.015625 (3215.902600, 125654.112488) in 3.93s 
Iter 15...	Training loss: 106988.031250 (2716.486578, 104271.539124) in 3.89s 
Top-1 Recall: 0.020888 Precision: 0.020888 NDCG: 0.020888 HR: 0.020888
Top-5 Recall: 0.058890 Precision: 0.011778 NDCG: 0.039860 HR: 0.058890
Top-10 Recall: 0.082547 Precision: 0.008255 NDCG: 0.047504 HR: 0.082547
Eval costs: 0.954227 s
Iter 16...	Training loss: 87784.210938 (2467.435637, 85316.782043) in 3.96s 
Iter 17...	Training loss: 72775.890625 (2391.952245, 70383.937500) in 3.91s 
Iter 18...	Training loss: 60142.765625 (2440.108392, 57702.655243) in 3.90s 
Iter 19...	Training loss: 47936.429688 (0.000000, 47936.429199) in 3.59s 
Iter 20...	Training loss: 45242.339844 (4561.812362, 40680.522491) in 4.22s 
Top-1 Recall: 0.024412 Precision: 0.024412 NDCG: 0.024412 HR: 0.024412
Top-5 Recall: 0.066818 Precision: 0.013364 NDCG: 0.046146 HR: 0.066818
Top-10 Recall: 0.096514 Precision: 0.009651 NDCG: 0.055729 HR: 0.096514
Eval costs: 0.970538 s
Iter 21...	Training loss: 37409.492188 (2901.130191, 34508.367645) in 3.89s 
Iter 22...	Training loss: 29386.259766 (0.000000, 29386.259506) in 3.57s 
Iter 23...	Training loss: 31333.109375 (5303.476348, 26029.630417) in 4.31s 
Iter 24...	Training loss: 22458.042969 (0.000000, 22458.044785) in 3.56s 
Iter 25...	Training loss: 26103.238281 (5896.867930, 20206.372803) in 4.24s 
Top-1 Recall: 0.025041 Precision: 0.025041 NDCG: 0.025041 HR: 0.025041
Top-5 Recall: 0.070844 Precision: 0.014169 NDCG: 0.048325 HR: 0.070844
Top-10 Recall: 0.099786 Precision: 0.009979 NDCG: 0.057621 HR: 0.099786
Eval costs: 0.982847 s
Iter 26...	Training loss: 21924.955078 (3843.498172, 18081.457413) in 3.89s 
Iter 27...	Training loss: 20043.923828 (4010.685505, 16033.237633) in 3.94s 
Iter 28...	Training loss: 18809.355469 (4171.599300, 14637.756432) in 3.88s 
Iter 29...	Training loss: 17428.964844 (4327.414253, 13101.549156) in 3.89s 
Iter 30...	Training loss: 16458.378906 (4492.248120, 11966.129341) in 3.98s 
Top-1 Recall: 0.024160 Precision: 0.024160 NDCG: 0.024160 HR: 0.024160
Top-5 Recall: 0.070467 Precision: 0.014093 NDCG: 0.047868 HR: 0.070467
Top-10 Recall: 0.100793 Precision: 0.010079 NDCG: 0.057574 HR: 0.100793
Eval costs: 0.988525 s
Iter 31...	Training loss: 10736.479492 (0.000000, 10736.479973) in 3.63s 
Iter 32...	Training loss: 18048.378906 (7863.136922, 10185.241417) in 4.23s 
Iter 33...	Training loss: 14339.193359 (4977.912872, 9361.280499) in 3.90s 
Iter 34...	Training loss: 13816.421875 (5110.302400, 8706.120380) in 3.94s 
Iter 35...	Training loss: 13295.751953 (5266.291949, 8029.459629) in 3.94s 
Top-1 Recall: 0.025041 Precision: 0.025041 NDCG: 0.025041 HR: 0.025041
Top-5 Recall: 0.071474 Precision: 0.014295 NDCG: 0.048739 HR: 0.071474
Top-10 Recall: 0.099912 Precision: 0.009991 NDCG: 0.057981 HR: 0.099912
Eval costs: 1.073616 s
Iter 36...	Training loss: 7431.108887 (0.000000, 7431.109154) in 3.58s 
Iter 37...	Training loss: 16115.277344 (9161.164572, 6954.111149) in 4.22s 
Iter 38...	Training loss: 12241.450195 (5682.793717, 6558.656391) in 4.03s 
Iter 39...	Training loss: 11983.870117 (5821.814459, 6162.055481) in 3.89s 
Iter 40...	Training loss: 5712.689453 (0.000000, 5712.689369) in 3.59s 
Top-1 Recall: 0.025922 Precision: 0.025922 NDCG: 0.025922 HR: 0.025922
Top-5 Recall: 0.072229 Precision: 0.014446 NDCG: 0.049335 HR: 0.072229
Top-10 Recall: 0.100038 Precision: 0.010004 NDCG: 0.058318 HR: 0.100038
Eval costs: 0.991755 s
Iter 41...	Training loss: 15767.982422 (10117.823889, 5650.157743) in 4.28s 
Iter 42...	Training loss: 11377.140625 (6228.730383, 5148.409983) in 3.91s 
Iter 43...	Training loss: 11126.644531 (6351.152916, 4775.491053) in 3.93s 
Iter 44...	Training loss: 11106.941406 (6494.534146, 4612.407862) in 3.88s 
Iter 45...	Training loss: 11027.005859 (6631.246843, 4395.758652) in 3.90s 
Top-1 Recall: 0.023657 Precision: 0.023657 NDCG: 0.023657 HR: 0.023657
Top-5 Recall: 0.072480 Precision: 0.014496 NDCG: 0.048539 HR: 0.072480
Top-10 Recall: 0.101674 Precision: 0.010167 NDCG: 0.057892 HR: 0.101674
Eval costs: 1.080480 s
Iter 46...	Training loss: 10881.358398 (6744.273861, 4137.084127) in 3.90s 
Iter 47...	Training loss: 10939.013672 (6867.805866, 4071.208645) in 3.89s 
Iter 48...	Training loss: 10721.333008 (6983.236357, 3738.096495) in 3.89s 
Iter 49...	Training loss: 10668.051758 (7106.244989, 3561.806471) in 4.02s 
Iter 50...	Training loss: 10710.835938 (7219.928114, 3490.907543) in 3.92s 
Top-1 Recall: 0.023405 Precision: 0.023405 NDCG: 0.023405 HR: 0.023405
Top-5 Recall: 0.073864 Precision: 0.014773 NDCG: 0.049027 HR: 0.073864
Top-10 Recall: 0.101925 Precision: 0.010193 NDCG: 0.058046 HR: 0.101925
Eval costs: 0.993201 s
Iter 51...	Training loss: 10730.713867 (7321.039508, 3409.674322) in 3.99s 
Iter 52...	Training loss: 10557.947266 (7454.159910, 3103.787345) in 3.88s 
Iter 53...	Training loss: 10640.406250 (7574.024993, 3066.381512) in 3.90s 
Iter 54...	Training loss: 10681.230469 (7691.571521, 2989.659362) in 4.20s 
Iter 55...	Training loss: 10657.048828 (7797.132374, 2859.916759) in 3.92s 
Top-1 Recall: 0.024160 Precision: 0.024160 NDCG: 0.024160 HR: 0.024160
Top-5 Recall: 0.072480 Precision: 0.014496 NDCG: 0.048834 HR: 0.072480
Top-10 Recall: 0.100667 Precision: 0.010067 NDCG: 0.057916 HR: 0.100667
Eval costs: 0.995964 s
Iter 56...	Training loss: 10686.437500 (7912.340008, 2774.097775) in 3.95s 
Iter 57...	Training loss: 10536.714844 (8011.825342, 2524.889689) in 3.92s 
Iter 58...	Training loss: 10637.534180 (8120.874115, 2516.660359) in 3.90s 
Iter 59...	Training loss: 10653.355469 (8224.419777, 2428.935305) in 3.93s 
Iter 60...	Training loss: 10659.107422 (8330.816486, 2328.291489) in 3.90s 
Top-1 Recall: 0.023531 Precision: 0.023531 NDCG: 0.023531 HR: 0.023531
Top-5 Recall: 0.071474 Precision: 0.014295 NDCG: 0.048098 HR: 0.071474
Top-10 Recall: 0.098150 Precision: 0.009815 NDCG: 0.056711 HR: 0.098150
Eval costs: 0.993429 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 473810.250000 (60239.865570, 413570.376709) in 4.11s 
Iter 2...	Training loss: 375404.500000 (45327.945076, 330076.567383) in 3.91s 
Iter 3...	Training loss: 333938.906250 (32665.202827, 301273.695312) in 3.95s 
Iter 4...	Training loss: 307722.875000 (22973.488161, 284749.382324) in 4.00s 
Iter 5...	Training loss: 288054.218750 (16500.510229, 271553.729004) in 3.92s 
Top-1 Recall: 0.008179 Precision: 0.008179 NDCG: 0.008179 HR: 0.008179
Top-5 Recall: 0.020511 Precision: 0.004102 NDCG: 0.014445 HR: 0.020511
Top-10 Recall: 0.028690 Precision: 0.002869 NDCG: 0.017081 HR: 0.028690
Eval costs: 0.959650 s
Iter 6...	Training loss: 271700.406250 (12274.381027, 259426.029297) in 3.89s 
Iter 7...	Training loss: 256951.390625 (9384.942598, 247566.432373) in 3.92s 
Iter 8...	Training loss: 242841.062500 (7319.075108, 235521.994141) in 3.87s 
Iter 9...	Training loss: 228165.281250 (5816.419853, 222348.853516) in 4.00s 
Iter 10...	Training loss: 212413.000000 (4660.694519, 207752.298340) in 3.94s 
Top-1 Recall: 0.014093 Precision: 0.014093 NDCG: 0.014093 HR: 0.014093
Top-5 Recall: 0.040518 Precision: 0.008104 NDCG: 0.027247 HR: 0.040518
Top-10 Recall: 0.058890 Precision: 0.005889 NDCG: 0.033137 HR: 0.058890
Eval costs: 0.909606 s
Iter 11...	Training loss: 194622.734375 (3769.374405, 190853.343262) in 4.00s 
Iter 12...	Training loss: 174735.359375 (3066.904708, 171668.452759) in 3.92s 
Iter 13...	Training loss: 153683.500000 (2551.675220, 151131.822876) in 3.94s 
Iter 14...	Training loss: 132247.140625 (2226.909835, 130020.233398) in 3.98s 
Iter 15...	Training loss: 111989.593750 (2057.717183, 109931.874146) in 3.89s 
Top-1 Recall: 0.023153 Precision: 0.023153 NDCG: 0.023153 HR: 0.023153
Top-5 Recall: 0.068957 Precision: 0.013791 NDCG: 0.046185 HR: 0.068957
Top-10 Recall: 0.096389 Precision: 0.009639 NDCG: 0.055050 HR: 0.096389
Eval costs: 0.942609 s
Iter 16...	Training loss: 90641.898438 (0.000000, 90641.899292) in 3.56s 
Iter 17...	Training loss: 81196.804688 (3648.334602, 77548.469910) in 4.23s 
Iter 18...	Training loss: 66872.843750 (2178.316753, 64694.527374) in 3.88s 
Iter 19...	Training loss: 52476.257812 (0.000000, 52476.261414) in 3.55s 
Iter 20...	Training loss: 50836.687500 (3951.101964, 46885.584351) in 4.23s 
Top-1 Recall: 0.026299 Precision: 0.026299 NDCG: 0.026299 HR: 0.026299
Top-5 Recall: 0.079275 Precision: 0.015855 NDCG: 0.053661 HR: 0.079275
Top-10 Recall: 0.112495 Precision: 0.011250 NDCG: 0.064414 HR: 0.112495
Eval costs: 0.964987 s
Iter 21...	Training loss: 42125.703125 (2479.285569, 39646.416809) in 3.88s 
Iter 22...	Training loss: 36882.328125 (2523.658319, 34358.670120) in 3.97s 
Iter 23...	Training loss: 32452.031250 (2577.162180, 29874.867493) in 3.89s 
Iter 24...	Training loss: 28860.171875 (2635.315753, 26224.854935) in 3.90s 
Iter 25...	Training loss: 25776.058594 (2704.989301, 23071.068924) in 3.97s 
Top-1 Recall: 0.026425 Precision: 0.026425 NDCG: 0.026425 HR: 0.026425
Top-5 Recall: 0.081037 Precision: 0.016207 NDCG: 0.053911 HR: 0.081037
Top-10 Recall: 0.116522 Precision: 0.011652 NDCG: 0.065302 HR: 0.116522
Eval costs: 0.976216 s
Iter 26...	Training loss: 19358.107422 (0.000000, 19358.108315) in 3.57s 
Iter 27...	Training loss: 23733.714844 (4771.617038, 18962.098000) in 4.24s 
Iter 28...	Training loss: 19769.236328 (2961.945485, 16807.290276) in 3.89s 
Iter 29...	Training loss: 18104.953125 (2987.728076, 15117.226219) in 3.89s 
Iter 30...	Training loss: 16847.251953 (3019.025928, 13828.226006) in 3.96s 
Top-1 Recall: 0.025418 Precision: 0.025418 NDCG: 0.025418 HR: 0.025418
Top-5 Recall: 0.079904 Precision: 0.015981 NDCG: 0.052979 HR: 0.079904
Top-10 Recall: 0.115012 Precision: 0.011501 NDCG: 0.064258 HR: 0.115012
Eval costs: 0.983579 s
Iter 31...	Training loss: 15533.382812 (3066.762694, 12466.620216) in 3.87s 
Iter 32...	Training loss: 14629.474609 (3107.468619, 11522.005951) in 3.95s 
Iter 33...	Training loss: 13897.385742 (3156.482764, 10740.903389) in 3.88s 
Iter 34...	Training loss: 13188.452148 (3192.086273, 9996.366592) in 3.91s 
Iter 35...	Training loss: 12472.384766 (3231.907640, 9240.476330) in 3.91s 
Top-1 Recall: 0.025041 Precision: 0.025041 NDCG: 0.025041 HR: 0.025041
Top-5 Recall: 0.077765 Precision: 0.015553 NDCG: 0.051985 HR: 0.077765
Top-10 Recall: 0.110859 Precision: 0.011086 NDCG: 0.062709 HR: 0.110859
Eval costs: 1.076919 s
Iter 36...	Training loss: 11984.212891 (3272.019622, 8712.192669) in 3.93s 
Iter 37...	Training loss: 11326.503906 (3312.263489, 8014.241314) in 3.92s 
Iter 38...	Training loss: 10739.066406 (3346.800456, 7392.265945) in 3.97s 
Iter 39...	Training loss: 10543.937500 (3381.199090, 7162.738632) in 3.90s 
Iter 40...	Training loss: 6408.699219 (0.000000, 6408.699589) in 3.61s 
Top-1 Recall: 0.026173 Precision: 0.026173 NDCG: 0.026173 HR: 0.026173
Top-5 Recall: 0.080408 Precision: 0.016082 NDCG: 0.053761 HR: 0.080408
Top-10 Recall: 0.114634 Precision: 0.011463 NDCG: 0.064814 HR: 0.114634
Eval costs: 0.992383 s
Iter 41...	Training loss: 12705.237305 (5943.328396, 6761.909325) in 4.27s 
Iter 42...	Training loss: 9576.158203 (3526.342813, 6049.815411) in 3.93s 
Iter 43...	Training loss: 9166.103516 (3520.414351, 5645.688816) in 3.93s 
Iter 44...	Training loss: 8964.420898 (3541.146341, 5423.274179) in 3.89s 
Iter 45...	Training loss: 8671.955078 (3562.115242, 5109.839720) in 3.92s 
Top-1 Recall: 0.027683 Precision: 0.027683 NDCG: 0.027683 HR: 0.027683
Top-5 Recall: 0.077891 Precision: 0.015578 NDCG: 0.053705 HR: 0.077891
Top-10 Recall: 0.110482 Precision: 0.011048 NDCG: 0.064197 HR: 0.110482
Eval costs: 1.076909 s
Iter 46...	Training loss: 8518.041992 (3575.420759, 4942.621269) in 3.91s 
Iter 47...	Training loss: 8295.369141 (3590.220439, 4705.148592) in 3.89s 
Iter 48...	Training loss: 8030.148438 (3607.476985, 4422.671694) in 3.89s 
Iter 49...	Training loss: 7778.429199 (3614.381470, 4164.047771) in 3.98s 
Iter 50...	Training loss: 7823.499512 (3634.242139, 4189.257627) in 3.94s 
Top-1 Recall: 0.028313 Precision: 0.028313 NDCG: 0.028313 HR: 0.028313
Top-5 Recall: 0.078394 Precision: 0.015679 NDCG: 0.053953 HR: 0.078394
Top-10 Recall: 0.107965 Precision: 0.010797 NDCG: 0.063438 HR: 0.107965
Eval costs: 0.992244 s
Iter 51...	Training loss: 7504.178711 (3653.876713, 3850.302250) in 3.99s 
Iter 52...	Training loss: 7341.963867 (3668.495796, 3673.468193) in 3.91s 
Iter 53...	Training loss: 7256.496582 (3683.107209, 3573.389065) in 3.91s 
Iter 54...	Training loss: 7154.897949 (3698.772316, 3456.125811) in 3.98s 
Iter 55...	Training loss: 7085.880371 (3710.635450, 3375.244930) in 3.91s 
Top-1 Recall: 0.028564 Precision: 0.028564 NDCG: 0.028564 HR: 0.028564
Top-5 Recall: 0.078646 Precision: 0.015729 NDCG: 0.054063 HR: 0.078646
Top-10 Recall: 0.107588 Precision: 0.010759 NDCG: 0.063397 HR: 0.107588
Eval costs: 0.991821 s
Iter 56...	Training loss: 2983.364746 (0.000000, 2983.365031) in 3.60s 
Iter 57...	Training loss: 9994.959961 (6564.840308, 3430.118917) in 4.23s 
Iter 58...	Training loss: 6843.591797 (3783.479783, 3060.112304) in 3.88s 
Iter 59...	Training loss: 6699.145508 (3764.336143, 2934.809596) in 3.94s 
Iter 60...	Training loss: 6557.390137 (3761.279313, 2796.110780) in 3.89s 
Top-1 Recall: 0.028690 Precision: 0.028690 NDCG: 0.028690 HR: 0.028690
Top-5 Recall: 0.076759 Precision: 0.015352 NDCG: 0.053569 HR: 0.076759
Top-10 Recall: 0.107965 Precision: 0.010797 NDCG: 0.063607 HR: 0.107965
Eval costs: 0.994371 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1498010.000000 (60185.485374, 1437824.413086) in 4.09s 
Iter 2...	Training loss: 803937.625000 (44720.083038, 759217.532715) in 3.89s 
Iter 3...	Training loss: 583044.500000 (28463.159374, 554581.354736) in 3.90s 
Iter 4...	Training loss: 460778.468750 (15824.520367, 444953.916748) in 4.02s 
Iter 5...	Training loss: 379423.656250 (9303.876087, 370119.788574) in 4.23s 
Top-1 Recall: 0.006040 Precision: 0.006040 NDCG: 0.006040 HR: 0.006040
Top-5 Recall: 0.020385 Precision: 0.004077 NDCG: 0.013444 HR: 0.020385
Top-10 Recall: 0.031333 Precision: 0.003133 NDCG: 0.016936 HR: 0.031333
Eval costs: 0.876441 s
Iter 6...	Training loss: 326980.062500 (6264.002975, 320716.088623) in 4.03s 
Iter 7...	Training loss: 291986.562500 (4716.253398, 287270.324219) in 3.93s 
Iter 8...	Training loss: 266743.406250 (3831.040186, 262912.383911) in 3.88s 
Iter 9...	Training loss: 246103.625000 (3228.658840, 242874.981934) in 3.99s 
Iter 10...	Training loss: 227742.296875 (2754.120295, 224988.175537) in 3.92s 
Top-1 Recall: 0.013590 Precision: 0.013590 NDCG: 0.013590 HR: 0.013590
Top-5 Recall: 0.037121 Precision: 0.007424 NDCG: 0.025768 HR: 0.037121
Top-10 Recall: 0.057632 Precision: 0.005763 NDCG: 0.032374 HR: 0.057632
Eval costs: 0.892200 s
Iter 11...	Training loss: 209897.515625 (2359.959299, 207537.558105) in 3.97s 
Iter 12...	Training loss: 192238.265625 (2037.554652, 190200.708252) in 3.87s 
Iter 13...	Training loss: 175108.953125 (1782.676685, 173326.281616) in 3.91s 
Iter 14...	Training loss: 159030.796875 (1585.681924, 157445.118164) in 3.93s 
Iter 15...	Training loss: 143413.296875 (1441.614472, 141971.687073) in 3.87s 
Top-1 Recall: 0.020133 Precision: 0.020133 NDCG: 0.020133 HR: 0.020133
Top-5 Recall: 0.057254 Precision: 0.011451 NDCG: 0.039014 HR: 0.057254
Top-10 Recall: 0.081414 Precision: 0.008141 NDCG: 0.046730 HR: 0.081414
Eval costs: 0.921816 s
Iter 16...	Training loss: 129194.250000 (1333.074393, 127861.180481) in 3.95s 
Iter 17...	Training loss: 115741.210938 (1260.672112, 114480.540039) in 3.86s 
Iter 18...	Training loss: 103770.117188 (1209.820872, 102560.298401) in 3.87s 
Iter 19...	Training loss: 92976.796875 (1171.164460, 91805.631897) in 3.88s 
Iter 20...	Training loss: 83033.406250 (1146.473840, 81886.926880) in 3.94s 
Top-1 Recall: 0.023783 Precision: 0.023783 NDCG: 0.023783 HR: 0.023783
Top-5 Recall: 0.064427 Precision: 0.012885 NDCG: 0.044380 HR: 0.064427
Top-10 Recall: 0.096514 Precision: 0.009651 NDCG: 0.054682 HR: 0.096514
Eval costs: 0.947285 s
Iter 21...	Training loss: 74418.960938 (1129.927239, 73289.032043) in 3.87s 
Iter 22...	Training loss: 66720.890625 (1115.336454, 65605.555115) in 3.99s 
Iter 23...	Training loss: 59653.316406 (1101.315322, 58552.004944) in 3.90s 
Iter 24...	Training loss: 53708.722656 (1092.179185, 52616.542908) in 3.87s 
Iter 25...	Training loss: 48231.367188 (1084.175283, 47147.194305) in 3.96s 
Top-1 Recall: 0.021895 Precision: 0.021895 NDCG: 0.021895 HR: 0.021895
Top-5 Recall: 0.071851 Precision: 0.014370 NDCG: 0.047325 HR: 0.071851
Top-10 Recall: 0.105700 Precision: 0.010570 NDCG: 0.058173 HR: 0.105700
Eval costs: 0.964675 s
Iter 26...	Training loss: 43403.511719 (1075.155967, 42328.359833) in 3.89s 
Iter 27...	Training loss: 35260.406250 (0.000000, 35260.406525) in 3.58s 
Iter 28...	Training loss: 38640.839844 (1992.413569, 36648.429092) in 4.26s 
Iter 29...	Training loss: 32826.691406 (1079.517756, 31747.174759) in 3.93s 
Iter 30...	Training loss: 29751.119141 (1048.942910, 28702.174591) in 3.92s 
Top-1 Recall: 0.023028 Precision: 0.023028 NDCG: 0.023028 HR: 0.023028
Top-5 Recall: 0.077262 Precision: 0.015452 NDCG: 0.051127 HR: 0.077262
Top-10 Recall: 0.109475 Precision: 0.010948 NDCG: 0.061498 HR: 0.109475
Eval costs: 0.976460 s
Iter 31...	Training loss: 27112.941406 (1032.082046, 26080.860138) in 3.88s 
Iter 32...	Training loss: 24774.810547 (1016.453039, 23758.357178) in 3.93s 
Iter 33...	Training loss: 19812.908203 (0.000000, 19812.910751) in 3.59s 
Iter 34...	Training loss: 24001.765625 (1861.812080, 22139.956116) in 4.21s 
Iter 35...	Training loss: 19886.541016 (1001.067723, 18885.474121) in 3.94s 
Top-1 Recall: 0.024663 Precision: 0.024663 NDCG: 0.024663 HR: 0.024663
Top-5 Recall: 0.080282 Precision: 0.016056 NDCG: 0.053079 HR: 0.080282
Top-10 Recall: 0.112369 Precision: 0.011237 NDCG: 0.063452 HR: 0.112369
Eval costs: 1.067327 s
Iter 36...	Training loss: 18274.707031 (975.431210, 17299.277039) in 3.90s 
Iter 37...	Training loss: 17058.812500 (956.687010, 16102.126678) in 3.92s 
Iter 38...	Training loss: 16116.169922 (940.504453, 15175.665802) in 4.02s 
Iter 39...	Training loss: 15113.517578 (925.979111, 14187.538269) in 3.89s 
Iter 40...	Training loss: 14193.320312 (916.551581, 13276.768959) in 3.89s 
Top-1 Recall: 0.024286 Precision: 0.024286 NDCG: 0.024286 HR: 0.024286
Top-5 Recall: 0.079275 Precision: 0.015855 NDCG: 0.052761 HR: 0.079275
Top-10 Recall: 0.110482 Precision: 0.011048 NDCG: 0.062837 HR: 0.110482
Eval costs: 1.074322 s
Iter 41...	Training loss: 13428.550781 (903.946330, 12524.603561) in 3.90s 
Iter 42...	Training loss: 12802.136719 (892.808592, 11909.328297) in 3.89s 
Iter 43...	Training loss: 9631.236328 (0.000000, 9631.236965) in 3.57s 
Iter 44...	Training loss: 14153.291016 (1643.396827, 12509.894695) in 4.21s 
Iter 45...	Training loss: 11656.621094 (877.050006, 10779.570789) in 3.88s 
Top-1 Recall: 0.025670 Precision: 0.025670 NDCG: 0.025670 HR: 0.025670
Top-5 Recall: 0.080408 Precision: 0.016082 NDCG: 0.054223 HR: 0.080408
Top-10 Recall: 0.112873 Precision: 0.011287 NDCG: 0.064703 HR: 0.112873
Eval costs: 0.994756 s
Iter 46...	Training loss: 10772.297852 (853.200969, 9919.095936) in 3.99s 
Iter 47...	Training loss: 10276.286133 (837.443611, 9438.843113) in 3.87s 
Iter 48...	Training loss: 9868.113281 (824.782111, 9043.330780) in 3.88s 
Iter 49...	Training loss: 9382.471680 (814.466042, 8568.006035) in 3.97s 
Iter 50...	Training loss: 9142.565430 (802.494696, 8340.070942) in 3.89s 
Top-1 Recall: 0.025922 Precision: 0.025922 NDCG: 0.025922 HR: 0.025922
Top-5 Recall: 0.079401 Precision: 0.015880 NDCG: 0.053571 HR: 0.079401
Top-10 Recall: 0.112118 Precision: 0.011212 NDCG: 0.064171 HR: 0.112118
Eval costs: 0.997374 s
Iter 51...	Training loss: 8840.715820 (790.552271, 8050.163406) in 3.94s 
Iter 52...	Training loss: 8714.924805 (780.487935, 7934.437088) in 3.91s 
Iter 53...	Training loss: 8286.214844 (770.037661, 7516.177452) in 3.91s 
Iter 54...	Training loss: 8126.457520 (760.537994, 7365.919262) in 3.94s 
Iter 55...	Training loss: 8012.073242 (751.623453, 7260.450016) in 3.86s 
Top-1 Recall: 0.026803 Precision: 0.026803 NDCG: 0.026803 HR: 0.026803
Top-5 Recall: 0.078520 Precision: 0.015704 NDCG: 0.053464 HR: 0.078520
Top-10 Recall: 0.110734 Precision: 0.011073 NDCG: 0.063919 HR: 0.110734
Eval costs: 0.993356 s
Iter 56...	Training loss: 7761.472168 (741.737267, 7019.734776) in 3.93s 
Iter 57...	Training loss: 7614.708008 (733.349895, 6881.357891) in 3.89s 
Iter 58...	Training loss: 7396.120605 (725.437443, 6670.683369) in 3.93s 
Iter 59...	Training loss: 7320.761230 (716.307266, 6604.454449) in 3.94s 
Iter 60...	Training loss: 7104.297852 (707.568277, 6396.729576) in 3.88s 
Top-1 Recall: 0.027180 Precision: 0.027180 NDCG: 0.027180 HR: 0.027180
Top-5 Recall: 0.080408 Precision: 0.016082 NDCG: 0.054452 HR: 0.080408
Top-10 Recall: 0.110734 Precision: 0.011073 NDCG: 0.064187 HR: 0.110734
Eval costs: 0.996604 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 409621.156250 (109193.954306, 300427.192383) in 7.09s 
Iter 2...	Training loss: 296179.406250 (14158.526672, 282020.828857) in 6.88s 
Iter 3...	Training loss: 280483.250000 (8381.508439, 272101.737061) in 6.87s 
Iter 4...	Training loss: 269895.031250 (6002.423001, 263892.546143) in 7.01s 
Iter 5...	Training loss: 261029.296875 (4686.099397, 256343.212036) in 6.87s 
Top-1 Recall: 0.004656 Precision: 0.004656 NDCG: 0.004656 HR: 0.004656
Top-5 Recall: 0.017491 Precision: 0.003498 NDCG: 0.011026 HR: 0.017491
Top-10 Recall: 0.025544 Precision: 0.002554 NDCG: 0.013599 HR: 0.025544
Eval costs: 0.878628 s
Iter 6...	Training loss: 252550.156250 (3852.110424, 248698.070312) in 7.04s 
Iter 7...	Training loss: 243610.046875 (3272.518460, 240337.534058) in 6.88s 
Iter 8...	Training loss: 233559.359375 (2860.706041, 230698.649902) in 6.88s 
Iter 9...	Training loss: 221925.796875 (2551.454418, 219374.340088) in 6.90s 
Iter 10...	Training loss: 207873.000000 (2326.717489, 205546.286865) in 6.96s 
Top-1 Recall: 0.010570 Precision: 0.010570 NDCG: 0.010570 HR: 0.010570
Top-5 Recall: 0.028313 Precision: 0.005663 NDCG: 0.019431 HR: 0.028313
Top-10 Recall: 0.040141 Precision: 0.004014 NDCG: 0.023256 HR: 0.040141
Eval costs: 0.921792 s
Iter 11...	Training loss: 190702.203125 (2158.501134, 188543.688965) in 6.86s 
Iter 12...	Training loss: 170211.609375 (2028.493375, 168183.124756) in 7.02s 
Iter 13...	Training loss: 147403.484375 (1928.241977, 145475.233887) in 6.88s 
Iter 14...	Training loss: 124321.835938 (1859.622683, 122462.202820) in 6.92s 
Iter 15...	Training loss: 102902.320312 (1802.645667, 101099.667969) in 6.92s 
Top-1 Recall: 0.020637 Precision: 0.020637 NDCG: 0.020637 HR: 0.020637
Top-5 Recall: 0.055241 Precision: 0.011048 NDCG: 0.038336 HR: 0.055241
Top-10 Recall: 0.079024 Precision: 0.007902 NDCG: 0.046019 HR: 0.079024
Eval costs: 0.956355 s
Iter 16...	Training loss: 85060.828125 (1761.655908, 83299.180603) in 6.86s 
Iter 17...	Training loss: 69826.375000 (1734.775500, 68091.604523) in 6.91s 
Iter 18...	Training loss: 57745.437500 (1707.125799, 56038.310333) in 7.04s 
Iter 19...	Training loss: 48598.308594 (1692.269338, 46906.039581) in 6.91s 
Iter 20...	Training loss: 41113.464844 (1679.891788, 39433.571350) in 6.89s 
Top-1 Recall: 0.023783 Precision: 0.023783 NDCG: 0.023783 HR: 0.023783
Top-5 Recall: 0.065182 Precision: 0.013036 NDCG: 0.044762 HR: 0.065182
Top-10 Recall: 0.092739 Precision: 0.009274 NDCG: 0.053678 HR: 0.092739
Eval costs: 0.972315 s
Iter 21...	Training loss: 35440.386719 (1672.044846, 33768.338425) in 6.88s 
Iter 22...	Training loss: 30886.681641 (1667.305794, 29219.371201) in 6.92s 
Iter 23...	Training loss: 27213.761719 (1661.350092, 25552.411697) in 6.91s 
Iter 24...	Training loss: 24052.404297 (1658.978584, 22393.423065) in 7.03s 
Iter 25...	Training loss: 21484.128906 (1659.031621, 19825.099884) in 6.89s 
Top-1 Recall: 0.023028 Precision: 0.023028 NDCG: 0.023028 HR: 0.023028
Top-5 Recall: 0.065308 Precision: 0.013062 NDCG: 0.044605 HR: 0.065308
Top-10 Recall: 0.095130 Precision: 0.009513 NDCG: 0.054240 HR: 0.095130
Eval costs: 0.981770 s
Iter 26...	Training loss: 19328.164062 (1658.728894, 17669.435349) in 6.89s 
Iter 27...	Training loss: 17634.861328 (1658.701312, 15976.160004) in 6.88s 
Iter 28...	Training loss: 16094.378906 (1659.770140, 14434.607689) in 6.93s 
Iter 29...	Training loss: 14878.968750 (1661.719508, 13217.248955) in 6.88s 
Iter 30...	Training loss: 13881.049805 (1665.694601, 12215.353043) in 7.02s 
Top-1 Recall: 0.024286 Precision: 0.024286 NDCG: 0.024286 HR: 0.024286
Top-5 Recall: 0.067699 Precision: 0.013540 NDCG: 0.046235 HR: 0.067699
Top-10 Recall: 0.097521 Precision: 0.009752 NDCG: 0.055879 HR: 0.097521
Eval costs: 0.987613 s
Iter 31...	Training loss: 10864.678711 (0.000000, 10864.676903) in 4.22s 
Iter 32...	Training loss: 13702.849609 (3254.837168, 10448.012833) in 9.66s 
Iter 33...	Training loss: 11146.615234 (1646.556017, 9500.059296) in 6.89s 
Iter 34...	Training loss: 10452.166016 (1668.177221, 8783.988766) in 6.91s 
Iter 35...	Training loss: 9950.267578 (1677.539867, 8272.726849) in 6.89s 
Top-1 Recall: 0.023908 Precision: 0.023908 NDCG: 0.023908 HR: 0.023908
Top-5 Recall: 0.071977 Precision: 0.014395 NDCG: 0.048290 HR: 0.071977
Top-10 Recall: 0.097395 Precision: 0.009740 NDCG: 0.056511 HR: 0.097395
Eval costs: 1.130129 s
Iter 36...	Training loss: 9378.341797 (1687.997073, 7690.344826) in 6.91s 
Iter 37...	Training loss: 7026.244629 (0.000000, 7026.245220) in 4.13s 
Iter 38...	Training loss: 10015.111328 (3298.678658, 6716.432949) in 9.63s 
Iter 39...	Training loss: 8046.936035 (1669.310727, 6377.625420) in 6.85s 
Iter 40...	Training loss: 7666.264648 (1693.139397, 5973.125786) in 6.85s 
Top-1 Recall: 0.024034 Precision: 0.024034 NDCG: 0.024034 HR: 0.024034
Top-5 Recall: 0.071474 Precision: 0.014295 NDCG: 0.048018 HR: 0.071474
Top-10 Recall: 0.100667 Precision: 0.010067 NDCG: 0.057349 HR: 0.100667
Eval costs: 1.133659 s
Iter 41...	Training loss: 7384.710938 (1703.770766, 5680.940346) in 6.89s 
Iter 42...	Training loss: 7108.549316 (1711.597779, 5396.951593) in 6.87s 
Iter 43...	Training loss: 6854.700195 (1715.448203, 5139.252449) in 6.89s 
Iter 44...	Training loss: 6646.478516 (1719.064403, 4927.414154) in 6.90s 
Iter 45...	Training loss: 6491.430664 (1719.799962, 4771.630066) in 6.89s 
Top-1 Recall: 0.024915 Precision: 0.024915 NDCG: 0.024915 HR: 0.024915
Top-5 Recall: 0.071725 Precision: 0.014345 NDCG: 0.048772 HR: 0.071725
Top-10 Recall: 0.098276 Precision: 0.009828 NDCG: 0.057380 HR: 0.098276
Eval costs: 1.137484 s
Iter 46...	Training loss: 6286.441895 (1722.553144, 4563.888895) in 6.86s 
Iter 47...	Training loss: 5991.939941 (1720.088920, 4271.851429) in 6.89s 
Iter 48...	Training loss: 5837.981445 (1725.091891, 4112.889601) in 6.88s 
Iter 49...	Training loss: 5694.273438 (1727.306458, 3966.966927) in 6.86s 
Iter 50...	Training loss: 5519.750488 (1730.497528, 3789.252827) in 6.91s 
Top-1 Recall: 0.025670 Precision: 0.025670 NDCG: 0.025670 HR: 0.025670
Top-5 Recall: 0.070593 Precision: 0.014119 NDCG: 0.048633 HR: 0.070593
Top-10 Recall: 0.098905 Precision: 0.009891 NDCG: 0.057735 HR: 0.098905
Eval costs: 1.131730 s
Iter 51...	Training loss: 5433.569336 (1731.700379, 3701.869169) in 6.85s 
Iter 52...	Training loss: 5236.858398 (1732.393733, 3504.465002) in 6.90s 
Iter 53...	Training loss: 5228.530273 (1733.448360, 3495.081833) in 6.86s 
Iter 54...	Training loss: 5018.190430 (1735.862314, 3282.328594) in 6.87s 
Iter 55...	Training loss: 4960.587891 (1735.635554, 3224.952070) in 6.89s 
Top-1 Recall: 0.026299 Precision: 0.026299 NDCG: 0.026299 HR: 0.026299
Top-5 Recall: 0.070719 Precision: 0.014144 NDCG: 0.048808 HR: 0.070719
Top-10 Recall: 0.098276 Precision: 0.009828 NDCG: 0.057703 HR: 0.098276
Eval costs: 1.134528 s
Iter 56...	Training loss: 4820.119141 (1736.595718, 3083.523335) in 6.90s 
Iter 57...	Training loss: 4642.309570 (1738.755467, 2903.554448) in 6.88s 
Iter 58...	Training loss: 4539.365234 (1739.792938, 2799.572074) in 6.87s 
Iter 59...	Training loss: 4559.848633 (1743.141447, 2816.706905) in 6.88s 
Iter 60...	Training loss: 4464.304199 (1742.017916, 2722.286524) in 6.87s 
Top-1 Recall: 0.024538 Precision: 0.024538 NDCG: 0.024538 HR: 0.024538
Top-5 Recall: 0.071096 Precision: 0.014219 NDCG: 0.048466 HR: 0.071096
Top-10 Recall: 0.098779 Precision: 0.009878 NDCG: 0.057424 HR: 0.098779
Eval costs: 0.995303 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 448267.875000 (108752.981174, 339514.870361) in 6.98s 
Iter 2...	Training loss: 325523.687500 (14166.423043, 311357.264160) in 7.00s 
Iter 3...	Training loss: 304334.218750 (8290.868803, 296043.350830) in 6.87s 
Iter 4...	Training loss: 289743.843750 (5827.217276, 283916.685547) in 6.87s 
Iter 5...	Training loss: 277449.656250 (4488.628308, 272960.997681) in 6.87s 
Top-1 Recall: 0.005033 Precision: 0.005033 NDCG: 0.005033 HR: 0.005033
Top-5 Recall: 0.017617 Precision: 0.003523 NDCG: 0.011548 HR: 0.017617
Top-10 Recall: 0.026928 Precision: 0.002693 NDCG: 0.014560 HR: 0.026928
Eval costs: 1.038782 s
Iter 6...	Training loss: 265933.000000 (3645.403334, 262287.601562) in 6.86s 
Iter 7...	Training loss: 254139.859375 (3077.466131, 251062.395386) in 6.85s 
Iter 8...	Training loss: 241463.984375 (2689.917746, 238774.057617) in 6.89s 
Iter 9...	Training loss: 227070.281250 (2400.036080, 224670.236328) in 6.89s 
Iter 10...	Training loss: 210167.375000 (2183.159750, 207984.229614) in 6.88s 
Top-1 Recall: 0.013338 Precision: 0.013338 NDCG: 0.013338 HR: 0.013338
Top-5 Recall: 0.036114 Precision: 0.007223 NDCG: 0.024825 HR: 0.036114
Top-10 Recall: 0.050459 Precision: 0.005046 NDCG: 0.029477 HR: 0.050459
Eval costs: 1.079717 s
Iter 11...	Training loss: 189837.281250 (2025.655937, 187811.612427) in 6.83s 
Iter 12...	Training loss: 166713.156250 (1902.259995, 164810.873657) in 6.85s 
Iter 13...	Training loss: 142046.812500 (1808.736663, 140238.066101) in 6.84s 
Iter 14...	Training loss: 118501.593750 (1741.306208, 116760.296387) in 6.87s 
Iter 15...	Training loss: 97767.843750 (1685.812359, 96082.040222) in 6.85s 
Top-1 Recall: 0.023531 Precision: 0.023531 NDCG: 0.023531 HR: 0.023531
Top-5 Recall: 0.067321 Precision: 0.013464 NDCG: 0.045659 HR: 0.067321
Top-10 Recall: 0.093369 Precision: 0.009337 NDCG: 0.054045 HR: 0.093369
Eval costs: 1.108372 s
Iter 16...	Training loss: 80228.570312 (1648.226558, 78580.343750) in 7.03s 
Iter 17...	Training loss: 66559.117188 (1621.021226, 64938.090149) in 6.83s 
Iter 18...	Training loss: 55901.890625 (1596.385432, 54305.502991) in 6.85s 
Iter 19...	Training loss: 47414.171875 (1579.294876, 45834.871033) in 6.85s 
Iter 20...	Training loss: 40441.738281 (1567.365878, 38874.369202) in 6.85s 
Top-1 Recall: 0.027306 Precision: 0.027306 NDCG: 0.027306 HR: 0.027306
Top-5 Recall: 0.076004 Precision: 0.015201 NDCG: 0.052122 HR: 0.076004
Top-10 Recall: 0.103939 Precision: 0.010394 NDCG: 0.061145 HR: 0.103939
Eval costs: 1.125900 s
Iter 21...	Training loss: 35426.511719 (1559.758737, 33866.751770) in 6.84s 
Iter 22...	Training loss: 31183.009766 (1551.605377, 29631.407913) in 6.93s 
Iter 23...	Training loss: 27551.982422 (1547.312719, 26004.669510) in 6.86s 
Iter 24...	Training loss: 24887.554688 (1545.617778, 23341.933899) in 6.84s 
Iter 25...	Training loss: 22365.373047 (1541.579058, 20823.795120) in 6.86s 
Top-1 Recall: 0.026425 Precision: 0.026425 NDCG: 0.026425 HR: 0.026425
Top-5 Recall: 0.077388 Precision: 0.015478 NDCG: 0.052528 HR: 0.077388
Top-10 Recall: 0.107210 Precision: 0.010721 NDCG: 0.062108 HR: 0.107210
Eval costs: 1.132135 s
Iter 26...	Training loss: 20506.187500 (1538.324859, 18967.860535) in 6.87s 
Iter 27...	Training loss: 18935.458984 (1537.597857, 17397.859497) in 6.89s 
Iter 28...	Training loss: 17376.060547 (1537.896632, 15838.163574) in 6.84s 
Iter 29...	Training loss: 16217.043945 (1536.885850, 14680.157135) in 6.87s 
Iter 30...	Training loss: 15259.649414 (1534.402221, 13725.246796) in 6.84s 
Top-1 Recall: 0.025796 Precision: 0.025796 NDCG: 0.025796 HR: 0.025796
Top-5 Recall: 0.075374 Precision: 0.015075 NDCG: 0.051482 HR: 0.075374
Top-10 Recall: 0.107839 Precision: 0.010784 NDCG: 0.061899 HR: 0.107839
Eval costs: 0.999177 s
Iter 31...	Training loss: 14044.283203 (1533.703362, 12510.579506) in 7.00s 
Iter 32...	Training loss: 13456.322266 (1533.948759, 11922.373169) in 6.86s 
Iter 33...	Training loss: 12648.499023 (1531.721382, 11116.776596) in 6.85s 
Iter 34...	Training loss: 12119.610352 (1533.287476, 10586.322632) in 6.85s 
Iter 35...	Training loss: 11363.516602 (1528.406036, 9835.111851) in 6.90s 
Top-1 Recall: 0.025293 Precision: 0.025293 NDCG: 0.025293 HR: 0.025293
Top-5 Recall: 0.075374 Precision: 0.015075 NDCG: 0.050757 HR: 0.075374
Top-10 Recall: 0.106329 Precision: 0.010633 NDCG: 0.060799 HR: 0.106329
Eval costs: 1.002227 s
Iter 36...	Training loss: 10866.901367 (1530.431002, 9336.470535) in 7.01s 
Iter 37...	Training loss: 10287.179688 (1530.695597, 8756.483627) in 6.86s 
Iter 38...	Training loss: 9926.041016 (1526.883359, 8399.159039) in 6.86s 
Iter 39...	Training loss: 9403.519531 (1524.748528, 7878.770298) in 6.87s 
Iter 40...	Training loss: 9124.732422 (1522.214013, 7602.519089) in 6.89s 
Top-1 Recall: 0.025418 Precision: 0.025418 NDCG: 0.025418 HR: 0.025418
Top-5 Recall: 0.076004 Precision: 0.015201 NDCG: 0.051248 HR: 0.076004
Top-10 Recall: 0.106581 Precision: 0.010658 NDCG: 0.061050 HR: 0.106581
Eval costs: 1.005098 s
Iter 41...	Training loss: 8729.907227 (1519.085910, 7210.821739) in 6.85s 
Iter 42...	Training loss: 8338.181641 (1516.773617, 6821.407539) in 7.00s 
Iter 43...	Training loss: 8106.456055 (1512.311699, 6594.144375) in 6.91s 
Iter 44...	Training loss: 7782.932617 (1508.112438, 6274.820374) in 6.88s 
Iter 45...	Training loss: 7593.846680 (1505.783505, 6088.063269) in 6.87s 
Top-1 Recall: 0.026173 Precision: 0.026173 NDCG: 0.026173 HR: 0.026173
Top-5 Recall: 0.076633 Precision: 0.015327 NDCG: 0.052260 HR: 0.076633
Top-10 Recall: 0.106959 Precision: 0.010696 NDCG: 0.062036 HR: 0.106959
Eval costs: 1.006608 s
Iter 46...	Training loss: 7273.083008 (1503.239311, 5769.843937) in 6.86s 
Iter 47...	Training loss: 7085.080078 (1501.138973, 5583.941404) in 6.87s 
Iter 48...	Training loss: 6841.367676 (1493.008116, 5348.359182) in 7.00s 
Iter 49...	Training loss: 6639.301270 (1490.639923, 5148.661089) in 6.92s 
Iter 50...	Training loss: 6494.319336 (1484.934549, 5009.384447) in 6.91s 
Top-1 Recall: 0.025670 Precision: 0.025670 NDCG: 0.025670 HR: 0.025670
Top-5 Recall: 0.078646 Precision: 0.015729 NDCG: 0.052657 HR: 0.078646
Top-10 Recall: 0.107965 Precision: 0.010797 NDCG: 0.062085 HR: 0.107965
Eval costs: 1.008045 s
Iter 51...	Training loss: 6322.669434 (1480.326438, 4842.343269) in 6.89s 
Iter 52...	Training loss: 6045.527344 (1476.755750, 4568.771193) in 6.89s 
Iter 53...	Training loss: 5935.626953 (1470.471805, 4465.155239) in 7.02s 
Iter 54...	Training loss: 5802.106445 (1467.122656, 4334.984222) in 6.87s 
Iter 55...	Training loss: 5589.586426 (1462.110046, 4127.477024) in 6.87s 
Top-1 Recall: 0.026299 Precision: 0.026299 NDCG: 0.026299 HR: 0.026299
Top-5 Recall: 0.075374 Precision: 0.015075 NDCG: 0.051587 HR: 0.075374
Top-10 Recall: 0.104945 Precision: 0.010495 NDCG: 0.061162 HR: 0.104945
Eval costs: 1.006999 s
Iter 56...	Training loss: 5460.397949 (1454.754208, 4005.643261) in 6.87s 
Iter 57...	Training loss: 5283.572266 (1451.525893, 3832.046848) in 6.88s 
Iter 58...	Training loss: 5261.381348 (1447.641460, 3813.739738) in 6.88s 
Iter 59...	Training loss: 5135.890625 (1440.754743, 3695.135969) in 7.04s 
Iter 60...	Training loss: 5035.667480 (1434.742750, 3600.924631) in 6.86s 
Top-1 Recall: 0.027935 Precision: 0.027935 NDCG: 0.027935 HR: 0.027935
Top-5 Recall: 0.074619 Precision: 0.014924 NDCG: 0.051888 HR: 0.074619
Top-10 Recall: 0.104442 Precision: 0.010444 NDCG: 0.061484 HR: 0.104442
Eval costs: 1.005100 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 797208.000000 (108864.570441, 688343.434082) in 7.13s 
Iter 2...	Training loss: 536141.312500 (13889.928405, 522251.423828) in 6.88s 
Iter 3...	Training loss: 443922.812500 (7656.835280, 436265.996094) in 6.88s 
Iter 4...	Training loss: 385629.875000 (5083.566436, 380546.374756) in 7.02s 
Iter 5...	Training loss: 342569.843750 (3769.322229, 338800.559570) in 6.89s 
Top-1 Recall: 0.004404 Precision: 0.004404 NDCG: 0.004404 HR: 0.004404
Top-5 Recall: 0.016484 Precision: 0.003297 NDCG: 0.010752 HR: 0.016484
Top-10 Recall: 0.025796 Precision: 0.002580 NDCG: 0.013779 HR: 0.025796
Eval costs: 0.889768 s
Iter 6...	Training loss: 308242.000000 (3002.882349, 305239.125000) in 6.89s 
Iter 7...	Training loss: 279249.250000 (2512.652898, 276736.583008) in 7.01s 
Iter 8...	Training loss: 252736.781250 (2172.465020, 250564.329956) in 6.87s 
Iter 9...	Training loss: 227150.859375 (1936.213913, 225214.649170) in 6.90s 
Iter 10...	Training loss: 202088.312500 (1757.363976, 200330.942261) in 6.90s 
Top-1 Recall: 0.019504 Precision: 0.019504 NDCG: 0.019504 HR: 0.019504
Top-5 Recall: 0.059142 Precision: 0.011828 NDCG: 0.039617 HR: 0.059142
Top-10 Recall: 0.082924 Precision: 0.008292 NDCG: 0.047230 HR: 0.082924
Eval costs: 0.932030 s
Iter 11...	Training loss: 177835.734375 (1623.303773, 176212.430542) in 6.88s 
Iter 12...	Training loss: 155249.781250 (1519.131576, 153730.662598) in 7.05s 
Iter 13...	Training loss: 134789.859375 (1438.832810, 133351.038513) in 6.91s 
Iter 14...	Training loss: 116347.703125 (1377.660992, 114970.039673) in 6.88s 
Iter 15...	Training loss: 100245.320312 (1327.947373, 98917.372742) in 6.90s 
Top-1 Recall: 0.027935 Precision: 0.027935 NDCG: 0.027935 HR: 0.027935
Top-5 Recall: 0.083931 Precision: 0.016786 NDCG: 0.056485 HR: 0.083931
Top-10 Recall: 0.118409 Precision: 0.011841 NDCG: 0.067546 HR: 0.118409
Eval costs: 0.957258 s
Iter 16...	Training loss: 85864.609375 (1289.299551, 84575.312317) in 6.91s 
Iter 17...	Training loss: 73774.515625 (1256.858896, 72517.653442) in 6.88s 
Iter 18...	Training loss: 63486.824219 (1230.738021, 62256.082520) in 7.03s 
Iter 19...	Training loss: 55088.117188 (1209.658556, 53878.457672) in 6.89s 
Iter 20...	Training loss: 47953.707031 (1192.515594, 46761.192719) in 6.88s 
Top-1 Recall: 0.031836 Precision: 0.031836 NDCG: 0.031836 HR: 0.031836
Top-5 Recall: 0.090600 Precision: 0.018120 NDCG: 0.061136 HR: 0.090600
Top-10 Recall: 0.127469 Precision: 0.012747 NDCG: 0.073080 HR: 0.127469
Eval costs: 0.970869 s
Iter 21...	Training loss: 42127.917969 (1175.476811, 40952.441223) in 6.90s 
Iter 22...	Training loss: 37268.585938 (1159.516248, 36109.070343) in 6.88s 
Iter 23...	Training loss: 33198.960938 (1147.368983, 32051.593307) in 6.89s 
Iter 24...	Training loss: 29900.578125 (1135.370124, 28765.208832) in 7.04s 
Iter 25...	Training loss: 26893.716797 (1124.160672, 25769.554230) in 6.89s 
Top-1 Recall: 0.032717 Precision: 0.032717 NDCG: 0.032717 HR: 0.032717
Top-5 Recall: 0.089342 Precision: 0.017868 NDCG: 0.060906 HR: 0.089342
Top-10 Recall: 0.126211 Precision: 0.012621 NDCG: 0.072754 HR: 0.126211
Eval costs: 0.982561 s
Iter 26...	Training loss: 24514.976562 (1112.464162, 23402.515198) in 6.90s 
Iter 27...	Training loss: 22434.544922 (1100.133366, 21334.411354) in 6.87s 
Iter 28...	Training loss: 20683.410156 (1088.930403, 19594.479118) in 6.87s 
Iter 29...	Training loss: 19219.544922 (1079.179451, 18140.363853) in 7.04s 
Iter 30...	Training loss: 17844.914062 (1070.227489, 16774.687363) in 6.87s 
Top-1 Recall: 0.031333 Precision: 0.031333 NDCG: 0.031333 HR: 0.031333
Top-5 Recall: 0.090097 Precision: 0.018019 NDCG: 0.060810 HR: 0.090097
Top-10 Recall: 0.127218 Precision: 0.012722 NDCG: 0.072754 HR: 0.127218
Eval costs: 0.987173 s
Iter 31...	Training loss: 16746.556641 (1059.468576, 15687.088364) in 6.89s 
Iter 32...	Training loss: 15643.732422 (1049.294448, 14594.437111) in 6.89s 
Iter 33...	Training loss: 14534.755859 (1039.252491, 13495.501503) in 6.89s 
Iter 34...	Training loss: 13933.267578 (1029.878941, 12903.386436) in 6.93s 
Iter 35...	Training loss: 13354.610352 (1020.546656, 12334.064705) in 7.03s 
Top-1 Recall: 0.032465 Precision: 0.032465 NDCG: 0.032465 HR: 0.032465
Top-5 Recall: 0.087958 Precision: 0.017592 NDCG: 0.060498 HR: 0.087958
Top-10 Recall: 0.126085 Precision: 0.012609 NDCG: 0.072811 HR: 0.126085
Eval costs: 0.990088 s
Iter 36...	Training loss: 12551.308594 (1010.666411, 11540.641209) in 6.90s 
Iter 37...	Training loss: 12020.110352 (1001.177486, 11018.932823) in 6.88s 
Iter 38...	Training loss: 11364.166016 (992.521190, 10371.644070) in 6.88s 
Iter 39...	Training loss: 10819.198242 (985.382502, 9833.816082) in 6.91s 
Iter 40...	Training loss: 10450.452148 (974.519384, 9475.934021) in 6.91s 
Top-1 Recall: 0.032339 Precision: 0.032339 NDCG: 0.032339 HR: 0.032339
Top-5 Recall: 0.086825 Precision: 0.017365 NDCG: 0.060078 HR: 0.086825
Top-10 Recall: 0.125834 Precision: 0.012583 NDCG: 0.072751 HR: 0.125834
Eval costs: 1.132184 s
Iter 41...	Training loss: 10139.404297 (965.435707, 9173.968822) in 6.86s 
Iter 42...	Training loss: 9745.430664 (958.338718, 8787.091106) in 6.86s 
Iter 43...	Training loss: 9371.447266 (949.980397, 8421.467773) in 6.86s 
Iter 44...	Training loss: 8971.342773 (942.768696, 8028.573746) in 6.88s 
Iter 45...	Training loss: 8642.741211 (933.798821, 7708.942793) in 6.88s 
Top-1 Recall: 0.032465 Precision: 0.032465 NDCG: 0.032465 HR: 0.032465
Top-5 Recall: 0.087706 Precision: 0.017541 NDCG: 0.060410 HR: 0.087706
Top-10 Recall: 0.120800 Precision: 0.012080 NDCG: 0.071139 HR: 0.120800
Eval costs: 1.149825 s
Iter 46...	Training loss: 8456.770508 (927.015793, 7529.754789) in 6.86s 
Iter 47...	Training loss: 8127.545898 (920.225146, 7207.320194) in 6.89s 
Iter 48...	Training loss: 7940.334473 (913.481056, 7026.853851) in 6.88s 
Iter 49...	Training loss: 7708.051270 (906.487394, 6801.563669) in 6.88s 
Iter 50...	Training loss: 7561.161133 (899.900592, 6661.260563) in 6.89s 
Top-1 Recall: 0.031962 Precision: 0.031962 NDCG: 0.031962 HR: 0.031962
Top-5 Recall: 0.086825 Precision: 0.017365 NDCG: 0.059905 HR: 0.086825
Top-10 Recall: 0.122310 Precision: 0.012231 NDCG: 0.071225 HR: 0.122310
Eval costs: 1.136844 s
Iter 51...	Training loss: 7386.730469 (895.013176, 6491.717102) in 6.87s 
Iter 52...	Training loss: 7161.842285 (888.749836, 6273.092106) in 6.86s 
Iter 53...	Training loss: 6957.726562 (882.542971, 6075.183310) in 6.89s 
Iter 54...	Training loss: 6800.212891 (875.976556, 5924.236423) in 6.89s 
Iter 55...	Training loss: 6788.254395 (870.172834, 5918.081867) in 6.87s 
Top-1 Recall: 0.031333 Precision: 0.031333 NDCG: 0.031333 HR: 0.031333
Top-5 Recall: 0.081792 Precision: 0.016358 NDCG: 0.057143 HR: 0.081792
Top-10 Recall: 0.117780 Precision: 0.011778 NDCG: 0.068805 HR: 0.117780
Eval costs: 1.132223 s
Iter 56...	Training loss: 6590.849121 (865.453698, 5725.395807) in 6.86s 
Iter 57...	Training loss: 6448.208984 (859.977664, 5588.231615) in 6.87s 
Iter 58...	Training loss: 6333.334473 (854.769875, 5478.565222) in 6.87s 
Iter 59...	Training loss: 6211.549316 (850.085332, 5361.463966) in 6.89s 
Iter 60...	Training loss: 6081.770508 (844.679882, 5237.091503) in 6.88s 
Top-1 Recall: 0.030452 Precision: 0.030452 NDCG: 0.030452 HR: 0.030452
Top-5 Recall: 0.084183 Precision: 0.016837 NDCG: 0.057803 HR: 0.084183
Top-10 Recall: 0.117151 Precision: 0.011715 NDCG: 0.068508 HR: 0.117151
Eval costs: 0.995348 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 4108697.250000 (108815.954694, 3999881.074219) in 6.99s 
Iter 2...	Training loss: 2427713.000000 (13600.515007, 2414112.438477) in 6.98s 
Iter 3...	Training loss: 1676079.875000 (6973.619800, 1669106.121094) in 6.88s 
Iter 4...	Training loss: 1225862.625000 (4411.825884, 1221450.728516) in 6.87s 
Iter 5...	Training loss: 916152.625000 (3170.936856, 912981.714355) in 6.85s 
Top-1 Recall: 0.001258 Precision: 0.001258 NDCG: 0.001258 HR: 0.001258
Top-5 Recall: 0.005663 Precision: 0.001133 NDCG: 0.003582 HR: 0.005663
Top-10 Recall: 0.007802 Precision: 0.000780 NDCG: 0.004287 HR: 0.007802
Eval costs: 1.032022 s
Iter 6...	Training loss: 698282.750000 (2461.671087, 695821.139648) in 6.86s 
Iter 7...	Training loss: 543573.937500 (2017.385876, 541556.540039) in 6.88s 
Iter 8...	Training loss: 434707.250000 (1717.743453, 432989.471191) in 6.90s 
Iter 9...	Training loss: 359074.093750 (1506.285133, 357567.830322) in 6.88s 
Iter 10...	Training loss: 302588.187500 (1349.166061, 301239.076050) in 6.86s 
Top-1 Recall: 0.011954 Precision: 0.011954 NDCG: 0.011954 HR: 0.011954
Top-5 Recall: 0.037498 Precision: 0.007500 NDCG: 0.024991 HR: 0.037498
Top-10 Recall: 0.055744 Precision: 0.005574 NDCG: 0.030862 HR: 0.055744
Eval costs: 1.069948 s
Iter 11...	Training loss: 260155.171875 (1230.437246, 258924.712280) in 6.88s 
Iter 12...	Training loss: 227803.734375 (1136.478720, 226667.248291) in 6.87s 
Iter 13...	Training loss: 202595.953125 (1058.225964, 201537.730957) in 6.85s 
Iter 14...	Training loss: 181928.156250 (998.458189, 180929.698364) in 6.84s 
Iter 15...	Training loss: 165410.687500 (947.753948, 164462.946899) in 6.86s 
Top-1 Recall: 0.024789 Precision: 0.024789 NDCG: 0.024789 HR: 0.024789
Top-5 Recall: 0.066188 Precision: 0.013238 NDCG: 0.045612 HR: 0.066188
Top-10 Recall: 0.096514 Precision: 0.009651 NDCG: 0.055389 HR: 0.096514
Eval costs: 1.092284 s
Iter 16...	Training loss: 151467.984375 (905.309381, 150562.674622) in 6.85s 
Iter 17...	Training loss: 139368.765625 (868.983184, 138499.777893) in 6.88s 
Iter 18...	Training loss: 128598.429688 (837.779107, 127760.643005) in 6.87s 
Iter 19...	Training loss: 118917.078125 (812.467807, 118104.620605) in 6.85s 
Iter 20...	Training loss: 110391.976562 (789.052956, 109602.911621) in 6.87s 
Top-1 Recall: 0.030703 Precision: 0.030703 NDCG: 0.030703 HR: 0.030703
Top-5 Recall: 0.081037 Precision: 0.016207 NDCG: 0.056072 HR: 0.081037
Top-10 Recall: 0.114005 Precision: 0.011401 NDCG: 0.066662 HR: 0.114005
Eval costs: 1.106296 s
Iter 21...	Training loss: 102183.507812 (771.375579, 101412.124084) in 6.88s 
Iter 22...	Training loss: 94848.226562 (753.019713, 94095.218811) in 6.86s 
Iter 23...	Training loss: 87727.023438 (737.456375, 86989.561432) in 6.85s 
Iter 24...	Training loss: 81475.156250 (725.810767, 80749.338165) in 6.82s 
Iter 25...	Training loss: 75393.554688 (713.532913, 74680.014587) in 6.89s 
Top-1 Recall: 0.031962 Precision: 0.031962 NDCG: 0.031962 HR: 0.031962
Top-5 Recall: 0.084560 Precision: 0.016912 NDCG: 0.058854 HR: 0.084560
Top-10 Recall: 0.117529 Precision: 0.011753 NDCG: 0.069466 HR: 0.117529
Eval costs: 1.117766 s
Iter 26...	Training loss: 69603.140625 (702.151841, 68900.988678) in 6.86s 
Iter 27...	Training loss: 64610.589844 (693.749650, 63916.842926) in 6.87s 
Iter 28...	Training loss: 60199.003906 (684.401236, 59514.601898) in 6.86s 
Iter 29...	Training loss: 56158.718750 (676.638980, 55482.078125) in 6.85s 
Iter 30...	Training loss: 52206.398438 (668.658029, 51537.738007) in 6.84s 
Top-1 Recall: 0.032213 Precision: 0.032213 NDCG: 0.032213 HR: 0.032213
Top-5 Recall: 0.085944 Precision: 0.017189 NDCG: 0.059389 HR: 0.085944
Top-10 Recall: 0.120045 Precision: 0.012005 NDCG: 0.070366 HR: 0.120045
Eval costs: 0.990205 s
Iter 31...	Training loss: 48746.164062 (662.443580, 48083.719040) in 7.02s 
Iter 32...	Training loss: 45968.839844 (656.764944, 45312.072266) in 6.90s 
Iter 33...	Training loss: 43353.222656 (650.329926, 42702.893753) in 6.88s 
Iter 34...	Training loss: 40990.089844 (644.200235, 40345.889633) in 6.89s 
Iter 35...	Training loss: 38761.890625 (639.617696, 38122.275482) in 6.89s 
Top-1 Recall: 0.030829 Precision: 0.030829 NDCG: 0.030829 HR: 0.030829
Top-5 Recall: 0.083931 Precision: 0.016786 NDCG: 0.057936 HR: 0.083931
Top-10 Recall: 0.120171 Precision: 0.012017 NDCG: 0.069637 HR: 0.120171
Eval costs: 0.995677 s
Iter 36...	Training loss: 36983.648438 (634.901728, 36348.748505) in 7.00s 
Iter 37...	Training loss: 35521.746094 (630.586888, 34891.158089) in 6.85s 
Iter 38...	Training loss: 34104.109375 (626.411557, 33477.697182) in 6.88s 
Iter 39...	Training loss: 32407.548828 (622.641418, 31784.907822) in 6.86s 
Iter 40...	Training loss: 31434.998047 (618.854302, 30816.145348) in 6.85s 
Top-1 Recall: 0.030326 Precision: 0.030326 NDCG: 0.030326 HR: 0.030326
Top-5 Recall: 0.084057 Precision: 0.016811 NDCG: 0.057787 HR: 0.084057
Top-10 Recall: 0.119164 Precision: 0.011916 NDCG: 0.069105 HR: 0.119164
Eval costs: 1.000235 s
Iter 41...	Training loss: 30320.630859 (614.311051, 29706.318352) in 6.87s 
Iter 42...	Training loss: 29651.289062 (611.556431, 29039.731018) in 7.01s 
Iter 43...	Training loss: 28825.718750 (608.819529, 28216.898178) in 6.85s 
Iter 44...	Training loss: 27868.888672 (605.316088, 27263.573189) in 6.90s 
Iter 45...	Training loss: 27265.880859 (602.610629, 26663.270004) in 6.88s 
Top-1 Recall: 0.030703 Precision: 0.030703 NDCG: 0.030703 HR: 0.030703
Top-5 Recall: 0.085693 Precision: 0.017139 NDCG: 0.058268 HR: 0.085693
Top-10 Recall: 0.119794 Precision: 0.011979 NDCG: 0.069246 HR: 0.119794
Eval costs: 1.003385 s
Iter 46...	Training loss: 26647.494141 (599.204306, 26048.289635) in 6.91s 
Iter 47...	Training loss: 25929.679688 (596.145645, 25333.535049) in 6.85s 
Iter 48...	Training loss: 25625.068359 (593.270008, 25031.799416) in 7.01s 
Iter 49...	Training loss: 25206.687500 (590.844703, 24615.842506) in 6.89s 
Iter 50...	Training loss: 24617.888672 (588.240749, 24029.646427) in 6.92s 
Top-1 Recall: 0.030200 Precision: 0.030200 NDCG: 0.030200 HR: 0.030200
Top-5 Recall: 0.084183 Precision: 0.016837 NDCG: 0.057492 HR: 0.084183
Top-10 Recall: 0.117403 Precision: 0.011740 NDCG: 0.068274 HR: 0.117403
Eval costs: 1.005980 s
Iter 51...	Training loss: 24475.265625 (586.375674, 23888.890781) in 6.86s 
Iter 52...	Training loss: 24133.630859 (583.991486, 23549.639431) in 6.88s 
Iter 53...	Training loss: 23701.986328 (582.332257, 23119.655949) in 7.00s 
Iter 54...	Training loss: 23386.490234 (578.363798, 22808.129112) in 6.86s 
Iter 55...	Training loss: 23111.126953 (577.732819, 22533.394966) in 6.88s 
Top-1 Recall: 0.029697 Precision: 0.029697 NDCG: 0.029697 HR: 0.029697
Top-5 Recall: 0.082044 Precision: 0.016409 NDCG: 0.056188 HR: 0.082044
Top-10 Recall: 0.117277 Precision: 0.011728 NDCG: 0.067538 HR: 0.117277
Eval costs: 1.005754 s
Iter 56...	Training loss: 22766.244141 (574.916641, 22191.331390) in 6.88s 
Iter 57...	Training loss: 22747.242188 (574.098310, 22173.144768) in 6.89s 
Iter 58...	Training loss: 22498.525391 (572.267671, 21926.255760) in 6.86s 
Iter 59...	Training loss: 22310.935547 (569.826202, 21741.109451) in 7.02s 
Iter 60...	Training loss: 22075.019531 (567.979732, 21507.043034) in 6.90s 
Top-1 Recall: 0.028061 Precision: 0.028061 NDCG: 0.028061 HR: 0.028061
Top-5 Recall: 0.080408 Precision: 0.016082 NDCG: 0.055068 HR: 0.080408
Top-10 Recall: 0.115893 Precision: 0.011589 NDCG: 0.066510 HR: 0.115893
Eval costs: 1.007943 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 471024.750000 (60198.299271, 109024.008345, 301802.441406) in 7.53s 
Iter 2...	Training loss: 342576.656250 (45627.286560, 14217.023603, 282732.344482) in 7.35s 
Iter 3...	Training loss: 315688.093750 (34656.012981, 8398.094845, 272633.997559) in 7.25s 
Iter 4...	Training loss: 297354.218750 (27002.292671, 5993.675876, 264358.244995) in 7.36s 
Iter 5...	Training loss: 283404.375000 (21978.582378, 4678.954879, 256746.822632) in 7.23s 
Top-1 Recall: 0.003775 Precision: 0.003775 NDCG: 0.003775 HR: 0.003775
Top-5 Recall: 0.017113 Precision: 0.003423 NDCG: 0.010612 HR: 0.017113
Top-10 Recall: 0.025293 Precision: 0.002529 NDCG: 0.013252 HR: 0.025293
Eval costs: 1.016791 s
Iter 6...	Training loss: 271190.750000 (18305.665737, 3841.880580, 249043.174072) in 7.20s 
Iter 7...	Training loss: 259331.750000 (15298.762363, 3273.488295, 240759.527222) in 7.22s 
Iter 8...	Training loss: 246684.625000 (12700.597755, 2859.239029, 231124.797607) in 7.35s 
Iter 9...	Training loss: 232704.343750 (10409.169811, 2552.447528, 219742.743164) in 7.20s 
Iter 10...	Training loss: 216596.468750 (8399.276724, 2323.388044, 205873.790771) in 7.35s 
Top-1 Recall: 0.009438 Precision: 0.009438 NDCG: 0.009438 HR: 0.009438
Top-5 Recall: 0.028438 Precision: 0.005688 NDCG: 0.019121 HR: 0.028438
Top-10 Recall: 0.039134 Precision: 0.003913 NDCG: 0.022566 HR: 0.039134
Eval costs: 0.919558 s
Iter 11...	Training loss: 191276.718750 (0.000000, 2156.124786, 189120.554810) in 6.90s 
Iter 12...	Training loss: 180461.750000 (9620.458278, 2027.346659, 168813.957031) in 7.69s 
Iter 13...	Training loss: 152181.546875 (4136.621996, 1927.087591, 146117.848633) in 7.23s 
Iter 14...	Training loss: 128272.242188 (3323.285325, 1857.574666, 123091.374695) in 7.23s 
Iter 15...	Training loss: 106581.210938 (2814.328917, 1804.350295, 101962.544556) in 7.36s 
Top-1 Recall: 0.020511 Precision: 0.020511 NDCG: 0.020511 HR: 0.020511
Top-5 Recall: 0.057003 Precision: 0.011401 NDCG: 0.039060 HR: 0.057003
Top-10 Recall: 0.080030 Precision: 0.008003 NDCG: 0.046461 HR: 0.080030
Eval costs: 0.955818 s
Iter 16...	Training loss: 87719.703125 (2566.076069, 1766.100302, 83387.521118) in 7.24s 
Iter 17...	Training loss: 72807.257812 (2493.061732, 1733.099199, 68581.107758) in 7.38s 
Iter 18...	Training loss: 60861.707031 (2536.595855, 1709.564364, 56615.544525) in 7.25s 
Iter 19...	Training loss: 51561.492188 (2654.250232, 1692.056327, 47215.183350) in 7.36s 
Iter 20...	Training loss: 44498.640625 (2819.485204, 1682.868203, 39996.291901) in 7.24s 
Top-1 Recall: 0.023279 Precision: 0.023279 NDCG: 0.023279 HR: 0.023279
Top-5 Recall: 0.066944 Precision: 0.013389 NDCG: 0.045591 HR: 0.066944
Top-10 Recall: 0.093494 Precision: 0.009349 NDCG: 0.054144 HR: 0.093494
Eval costs: 0.972901 s
Iter 21...	Training loss: 38528.671875 (3008.946498, 1675.226944, 33844.493088) in 7.41s 
Iter 22...	Training loss: 34196.750000 (3210.150025, 1668.838341, 29317.763489) in 7.25s 
Iter 23...	Training loss: 30678.136719 (3412.919196, 1664.305740, 25600.913925) in 7.22s 
Iter 24...	Training loss: 27768.457031 (3623.499694, 1658.966358, 22485.989990) in 7.38s 
Iter 25...	Training loss: 25301.132812 (3835.748646, 1660.565306, 19804.818924) in 7.23s 
Top-1 Recall: 0.024915 Precision: 0.024915 NDCG: 0.024915 HR: 0.024915
Top-5 Recall: 0.068328 Precision: 0.013666 NDCG: 0.046914 HR: 0.068328
Top-10 Recall: 0.097269 Precision: 0.009727 NDCG: 0.056187 HR: 0.097269
Eval costs: 0.980510 s
Iter 26...	Training loss: 23487.943359 (4051.627509, 1658.727652, 17777.587448) in 7.38s 
Iter 27...	Training loss: 22012.478516 (4257.321256, 1659.898443, 16095.258148) in 7.22s 
Iter 28...	Training loss: 20786.546875 (4470.039746, 1661.206173, 14655.299553) in 7.36s 
Iter 29...	Training loss: 19535.960938 (4691.550405, 1665.348314, 13179.062920) in 7.22s 
Iter 30...	Training loss: 18764.355469 (4893.174417, 1667.711581, 12203.468712) in 7.21s 
Top-1 Recall: 0.024789 Precision: 0.024789 NDCG: 0.024789 HR: 0.024789
Top-5 Recall: 0.070593 Precision: 0.014119 NDCG: 0.048006 HR: 0.070593
Top-10 Recall: 0.095634 Precision: 0.009563 NDCG: 0.056104 HR: 0.095634
Eval costs: 1.126548 s
Iter 31...	Training loss: 12759.300781 (0.000000, 1669.170149, 11090.131386) in 6.95s 
Iter 32...	Training loss: 20568.910156 (8668.237648, 1672.036627, 10228.633919) in 7.52s 
Iter 33...	Training loss: 16678.878906 (5487.886404, 1675.511258, 9515.480762) in 7.38s 
Iter 34...	Training loss: 16159.718750 (5663.862927, 1679.294439, 8816.561745) in 7.22s 
Iter 35...	Training loss: 15732.367188 (5856.278795, 1684.978018, 8191.110786) in 7.22s 
Top-1 Recall: 0.024663 Precision: 0.024663 NDCG: 0.024663 HR: 0.024663
Top-5 Recall: 0.070844 Precision: 0.014169 NDCG: 0.047918 HR: 0.070844
Top-10 Recall: 0.094627 Precision: 0.009463 NDCG: 0.055555 HR: 0.094627
Eval costs: 1.137151 s
Iter 36...	Training loss: 15437.712891 (6052.239911, 1689.350082, 7696.123230) in 7.19s 
Iter 37...	Training loss: 15138.243164 (6230.384962, 1692.428799, 7215.428997) in 7.39s 
Iter 38...	Training loss: 14886.791992 (6419.025141, 1696.658746, 6771.107822) in 7.20s 
Iter 39...	Training loss: 14795.222656 (6618.445303, 1699.970636, 6476.807098) in 7.23s 
Iter 40...	Training loss: 14636.812500 (6800.433655, 1700.911725, 6135.466564) in 7.35s 
Top-1 Recall: 0.025167 Precision: 0.025167 NDCG: 0.025167 HR: 0.025167
Top-5 Recall: 0.069334 Precision: 0.013867 NDCG: 0.047882 HR: 0.069334
Top-10 Recall: 0.097647 Precision: 0.009765 NDCG: 0.056981 HR: 0.097647
Eval costs: 0.991858 s
Iter 41...	Training loss: 14496.333008 (6995.113657, 1705.031863, 5796.187973) in 7.24s 
Iter 42...	Training loss: 14413.777344 (7163.623168, 1707.260341, 5542.894089) in 7.36s 
Iter 43...	Training loss: 14260.460938 (7340.361874, 1710.568071, 5209.531242) in 7.21s 
Iter 44...	Training loss: 14275.062500 (7514.762753, 1710.601519, 5049.696955) in 7.35s 
Iter 45...	Training loss: 14083.203125 (7690.142725, 1714.505605, 4678.555574) in 7.22s 
Top-1 Recall: 0.025418 Precision: 0.025418 NDCG: 0.025418 HR: 0.025418
Top-5 Recall: 0.068202 Precision: 0.013640 NDCG: 0.047170 HR: 0.068202
Top-10 Recall: 0.096389 Precision: 0.009639 NDCG: 0.056257 HR: 0.096389
Eval costs: 0.991984 s
Iter 46...	Training loss: 14177.655273 (7862.097326, 1718.010146, 4597.546082) in 7.38s 
Iter 47...	Training loss: 14103.093750 (8038.709982, 1720.468139, 4343.915691) in 7.23s 
Iter 48...	Training loss: 14085.148438 (8195.078118, 1724.260437, 4165.810003) in 7.23s 
Iter 49...	Training loss: 14084.682617 (8362.074030, 1725.014909, 3997.593601) in 7.38s 
Iter 50...	Training loss: 14087.368164 (8548.381383, 1728.642339, 3810.344524) in 7.23s 
Top-1 Recall: 0.024789 Precision: 0.024789 NDCG: 0.024789 HR: 0.024789
Top-5 Recall: 0.068957 Precision: 0.013791 NDCG: 0.047102 HR: 0.068957
Top-10 Recall: 0.099031 Precision: 0.009903 NDCG: 0.056767 HR: 0.099031
Eval costs: 0.991024 s
Iter 51...	Training loss: 14105.266602 (8724.034124, 1731.607237, 3649.625443) in 7.39s 
Iter 52...	Training loss: 14146.605469 (8895.050192, 1732.297740, 3519.258595) in 7.22s 
Iter 53...	Training loss: 14226.234375 (9056.129457, 1737.286501, 3432.818411) in 7.39s 
Iter 54...	Training loss: 14321.494141 (9228.474823, 1737.037685, 3355.979856) in 7.25s 
Iter 55...	Training loss: 14414.327148 (9389.546846, 1734.700603, 3290.079067) in 7.24s 
Top-1 Recall: 0.026048 Precision: 0.026048 NDCG: 0.026048 HR: 0.026048
Top-5 Recall: 0.069586 Precision: 0.013917 NDCG: 0.048092 HR: 0.069586
Top-10 Recall: 0.098905 Precision: 0.009891 NDCG: 0.057544 HR: 0.098905
Eval costs: 1.136764 s
Iter 56...	Training loss: 14367.072266 (9555.479390, 1741.145436, 3070.447320) in 7.23s 
Iter 57...	Training loss: 14563.817383 (9715.222008, 1741.135865, 3107.459482) in 7.21s 
Iter 58...	Training loss: 14562.192383 (9891.338497, 1742.418312, 2928.435819) in 7.34s 
Iter 59...	Training loss: 14619.352539 (10038.867672, 1742.753412, 2837.731494) in 7.21s 
Iter 60...	Training loss: 14775.128906 (10201.593479, 1742.976582, 2830.558483) in 7.22s 
Top-1 Recall: 0.025293 Precision: 0.025293 NDCG: 0.025293 HR: 0.025293
Top-5 Recall: 0.069712 Precision: 0.013942 NDCG: 0.047965 HR: 0.069712
Top-10 Recall: 0.098402 Precision: 0.009840 NDCG: 0.057202 HR: 0.098402
Eval costs: 1.133817 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 510241.656250 (60288.926880, 109091.195377, 340861.528809) in 7.54s 
Iter 2...	Training loss: 372152.812500 (45810.692696, 14201.574338, 312140.543945) in 7.35s 
Iter 3...	Training loss: 339439.406250 (34674.908821, 8272.617088, 296491.877441) in 7.19s 
Iter 4...	Training loss: 317106.218750 (26957.085602, 5812.928404, 284336.229492) in 7.38s 
Iter 5...	Training loss: 299570.625000 (21749.484688, 4468.465493, 273352.705933) in 7.23s 
Top-1 Recall: 0.005914 Precision: 0.005914 NDCG: 0.005914 HR: 0.005914
Top-5 Recall: 0.018749 Precision: 0.003750 NDCG: 0.012359 HR: 0.018749
Top-10 Recall: 0.025418 Precision: 0.002542 NDCG: 0.014544 HR: 0.025418
Eval costs: 1.033181 s
Iter 6...	Training loss: 284112.906250 (17806.187050, 3648.432866, 262658.250244) in 7.20s 
Iter 7...	Training loss: 269048.281250 (14533.270592, 3072.050962, 251442.952515) in 7.21s 
Iter 8...	Training loss: 241782.234375 (0.000000, 2683.974283, 239098.271973) in 6.95s 
Iter 9...	Training loss: 244930.000000 (17420.846075, 2396.030752, 225113.105835) in 7.67s 
Iter 10...	Training loss: 218183.406250 (7603.183374, 2184.152142, 208396.081665) in 7.21s 
Top-1 Recall: 0.012709 Precision: 0.012709 NDCG: 0.012709 HR: 0.012709
Top-5 Recall: 0.035863 Precision: 0.007173 NDCG: 0.024682 HR: 0.035863
Top-10 Recall: 0.052221 Precision: 0.005222 NDCG: 0.029939 HR: 0.052221
Eval costs: 1.083517 s
Iter 11...	Training loss: 196044.843750 (5911.946559, 2023.490684, 188109.408813) in 7.20s 
Iter 12...	Training loss: 171412.062500 (4556.975666, 1902.102077, 164952.959595) in 7.34s 
Iter 13...	Training loss: 145847.984375 (3577.140623, 1811.472917, 140459.368958) in 7.20s 
Iter 14...	Training loss: 121697.054688 (2963.646938, 1743.947694, 116989.463745) in 7.26s 
Iter 15...	Training loss: 100543.453125 (2670.815710, 1694.897917, 96177.729675) in 7.38s 
Top-1 Recall: 0.022273 Precision: 0.022273 NDCG: 0.022273 HR: 0.022273
Top-5 Recall: 0.067321 Precision: 0.013464 NDCG: 0.045205 HR: 0.067321
Top-10 Recall: 0.093494 Precision: 0.009349 NDCG: 0.053631 HR: 0.093494
Eval costs: 0.972903 s
Iter 16...	Training loss: 83413.398438 (2594.021420, 1656.461196, 79162.906006) in 7.22s 
Iter 17...	Training loss: 69659.875000 (2660.589098, 1621.967147, 65377.318695) in 7.40s 
Iter 18...	Training loss: 58948.523438 (2798.699951, 1605.400910, 54544.425018) in 7.27s 
Iter 19...	Training loss: 50555.410156 (2979.884661, 1585.110850, 45990.414032) in 7.38s 
Iter 20...	Training loss: 40836.265625 (0.000000, 1571.590749, 39264.670471) in 6.95s 
Top-1 Recall: 0.025796 Precision: 0.025796 NDCG: 0.025796 HR: 0.025796
Top-5 Recall: 0.074368 Precision: 0.014874 NDCG: 0.050853 HR: 0.074368
Top-10 Recall: 0.107210 Precision: 0.010721 NDCG: 0.061463 HR: 0.107210
Eval costs: 0.986395 s
Iter 21...	Training loss: 41254.035156 (5597.497862, 1563.879223, 34092.659027) in 7.67s 
Iter 22...	Training loss: 34876.128906 (3662.576862, 1556.284414, 29657.267075) in 7.22s 
Iter 23...	Training loss: 31709.875000 (3861.341556, 1549.608950, 26298.924728) in 7.22s 
Iter 24...	Training loss: 29152.457031 (4079.581217, 1545.063594, 23527.808304) in 7.37s 
Iter 25...	Training loss: 26901.933594 (4283.962765, 1542.669103, 21075.304260) in 7.24s 
Top-1 Recall: 0.026677 Precision: 0.026677 NDCG: 0.026677 HR: 0.026677
Top-5 Recall: 0.079149 Precision: 0.015830 NDCG: 0.053114 HR: 0.079149
Top-10 Recall: 0.109727 Precision: 0.010973 NDCG: 0.062902 HR: 0.109727
Eval costs: 0.996326 s
Iter 26...	Training loss: 25059.183594 (4507.746916, 1541.856658, 19009.578125) in 7.39s 
Iter 27...	Training loss: 23541.181641 (4711.330632, 1541.483338, 17288.369087) in 7.22s 
Iter 28...	Training loss: 17442.914062 (0.000000, 1541.561127, 15901.352600) in 6.91s 
Iter 29...	Training loss: 24687.781250 (8389.132149, 1541.729401, 14756.919136) in 7.67s 
Iter 30...	Training loss: 20623.070312 (5335.795115, 1540.554128, 13746.720322) in 7.25s 
Top-1 Recall: 0.026299 Precision: 0.026299 NDCG: 0.026299 HR: 0.026299
Top-5 Recall: 0.076381 Precision: 0.015276 NDCG: 0.051886 HR: 0.076381
Top-10 Recall: 0.109349 Precision: 0.010935 NDCG: 0.062558 HR: 0.109349
Eval costs: 1.141130 s
Iter 31...	Training loss: 19863.572266 (5533.663366, 1538.209469, 12791.698700) in 7.22s 
Iter 32...	Training loss: 19088.832031 (5746.894611, 1536.457801, 11805.478706) in 7.21s 
Iter 33...	Training loss: 18729.248047 (5936.903441, 1535.846547, 11256.497177) in 7.36s 
Iter 34...	Training loss: 18179.103516 (6124.914864, 1533.806962, 10520.381409) in 7.24s 
Iter 35...	Training loss: 17829.150391 (6312.396635, 1532.951529, 9983.802990) in 7.25s 
Top-1 Recall: 0.026173 Precision: 0.026173 NDCG: 0.026173 HR: 0.026173
Top-5 Recall: 0.075878 Precision: 0.015176 NDCG: 0.051253 HR: 0.075878
Top-10 Recall: 0.110482 Precision: 0.011048 NDCG: 0.062449 HR: 0.110482
Eval costs: 1.146223 s
Iter 36...	Training loss: 17305.042969 (6501.610138, 1529.290413, 9274.145103) in 7.23s 
Iter 37...	Training loss: 17061.523438 (6693.358204, 1528.099608, 8840.064804) in 7.36s 
Iter 38...	Training loss: 9878.718750 (0.000000, 1529.495729, 8349.223866) in 6.93s 
Iter 39...	Training loss: 21231.587891 (11805.760855, 1527.101010, 7898.725780) in 7.54s 
Iter 40...	Training loss: 16412.060547 (7249.493954, 1522.758585, 7639.807030) in 7.38s 
Top-1 Recall: 0.026551 Precision: 0.026551 NDCG: 0.026551 HR: 0.026551
Top-5 Recall: 0.075374 Precision: 0.015075 NDCG: 0.051176 HR: 0.075374
Top-10 Recall: 0.111740 Precision: 0.011174 NDCG: 0.062930 HR: 0.111740
Eval costs: 1.006059 s
Iter 41...	Training loss: 16375.716797 (7432.161926, 1520.036212, 7423.518032) in 7.25s 
Iter 42...	Training loss: 8495.644531 (0.000000, 1519.510298, 6976.134544) in 6.96s 
Iter 43...	Training loss: 21127.087891 (13039.724233, 1512.494827, 6574.869644) in 7.68s 
Iter 44...	Training loss: 15892.888672 (7982.100381, 1508.140948, 6402.646458) in 7.37s 
Iter 45...	Training loss: 15807.949219 (8168.702686, 1506.014179, 6133.231541) in 7.23s 
Top-1 Recall: 0.027432 Precision: 0.027432 NDCG: 0.027432 HR: 0.027432
Top-5 Recall: 0.075878 Precision: 0.015176 NDCG: 0.051587 HR: 0.075878
Top-10 Recall: 0.107965 Precision: 0.010797 NDCG: 0.061965 HR: 0.107965
Eval costs: 1.006683 s
Iter 46...	Training loss: 15813.648438 (8353.132465, 1500.994522, 5959.523014) in 7.38s 
Iter 47...	Training loss: 15685.995117 (8546.242821, 1498.146598, 5641.605429) in 7.24s 
Iter 48...	Training loss: 15665.275391 (8743.233131, 1495.721406, 5426.320160) in 7.27s 
Iter 49...	Training loss: 15665.933594 (8942.611340, 1489.323506, 5233.998648) in 7.40s 
Iter 50...	Training loss: 15671.245117 (9126.903744, 1486.822348, 5057.518343) in 7.24s 
Top-1 Recall: 0.023908 Precision: 0.023908 NDCG: 0.023908 HR: 0.023908
Top-5 Recall: 0.077639 Precision: 0.015528 NDCG: 0.051366 HR: 0.077639
Top-10 Recall: 0.107336 Precision: 0.010734 NDCG: 0.060897 HR: 0.107336
Eval costs: 1.008057 s
Iter 51...	Training loss: 15670.007812 (9307.454477, 1481.372393, 4881.181019) in 7.36s 
Iter 52...	Training loss: 15654.604492 (9481.821404, 1476.679521, 4696.103117) in 7.23s 
Iter 53...	Training loss: 15719.062500 (9662.106360, 1471.276631, 4585.679352) in 7.37s 
Iter 54...	Training loss: 5860.344727 (0.000000, 1468.229731, 4392.115017) in 6.93s 
Iter 55...	Training loss: 22786.253906 (17011.549189, 1461.067473, 4313.636635) in 7.52s 
Top-1 Recall: 0.026173 Precision: 0.026173 NDCG: 0.026173 HR: 0.026173
Top-5 Recall: 0.075752 Precision: 0.015150 NDCG: 0.051363 HR: 0.075752
Top-10 Recall: 0.106707 Precision: 0.010671 NDCG: 0.061336 HR: 0.106707
Eval costs: 1.153231 s
Iter 56...	Training loss: 15644.968750 (10172.768660, 1457.317950, 4014.883223) in 7.20s 
Iter 57...	Training loss: 5394.634766 (0.000000, 1451.775422, 3942.858801) in 6.91s 
Iter 58...	Training loss: 23214.101562 (17871.253759, 1448.433002, 3894.414133) in 7.65s 
Iter 59...	Training loss: 15860.128906 (10705.481588, 1442.279878, 3712.367408) in 7.24s 
Iter 60...	Training loss: 15963.087891 (10893.646057, 1438.636002, 3630.805653) in 7.23s 
Top-1 Recall: 0.024663 Precision: 0.024663 NDCG: 0.024663 HR: 0.024663
Top-5 Recall: 0.075249 Precision: 0.015050 NDCG: 0.050426 HR: 0.075249
Top-10 Recall: 0.104568 Precision: 0.010457 NDCG: 0.059796 HR: 0.104568
Eval costs: 1.147034 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 859075.687500 (60318.587646, 108769.842727, 689987.201660) in 7.55s 
Iter 2...	Training loss: 582590.500000 (45809.159073, 13888.247520, 522893.036621) in 7.37s 
Iter 3...	Training loss: 478581.312500 (34291.168667, 7660.359313, 436629.829102) in 7.23s 
Iter 4...	Training loss: 411665.375000 (25428.457928, 5067.334337, 381169.532227) in 7.35s 
Iter 5...	Training loss: 362046.750000 (19071.217367, 3757.290269, 339218.229248) in 7.23s 
Top-1 Recall: 0.004404 Precision: 0.004404 NDCG: 0.004404 HR: 0.004404
Top-5 Recall: 0.018623 Precision: 0.003725 NDCG: 0.011502 HR: 0.018623
Top-10 Recall: 0.026803 Precision: 0.002680 NDCG: 0.014168 HR: 0.026803
Eval costs: 1.035307 s
Iter 6...	Training loss: 323127.812500 (14694.224480, 2999.316192, 305434.265137) in 7.21s 
Iter 7...	Training loss: 290798.468750 (11246.988336, 2506.201452, 277045.288208) in 7.25s 
Iter 8...	Training loss: 261585.859375 (8529.470479, 2173.944083, 250882.436646) in 7.36s 
Iter 9...	Training loss: 233782.406250 (6379.605778, 1933.712293, 225469.098145) in 7.21s 
Iter 10...	Training loss: 207342.109375 (4809.089519, 1753.915801, 200779.117554) in 7.20s 
Top-1 Recall: 0.019378 Precision: 0.019378 NDCG: 0.019378 HR: 0.019378
Top-5 Recall: 0.057758 Precision: 0.011552 NDCG: 0.039105 HR: 0.057758
Top-10 Recall: 0.082421 Precision: 0.008242 NDCG: 0.047064 HR: 0.082421
Eval costs: 1.073254 s
Iter 11...	Training loss: 182129.765625 (3757.986029, 1616.888634, 176754.884033) in 7.25s 
Iter 12...	Training loss: 158929.828125 (3143.520027, 1515.799136, 154270.495239) in 7.36s 
Iter 13...	Training loss: 138392.718750 (2864.244557, 1436.221157, 134092.263489) in 7.24s 
Iter 14...	Training loss: 119836.507812 (2801.414646, 1375.279231, 115659.805664) in 7.23s 
Iter 15...	Training loss: 103444.898438 (2870.079591, 1328.003269, 99246.819580) in 7.34s 
Top-1 Recall: 0.029068 Precision: 0.029068 NDCG: 0.029068 HR: 0.029068
Top-5 Recall: 0.086322 Precision: 0.017264 NDCG: 0.058217 HR: 0.086322
Top-10 Recall: 0.117529 Precision: 0.011753 NDCG: 0.068262 HR: 0.117529
Eval costs: 0.960086 s
Iter 16...	Training loss: 89519.578125 (3017.279178, 1287.765807, 85214.538574) in 7.22s 
Iter 17...	Training loss: 77563.164062 (3228.472078, 1258.013967, 73076.670502) in 7.40s 
Iter 18...	Training loss: 67673.515625 (3460.181761, 1230.943224, 62982.396606) in 7.23s 
Iter 19...	Training loss: 59219.921875 (3697.788074, 1209.846456, 54312.278107) in 7.37s 
Iter 20...	Training loss: 52595.929688 (3985.477920, 1189.390551, 47421.062622) in 7.25s 
Top-1 Recall: 0.032088 Precision: 0.032088 NDCG: 0.032088 HR: 0.032088
Top-5 Recall: 0.091481 Precision: 0.018296 NDCG: 0.062002 HR: 0.091481
Top-10 Recall: 0.125456 Precision: 0.012546 NDCG: 0.072846 HR: 0.125456
Eval costs: 0.975307 s
Iter 21...	Training loss: 42556.347656 (0.000000, 1173.484447, 41382.863617) in 6.97s 
Iter 22...	Training loss: 44883.605469 (7384.927417, 1161.258333, 36337.418793) in 7.68s 
Iter 23...	Training loss: 38284.589844 (4891.869683, 1146.445968, 32246.275360) in 7.24s 
Iter 24...	Training loss: 35312.898438 (5135.744310, 1134.785822, 29042.367126) in 7.36s 
Iter 25...	Training loss: 27344.646484 (0.000000, 1121.884194, 26222.762970) in 6.93s 
Top-1 Recall: 0.030326 Precision: 0.030326 NDCG: 0.030326 HR: 0.030326
Top-5 Recall: 0.089845 Precision: 0.017969 NDCG: 0.060607 HR: 0.089845
Top-10 Recall: 0.125204 Precision: 0.012520 NDCG: 0.071981 HR: 0.125204
Eval costs: 0.983851 s
Iter 26...	Training loss: 34156.250000 (9264.217736, 1110.435977, 23781.594147) in 7.70s 
Iter 27...	Training loss: 28785.359375 (5995.233954, 1098.456563, 21691.668060) in 7.21s 
Iter 28...	Training loss: 20905.554688 (0.000000, 1089.128009, 19816.428139) in 6.93s 
Iter 29...	Training loss: 29919.781250 (10622.187597, 1078.695266, 18218.899445) in 7.68s 
Iter 30...	Training loss: 24957.492188 (6770.209303, 1067.079095, 17120.204247) in 7.25s 
Top-1 Recall: 0.030829 Precision: 0.030829 NDCG: 0.030829 HR: 0.030829
Top-5 Recall: 0.089971 Precision: 0.017994 NDCG: 0.061026 HR: 0.089971
Top-10 Recall: 0.124827 Precision: 0.012483 NDCG: 0.072204 HR: 0.124827
Eval costs: 1.133888 s
Iter 31...	Training loss: 23827.589844 (7012.271024, 1056.651376, 15758.664894) in 7.24s 
Iter 32...	Training loss: 15800.698242 (0.000000, 1047.757542, 14752.939873) in 6.92s 
Iter 33...	Training loss: 27422.542969 (12382.377957, 1038.160215, 14002.005287) in 7.69s 
Iter 34...	Training loss: 21854.115234 (7744.922174, 1027.540362, 13081.652069) in 7.28s 
Iter 35...	Training loss: 21215.359375 (7977.429565, 1018.321089, 12219.609734) in 7.25s 
Top-1 Recall: 0.033472 Precision: 0.033472 NDCG: 0.033472 HR: 0.033472
Top-5 Recall: 0.086699 Precision: 0.017340 NDCG: 0.060828 HR: 0.086699
Top-10 Recall: 0.122939 Precision: 0.012294 NDCG: 0.072505 HR: 0.122939
Eval costs: 1.131273 s
Iter 36...	Training loss: 20688.166016 (8201.761347, 1007.562830, 11478.842175) in 7.23s 
Iter 37...	Training loss: 20575.503906 (8415.660964, 999.693168, 11160.149143) in 7.36s 
Iter 38...	Training loss: 20260.490234 (8638.827591, 990.700567, 10630.962246) in 7.23s 
Iter 39...	Training loss: 19860.261719 (8873.705799, 982.062805, 10004.494919) in 7.27s 
Iter 40...	Training loss: 19695.222656 (9116.873730, 972.527347, 9605.823093) in 7.36s 
Top-1 Recall: 0.033220 Precision: 0.033220 NDCG: 0.033220 HR: 0.033220
Top-5 Recall: 0.088209 Precision: 0.017642 NDCG: 0.061310 HR: 0.088209
Top-10 Recall: 0.121933 Precision: 0.012193 NDCG: 0.072225 HR: 0.121933
Eval costs: 0.994850 s
Iter 41...	Training loss: 19467.113281 (9367.124767, 963.937257, 9136.051044) in 7.21s 
Iter 42...	Training loss: 19441.132812 (9606.600412, 957.850453, 8876.684362) in 7.41s 
Iter 43...	Training loss: 19255.044922 (9841.808844, 948.832238, 8464.404091) in 7.23s 
Iter 44...	Training loss: 19245.398438 (10080.932076, 941.493456, 8222.972725) in 7.36s 
Iter 45...	Training loss: 19140.429688 (10315.431183, 934.138493, 7890.858513) in 7.26s 
Top-1 Recall: 0.032843 Precision: 0.032843 NDCG: 0.032843 HR: 0.032843
Top-5 Recall: 0.089090 Precision: 0.017818 NDCG: 0.061549 HR: 0.089090
Top-10 Recall: 0.120549 Precision: 0.012055 NDCG: 0.071714 HR: 0.120549
Eval costs: 0.999069 s
Iter 46...	Training loss: 19171.253906 (10553.470831, 925.163021, 7692.619911) in 7.37s 
Iter 47...	Training loss: 19080.871094 (10781.075947, 919.715035, 7380.081844) in 7.21s 
Iter 48...	Training loss: 19028.839844 (11021.316441, 913.335606, 7094.185526) in 7.25s 
Iter 49...	Training loss: 7773.211426 (0.000000, 907.347798, 6865.863476) in 6.92s 
Iter 50...	Training loss: 27217.652344 (19631.019726, 899.684877, 6686.944963) in 7.70s 
Top-1 Recall: 0.033094 Precision: 0.033094 NDCG: 0.033094 HR: 0.033094
Top-5 Recall: 0.085189 Precision: 0.017038 NDCG: 0.059825 HR: 0.085189
Top-10 Recall: 0.121304 Precision: 0.012130 NDCG: 0.071414 HR: 0.121304
Eval costs: 0.993778 s
Iter 51...	Training loss: 19171.199219 (11719.945705, 893.546252, 6557.707966) in 7.38s 
Iter 52...	Training loss: 19236.296875 (11969.128880, 887.118801, 6380.050922) in 7.22s 
Iter 53...	Training loss: 19275.357422 (12200.346640, 881.357515, 6193.651880) in 7.41s 
Iter 54...	Training loss: 19431.572266 (12443.370213, 875.184691, 6113.018974) in 7.24s 
Iter 55...	Training loss: 19420.402344 (12690.893801, 870.173445, 5859.335278) in 7.23s 
Top-1 Recall: 0.033094 Precision: 0.033094 NDCG: 0.033094 HR: 0.033094
Top-5 Recall: 0.084686 Precision: 0.016937 NDCG: 0.059364 HR: 0.084686
Top-10 Recall: 0.118535 Precision: 0.011854 NDCG: 0.070288 HR: 0.118535
Eval costs: 1.136811 s
Iter 56...	Training loss: 19607.931641 (12942.270531, 864.442878, 5801.217405) in 7.23s 
Iter 57...	Training loss: 19695.345703 (13180.578341, 859.493332, 5655.273285) in 7.25s 
Iter 58...	Training loss: 19862.007812 (13437.218769, 854.016324, 5570.773127) in 7.37s 
Iter 59...	Training loss: 19905.275391 (13664.150146, 849.286099, 5391.838528) in 7.22s 
Iter 60...	Training loss: 20043.628906 (13938.732094, 843.860289, 5261.036934) in 7.21s 
Top-1 Recall: 0.032717 Precision: 0.032717 NDCG: 0.032717 HR: 0.032717
Top-5 Recall: 0.083554 Precision: 0.016711 NDCG: 0.058596 HR: 0.083554
Top-10 Recall: 0.115264 Precision: 0.011526 NDCG: 0.068804 HR: 0.115264
Eval costs: 1.155037 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 4168006.750000 (60310.070938, 109009.844566, 3998686.501953) in 7.53s 
Iter 2...	Training loss: 2473687.000000 (45722.049484, 13616.651147, 2414348.031250) in 7.41s 
Iter 3...	Training loss: 1707763.750000 (33460.706749, 6972.380659, 1667330.671875) in 7.22s 
Iter 4...	Training loss: 1249133.375000 (23008.593603, 4406.970817, 1221717.738281) in 7.38s 
Iter 5...	Training loss: 932369.687500 (15949.801235, 3168.833868, 913251.082031) in 7.24s 
Top-1 Recall: 0.001510 Precision: 0.001510 NDCG: 0.001510 HR: 0.001510
Top-5 Recall: 0.005663 Precision: 0.001133 NDCG: 0.003596 HR: 0.005663
Top-10 Recall: 0.008305 Precision: 0.000831 NDCG: 0.004453 HR: 0.008305
Eval costs: 1.038016 s
Iter 6...	Training loss: 709851.062500 (11250.105921, 2464.415983, 696136.497559) in 7.23s 
Iter 7...	Training loss: 552071.375000 (8081.806334, 2018.996092, 541970.626709) in 7.24s 
Iter 8...	Training loss: 441600.218750 (5922.181761, 1720.732115, 433957.297119) in 7.39s 
Iter 9...	Training loss: 363567.656250 (4484.128048, 1506.459451, 357577.108643) in 7.22s 
Iter 10...	Training loss: 305744.031250 (3584.100845, 1350.934035, 300809.007202) in 7.22s 
Top-1 Recall: 0.013213 Precision: 0.013213 NDCG: 0.013213 HR: 0.013213
Top-5 Recall: 0.038631 Precision: 0.007726 NDCG: 0.026199 HR: 0.038631
Top-10 Recall: 0.055241 Precision: 0.005524 NDCG: 0.031543 HR: 0.055241
Eval costs: 1.070264 s
Iter 11...	Training loss: 263628.875000 (3109.523336, 1230.312285, 259289.054199) in 7.24s 
Iter 12...	Training loss: 231054.687500 (2921.184536, 1136.799731, 226996.689087) in 7.35s 
Iter 13...	Training loss: 203235.218750 (0.000000, 1060.590348, 202174.652466) in 6.93s 
Iter 14...	Training loss: 188212.656250 (5367.243954, 996.940166, 181848.477173) in 7.58s 
Iter 15...	Training loss: 169588.625000 (3511.586416, 946.895027, 165130.155396) in 7.38s 
Top-1 Recall: 0.023028 Precision: 0.023028 NDCG: 0.023028 HR: 0.023028
Top-5 Recall: 0.068957 Precision: 0.013791 NDCG: 0.046156 HR: 0.068957
Top-10 Recall: 0.097269 Precision: 0.009727 NDCG: 0.055365 HR: 0.097269
Eval costs: 0.952295 s
Iter 16...	Training loss: 155668.062500 (3740.189803, 903.783519, 151024.101196) in 7.25s 
Iter 17...	Training loss: 144260.859375 (4030.754181, 866.835133, 139363.273254) in 7.36s 
Iter 18...	Training loss: 133492.968750 (4344.634503, 836.644786, 128311.689270) in 7.24s 
Iter 19...	Training loss: 124349.367188 (4694.153779, 810.538921, 118844.683105) in 7.38s 
Iter 20...	Training loss: 115959.625000 (5047.718155, 788.907786, 110123.006897) in 7.23s 
Top-1 Recall: 0.030452 Precision: 0.030452 NDCG: 0.030452 HR: 0.030452
Top-5 Recall: 0.079401 Precision: 0.015880 NDCG: 0.055015 HR: 0.079401
Top-10 Recall: 0.111866 Precision: 0.011187 NDCG: 0.065472 HR: 0.111866
Eval costs: 0.966831 s
Iter 21...	Training loss: 107816.468750 (5389.435750, 769.155872, 101657.885315) in 7.39s 
Iter 22...	Training loss: 100786.007812 (5745.771708, 752.386708, 94287.849792) in 7.23s 
Iter 23...	Training loss: 94379.914062 (6128.025784, 737.542773, 87514.341736) in 7.22s 
Iter 24...	Training loss: 88187.648438 (6504.526409, 724.692128, 80958.425568) in 7.38s 
Iter 25...	Training loss: 82600.640625 (6923.243752, 712.827927, 74964.565002) in 7.21s 
Top-1 Recall: 0.030452 Precision: 0.030452 NDCG: 0.030452 HR: 0.030452
Top-5 Recall: 0.083805 Precision: 0.016761 NDCG: 0.057451 HR: 0.083805
Top-10 Recall: 0.116774 Precision: 0.011677 NDCG: 0.068159 HR: 0.116774
Eval costs: 0.980382 s
Iter 26...	Training loss: 77962.015625 (7338.879500, 701.263815, 69921.878937) in 7.40s 
Iter 27...	Training loss: 73047.781250 (7715.764361, 691.342750, 64640.679901) in 7.22s 
Iter 28...	Training loss: 68807.320312 (8138.015348, 683.291995, 59986.010193) in 7.38s 
Iter 29...	Training loss: 64945.812500 (8599.292414, 675.397494, 55671.119476) in 7.24s 
Iter 30...	Training loss: 61761.031250 (9049.019375, 668.458170, 52043.550903) in 7.27s 
Top-1 Recall: 0.030452 Precision: 0.030452 NDCG: 0.030452 HR: 0.030452
Top-5 Recall: 0.084434 Precision: 0.016887 NDCG: 0.057596 HR: 0.084434
Top-10 Recall: 0.118787 Precision: 0.011879 NDCG: 0.068783 HR: 0.118787
Eval costs: 1.128530 s
Iter 31...	Training loss: 49139.968750 (0.000000, 661.069231, 48478.895721) in 6.93s 
Iter 32...	Training loss: 62929.523438 (16594.277559, 655.042597, 45680.203552) in 7.51s 
Iter 33...	Training loss: 54265.621094 (10533.316032, 649.515375, 43082.787720) in 7.36s 
Iter 34...	Training loss: 52254.125000 (10941.617872, 643.478885, 40669.026321) in 7.23s 
Iter 35...	Training loss: 50472.171875 (11327.901161, 639.016081, 38505.251709) in 7.23s 
Top-1 Recall: 0.030200 Precision: 0.030200 NDCG: 0.030200 HR: 0.030200
Top-5 Recall: 0.083554 Precision: 0.016711 NDCG: 0.056974 HR: 0.083554
Top-10 Recall: 0.122059 Precision: 0.012206 NDCG: 0.069561 HR: 0.122059
Eval costs: 1.136546 s
Iter 36...	Training loss: 48950.925781 (11758.716568, 634.725807, 36557.481445) in 7.21s 
Iter 37...	Training loss: 47840.699219 (12178.425810, 629.783593, 35032.493103) in 7.35s 
Iter 38...	Training loss: 46753.289062 (12590.358433, 625.795596, 33537.138969) in 7.24s 
Iter 39...	Training loss: 45910.753906 (13047.296223, 621.712648, 32241.746010) in 7.26s 
Iter 40...	Training loss: 45149.546875 (13447.462824, 618.539593, 31083.544632) in 7.41s 
Top-1 Recall: 0.030578 Precision: 0.030578 NDCG: 0.030578 HR: 0.030578
Top-5 Recall: 0.085567 Precision: 0.017113 NDCG: 0.057951 HR: 0.085567
Top-10 Recall: 0.122436 Precision: 0.012244 NDCG: 0.069793 HR: 0.122436
Eval costs: 1.005206 s
Iter 41...	Training loss: 44487.742188 (13861.483837, 614.740302, 30011.524185) in 7.30s 
Iter 42...	Training loss: 44167.445312 (14255.435345, 612.019371, 29299.990913) in 7.40s 
Iter 43...	Training loss: 25446.552734 (14653.326555, 0.000000, 10793.226524) in 4.48s 
Iter 44...	Training loss: 45465.328125 (15056.429432, 1295.886258, 29113.010536) in 10.18s 
Iter 45...	Training loss: 38909.289062 (15399.428629, 602.044770, 22907.814873) in 7.21s 
Top-1 Recall: 0.030452 Precision: 0.030452 NDCG: 0.030452 HR: 0.030452
Top-5 Recall: 0.085441 Precision: 0.017088 NDCG: 0.057902 HR: 0.085441
Top-10 Recall: 0.121304 Precision: 0.012130 NDCG: 0.069511 HR: 0.121304
Eval costs: 1.006577 s
Iter 46...	Training loss: 38186.109375 (15791.147840, 590.721863, 21804.237633) in 7.39s 
Iter 47...	Training loss: 41079.359375 (16199.656487, 593.124528, 24286.576469) in 7.25s 
Iter 48...	Training loss: 26287.605469 (0.000000, 595.930061, 25691.673492) in 6.95s 
Iter 49...	Training loss: 55028.031250 (29289.066433, 593.088062, 25145.872002) in 7.70s 
Iter 50...	Training loss: 42104.414062 (17446.213531, 588.436651, 24069.762745) in 7.22s 
Top-1 Recall: 0.028816 Precision: 0.028816 NDCG: 0.028816 HR: 0.028816
Top-5 Recall: 0.083554 Precision: 0.016711 NDCG: 0.056260 HR: 0.083554
Top-10 Recall: 0.120800 Precision: 0.012080 NDCG: 0.068301 HR: 0.120800
Eval costs: 1.001301 s
Iter 51...	Training loss: 41958.125000 (17845.317940, 586.226126, 23526.578571) in 7.35s 
Iter 52...	Training loss: 42252.546875 (18247.216019, 582.980932, 23422.350739) in 7.21s 
Iter 53...	Training loss: 42420.757812 (18649.882671, 581.888149, 23188.982307) in 7.38s 
Iter 54...	Training loss: 42633.984375 (19048.700771, 579.229823, 23006.047878) in 7.24s 
Iter 55...	Training loss: 42637.171875 (19449.782745, 576.910582, 22610.474644) in 7.26s 
Top-1 Recall: 0.030703 Precision: 0.030703 NDCG: 0.030703 HR: 0.030703
Top-5 Recall: 0.081666 Precision: 0.016333 NDCG: 0.055939 HR: 0.081666
Top-10 Recall: 0.119416 Precision: 0.011942 NDCG: 0.068230 HR: 0.119416
Eval costs: 1.145346 s
Iter 56...	Training loss: 42908.632812 (19825.340378, 575.023434, 22508.270008) in 7.22s 
Iter 57...	Training loss: 42827.812500 (20225.251236, 572.820317, 22029.743504) in 7.22s 
Iter 58...	Training loss: 43183.898438 (20641.386120, 571.295830, 21971.213310) in 7.37s 
Iter 59...	Training loss: 43276.101562 (21015.687214, 568.697813, 21691.717648) in 7.21s 
Iter 60...	Training loss: 43781.988281 (21426.901901, 567.279716, 21787.808083) in 7.23s 
Top-1 Recall: 0.028187 Precision: 0.028187 NDCG: 0.028187 HR: 0.028187
Top-5 Recall: 0.083050 Precision: 0.016610 NDCG: 0.055839 HR: 0.083050
Top-10 Recall: 0.116270 Precision: 0.011627 NDCG: 0.066614 HR: 0.116270
Eval costs: 1.148999 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 482379.562500 (60209.695862, 108660.941245, 313508.922119) in 7.53s 
Iter 2...	Training loss: 348579.000000 (45594.898651, 14174.615973, 288809.464600) in 7.37s 
Iter 3...	Training loss: 319527.343750 (34363.671448, 8355.245788, 276808.433838) in 7.21s 
Iter 4...	Training loss: 300222.562500 (26518.568916, 5970.526551, 267733.468506) in 7.37s 
Iter 5...	Training loss: 285564.312500 (21315.793278, 4660.406905, 259588.146240) in 7.24s 
Top-1 Recall: 0.004027 Precision: 0.004027 NDCG: 0.004027 HR: 0.004027
Top-5 Recall: 0.017113 Precision: 0.003423 NDCG: 0.010713 HR: 0.017113
Top-10 Recall: 0.025167 Precision: 0.002517 NDCG: 0.013355 HR: 0.025167
Eval costs: 1.045185 s
Iter 6...	Training loss: 273188.906250 (17584.563498, 3824.951474, 251779.396973) in 7.19s 
Iter 7...	Training loss: 261131.156250 (14596.488848, 3253.199170, 243281.439575) in 7.22s 
Iter 8...	Training loss: 248509.140625 (12031.107346, 2844.245864, 233633.786011) in 7.34s 
Iter 9...	Training loss: 234705.234375 (9829.673460, 2537.185586, 222338.375977) in 7.23s 
Iter 10...	Training loss: 218882.625000 (7949.573626, 2309.183996, 208623.874390) in 7.24s 
Top-1 Recall: 0.010948 Precision: 0.010948 NDCG: 0.010948 HR: 0.010948
Top-5 Recall: 0.028942 Precision: 0.005788 NDCG: 0.020272 HR: 0.028942
Top-10 Recall: 0.042406 Precision: 0.004241 NDCG: 0.024625 HR: 0.042406
Eval costs: 1.075710 s
Iter 11...	Training loss: 200329.515625 (6313.132729, 2148.575572, 191867.796387) in 7.24s 
Iter 12...	Training loss: 178911.312500 (4951.696921, 2014.413345, 171945.201904) in 7.38s 
Iter 13...	Training loss: 155098.593750 (3888.249345, 1922.607707, 149287.747559) in 7.21s 
Iter 14...	Training loss: 131256.328125 (3136.352278, 1852.761874, 126267.207825) in 7.21s 
Iter 15...	Training loss: 109263.289062 (2674.130213, 1797.536240, 104791.620728) in 7.37s 
Top-1 Recall: 0.021140 Precision: 0.021140 NDCG: 0.021140 HR: 0.021140
Top-5 Recall: 0.059771 Precision: 0.011954 NDCG: 0.040808 HR: 0.059771
Top-10 Recall: 0.083554 Precision: 0.008355 NDCG: 0.048548 HR: 0.083554
Eval costs: 0.962690 s
Iter 16...	Training loss: 90212.804688 (2449.654188, 1760.589039, 86002.551758) in 7.22s 
Iter 17...	Training loss: 74835.367188 (2396.785324, 1730.457315, 70708.117065) in 7.38s 
Iter 18...	Training loss: 62385.554688 (2456.917444, 1710.885739, 58217.755615) in 7.22s 
Iter 19...	Training loss: 52820.187500 (2567.902346, 1693.577101, 48558.712524) in 7.38s 
Iter 20...	Training loss: 45474.843750 (2720.121725, 1680.762110, 41073.959381) in 7.24s 
Top-1 Recall: 0.025293 Precision: 0.025293 NDCG: 0.025293 HR: 0.025293
Top-5 Recall: 0.067699 Precision: 0.013540 NDCG: 0.047022 HR: 0.067699
Top-10 Recall: 0.097647 Precision: 0.009765 NDCG: 0.056701 HR: 0.097647
Eval costs: 0.982734 s
Iter 21...	Training loss: 39800.066406 (2892.615808, 1675.354137, 35232.093414) in 7.41s 
Iter 22...	Training loss: 34760.371094 (3070.803158, 1670.192047, 30019.372421) in 7.22s 
Iter 23...	Training loss: 31085.039062 (3251.205362, 1663.946264, 26169.884827) in 7.26s 
Iter 24...	Training loss: 28365.699219 (3438.224405, 1661.295302, 23266.181427) in 7.36s 
Iter 25...	Training loss: 25538.332031 (3630.006767, 1658.365315, 20249.962234) in 7.23s 
Top-1 Recall: 0.025293 Precision: 0.025293 NDCG: 0.025293 HR: 0.025293
Top-5 Recall: 0.071222 Precision: 0.014244 NDCG: 0.048945 HR: 0.071222
Top-10 Recall: 0.099409 Precision: 0.009941 NDCG: 0.057995 HR: 0.099409
Eval costs: 0.991112 s
Iter 26...	Training loss: 23747.400391 (3805.849652, 1658.530882, 18283.019432) in 7.36s 
Iter 27...	Training loss: 22256.666016 (3989.968083, 1661.911467, 16604.786201) in 7.23s 
Iter 28...	Training loss: 20678.296875 (4174.600185, 1661.099968, 14842.595795) in 7.37s 
Iter 29...	Training loss: 19442.746094 (4350.277840, 1665.253357, 13427.213615) in 7.26s 
Iter 30...	Training loss: 18472.707031 (4518.585126, 1665.868067, 12288.254166) in 7.23s 
Top-1 Recall: 0.025796 Precision: 0.025796 NDCG: 0.025796 HR: 0.025796
Top-5 Recall: 0.071977 Precision: 0.014395 NDCG: 0.048989 HR: 0.071977
Top-10 Recall: 0.101925 Precision: 0.010193 NDCG: 0.058620 HR: 0.101925
Eval costs: 1.139256 s
Iter 31...	Training loss: 17608.644531 (4681.130677, 1666.765355, 11260.750244) in 7.22s 
Iter 32...	Training loss: 17008.322266 (4842.803681, 1670.339538, 10495.178616) in 7.20s 
Iter 33...	Training loss: 16483.519531 (5005.278185, 1674.263403, 9803.977020) in 7.37s 
Iter 34...	Training loss: 15954.081055 (5169.519944, 1680.226590, 9104.333591) in 7.22s 
Iter 35...	Training loss: 15474.829102 (5324.744517, 1683.612843, 8466.471863) in 7.21s 
Top-1 Recall: 0.025544 Precision: 0.025544 NDCG: 0.025544 HR: 0.025544
Top-5 Recall: 0.072480 Precision: 0.014496 NDCG: 0.049497 HR: 0.072480
Top-10 Recall: 0.101925 Precision: 0.010193 NDCG: 0.058975 HR: 0.101925
Eval costs: 1.143221 s
Iter 36...	Training loss: 15023.535156 (5469.502679, 1687.696583, 7866.335999) in 7.24s 
Iter 37...	Training loss: 14791.845703 (5618.014305, 1690.793683, 7483.038517) in 7.39s 
Iter 38...	Training loss: 14488.457031 (5763.759228, 1691.946937, 7032.750526) in 7.24s 
Iter 39...	Training loss: 14154.351562 (5905.565191, 1694.883942, 6553.902557) in 7.22s 
Iter 40...	Training loss: 7720.440918 (0.000000, 1699.112012, 6021.328846) in 6.93s 
Top-1 Recall: 0.025796 Precision: 0.025796 NDCG: 0.025796 HR: 0.025796
Top-5 Recall: 0.072229 Precision: 0.014446 NDCG: 0.049498 HR: 0.072229
Top-10 Recall: 0.102806 Precision: 0.010281 NDCG: 0.059416 HR: 0.102806
Eval costs: 1.144781 s
Iter 41...	Training loss: 17972.500000 (10301.497589, 1702.743641, 5968.259319) in 7.55s 
Iter 42...	Training loss: 13777.497070 (6323.258003, 1704.095829, 5750.143841) in 7.33s 
Iter 43...	Training loss: 13439.834961 (6454.609015, 1705.432351, 5279.793446) in 7.24s 
Iter 44...	Training loss: 13430.504883 (6591.691122, 1711.663767, 5127.150099) in 7.24s 
Iter 45...	Training loss: 13260.171875 (6709.350588, 1712.915375, 4837.905972) in 7.37s 
Top-1 Recall: 0.026173 Precision: 0.026173 NDCG: 0.026173 HR: 0.026173
Top-5 Recall: 0.073109 Precision: 0.014622 NDCG: 0.049841 HR: 0.073109
Top-10 Recall: 0.103058 Precision: 0.010306 NDCG: 0.059519 HR: 0.103058
Eval costs: 1.008223 s
Iter 46...	Training loss: 13160.262695 (6851.349312, 1715.847661, 4593.066339) in 7.37s 
Iter 47...	Training loss: 13208.701172 (6981.830883, 1719.259472, 4507.610785) in 7.22s 
Iter 48...	Training loss: 12970.196289 (7093.546140, 1718.269746, 4158.380684) in 7.25s 
Iter 49...	Training loss: 13045.672852 (7206.850888, 1720.238129, 4118.582422) in 7.40s 
Iter 50...	Training loss: 13099.823242 (7333.283871, 1721.206007, 4045.333282) in 7.21s 
Top-1 Recall: 0.024789 Precision: 0.024789 NDCG: 0.024789 HR: 0.024789
Top-5 Recall: 0.073361 Precision: 0.014672 NDCG: 0.049288 HR: 0.073361
Top-10 Recall: 0.100667 Precision: 0.010067 NDCG: 0.058109 HR: 0.100667
Eval costs: 1.008849 s
Iter 51...	Training loss: 12917.700195 (7451.913903, 1726.119737, 3739.667101) in 7.37s 
Iter 52...	Training loss: 12977.579102 (7568.437588, 1729.599149, 3679.542387) in 7.21s 
Iter 53...	Training loss: 12991.498047 (7681.039755, 1730.693242, 3579.765913) in 7.38s 
Iter 54...	Training loss: 13032.063477 (7808.783072, 1735.616041, 3487.663671) in 7.22s 
Iter 55...	Training loss: 13009.375000 (7929.470654, 1734.693855, 3345.210226) in 7.22s 
Top-1 Recall: 0.025796 Precision: 0.025796 NDCG: 0.025796 HR: 0.025796
Top-5 Recall: 0.072354 Precision: 0.014471 NDCG: 0.049602 HR: 0.072354
Top-10 Recall: 0.101925 Precision: 0.010193 NDCG: 0.059170 HR: 0.101925
Eval costs: 1.150439 s
Iter 56...	Training loss: 12935.634766 (8044.238703, 1736.727330, 3154.668785) in 7.21s 
Iter 57...	Training loss: 12975.742188 (8150.401590, 1737.628445, 3087.711837) in 7.25s 
Iter 58...	Training loss: 12961.978516 (8257.506710, 1739.981513, 2964.491493) in 7.36s 
Iter 59...	Training loss: 13000.807617 (8378.298079, 1742.082638, 2880.426828) in 7.23s 
Iter 60...	Training loss: 13003.706055 (8472.853759, 1742.491595, 2788.359932) in 7.23s 
Top-1 Recall: 0.026048 Precision: 0.026048 NDCG: 0.026048 HR: 0.026048
Top-5 Recall: 0.071851 Precision: 0.014370 NDCG: 0.049587 HR: 0.071851
Top-10 Recall: 0.097773 Precision: 0.009777 NDCG: 0.058002 HR: 0.097773
Eval costs: 1.156320 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 521516.500000 (60256.806000, 108812.122542, 352447.539062) in 7.56s 
Iter 2...	Training loss: 377947.406250 (45628.705879, 14190.073994, 318128.633545) in 7.36s 
Iter 3...	Training loss: 308050.187500 (0.000000, 8296.774184, 299753.453369) in 6.91s 
Iter 4...	Training loss: 348464.468750 (54422.035967, 5823.148309, 288219.279785) in 7.68s 
Iter 5...	Training loss: 300828.406250 (19961.119823, 4476.219950, 276391.030518) in 7.23s 
Top-1 Recall: 0.005411 Precision: 0.005411 NDCG: 0.005411 HR: 0.005411
Top-5 Recall: 0.019504 Precision: 0.003901 NDCG: 0.012667 HR: 0.019504
Top-10 Recall: 0.027683 Precision: 0.002768 NDCG: 0.015292 HR: 0.027683
Eval costs: 1.031714 s
Iter 6...	Training loss: 285522.031250 (16546.738905, 3633.494163, 265341.793335) in 7.21s 
Iter 7...	Training loss: 256275.906250 (0.000000, 3071.452049, 253204.441040) in 6.89s 
Iter 8...	Training loss: 265445.062500 (20872.671513, 2673.831789, 241898.564819) in 7.67s 
Iter 9...	Training loss: 238847.046875 (9000.520431, 2381.942951, 227464.590698) in 7.19s 
Iter 10...	Training loss: 220127.921875 (7176.186720, 2179.651194, 210772.086548) in 7.25s 
Top-1 Recall: 0.014093 Precision: 0.014093 NDCG: 0.014093 HR: 0.014093
Top-5 Recall: 0.036618 Precision: 0.007324 NDCG: 0.025584 HR: 0.036618
Top-10 Recall: 0.055115 Precision: 0.005512 NDCG: 0.031547 HR: 0.055115
Eval costs: 1.083818 s
Iter 11...	Training loss: 198345.531250 (5582.544529, 2017.733772, 190745.246216) in 7.22s 
Iter 12...	Training loss: 174090.578125 (4297.127590, 1901.827039, 167891.604980) in 7.36s 
Iter 13...	Training loss: 148872.921875 (3355.773215, 1806.438223, 143710.707764) in 7.22s 
Iter 14...	Training loss: 124822.210938 (2802.441223, 1743.759423, 120276.008545) in 7.25s 
Iter 15...	Training loss: 103420.031250 (2533.348763, 1691.198592, 99195.485657) in 7.41s 
Top-1 Recall: 0.025041 Precision: 0.025041 NDCG: 0.025041 HR: 0.025041
Top-5 Recall: 0.071599 Precision: 0.014320 NDCG: 0.048573 HR: 0.071599
Top-10 Recall: 0.099786 Precision: 0.009979 NDCG: 0.057687 HR: 0.099786
Eval costs: 0.970793 s
Iter 16...	Training loss: 85879.054688 (2474.506660, 1648.074617, 81756.476440) in 7.25s 
Iter 17...	Training loss: 71587.437500 (2540.941724, 1622.417540, 67424.085175) in 7.39s 
Iter 18...	Training loss: 60843.535156 (2673.390474, 1598.300757, 56571.841095) in 7.23s 
Iter 19...	Training loss: 51920.937500 (2839.572691, 1584.111611, 47497.255798) in 7.26s 
Iter 20...	Training loss: 45216.769531 (3022.919301, 1572.300892, 40621.548492) in 7.36s 
Top-1 Recall: 0.027935 Precision: 0.027935 NDCG: 0.027935 HR: 0.027935
Top-5 Recall: 0.080534 Precision: 0.016107 NDCG: 0.054747 HR: 0.080534
Top-10 Recall: 0.110859 Precision: 0.011086 NDCG: 0.064536 HR: 0.110859
Eval costs: 0.985156 s
Iter 21...	Training loss: 40186.468750 (3215.405201, 1561.952530, 35409.112427) in 7.37s 
Iter 22...	Training loss: 35814.167969 (3400.925713, 1556.849424, 30856.390594) in 7.23s 
Iter 23...	Training loss: 32233.609375 (3601.650545, 1550.401873, 27081.554947) in 7.24s 
Iter 24...	Training loss: 29492.708984 (3788.139684, 1545.434865, 24159.135101) in 7.38s 
Iter 25...	Training loss: 27469.406250 (3974.861331, 1544.868010, 21949.677521) in 7.22s 
Top-1 Recall: 0.028690 Precision: 0.028690 NDCG: 0.028690 HR: 0.028690
Top-5 Recall: 0.076759 Precision: 0.015352 NDCG: 0.053190 HR: 0.076759
Top-10 Recall: 0.112621 Precision: 0.011262 NDCG: 0.064770 HR: 0.112621
Eval costs: 0.993749 s
Iter 26...	Training loss: 25477.761719 (4154.099585, 1542.408333, 19781.254349) in 7.38s 
Iter 27...	Training loss: 24070.347656 (4335.879851, 1541.797465, 18192.671867) in 7.24s 
Iter 28...	Training loss: 22469.816406 (4505.879294, 1540.109325, 16423.829224) in 7.22s 
Iter 29...	Training loss: 21469.355469 (4672.294580, 1540.426144, 15256.635674) in 7.38s 
Iter 30...	Training loss: 15572.512695 (0.000000, 1540.404941, 14032.107986) in 6.92s 
Top-1 Recall: 0.029068 Precision: 0.029068 NDCG: 0.029068 HR: 0.029068
Top-5 Recall: 0.079653 Precision: 0.015931 NDCG: 0.054519 HR: 0.079653
Top-10 Recall: 0.114509 Precision: 0.011451 NDCG: 0.065687 HR: 0.114509
Eval costs: 1.000866 s
Iter 31...	Training loss: 23179.171875 (8266.055574, 1539.831776, 13373.285446) in 7.70s 
Iter 32...	Training loss: 13686.683594 (0.000000, 1538.610671, 12148.074005) in 6.94s 
Iter 33...	Training loss: 21904.015625 (8835.017892, 1535.896643, 11533.104088) in 7.69s 
Iter 34...	Training loss: 12352.951172 (0.000000, 1534.910892, 10818.039478) in 6.93s 
Iter 35...	Training loss: 21165.796875 (9339.968342, 1536.362853, 10289.466251) in 7.55s 
Top-1 Recall: 0.026803 Precision: 0.026803 NDCG: 0.026803 HR: 0.026803
Top-5 Recall: 0.077514 Precision: 0.015503 NDCG: 0.052677 HR: 0.077514
Top-10 Recall: 0.110356 Precision: 0.011036 NDCG: 0.063247 HR: 0.110356
Eval costs: 1.150118 s
Iter 36...	Training loss: 16865.656250 (5830.948988, 1533.513769, 9501.192787) in 7.20s 
Iter 37...	Training loss: 16672.707031 (5952.480305, 1530.930661, 9189.297028) in 7.19s 
Iter 38...	Training loss: 16299.057617 (6088.080909, 1528.650192, 8682.328026) in 7.33s 
Iter 39...	Training loss: 16154.948242 (6226.944456, 1528.014464, 8399.989944) in 7.24s 
Iter 40...	Training loss: 15710.689453 (6358.160712, 1526.918132, 7825.610870) in 7.35s 
Top-1 Recall: 0.027054 Precision: 0.027054 NDCG: 0.027054 HR: 0.027054
Top-5 Recall: 0.078017 Precision: 0.015603 NDCG: 0.052941 HR: 0.078017
Top-10 Recall: 0.112999 Precision: 0.011300 NDCG: 0.064253 HR: 0.112999
Eval costs: 1.002063 s
Iter 41...	Training loss: 15588.060547 (6491.901808, 1523.260876, 7572.899067) in 7.22s 
Iter 42...	Training loss: 15281.867188 (6636.182298, 1518.666876, 7127.017578) in 7.35s 
Iter 43...	Training loss: 15221.966797 (6746.777721, 1516.916835, 6958.272785) in 7.24s 
Iter 44...	Training loss: 15039.660156 (6888.217730, 1513.992588, 6637.450092) in 7.24s 
Iter 45...	Training loss: 14858.579102 (7018.429794, 1508.380188, 6331.769444) in 7.38s 
Top-1 Recall: 0.028690 Precision: 0.028690 NDCG: 0.028690 HR: 0.028690
Top-5 Recall: 0.078646 Precision: 0.015729 NDCG: 0.054213 HR: 0.078646
Top-10 Recall: 0.111992 Precision: 0.011199 NDCG: 0.065031 HR: 0.111992
Eval costs: 1.003750 s
Iter 46...	Training loss: 14661.025391 (7150.102752, 1506.496012, 6004.426670) in 7.23s 
Iter 47...	Training loss: 14623.322266 (7265.675283, 1502.294072, 5855.351683) in 7.38s 
Iter 48...	Training loss: 14571.552734 (7398.185064, 1499.105336, 5674.261948) in 7.21s 
Iter 49...	Training loss: 14536.035156 (7535.320782, 1494.426822, 5506.287485) in 7.38s 
Iter 50...	Training loss: 14353.947266 (7684.374785, 1489.777287, 5179.794430) in 7.21s 
Top-1 Recall: 0.028187 Precision: 0.028187 NDCG: 0.028187 HR: 0.028187
Top-5 Recall: 0.079275 Precision: 0.015855 NDCG: 0.054244 HR: 0.079275
Top-10 Recall: 0.110985 Precision: 0.011099 NDCG: 0.064518 HR: 0.110985
Eval costs: 1.005036 s
Iter 51...	Training loss: 6496.168457 (0.000000, 1485.431098, 5010.737535) in 6.92s 
Iter 52...	Training loss: 19821.783203 (13458.242210, 1480.780167, 4882.761202) in 7.68s 
Iter 53...	Training loss: 14216.794922 (8050.339321, 1473.890977, 4692.564308) in 7.28s 
Iter 54...	Training loss: 14223.430664 (8158.554163, 1469.361488, 4595.515522) in 7.37s 
Iter 55...	Training loss: 14172.212891 (8284.958973, 1465.546144, 4421.707962) in 7.25s 
Top-1 Recall: 0.027809 Precision: 0.027809 NDCG: 0.027809 HR: 0.027809
Top-5 Recall: 0.079904 Precision: 0.015981 NDCG: 0.054624 HR: 0.079904
Top-10 Recall: 0.109853 Precision: 0.010985 NDCG: 0.064299 HR: 0.109853
Eval costs: 1.006313 s
Iter 56...	Training loss: 14115.152344 (8410.710478, 1461.055845, 4243.386091) in 7.35s 
Iter 57...	Training loss: 5443.465332 (0.000000, 1455.410434, 3988.055132) in 6.94s 
Iter 58...	Training loss: 20258.867188 (14712.168056, 1451.251587, 4095.447329) in 7.70s 
Iter 59...	Training loss: 14066.428711 (8758.663927, 1444.835253, 3862.930048) in 7.23s 
Iter 60...	Training loss: 14005.885742 (8862.831039, 1440.435172, 3702.620243) in 7.22s 
Top-1 Recall: 0.027180 Precision: 0.027180 NDCG: 0.027180 HR: 0.027180
Top-5 Recall: 0.077262 Precision: 0.015452 NDCG: 0.053262 HR: 0.077262
Top-10 Recall: 0.106959 Precision: 0.010696 NDCG: 0.062914 HR: 0.106959
Eval costs: 1.147460 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 693513.937500 (60283.585327, 0.000000, 633230.357666) in 4.74s 
Iter 2...	Training loss: 699830.187500 (45692.021782, 110916.700962, 543221.469971) in 10.06s 
Iter 3...	Training loss: 451918.843750 (0.000000, 7576.856376, 444342.026611) in 6.88s 
Iter 4...	Training loss: 441940.718750 (51615.564638, 4820.402923, 385504.719238) in 7.60s 
Iter 5...	Training loss: 343001.281250 (0.000000, 3566.084826, 339435.238037) in 6.86s 
Top-1 Recall: 0.007550 Precision: 0.007550 NDCG: 0.007550 HR: 0.007550
Top-5 Recall: 0.020385 Precision: 0.004077 NDCG: 0.014117 HR: 0.020385
Top-10 Recall: 0.029823 Precision: 0.002982 NDCG: 0.017170 HR: 0.029823
Eval costs: 0.904487 s
Iter 6...	Training loss: 335706.843750 (26785.000099, 2850.335045, 306071.517334) in 7.65s 
Iter 7...	Training loss: 289709.031250 (10720.124944, 2389.464621, 276599.411621) in 7.21s 
Iter 8...	Training loss: 260334.531250 (8160.684464, 2070.320138, 250103.515625) in 7.36s 
Iter 9...	Training loss: 232986.140625 (6069.022120, 1848.323914, 225068.791016) in 7.18s 
Iter 10...	Training loss: 206598.203125 (4547.327124, 1683.082017, 200367.794189) in 7.20s 
Top-1 Recall: 0.020763 Precision: 0.020763 NDCG: 0.020763 HR: 0.020763
Top-5 Recall: 0.062162 Precision: 0.012432 NDCG: 0.041981 HR: 0.062162
Top-10 Recall: 0.086951 Precision: 0.008695 NDCG: 0.049959 HR: 0.086951
Eval costs: 1.081911 s
Iter 11...	Training loss: 181995.843750 (3530.806664, 1555.611880, 176909.416870) in 7.21s 
Iter 12...	Training loss: 159700.734375 (2962.167636, 1464.122873, 155274.443481) in 7.31s 
Iter 13...	Training loss: 139743.265625 (2693.154946, 1386.114480, 135663.981873) in 7.16s 
Iter 14...	Training loss: 121907.820312 (2628.821242, 1327.220398, 117951.789185) in 7.19s 
Iter 15...	Training loss: 106079.250000 (2672.514668, 1281.700307, 102125.020081) in 7.34s 
Top-1 Recall: 0.030703 Precision: 0.030703 NDCG: 0.030703 HR: 0.030703
Top-5 Recall: 0.085944 Precision: 0.017189 NDCG: 0.058784 HR: 0.085944
Top-10 Recall: 0.119794 Precision: 0.011979 NDCG: 0.069650 HR: 0.119794
Eval costs: 0.967913 s
Iter 16...	Training loss: 92303.085938 (2804.321847, 1245.722856, 88253.045593) in 7.21s 
Iter 17...	Training loss: 80391.570312 (2966.423061, 1214.709550, 76210.442932) in 7.35s 
Iter 18...	Training loss: 70173.640625 (3170.666490, 1191.687494, 65811.287292) in 7.22s 
Iter 19...	Training loss: 61665.398438 (3396.363807, 1171.432989, 57097.603485) in 7.33s 
Iter 20...	Training loss: 54421.675781 (3635.378178, 1155.567916, 49630.725830) in 7.21s 
Top-1 Recall: 0.032465 Precision: 0.032465 NDCG: 0.032465 HR: 0.032465
Top-5 Recall: 0.090223 Precision: 0.018045 NDCG: 0.061990 HR: 0.090223
Top-10 Recall: 0.128979 Precision: 0.012898 NDCG: 0.074489 HR: 0.128979
Eval costs: 0.984939 s
Iter 21...	Training loss: 48734.183594 (3862.511209, 1141.716076, 43729.952667) in 7.33s 
Iter 22...	Training loss: 43880.492188 (4094.614924, 1127.657669, 38658.213440) in 7.20s 
Iter 23...	Training loss: 39760.378906 (4323.146644, 1115.014549, 34322.216187) in 7.20s 
Iter 24...	Training loss: 36270.542969 (4539.044786, 1105.035392, 30626.466965) in 7.35s 
Iter 25...	Training loss: 33713.378906 (4767.809584, 1094.976719, 27850.592773) in 7.21s 
Top-1 Recall: 0.032088 Precision: 0.032088 NDCG: 0.032088 HR: 0.032088
Top-5 Recall: 0.091607 Precision: 0.018321 NDCG: 0.062014 HR: 0.091607
Top-10 Recall: 0.130489 Precision: 0.013049 NDCG: 0.074541 HR: 0.130489
Eval costs: 0.993991 s
Iter 26...	Training loss: 31277.152344 (4980.540166, 1085.470911, 25211.141632) in 7.35s 
Iter 27...	Training loss: 29199.871094 (5191.661656, 1075.733953, 22932.475723) in 7.22s 
Iter 28...	Training loss: 27501.847656 (5400.068048, 1065.164792, 21036.617424) in 7.34s 
Iter 29...	Training loss: 26010.011719 (5602.039198, 1056.650863, 19351.323257) in 7.23s 
Iter 30...	Training loss: 25016.859375 (5804.825005, 1047.830445, 18164.199364) in 7.20s 
Top-1 Recall: 0.033220 Precision: 0.033220 NDCG: 0.033220 HR: 0.033220
Top-5 Recall: 0.089719 Precision: 0.017944 NDCG: 0.061812 HR: 0.089719
Top-10 Recall: 0.129231 Precision: 0.012923 NDCG: 0.074494 HR: 0.129231
Eval costs: 1.143665 s
Iter 31...	Training loss: 24050.097656 (6001.858717, 1040.337769, 17007.902336) in 7.19s 
Iter 32...	Training loss: 23008.167969 (6217.813116, 1031.224610, 15759.131798) in 7.21s 
Iter 33...	Training loss: 22226.261719 (6401.067665, 1022.400906, 14802.793854) in 7.36s 
Iter 34...	Training loss: 21411.031250 (6604.436178, 1015.279979, 13791.314857) in 7.18s 
Iter 35...	Training loss: 20975.386719 (6783.749404, 1005.922411, 13185.712559) in 7.20s 
Top-1 Recall: 0.032213 Precision: 0.032213 NDCG: 0.032213 HR: 0.032213
Top-5 Recall: 0.091733 Precision: 0.018347 NDCG: 0.062031 HR: 0.091733
Top-10 Recall: 0.124701 Precision: 0.012470 NDCG: 0.072705 HR: 0.124701
Eval costs: 1.143068 s
Iter 36...	Training loss: 20345.400391 (6966.618826, 998.046747, 12380.733574) in 7.18s 
Iter 37...	Training loss: 12507.804688 (0.000000, 989.608827, 11518.196369) in 6.90s 
Iter 38...	Training loss: 24617.531250 (12349.032269, 981.757673, 11286.741394) in 7.62s 
Iter 39...	Training loss: 11361.672852 (0.000000, 975.134411, 10386.537464) in 6.89s 
Iter 40...	Training loss: 24242.849609 (13018.775548, 966.288371, 10257.784161) in 7.62s 
Top-1 Recall: 0.032968 Precision: 0.032968 NDCG: 0.032968 HR: 0.032968
Top-5 Recall: 0.089090 Precision: 0.017818 NDCG: 0.061475 HR: 0.089090
Top-10 Recall: 0.125582 Precision: 0.012558 NDCG: 0.073255 HR: 0.125582
Eval costs: 1.002695 s
Iter 41...	Training loss: 18744.896484 (7938.874998, 958.792533, 9847.229538) in 7.19s 
Iter 42...	Training loss: 18460.394531 (8110.238626, 952.153191, 9398.001793) in 7.34s 
Iter 43...	Training loss: 18226.861328 (8270.097214, 944.932353, 9011.831146) in 7.20s 
Iter 44...	Training loss: 18067.992188 (8426.369871, 938.917205, 8702.703411) in 7.22s 
Iter 45...	Training loss: 17871.042969 (8605.610844, 930.265735, 8335.168343) in 7.35s 
Top-1 Recall: 0.033975 Precision: 0.033975 NDCG: 0.033975 HR: 0.033975
Top-5 Recall: 0.089468 Precision: 0.017894 NDCG: 0.061937 HR: 0.089468
Top-10 Recall: 0.124575 Precision: 0.012458 NDCG: 0.073286 HR: 0.124575
Eval costs: 1.003662 s
Iter 46...	Training loss: 17753.318359 (8748.713012, 924.488479, 8080.116562) in 7.35s 
Iter 47...	Training loss: 17716.332031 (8927.943335, 919.022961, 7869.365456) in 7.20s 
Iter 48...	Training loss: 17623.261719 (9090.786911, 912.997466, 7619.476805) in 7.24s 
Iter 49...	Training loss: 17407.218750 (9256.119221, 906.218337, 7244.881926) in 7.40s 
Iter 50...	Training loss: 17502.593750 (9408.293871, 898.871679, 7195.429783) in 7.22s 
Top-1 Recall: 0.033723 Precision: 0.033723 NDCG: 0.033723 HR: 0.033723
Top-5 Recall: 0.087077 Precision: 0.017415 NDCG: 0.060565 HR: 0.087077
Top-10 Recall: 0.122184 Precision: 0.012218 NDCG: 0.071915 HR: 0.122184
Eval costs: 1.006399 s
Iter 51...	Training loss: 17438.505859 (9572.056412, 894.658711, 6971.791723) in 7.32s 
Iter 52...	Training loss: 17394.716797 (9738.984871, 888.212473, 6767.519957) in 7.26s 
Iter 53...	Training loss: 17349.384766 (9900.825010, 882.792958, 6565.768805) in 7.19s 
Iter 54...	Training loss: 17368.072266 (10056.035242, 878.572708, 6433.464327) in 7.34s 
Iter 55...	Training loss: 17321.671875 (10216.371635, 872.704149, 6232.595249) in 7.21s 
Top-1 Recall: 0.032843 Precision: 0.032843 NDCG: 0.032843 HR: 0.032843
Top-5 Recall: 0.084812 Precision: 0.016962 NDCG: 0.059444 HR: 0.084812
Top-10 Recall: 0.121555 Precision: 0.012156 NDCG: 0.071325 HR: 0.121555
Eval costs: 1.149312 s
Iter 56...	Training loss: 17338.101562 (10386.074787, 866.201612, 6085.825485) in 7.18s 
Iter 57...	Training loss: 17394.300781 (10536.538963, 861.841561, 5995.919884) in 7.18s 
Iter 58...	Training loss: 17369.113281 (10709.225508, 856.921111, 5802.967714) in 7.32s 
Iter 59...	Training loss: 17362.947266 (10881.845509, 851.752060, 5629.351231) in 7.21s 
Iter 60...	Training loss: 17365.714844 (11028.425095, 847.397288, 5489.894308) in 7.20s 
Top-1 Recall: 0.031836 Precision: 0.031836 NDCG: 0.031836 HR: 0.031836
Top-5 Recall: 0.084560 Precision: 0.016912 NDCG: 0.058661 HR: 0.084560
Top-10 Recall: 0.119919 Precision: 0.011992 NDCG: 0.070050 HR: 0.119919
Eval costs: 1.148030 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 4174651.500000 (60228.950165, 108953.503681, 4005469.466797) in 7.54s 
Iter 2...	Training loss: 2466478.250000 (45484.232300, 13636.196107, 2407357.592773) in 7.38s 
Iter 3...	Training loss: 1707613.750000 (33098.509483, 6980.352666, 1667535.010742) in 7.23s 
Iter 4...	Training loss: 1250905.125000 (22756.137615, 4413.358663, 1223735.609375) in 7.38s 
Iter 5...	Training loss: 937277.687500 (15701.215000, 3174.414100, 918401.990723) in 7.23s 
Top-1 Recall: 0.001762 Precision: 0.001762 NDCG: 0.001762 HR: 0.001762
Top-5 Recall: 0.006040 Precision: 0.001208 NDCG: 0.003839 HR: 0.006040
Top-10 Recall: 0.009186 Precision: 0.000919 NDCG: 0.004852 HR: 0.009186
Eval costs: 1.034546 s
Iter 6...	Training loss: 713427.375000 (11151.089408, 2464.163182, 699812.098633) in 7.21s 
Iter 7...	Training loss: 555666.187500 (8031.218647, 2022.322884, 545612.720459) in 7.25s 
Iter 8...	Training loss: 443119.156250 (5873.590934, 1720.515505, 435525.037598) in 7.36s 
Iter 9...	Training loss: 365491.531250 (4421.738463, 1507.595603, 359562.183838) in 7.23s 
Iter 10...	Training loss: 309090.781250 (3526.837595, 1351.267879, 304212.667480) in 7.22s 
Top-1 Recall: 0.013590 Precision: 0.013590 NDCG: 0.013590 HR: 0.013590
Top-5 Recall: 0.038379 Precision: 0.007676 NDCG: 0.026188 HR: 0.038379
Top-10 Recall: 0.058513 Precision: 0.005851 NDCG: 0.032686 HR: 0.058513
Eval costs: 1.072436 s
Iter 11...	Training loss: 266557.343750 (3033.391361, 1230.215794, 262293.741333) in 7.22s 
Iter 12...	Training loss: 234853.515625 (2843.662156, 1136.393976, 230873.454712) in 7.36s 
Iter 13...	Training loss: 209401.218750 (2845.574198, 1059.523394, 205496.118408) in 7.22s 
Iter 14...	Training loss: 185904.109375 (0.000000, 997.597360, 184906.529053) in 6.93s 
Iter 15...	Training loss: 175435.890625 (5345.794391, 945.679317, 169144.408325) in 7.70s 
Top-1 Recall: 0.024034 Precision: 0.024034 NDCG: 0.024034 HR: 0.024034
Top-5 Recall: 0.068831 Precision: 0.013766 NDCG: 0.046803 HR: 0.068831
Top-10 Recall: 0.100038 Precision: 0.010004 NDCG: 0.056822 HR: 0.100038
Eval costs: 0.952437 s
Iter 16...	Training loss: 159442.765625 (3597.865473, 903.523473, 154941.374939) in 7.22s 
Iter 17...	Training loss: 148056.437500 (3809.333689, 869.577680, 143377.528748) in 7.41s 
Iter 18...	Training loss: 137453.359375 (4066.593909, 837.084616, 132549.675720) in 7.24s 
Iter 19...	Training loss: 128213.703125 (4327.063792, 812.439635, 123074.194458) in 7.41s 
Iter 20...	Training loss: 119557.570312 (4602.615783, 789.836611, 114165.116333) in 7.26s 
Top-1 Recall: 0.030326 Precision: 0.030326 NDCG: 0.030326 HR: 0.030326
Top-5 Recall: 0.081918 Precision: 0.016384 NDCG: 0.056231 HR: 0.081918
Top-10 Recall: 0.115515 Precision: 0.011552 NDCG: 0.067068 HR: 0.115515
Eval costs: 0.965245 s
Iter 21...	Training loss: 111826.867188 (4897.621543, 770.667088, 106158.587952) in 7.47s 
Iter 22...	Training loss: 98776.234375 (0.000000, 754.521055, 98021.701416) in 6.94s 
Iter 23...	Training loss: 101552.296875 (9015.631704, 739.037255, 91797.618835) in 7.54s 
Iter 24...	Training loss: 92315.523438 (6115.130705, 725.439031, 85474.941467) in 7.38s 
Iter 25...	Training loss: 86587.156250 (6416.269138, 713.700787, 79457.187561) in 7.24s 
Top-1 Recall: 0.031333 Precision: 0.031333 NDCG: 0.031333 HR: 0.031333
Top-5 Recall: 0.085189 Precision: 0.017038 NDCG: 0.058624 HR: 0.085189
Top-10 Recall: 0.121429 Precision: 0.012143 NDCG: 0.070373 HR: 0.121429
Eval costs: 0.980484 s
Iter 26...	Training loss: 81000.000000 (6691.076624, 704.543523, 73604.378632) in 7.38s 
Iter 27...	Training loss: 76280.250000 (6998.785446, 694.045544, 68587.422546) in 7.24s 
Iter 28...	Training loss: 71350.937500 (7344.439237, 685.367688, 63321.133850) in 7.38s 
Iter 29...	Training loss: 67771.875000 (7699.572418, 678.650463, 59393.650726) in 7.23s 
Iter 30...	Training loss: 64049.453125 (8063.290291, 670.568608, 55315.591156) in 7.22s 
Top-1 Recall: 0.031584 Precision: 0.031584 NDCG: 0.031584 HR: 0.031584
Top-5 Recall: 0.086448 Precision: 0.017290 NDCG: 0.059510 HR: 0.086448
Top-10 Recall: 0.121555 Precision: 0.012156 NDCG: 0.070822 HR: 0.121555
Eval costs: 1.137166 s
Iter 31...	Training loss: 60624.933594 (8356.844275, 663.881932, 51604.205078) in 7.20s 
Iter 32...	Training loss: 57922.550781 (8751.679917, 658.480050, 48512.390244) in 7.22s 
Iter 33...	Training loss: 55300.687500 (9052.814199, 651.778691, 45596.095367) in 7.41s 
Iter 34...	Training loss: 53127.980469 (9386.956213, 646.924683, 43094.095459) in 7.23s 
Iter 35...	Training loss: 51494.898438 (9744.590870, 642.621786, 41107.686554) in 7.22s 
Top-1 Recall: 0.032339 Precision: 0.032339 NDCG: 0.032339 HR: 0.032339
Top-5 Recall: 0.083679 Precision: 0.016736 NDCG: 0.058548 HR: 0.083679
Top-10 Recall: 0.121052 Precision: 0.012105 NDCG: 0.070627 HR: 0.121052
Eval costs: 1.135710 s
Iter 36...	Training loss: 38932.718750 (0.000000, 636.887709, 38295.829117) in 6.93s 
Iter 37...	Training loss: 55318.437500 (17617.816998, 632.847179, 37067.772583) in 7.67s 
Iter 38...	Training loss: 46957.531250 (10902.251846, 628.769978, 35426.511673) in 7.20s 
Iter 39...	Training loss: 45786.179688 (11199.486706, 624.694619, 33961.999863) in 7.23s 
Iter 40...	Training loss: 44900.117188 (11500.852831, 621.229671, 32778.032051) in 7.36s 
Top-1 Recall: 0.030452 Precision: 0.030452 NDCG: 0.030452 HR: 0.030452
Top-5 Recall: 0.084057 Precision: 0.016811 NDCG: 0.057581 HR: 0.084057
Top-10 Recall: 0.122059 Precision: 0.012206 NDCG: 0.069874 HR: 0.122059
Eval costs: 0.999373 s
Iter 41...	Training loss: 44104.113281 (11809.339058, 617.468063, 31677.307846) in 7.23s 
Iter 42...	Training loss: 43480.449219 (12091.636799, 613.698079, 30775.118011) in 7.37s 
Iter 43...	Training loss: 42977.117188 (12397.348846, 611.759733, 29968.012566) in 7.20s 
Iter 44...	Training loss: 41976.636719 (12714.757675, 607.981531, 28653.897469) in 7.25s 
Iter 45...	Training loss: 41704.625000 (13024.929472, 604.161472, 28075.531754) in 7.37s 
Top-1 Recall: 0.030452 Precision: 0.030452 NDCG: 0.030452 HR: 0.030452
Top-5 Recall: 0.083679 Precision: 0.016736 NDCG: 0.057557 HR: 0.083679
Top-10 Recall: 0.121304 Precision: 0.012130 NDCG: 0.069695 HR: 0.121304
Eval costs: 1.005152 s
Iter 46...	Training loss: 41443.796875 (13325.453497, 603.157799, 27515.186974) in 7.42s 
Iter 47...	Training loss: 40799.972656 (13589.226997, 599.124200, 26611.621300) in 7.25s 
Iter 48...	Training loss: 26712.199219 (0.000000, 596.535667, 26115.664093) in 6.94s 
Iter 49...	Training loss: 50770.531250 (24357.944870, 593.532746, 25819.053978) in 7.70s 
Iter 50...	Training loss: 40373.453125 (14522.199738, 591.645581, 25259.609413) in 7.22s 
Top-1 Recall: 0.029697 Precision: 0.029697 NDCG: 0.029697 HR: 0.029697
Top-5 Recall: 0.081289 Precision: 0.016258 NDCG: 0.055794 HR: 0.081289
Top-10 Recall: 0.117403 Precision: 0.011740 NDCG: 0.067555 HR: 0.117403
Eval costs: 1.003954 s
Iter 51...	Training loss: 40477.539062 (14853.006031, 588.940436, 25035.588001) in 7.37s 
Iter 52...	Training loss: 40186.136719 (15115.597214, 586.819600, 24483.721603) in 7.27s 
Iter 53...	Training loss: 40213.105469 (15381.566639, 584.578582, 24246.960930) in 7.23s 
Iter 54...	Training loss: 40118.921875 (15649.168617, 583.031977, 23886.719933) in 7.35s 
Iter 55...	Training loss: 39998.929688 (15934.656942, 580.559321, 23483.715778) in 7.23s 
Top-1 Recall: 0.029823 Precision: 0.029823 NDCG: 0.029823 HR: 0.029823
Top-5 Recall: 0.079779 Precision: 0.015956 NDCG: 0.055179 HR: 0.079779
Top-10 Recall: 0.115515 Precision: 0.011552 NDCG: 0.066841 HR: 0.115515
Eval costs: 1.145905 s
Iter 56...	Training loss: 40072.054688 (16202.836941, 578.448237, 23290.771519) in 7.24s 
Iter 57...	Training loss: 39987.703125 (16478.691639, 576.364136, 22932.649063) in 7.33s 
Iter 58...	Training loss: 40071.875000 (16733.909836, 574.502980, 22763.463551) in 7.39s 
Iter 59...	Training loss: 40220.507812 (17068.292042, 572.536484, 22579.679234) in 7.24s 
Iter 60...	Training loss: 40137.921875 (17306.765053, 570.594525, 22260.564598) in 7.23s 
Top-1 Recall: 0.027935 Precision: 0.027935 NDCG: 0.027935 HR: 0.027935
Top-5 Recall: 0.081289 Precision: 0.016258 NDCG: 0.054853 HR: 0.081289
Top-10 Recall: 0.115264 Precision: 0.011526 NDCG: 0.065876 HR: 0.115264
Eval costs: 1.147074 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 586852.312500 (60225.832413, 108762.961107, 417863.533447) in 7.55s 
Iter 2...	Training loss: 393184.843750 (45323.572952, 14231.311602, 333629.946289) in 7.42s 
Iter 3...	Training loss: 345243.843750 (32654.137592, 8387.964854, 304201.732178) in 7.23s 
Iter 4...	Training loss: 316272.031250 (22929.950981, 5961.339101, 287380.717041) in 7.35s 
Iter 5...	Training loss: 295088.656250 (16532.480030, 4624.685512, 273931.536255) in 7.22s 
Top-1 Recall: 0.008305 Precision: 0.008305 NDCG: 0.008305 HR: 0.008305
Top-5 Recall: 0.020385 Precision: 0.004077 NDCG: 0.014498 HR: 0.020385
Top-10 Recall: 0.029445 Precision: 0.002945 NDCG: 0.017368 HR: 0.029445
Eval costs: 1.030149 s
Iter 6...	Training loss: 277525.125000 (12319.719378, 3775.934810, 261429.483154) in 7.21s 
Iter 7...	Training loss: 262055.234375 (9417.197943, 3186.016342, 249452.018066) in 7.26s 
Iter 8...	Training loss: 247338.890625 (7348.818459, 2772.669214, 237217.396484) in 7.36s 
Iter 9...	Training loss: 232110.656250 (5802.742211, 2476.790188, 223831.142944) in 7.23s 
Iter 10...	Training loss: 215925.593750 (4662.114206, 2267.022773, 208996.461914) in 7.22s 
Top-1 Recall: 0.014974 Precision: 0.014974 NDCG: 0.014974 HR: 0.014974
Top-5 Recall: 0.041903 Precision: 0.008381 NDCG: 0.028391 HR: 0.041903
Top-10 Recall: 0.057506 Precision: 0.005751 NDCG: 0.033363 HR: 0.057506
Eval costs: 1.064687 s
Iter 11...	Training loss: 197870.828125 (3764.767202, 2112.833077, 191993.206421) in 7.22s 
Iter 12...	Training loss: 177330.656250 (3063.432614, 1990.254828, 172276.954590) in 7.41s 
Iter 13...	Training loss: 156244.671875 (2550.665993, 1906.629106, 151787.388672) in 7.23s 
Iter 14...	Training loss: 134839.390625 (2225.603019, 1843.592858, 130770.201965) in 7.24s 
Iter 15...	Training loss: 114343.796875 (2067.734125, 1795.124279, 110480.937073) in 7.40s 
Top-1 Recall: 0.022902 Precision: 0.022902 NDCG: 0.022902 HR: 0.022902
Top-5 Recall: 0.065559 Precision: 0.013112 NDCG: 0.044632 HR: 0.065559
Top-10 Recall: 0.096766 Precision: 0.009677 NDCG: 0.054713 HR: 0.096766
Eval costs: 0.958403 s
Iter 16...	Training loss: 96741.687500 (2020.569061, 1761.748151, 92959.372681) in 7.26s 
Iter 17...	Training loss: 81613.914062 (2043.392313, 1737.989009, 77832.528992) in 7.39s 
Iter 18...	Training loss: 69022.906250 (2108.951503, 1719.783781, 65194.171875) in 7.24s 
Iter 19...	Training loss: 58984.992188 (2185.283157, 1708.508612, 55091.201080) in 7.38s 
Iter 20...	Training loss: 50707.843750 (2282.376244, 1702.447228, 46723.021484) in 7.21s 
Top-1 Recall: 0.026928 Precision: 0.026928 NDCG: 0.026928 HR: 0.026928
Top-5 Recall: 0.080030 Precision: 0.016006 NDCG: 0.053739 HR: 0.080030
Top-10 Recall: 0.110859 Precision: 0.011086 NDCG: 0.063662 HR: 0.110859
Eval costs: 0.977611 s
Iter 21...	Training loss: 43833.488281 (2379.963190, 1696.941058, 39756.590332) in 7.43s 
Iter 22...	Training loss: 34578.742188 (0.000000, 1693.429619, 32885.311707) in 6.92s 
Iter 23...	Training loss: 36517.132812 (4317.573183, 1691.178515, 30508.378357) in 7.54s 
Iter 24...	Training loss: 26417.572266 (0.000000, 1690.724132, 24726.847260) in 6.94s 
Iter 25...	Training loss: 30485.234375 (4683.170836, 1696.300113, 24105.763260) in 7.69s 
Top-1 Recall: 0.026425 Precision: 0.026425 NDCG: 0.026425 HR: 0.026425
Top-5 Recall: 0.078394 Precision: 0.015679 NDCG: 0.053355 HR: 0.078394
Top-10 Recall: 0.114760 Precision: 0.011476 NDCG: 0.065059 HR: 0.114760
Eval costs: 0.992219 s
Iter 26...	Training loss: 25938.769531 (2927.189687, 1700.056980, 21311.522995) in 7.37s 
Iter 27...	Training loss: 23667.402344 (2940.904359, 1701.168647, 19025.329239) in 7.25s 
Iter 28...	Training loss: 21752.371094 (2984.132854, 1702.588732, 17065.649208) in 7.38s 
Iter 29...	Training loss: 20491.699219 (3026.144810, 1705.032127, 15760.522728) in 7.27s 
Iter 30...	Training loss: 19041.871094 (3069.839225, 1706.858835, 14265.171837) in 7.23s 
Top-1 Recall: 0.026677 Precision: 0.026677 NDCG: 0.026677 HR: 0.026677
Top-5 Recall: 0.079779 Precision: 0.015956 NDCG: 0.053853 HR: 0.079779
Top-10 Recall: 0.115515 Precision: 0.011552 NDCG: 0.065328 HR: 0.115515
Eval costs: 1.138700 s
Iter 31...	Training loss: 17935.890625 (3112.761275, 1710.097819, 13113.030121) in 7.24s 
Iter 32...	Training loss: 13072.647461 (0.000000, 1715.441427, 11357.204971) in 6.95s 
Iter 33...	Training loss: 18817.302734 (5440.292130, 1720.890591, 11656.118660) in 7.70s 
Iter 34...	Training loss: 15482.602539 (3296.397044, 1723.932207, 10462.273430) in 7.25s 
Iter 35...	Training loss: 14767.947266 (3306.427802, 1727.841039, 9733.678890) in 7.26s 
Top-1 Recall: 0.024915 Precision: 0.024915 NDCG: 0.024915 HR: 0.024915
Top-5 Recall: 0.079779 Precision: 0.015956 NDCG: 0.052784 HR: 0.079779
Top-10 Recall: 0.113376 Precision: 0.011338 NDCG: 0.063606 HR: 0.113376
Eval costs: 1.164870 s
Iter 36...	Training loss: 14064.049805 (3326.055731, 1732.140760, 9005.853138) in 7.24s 
Iter 37...	Training loss: 13682.372070 (3353.860540, 1734.808861, 8593.702057) in 7.39s 
Iter 38...	Training loss: 13243.115234 (3378.138619, 1738.427310, 8126.550068) in 7.24s 
Iter 39...	Training loss: 12785.637695 (3408.221285, 1742.042365, 7635.374077) in 7.26s 
Iter 40...	Training loss: 12334.749023 (3438.608711, 1744.379440, 7151.761051) in 7.39s 
Top-1 Recall: 0.027054 Precision: 0.027054 NDCG: 0.027054 HR: 0.027054
Top-5 Recall: 0.079024 Precision: 0.015805 NDCG: 0.053525 HR: 0.079024
Top-10 Recall: 0.111740 Precision: 0.011174 NDCG: 0.064037 HR: 0.111740
Eval costs: 1.005020 s
Iter 41...	Training loss: 12028.872070 (3461.075186, 1751.529849, 6816.267002) in 7.25s 
Iter 42...	Training loss: 11743.523438 (3485.897933, 1753.084554, 6504.541584) in 7.38s 
Iter 43...	Training loss: 11464.582031 (3510.829994, 1754.368353, 6199.383991) in 7.27s 
Iter 44...	Training loss: 11124.001953 (3538.307822, 1759.566060, 5826.128490) in 7.24s 
Iter 45...	Training loss: 6974.618652 (0.000000, 1762.593579, 5212.024801) in 7.08s 
Top-1 Recall: 0.028816 Precision: 0.028816 NDCG: 0.028816 HR: 0.028816
Top-5 Recall: 0.079653 Precision: 0.015931 NDCG: 0.054938 HR: 0.079653
Top-10 Recall: 0.112999 Precision: 0.011300 NDCG: 0.065676 HR: 0.112999
Eval costs: 1.008670 s
Iter 46...	Training loss: 13781.796875 (6229.696297, 1763.824152, 5788.276684) in 7.70s 
Iter 47...	Training loss: 10541.570312 (3645.266518, 1765.742215, 5130.561523) in 7.23s 
Iter 48...	Training loss: 10333.902344 (3640.563832, 1768.792876, 4924.546438) in 7.25s 
Iter 49...	Training loss: 10176.021484 (3641.043121, 1771.709961, 4763.268482) in 7.38s 
Iter 50...	Training loss: 10063.907227 (3655.620372, 1777.505909, 4630.781715) in 7.24s 
Top-1 Recall: 0.028061 Precision: 0.028061 NDCG: 0.028061 HR: 0.028061
Top-5 Recall: 0.078520 Precision: 0.015704 NDCG: 0.053886 HR: 0.078520
Top-10 Recall: 0.111111 Precision: 0.011111 NDCG: 0.064405 HR: 0.111111
Eval costs: 1.007769 s
Iter 51...	Training loss: 9916.384766 (3667.839965, 1779.871294, 4468.674000) in 7.38s 
Iter 52...	Training loss: 9699.180664 (3682.081084, 1780.707721, 4236.391493) in 7.30s 
Iter 53...	Training loss: 9544.462891 (3689.045243, 1781.885051, 4073.532251) in 7.27s 
Iter 54...	Training loss: 9506.947266 (3707.111278, 1784.651400, 4015.185249) in 7.42s 
Iter 55...	Training loss: 9424.197266 (3718.641584, 1787.438964, 3918.116903) in 7.27s 
Top-1 Recall: 0.028816 Precision: 0.028816 NDCG: 0.028816 HR: 0.028816
Top-5 Recall: 0.077891 Precision: 0.015578 NDCG: 0.054239 HR: 0.077891
Top-10 Recall: 0.109098 Precision: 0.010910 NDCG: 0.064428 HR: 0.109098
Eval costs: 1.150584 s
Iter 56...	Training loss: 9342.509766 (3729.838227, 1789.095884, 3823.576715) in 7.25s 
Iter 57...	Training loss: 9220.124023 (3735.784410, 1791.749901, 3692.589392) in 7.26s 
Iter 58...	Training loss: 9129.091797 (3748.534147, 1794.993410, 3585.564108) in 7.39s 
Iter 59...	Training loss: 8997.642578 (3749.262398, 1796.569441, 3451.810417) in 7.25s 
Iter 60...	Training loss: 9008.214844 (3758.395866, 1798.352048, 3451.466852) in 7.26s 
Top-1 Recall: 0.028816 Precision: 0.028816 NDCG: 0.028816 HR: 0.028816
Top-5 Recall: 0.080911 Precision: 0.016182 NDCG: 0.055724 HR: 0.080911
Top-10 Recall: 0.107462 Precision: 0.010746 NDCG: 0.064199 HR: 0.107462
Eval costs: 1.150301 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 626258.625000 (60277.719818, 109262.345235, 456718.504395) in 7.55s 
Iter 2...	Training loss: 422213.375000 (45391.561195, 14259.584693, 362562.201172) in 7.36s 
Iter 3...	Training loss: 368674.562500 (32657.040501, 8324.590176, 327692.933350) in 7.22s 
Iter 4...	Training loss: 305358.625000 (0.000000, 5815.969850, 299542.655518) in 6.93s 
Iter 5...	Training loss: 333030.406250 (33038.383573, 4445.651434, 295546.345703) in 7.66s 
Top-1 Recall: 0.008934 Precision: 0.008934 NDCG: 0.008934 HR: 0.008934
Top-5 Recall: 0.021769 Precision: 0.004354 NDCG: 0.015605 HR: 0.021769
Top-10 Recall: 0.029445 Precision: 0.002945 NDCG: 0.018102 HR: 0.029445
Eval costs: 1.029034 s
Iter 6...	Training loss: 292952.062500 (12727.933093, 3596.088543, 276628.014404) in 7.21s 
Iter 7...	Training loss: 274167.343750 (9431.248884, 3030.768754, 261705.343994) in 7.21s 
Iter 8...	Training loss: 256679.718750 (7171.927252, 2641.789073, 246866.008911) in 7.33s 
Iter 9...	Training loss: 239016.359375 (5536.501256, 2350.372635, 231129.474487) in 7.21s 
Iter 10...	Training loss: 220170.203125 (4324.960678, 2144.341831, 213700.879761) in 7.24s 
Top-1 Recall: 0.015226 Precision: 0.015226 NDCG: 0.015226 HR: 0.015226
Top-5 Recall: 0.046181 Precision: 0.009236 NDCG: 0.030955 HR: 0.046181
Top-10 Recall: 0.063672 Precision: 0.006367 NDCG: 0.036598 HR: 0.063672
Eval costs: 1.074965 s
Iter 11...	Training loss: 199834.625000 (3420.832788, 1992.152949, 194421.628052) in 7.22s 
Iter 12...	Training loss: 177764.812500 (2766.108731, 1879.258838, 173119.422974) in 7.37s 
Iter 13...	Training loss: 155535.281250 (2342.928644, 1794.619923, 151397.747559) in 7.23s 
Iter 14...	Training loss: 133909.187500 (2114.711461, 1733.794526, 130060.696106) in 7.21s 
Iter 15...	Training loss: 114103.257812 (2029.724007, 1686.480244, 110387.046509) in 7.37s 
Top-1 Recall: 0.027306 Precision: 0.027306 NDCG: 0.027306 HR: 0.027306
Top-5 Recall: 0.075752 Precision: 0.015150 NDCG: 0.052031 HR: 0.075752
Top-10 Recall: 0.107714 Precision: 0.010771 NDCG: 0.062378 HR: 0.107714
Eval costs: 0.959824 s
Iter 16...	Training loss: 96961.718750 (2039.506140, 1649.285168, 93272.931763) in 7.23s 
Iter 17...	Training loss: 82487.250000 (2094.618867, 1618.236547, 78774.385254) in 7.37s 
Iter 18...	Training loss: 70253.007812 (2172.959595, 1602.731575, 66477.311646) in 7.23s 
Iter 19...	Training loss: 60413.753906 (2267.263606, 1585.786262, 56560.702545) in 7.40s 
Iter 20...	Training loss: 52757.042969 (2361.260466, 1577.714155, 48818.070862) in 7.23s 
Top-1 Recall: 0.032088 Precision: 0.032088 NDCG: 0.032088 HR: 0.032088
Top-5 Recall: 0.086699 Precision: 0.017340 NDCG: 0.060157 HR: 0.086699
Top-10 Recall: 0.123191 Precision: 0.012319 NDCG: 0.071958 HR: 0.123191
Eval costs: 0.988492 s
Iter 21...	Training loss: 46439.390625 (2456.694442, 1568.989131, 42413.706055) in 7.41s 
Iter 22...	Training loss: 36769.632812 (0.000000, 1561.546171, 35208.084961) in 6.92s 
Iter 23...	Training loss: 39119.914062 (4441.058310, 1557.655407, 33121.199493) in 7.53s 
Iter 24...	Training loss: 33367.039062 (2804.349771, 1555.813577, 29006.874405) in 7.37s 
Iter 25...	Training loss: 30448.203125 (2834.151694, 1556.445582, 26057.606705) in 7.26s 
Top-1 Recall: 0.030578 Precision: 0.030578 NDCG: 0.030578 HR: 0.030578
Top-5 Recall: 0.086322 Precision: 0.017264 NDCG: 0.059053 HR: 0.086322
Top-10 Recall: 0.122059 Precision: 0.012206 NDCG: 0.070600 HR: 0.122059
Eval costs: 0.995379 s
Iter 26...	Training loss: 27884.117188 (2884.031616, 1551.555584, 23448.533173) in 7.38s 
Iter 27...	Training loss: 25962.169922 (2919.496814, 1552.641897, 21490.029129) in 7.21s 
Iter 28...	Training loss: 24062.105469 (2978.548933, 1552.074887, 19531.480759) in 7.38s 
Iter 29...	Training loss: 22446.722656 (3028.112120, 1551.959563, 17866.650719) in 7.24s 
Iter 30...	Training loss: 21100.283203 (3086.249252, 1553.129065, 16460.905434) in 7.22s 
Top-1 Recall: 0.029823 Precision: 0.029823 NDCG: 0.029823 HR: 0.029823
Top-5 Recall: 0.084686 Precision: 0.016937 NDCG: 0.057706 HR: 0.084686
Top-10 Recall: 0.121807 Precision: 0.012181 NDCG: 0.069656 HR: 0.121807
Eval costs: 1.141426 s
Iter 31...	Training loss: 20204.375000 (3136.936803, 1553.148307, 15514.290833) in 7.22s 
Iter 32...	Training loss: 19126.416016 (3173.085404, 1552.226377, 14401.104393) in 7.21s 
Iter 33...	Training loss: 14156.970703 (0.000000, 1551.044807, 12605.925758) in 6.94s 
Iter 34...	Training loss: 20191.033203 (5593.314714, 1552.814789, 13044.904640) in 7.68s 
Iter 35...	Training loss: 16810.781250 (3356.182647, 1548.688226, 11905.908852) in 7.24s 
Top-1 Recall: 0.030578 Precision: 0.030578 NDCG: 0.030578 HR: 0.030578
Top-5 Recall: 0.084434 Precision: 0.016887 NDCG: 0.058391 HR: 0.084434
Top-10 Recall: 0.118913 Precision: 0.011891 NDCG: 0.069563 HR: 0.118913
Eval costs: 1.144185 s
Iter 36...	Training loss: 16189.371094 (3362.882207, 1549.583511, 11276.904716) in 7.20s 
Iter 37...	Training loss: 15459.312500 (3393.094347, 1547.067600, 10519.150784) in 7.37s 
Iter 38...	Training loss: 15088.902344 (3418.342564, 1546.179301, 10124.380035) in 7.22s 
Iter 39...	Training loss: 14530.894531 (3440.575172, 1544.878682, 9545.439995) in 7.20s 
Iter 40...	Training loss: 14211.091797 (3476.637396, 1542.260392, 9192.194180) in 7.39s 
Top-1 Recall: 0.029823 Precision: 0.029823 NDCG: 0.029823 HR: 0.029823
Top-5 Recall: 0.083428 Precision: 0.016686 NDCG: 0.057320 HR: 0.083428
Top-10 Recall: 0.117906 Precision: 0.011791 NDCG: 0.068460 HR: 0.117906
Eval costs: 1.006137 s
Iter 41...	Training loss: 13707.047852 (3499.808709, 1541.977100, 8665.262146) in 7.19s 
Iter 42...	Training loss: 13385.533203 (3527.048868, 1538.565112, 8319.919060) in 7.37s 
Iter 43...	Training loss: 13075.704102 (3544.365144, 1537.699065, 7993.639957) in 7.21s 
Iter 44...	Training loss: 12758.510742 (3566.000639, 1533.243947, 7659.266117) in 7.25s 
Iter 45...	Training loss: 12536.671875 (3595.798944, 1531.275702, 7409.597279) in 7.37s 
Top-1 Recall: 0.030074 Precision: 0.030074 NDCG: 0.030074 HR: 0.030074
Top-5 Recall: 0.082044 Precision: 0.016409 NDCG: 0.056800 HR: 0.082044
Top-10 Recall: 0.115012 Precision: 0.011501 NDCG: 0.067405 HR: 0.115012
Eval costs: 1.005070 s
Iter 46...	Training loss: 12159.183594 (3618.694207, 1527.303465, 7013.186268) in 7.38s 
Iter 47...	Training loss: 11984.855469 (3639.348885, 1526.348122, 6819.158741) in 7.25s 
Iter 48...	Training loss: 11750.265625 (3657.225144, 1522.974243, 6570.066998) in 7.27s 
Iter 49...	Training loss: 11570.550781 (3677.181631, 1519.574943, 6373.794292) in 7.39s 
Iter 50...	Training loss: 11373.029297 (3699.032741, 1514.161318, 6159.835159) in 7.22s 
Top-1 Recall: 0.031333 Precision: 0.031333 NDCG: 0.031333 HR: 0.031333
Top-5 Recall: 0.082295 Precision: 0.016459 NDCG: 0.057810 HR: 0.082295
Top-10 Recall: 0.117025 Precision: 0.011703 NDCG: 0.068989 HR: 0.117025
Eval costs: 1.010211 s
Iter 51...	Training loss: 11075.238281 (3721.980143, 1510.870859, 5842.388460) in 7.38s 
Iter 52...	Training loss: 11029.366211 (3746.441752, 1509.568212, 5773.355255) in 7.26s 
Iter 53...	Training loss: 10771.894531 (3762.439161, 1502.272271, 5507.182558) in 7.23s 
Iter 54...	Training loss: 10767.783203 (3786.036946, 1498.310590, 5483.436655) in 7.40s 
Iter 55...	Training loss: 10593.393555 (3798.820804, 1493.302417, 5301.270235) in 7.22s 
Top-1 Recall: 0.030326 Precision: 0.030326 NDCG: 0.030326 HR: 0.030326
Top-5 Recall: 0.081414 Precision: 0.016283 NDCG: 0.056583 HR: 0.081414
Top-10 Recall: 0.112495 Precision: 0.011250 NDCG: 0.066553 HR: 0.112495
Eval costs: 1.157868 s
Iter 56...	Training loss: 10456.631836 (3809.092896, 1492.993204, 5154.545492) in 7.24s 
Iter 57...	Training loss: 10335.207031 (3836.354341, 1487.442787, 5011.409529) in 7.22s 
Iter 58...	Training loss: 10122.132812 (3853.800117, 1485.038528, 4783.293863) in 7.37s 
Iter 59...	Training loss: 10023.486328 (3879.198621, 1480.199353, 4664.088041) in 7.21s 
Iter 60...	Training loss: 9924.935547 (3889.055447, 1476.657416, 4559.223015) in 7.24s 
Top-1 Recall: 0.027809 Precision: 0.027809 NDCG: 0.027809 HR: 0.027809
Top-5 Recall: 0.080156 Precision: 0.016031 NDCG: 0.054859 HR: 0.080156
Top-10 Recall: 0.111740 Precision: 0.011174 NDCG: 0.065019 HR: 0.111740
Eval costs: 1.148506 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 972662.000000 (60252.358871, 109111.867569, 803297.753906) in 7.54s 
Iter 2...	Training loss: 629085.937500 (45308.509865, 13946.139584, 569831.219238) in 7.37s 
Iter 3...	Training loss: 506105.000000 (32287.208374, 7642.176380, 466175.653320) in 7.22s 
Iter 4...	Training loss: 429298.000000 (21930.230839, 5050.260276, 402317.486572) in 7.37s 
Iter 5...	Training loss: 373834.281250 (15141.948147, 3745.846671, 354946.478271) in 7.25s 
Top-1 Recall: 0.008053 Precision: 0.008053 NDCG: 0.008053 HR: 0.008053
Top-5 Recall: 0.023405 Precision: 0.004681 NDCG: 0.015771 HR: 0.023405
Top-10 Recall: 0.033598 Precision: 0.003360 NDCG: 0.019080 HR: 0.033598
Eval costs: 1.044075 s
Iter 6...	Training loss: 331206.250000 (10840.607933, 2968.791497, 317396.801025) in 7.23s 
Iter 7...	Training loss: 297007.468750 (7951.447940, 2475.399206, 286580.651611) in 7.23s 
Iter 8...	Training loss: 267387.562500 (5859.294930, 2140.921571, 259387.346802) in 7.37s 
Iter 9...	Training loss: 240545.406250 (4381.267444, 1902.494928, 234261.645142) in 7.24s 
Iter 10...	Training loss: 211494.984375 (0.000000, 1728.636687, 209766.332520) in 6.93s 
Top-1 Recall: 0.021140 Precision: 0.021140 NDCG: 0.021140 HR: 0.021140
Top-5 Recall: 0.061658 Precision: 0.012332 NDCG: 0.041866 HR: 0.061658
Top-10 Recall: 0.085189 Precision: 0.008519 NDCG: 0.049485 HR: 0.085189
Eval costs: 1.076986 s
Iter 11...	Training loss: 196627.562500 (5301.555261, 1602.827731, 189723.187012) in 7.55s 
Iter 12...	Training loss: 172512.265625 (2487.358268, 1500.283996, 168524.596558) in 7.36s 
Iter 13...	Training loss: 153972.312500 (2274.950604, 1422.645021, 150274.734131) in 7.27s 
Iter 14...	Training loss: 137024.843750 (2198.058070, 1360.433734, 133466.380066) in 7.25s 
Iter 15...	Training loss: 121871.570312 (2182.535709, 1313.766167, 118375.273865) in 7.37s 
Top-1 Recall: 0.034227 Precision: 0.034227 NDCG: 0.034227 HR: 0.034227
Top-5 Recall: 0.084686 Precision: 0.016937 NDCG: 0.060520 HR: 0.084686
Top-10 Recall: 0.119039 Precision: 0.011904 NDCG: 0.071550 HR: 0.119039
Eval costs: 0.961773 s
Iter 16...	Training loss: 108193.335938 (2208.493796, 1273.332444, 104711.514038) in 7.24s 
Iter 17...	Training loss: 95774.140625 (2261.573674, 1242.550011, 92270.016724) in 7.45s 
Iter 18...	Training loss: 84727.437500 (2335.319170, 1216.847697, 81175.261536) in 7.25s 
Iter 19...	Training loss: 74834.445312 (2423.932938, 1194.980350, 71215.534424) in 7.30s 
Iter 20...	Training loss: 61687.148438 (0.000000, 1176.537459, 60510.620178) in 7.11s 
Top-1 Recall: 0.035233 Precision: 0.035233 NDCG: 0.035233 HR: 0.035233
Top-5 Recall: 0.092236 Precision: 0.018447 NDCG: 0.064620 HR: 0.092236
Top-10 Recall: 0.132125 Precision: 0.013213 NDCG: 0.077503 HR: 0.132125
Eval costs: 0.982927 s
Iter 21...	Training loss: 61643.046875 (4436.775620, 1159.018446, 56047.254730) in 7.67s 
Iter 22...	Training loss: 53314.371094 (2864.326794, 1147.410622, 49302.632477) in 7.24s 
Iter 23...	Training loss: 48032.968750 (2902.947093, 1135.428170, 43994.590393) in 7.24s 
Iter 24...	Training loss: 38524.136719 (0.000000, 1127.572380, 37396.562347) in 6.93s 
Iter 25...	Training loss: 42463.460938 (5089.647522, 1116.693762, 36257.117126) in 7.71s 
Top-1 Recall: 0.036240 Precision: 0.036240 NDCG: 0.036240 HR: 0.036240
Top-5 Recall: 0.095759 Precision: 0.019152 NDCG: 0.066480 HR: 0.095759
Top-10 Recall: 0.134516 Precision: 0.013452 NDCG: 0.079006 HR: 0.134516
Eval costs: 0.997480 s
Iter 26...	Training loss: 36615.511719 (3221.596400, 1107.917840, 32285.996033) in 7.42s 
Iter 27...	Training loss: 33880.160156 (3220.622690, 1097.651911, 29561.882217) in 7.26s 
Iter 28...	Training loss: 26465.701172 (0.000000, 1089.865378, 25375.835785) in 6.95s 
Iter 29...	Training loss: 31993.242188 (5593.614390, 1082.182673, 25317.447937) in 7.70s 
Iter 30...	Training loss: 27571.236328 (3460.328956, 1074.426572, 23036.481079) in 7.26s 
Top-1 Recall: 0.034478 Precision: 0.034478 NDCG: 0.034478 HR: 0.034478
Top-5 Recall: 0.095885 Precision: 0.019177 NDCG: 0.066195 HR: 0.095885
Top-10 Recall: 0.132503 Precision: 0.013250 NDCG: 0.077941 HR: 0.132503
Eval costs: 1.000860 s
Iter 31...	Training loss: 25851.121094 (3454.399897, 1066.779459, 21329.942230) in 7.39s 
Iter 32...	Training loss: 24385.519531 (3484.914065, 1058.496448, 19842.107819) in 7.23s 
Iter 33...	Training loss: 23245.638672 (3521.811367, 1050.316599, 18673.509628) in 7.39s 
Iter 34...	Training loss: 21961.802734 (3552.856606, 1042.795314, 17366.150520) in 7.24s 
Iter 35...	Training loss: 21009.527344 (3585.534191, 1034.700761, 16389.293053) in 7.24s 
Top-1 Recall: 0.033849 Precision: 0.033849 NDCG: 0.033849 HR: 0.033849
Top-5 Recall: 0.093620 Precision: 0.018724 NDCG: 0.064450 HR: 0.093620
Top-10 Recall: 0.128099 Precision: 0.012810 NDCG: 0.075645 HR: 0.128099
Eval costs: 1.147831 s
Iter 36...	Training loss: 20123.501953 (3631.281693, 1028.536343, 15463.685051) in 7.23s 
Iter 37...	Training loss: 19200.574219 (3674.695573, 1018.932416, 14506.945854) in 7.22s 
Iter 38...	Training loss: 18609.263672 (3718.925243, 1011.564833, 13878.773697) in 7.37s 
Iter 39...	Training loss: 18024.734375 (3758.833199, 1004.764899, 13261.136047) in 7.28s 
Iter 40...	Training loss: 17314.248047 (3801.917169, 997.187790, 12515.141739) in 7.28s 
Top-1 Recall: 0.031710 Precision: 0.031710 NDCG: 0.031710 HR: 0.031710
Top-5 Recall: 0.093872 Precision: 0.018774 NDCG: 0.063480 HR: 0.093872
Top-10 Recall: 0.128476 Precision: 0.012848 NDCG: 0.074591 HR: 0.128476
Eval costs: 1.145006 s
Iter 41...	Training loss: 16921.566406 (3847.272885, 990.345820, 12083.945889) in 7.26s 
Iter 42...	Training loss: 16447.597656 (3891.125886, 982.723114, 11573.748089) in 7.39s 
Iter 43...	Training loss: 11526.931641 (0.000000, 977.294833, 10549.637135) in 6.91s 
Iter 44...	Training loss: 18907.511719 (6926.682813, 968.411086, 11012.417824) in 7.56s 
Iter 45...	Training loss: 15340.840820 (4081.578636, 961.108856, 10298.152794) in 7.37s 
Top-1 Recall: 0.032088 Precision: 0.032088 NDCG: 0.032088 HR: 0.032088
Top-5 Recall: 0.093243 Precision: 0.018649 NDCG: 0.063717 HR: 0.093243
Top-10 Recall: 0.126589 Precision: 0.012659 NDCG: 0.074457 HR: 0.126589
Eval costs: 1.009643 s
Iter 46...	Training loss: 14830.820312 (4087.628894, 955.325831, 9787.865562) in 7.23s 
Iter 47...	Training loss: 14595.035156 (4119.036969, 949.962168, 9526.036339) in 7.38s 
Iter 48...	Training loss: 14397.175781 (4149.255582, 941.741974, 9306.176815) in 7.23s 
Iter 49...	Training loss: 14047.482422 (4169.298297, 936.887184, 8941.297558) in 7.40s 
Iter 50...	Training loss: 13836.763672 (4205.749213, 930.933039, 8700.080986) in 7.25s 
Top-1 Recall: 0.030829 Precision: 0.030829 NDCG: 0.030829 HR: 0.030829
Top-5 Recall: 0.089845 Precision: 0.017969 NDCG: 0.061404 HR: 0.089845
Top-10 Recall: 0.120926 Precision: 0.012093 NDCG: 0.071424 HR: 0.120926
Eval costs: 1.007736 s
Iter 51...	Training loss: 13493.190430 (4229.769592, 923.695294, 8339.725796) in 7.38s 
Iter 52...	Training loss: 13405.206055 (4249.431157, 919.378041, 8236.397068) in 7.21s 
Iter 53...	Training loss: 13127.314453 (4287.843159, 913.236607, 7926.235228) in 7.21s 
Iter 54...	Training loss: 12928.021484 (4322.563686, 907.309696, 7698.148890) in 7.40s 
Iter 55...	Training loss: 12854.296875 (4353.517529, 902.498968, 7598.279833) in 7.27s 
Top-1 Recall: 0.030326 Precision: 0.030326 NDCG: 0.030326 HR: 0.030326
Top-5 Recall: 0.087706 Precision: 0.017541 NDCG: 0.059458 HR: 0.087706
Top-10 Recall: 0.118913 Precision: 0.011891 NDCG: 0.069604 HR: 0.118913
Eval costs: 1.009620 s
Iter 56...	Training loss: 12627.509766 (4379.515207, 895.844620, 7352.149490) in 7.40s 
Iter 57...	Training loss: 12434.568359 (4414.215309, 892.239366, 7128.114851) in 7.26s 
Iter 58...	Training loss: 12336.251953 (4445.488584, 888.099417, 7002.664377) in 7.39s 
Iter 59...	Training loss: 7479.202637 (0.000000, 883.332951, 6595.869576) in 6.96s 
Iter 60...	Training loss: 15916.706055 (7951.920160, 877.141539, 7087.644274) in 7.55s 
Top-1 Recall: 0.030829 Precision: 0.030829 NDCG: 0.030829 HR: 0.030829
Top-5 Recall: 0.087706 Precision: 0.017541 NDCG: 0.059800 HR: 0.087706
Top-10 Recall: 0.117277 Precision: 0.011728 NDCG: 0.069390 HR: 0.117277
Eval costs: 1.151693 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 4249160.500000 (60265.945984, 109078.905378, 4079815.970703) in 7.50s 
Iter 2...	Training loss: 2477998.000000 (45217.892609, 13599.810167, 2419180.283203) in 7.21s 
Iter 3...	Training loss: 1730977.500000 (31599.735752, 6963.817904, 1692413.958984) in 7.32s 
Iter 4...	Training loss: 1272870.625000 (20589.185335, 4414.357876, 1247866.958496) in 7.32s 
Iter 5...	Training loss: 957276.125000 (13609.922220, 3170.251243, 940495.889160) in 7.18s 
Top-1 Recall: 0.001762 Precision: 0.001762 NDCG: 0.001762 HR: 0.001762
Top-5 Recall: 0.005663 Precision: 0.001133 NDCG: 0.003697 HR: 0.005663
Top-10 Recall: 0.008557 Precision: 0.000856 NDCG: 0.004593 HR: 0.008557
Eval costs: 0.892966 s
Iter 6...	Training loss: 726444.875000 (9466.255668, 2464.305479, 714514.204102) in 7.31s 
Iter 7...	Training loss: 566656.562500 (6802.043281, 2021.336659, 557833.191406) in 7.22s 
Iter 8...	Training loss: 453888.656250 (4996.931017, 1722.332671, 447169.353027) in 7.34s 
Iter 9...	Training loss: 377098.968750 (3815.202057, 1507.414787, 371776.357910) in 7.20s 
Iter 10...	Training loss: 321973.687500 (3091.882903, 1351.756655, 317529.991577) in 7.20s 
Top-1 Recall: 0.012961 Precision: 0.012961 NDCG: 0.012961 HR: 0.012961
Top-5 Recall: 0.035611 Precision: 0.007122 NDCG: 0.024226 HR: 0.035611
Top-10 Recall: 0.050459 Precision: 0.005046 NDCG: 0.029075 HR: 0.050459
Eval costs: 1.063862 s
Iter 11...	Training loss: 280532.281250 (2664.803608, 1231.271930, 276636.189575) in 7.20s 
Iter 12...	Training loss: 249012.812500 (2443.490623, 1137.702528, 245431.620850) in 7.20s 
Iter 13...	Training loss: 224605.906250 (2361.404203, 1061.415782, 221183.103149) in 7.34s 
Iter 14...	Training loss: 177732.609375 (2351.515125, 0.000000, 175381.089111) in 4.52s 
Iter 15...	Training loss: 203627.171875 (2346.613621, 1939.978638, 199340.607910) in 9.96s 
Top-1 Recall: 0.023531 Precision: 0.023531 NDCG: 0.023531 HR: 0.023531
Top-5 Recall: 0.065937 Precision: 0.013187 NDCG: 0.045257 HR: 0.065937
Top-10 Recall: 0.095508 Precision: 0.009551 NDCG: 0.054792 HR: 0.095508
Eval costs: 1.087955 s
Iter 16...	Training loss: 176125.140625 (2382.961193, 918.719160, 172823.461792) in 7.21s 
Iter 17...	Training loss: 139577.234375 (2462.039285, 0.000000, 137115.193787) in 4.61s 
Iter 18...	Training loss: 164769.312500 (2527.298120, 1708.035657, 160533.985657) in 9.93s 
Iter 19...	Training loss: 145510.484375 (2618.456990, 827.067202, 142064.955872) in 7.22s 
Iter 20...	Training loss: 134506.031250 (2730.400952, 792.170009, 130983.455444) in 7.38s 
Top-1 Recall: 0.031207 Precision: 0.031207 NDCG: 0.031207 HR: 0.031207
Top-5 Recall: 0.078646 Precision: 0.015729 NDCG: 0.055109 HR: 0.078646
Top-10 Recall: 0.108217 Precision: 0.010822 NDCG: 0.064746 HR: 0.108217
Eval costs: 0.962915 s
Iter 21...	Training loss: 128414.843750 (2842.328022, 772.244961, 124800.269958) in 7.24s 
Iter 22...	Training loss: 121637.132812 (2949.663142, 757.296108, 117930.175476) in 7.34s 
Iter 23...	Training loss: 114674.859375 (3089.524940, 742.575805, 110842.768555) in 7.23s 
Iter 24...	Training loss: 107100.843750 (3223.177190, 729.265091, 103148.402527) in 7.23s 
Iter 25...	Training loss: 100836.953125 (3359.251160, 717.406234, 96760.291077) in 7.34s 
Top-1 Recall: 0.032339 Precision: 0.032339 NDCG: 0.032339 HR: 0.032339
Top-5 Recall: 0.084183 Precision: 0.016837 NDCG: 0.058704 HR: 0.084183
Top-10 Recall: 0.117529 Precision: 0.011753 NDCG: 0.069562 HR: 0.117529
Eval costs: 0.979439 s
Iter 26...	Training loss: 94862.445312 (3495.761739, 707.985986, 90658.699341) in 7.37s 
Iter 27...	Training loss: 88941.515625 (3627.678429, 699.298372, 84614.537842) in 7.24s 
Iter 28...	Training loss: 83565.101562 (3780.851919, 690.634808, 79093.625305) in 7.23s 
Iter 29...	Training loss: 78547.406250 (3938.023680, 683.100537, 73926.280182) in 7.39s 
Iter 30...	Training loss: 73792.359375 (4084.488715, 677.190728, 69030.674103) in 7.21s 
Top-1 Recall: 0.030829 Precision: 0.030829 NDCG: 0.030829 HR: 0.030829
Top-5 Recall: 0.086448 Precision: 0.017290 NDCG: 0.059322 HR: 0.086448
Top-10 Recall: 0.119919 Precision: 0.011992 NDCG: 0.070149 HR: 0.119919
Eval costs: 0.989003 s
Iter 31...	Training loss: 69644.554688 (4244.793187, 671.209014, 64728.554626) in 7.36s 
Iter 32...	Training loss: 65289.316406 (4384.788199, 665.047033, 60239.480408) in 7.21s 
Iter 33...	Training loss: 61975.449219 (4550.646689, 660.082866, 56764.718079) in 7.24s 
Iter 34...	Training loss: 52246.925781 (0.000000, 655.524998, 51591.398590) in 7.09s 
Iter 35...	Training loss: 60102.800781 (8197.523031, 649.777589, 51255.493500) in 7.51s 
Top-1 Recall: 0.032088 Precision: 0.032088 NDCG: 0.032088 HR: 0.032088
Top-5 Recall: 0.086825 Precision: 0.017365 NDCG: 0.060004 HR: 0.086825
Top-10 Recall: 0.121933 Precision: 0.012193 NDCG: 0.071353 HR: 0.121933
Eval costs: 1.137094 s
Iter 36...	Training loss: 53749.707031 (5161.325451, 645.838876, 47942.540955) in 7.20s 
Iter 37...	Training loss: 51618.312500 (5227.810749, 641.447063, 45749.058014) in 7.20s 
Iter 38...	Training loss: 49268.710938 (5316.006701, 637.769100, 43314.932892) in 7.35s 
Iter 39...	Training loss: 40511.832031 (0.000000, 634.399850, 39877.427979) in 6.94s 
Iter 40...	Training loss: 50189.226562 (9449.761153, 630.924945, 40108.539124) in 7.52s 
Top-1 Recall: 0.033346 Precision: 0.033346 NDCG: 0.033346 HR: 0.033346
Top-5 Recall: 0.083679 Precision: 0.016736 NDCG: 0.059190 HR: 0.083679
Top-10 Recall: 0.118787 Precision: 0.011879 NDCG: 0.070578 HR: 0.118787
Eval costs: 1.143485 s
Iter 41...	Training loss: 44420.996094 (5799.644721, 626.905807, 37994.443237) in 7.24s 
Iter 42...	Training loss: 43035.335938 (5835.995615, 624.077734, 36575.259521) in 7.35s 
Iter 43...	Training loss: 41950.492188 (5911.248978, 621.838493, 35417.403564) in 7.23s 
Iter 44...	Training loss: 40723.898438 (5972.154967, 617.598443, 34134.148598) in 7.22s 
Iter 45...	Training loss: 39834.296875 (6061.622842, 615.182909, 33157.488899) in 7.35s 
Top-1 Recall: 0.030955 Precision: 0.030955 NDCG: 0.030955 HR: 0.030955
Top-5 Recall: 0.082799 Precision: 0.016560 NDCG: 0.057233 HR: 0.082799
Top-10 Recall: 0.117654 Precision: 0.011765 NDCG: 0.068444 HR: 0.117654
Eval costs: 1.002295 s
Iter 46...	Training loss: 38876.359375 (6144.862411, 613.072032, 32118.425270) in 7.22s 
Iter 47...	Training loss: 37932.054688 (6213.723709, 609.739368, 31108.596581) in 7.34s 
Iter 48...	Training loss: 37210.562500 (6296.001656, 607.306251, 30307.253609) in 7.20s 
Iter 49...	Training loss: 36580.796875 (6366.293671, 604.656785, 29609.845596) in 7.22s 
Iter 50...	Training loss: 36156.832031 (6456.371172, 602.942714, 29097.519821) in 7.35s 
Top-1 Recall: 0.029948 Precision: 0.029948 NDCG: 0.029948 HR: 0.029948
Top-5 Recall: 0.080534 Precision: 0.016107 NDCG: 0.055930 HR: 0.080534
Top-10 Recall: 0.114383 Precision: 0.011438 NDCG: 0.066768 HR: 0.114383
Eval costs: 1.004295 s
Iter 51...	Training loss: 35559.742188 (6547.305495, 600.306512, 28412.128174) in 7.35s 
Iter 52...	Training loss: 34943.574219 (6624.049124, 598.021230, 27721.503845) in 7.21s 
Iter 53...	Training loss: 34558.609375 (6711.807112, 596.575583, 27250.225471) in 7.22s 
Iter 54...	Training loss: 34075.632812 (6798.303183, 593.707492, 26683.622612) in 7.34s 
Iter 55...	Training loss: 33825.105469 (6858.437707, 591.512967, 26375.153923) in 7.20s 
Top-1 Recall: 0.031710 Precision: 0.031710 NDCG: 0.031710 HR: 0.031710
Top-5 Recall: 0.077765 Precision: 0.015553 NDCG: 0.055330 HR: 0.077765
Top-10 Recall: 0.111992 Precision: 0.011199 NDCG: 0.066400 HR: 0.111992
Eval costs: 1.005869 s
Iter 56...	Training loss: 33427.976562 (6944.512676, 589.955015, 25893.509010) in 7.37s 
Iter 57...	Training loss: 33053.812500 (7020.876768, 587.083069, 25445.852776) in 7.21s 
Iter 58...	Training loss: 33019.355469 (7088.754524, 585.331866, 25345.268951) in 7.20s 
Iter 59...	Training loss: 32764.250000 (7175.598282, 582.978954, 25005.672256) in 7.34s 
Iter 60...	Training loss: 32467.917969 (7251.519924, 582.387142, 24634.010353) in 7.19s 
Top-1 Recall: 0.029193 Precision: 0.029193 NDCG: 0.029193 HR: 0.029193
Top-5 Recall: 0.076759 Precision: 0.015352 NDCG: 0.053884 HR: 0.076759
Top-10 Recall: 0.110608 Precision: 0.011061 NDCG: 0.064732 HR: 0.110608
Eval costs: 1.006275 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1611808.000000 (60302.817734, 109056.510132, 1442448.556152) in 7.47s 
Iter 2...	Training loss: 822768.687500 (44815.408226, 14218.556473, 763734.818848) in 7.18s 
Iter 3...	Training loss: 594399.125000 (28535.725208, 8394.499474, 557468.988770) in 7.31s 
Iter 4...	Training loss: 469709.656250 (15901.761097, 5944.347328, 447863.531982) in 7.33s 
Iter 5...	Training loss: 386613.250000 (9357.316329, 4570.437991, 372685.517090) in 7.18s 
Top-1 Recall: 0.007047 Precision: 0.007047 NDCG: 0.007047 HR: 0.007047
Top-5 Recall: 0.022273 Precision: 0.004455 NDCG: 0.014773 HR: 0.022273
Top-10 Recall: 0.031081 Precision: 0.003108 NDCG: 0.017588 HR: 0.031081
Eval costs: 0.893085 s
Iter 6...	Training loss: 332855.718750 (6285.539238, 3698.604996, 322871.617188) in 7.32s 
Iter 7...	Training loss: 297311.468750 (4734.801818, 3122.741758, 289453.937500) in 7.22s 
Iter 8...	Training loss: 260179.125000 (0.000000, 2732.684444, 257446.464111) in 6.91s 
Iter 9...	Training loss: 260659.484375 (6633.224451, 2453.247187, 251573.037842) in 7.65s 
Iter 10...	Training loss: 232562.265625 (2779.440847, 2256.978199, 227525.846069) in 7.20s 
Top-1 Recall: 0.013338 Precision: 0.013338 NDCG: 0.013338 HR: 0.013338
Top-5 Recall: 0.037498 Precision: 0.007500 NDCG: 0.025605 HR: 0.037498
Top-10 Recall: 0.056625 Precision: 0.005663 NDCG: 0.031764 HR: 0.056625
Eval costs: 1.047662 s
Iter 11...	Training loss: 208149.031250 (0.000000, 2111.163555, 206037.865845) in 6.90s 
Iter 12...	Training loss: 202277.562500 (4103.934901, 2005.291741, 196168.340698) in 7.50s 
Iter 13...	Training loss: 179189.140625 (1779.205669, 1920.361310, 175489.559692) in 7.33s 
Iter 14...	Training loss: 162092.781250 (1573.254385, 1861.750813, 158657.784424) in 7.20s 
Iter 15...	Training loss: 146924.593750 (1425.698484, 1815.961292, 143682.935791) in 7.33s 
Top-1 Recall: 0.021769 Precision: 0.021769 NDCG: 0.021769 HR: 0.021769
Top-5 Recall: 0.054360 Precision: 0.010872 NDCG: 0.038521 HR: 0.054360
Top-10 Recall: 0.080408 Precision: 0.008041 NDCG: 0.046926 HR: 0.080408
Eval costs: 0.935959 s
Iter 16...	Training loss: 131899.578125 (1320.254414, 1779.056768, 128800.271973) in 7.24s 
Iter 17...	Training loss: 118710.039062 (1244.238287, 1756.516013, 115709.303101) in 7.33s 
Iter 18...	Training loss: 106806.414062 (1192.867535, 1737.615499, 103875.931702) in 7.23s 
Iter 19...	Training loss: 95824.585938 (1160.276695, 1720.986324, 92943.313721) in 7.19s 
Iter 20...	Training loss: 85676.656250 (1133.934819, 1712.077375, 82830.644592) in 7.36s 
Top-1 Recall: 0.023279 Precision: 0.023279 NDCG: 0.023279 HR: 0.023279
Top-5 Recall: 0.066944 Precision: 0.013389 NDCG: 0.045399 HR: 0.066944
Top-10 Recall: 0.098402 Precision: 0.009840 NDCG: 0.055490 HR: 0.098402
Eval costs: 0.962109 s
Iter 21...	Training loss: 77074.031250 (1115.908227, 1702.994204, 74255.125916) in 7.35s 
Iter 22...	Training loss: 64906.816406 (0.000000, 1698.444036, 63208.366364) in 6.93s 
Iter 23...	Training loss: 65838.867188 (2073.283367, 1697.794176, 62067.792023) in 7.49s 
Iter 24...	Training loss: 51408.757812 (0.000000, 1697.711028, 49711.048950) in 6.92s 
Iter 25...	Training loss: 54252.484375 (2067.336969, 1700.462840, 50484.679382) in 7.62s 
Top-1 Recall: 0.024034 Precision: 0.024034 NDCG: 0.024034 HR: 0.024034
Top-5 Recall: 0.073109 Precision: 0.014622 NDCG: 0.049127 HR: 0.073109
Top-10 Recall: 0.106707 Precision: 0.010671 NDCG: 0.059887 HR: 0.106707
Eval costs: 0.981493 s
Iter 26...	Training loss: 46686.351562 (1108.570587, 1701.562294, 43876.220215) in 7.39s 
Iter 27...	Training loss: 42230.898438 (1062.903444, 1706.145524, 39461.848129) in 7.20s 
Iter 28...	Training loss: 38585.296875 (1036.762790, 1712.580953, 35835.954666) in 7.22s 
Iter 29...	Training loss: 35006.523438 (1022.658286, 1716.699773, 32267.166901) in 7.34s 
Iter 30...	Training loss: 32035.548828 (1007.313265, 1727.171764, 29301.061172) in 7.22s 
Top-1 Recall: 0.023657 Precision: 0.023657 NDCG: 0.023657 HR: 0.023657
Top-5 Recall: 0.076759 Precision: 0.015352 NDCG: 0.050429 HR: 0.076759
Top-10 Recall: 0.108343 Precision: 0.010834 NDCG: 0.060555 HR: 0.108343
Eval costs: 0.990272 s
Iter 31...	Training loss: 29433.732422 (994.770821, 1731.625981, 26707.335785) in 7.38s 
Iter 32...	Training loss: 27224.529297 (984.312702, 1737.842773, 24502.371750) in 7.24s 
Iter 33...	Training loss: 25245.443359 (976.191258, 1745.596049, 22523.654678) in 7.37s 
Iter 34...	Training loss: 23519.785156 (966.726768, 1755.439006, 20797.619774) in 7.22s 
Iter 35...	Training loss: 19070.439453 (0.000000, 1764.891029, 17305.549675) in 6.91s 
Top-1 Recall: 0.024789 Precision: 0.024789 NDCG: 0.024789 HR: 0.024789
Top-5 Recall: 0.079149 Precision: 0.015830 NDCG: 0.052385 HR: 0.079149
Top-10 Recall: 0.112873 Precision: 0.011287 NDCG: 0.063289 HR: 0.112873
Eval costs: 0.996464 s
Iter 36...	Training loss: 23311.333984 (1777.792379, 1768.612136, 19764.933434) in 7.70s 
Iter 37...	Training loss: 19984.277344 (956.343303, 1774.212711, 17253.719734) in 7.24s 
Iter 38...	Training loss: 18783.255859 (932.028617, 1781.976756, 16069.251274) in 7.40s 
Iter 39...	Training loss: 14830.294922 (0.000000, 1791.501355, 13038.795296) in 6.91s 
Iter 40...	Training loss: 19173.136719 (1699.514691, 1798.106787, 15675.515320) in 7.70s 
Top-1 Recall: 0.027054 Precision: 0.027054 NDCG: 0.027054 HR: 0.027054
Top-5 Recall: 0.078520 Precision: 0.015704 NDCG: 0.053051 HR: 0.078520
Top-10 Recall: 0.114131 Precision: 0.011413 NDCG: 0.064511 HR: 0.114131
Eval costs: 1.000583 s
Iter 41...	Training loss: 16371.955078 (907.357510, 1803.990440, 13660.606133) in 7.24s 
Iter 42...	Training loss: 15244.586914 (881.869685, 1807.643841, 12555.074020) in 7.36s 
Iter 43...	Training loss: 14687.478516 (864.684960, 1816.728411, 12006.065987) in 7.23s 
Iter 44...	Training loss: 14293.076172 (851.248908, 1821.385536, 11620.441551) in 7.25s 
Iter 45...	Training loss: 13527.025391 (838.660567, 1828.275403, 10860.090099) in 7.40s 
Top-1 Recall: 0.027935 Precision: 0.027935 NDCG: 0.027935 HR: 0.027935
Top-5 Recall: 0.080156 Precision: 0.016031 NDCG: 0.054538 HR: 0.080156
Top-10 Recall: 0.111866 Precision: 0.011187 NDCG: 0.064806 HR: 0.111866
Eval costs: 1.005501 s
Iter 46...	Training loss: 13111.027344 (826.019938, 1837.782425, 10447.225430) in 7.22s 
Iter 47...	Training loss: 12770.231445 (815.921154, 1840.029960, 10114.279598) in 7.37s 
Iter 48...	Training loss: 12456.741211 (806.186768, 1847.392018, 9803.163170) in 7.25s 
Iter 49...	Training loss: 12084.142578 (797.400406, 1848.600032, 9438.143074) in 7.38s 
Iter 50...	Training loss: 11694.589844 (789.131097, 1858.125183, 9047.332966) in 7.28s 
Top-1 Recall: 0.028816 Precision: 0.028816 NDCG: 0.028816 HR: 0.028816
Top-5 Recall: 0.080785 Precision: 0.016157 NDCG: 0.055184 HR: 0.080785
Top-10 Recall: 0.113376 Precision: 0.011338 NDCG: 0.065796 HR: 0.113376
Eval costs: 1.009209 s
Iter 51...	Training loss: 11450.826172 (778.545914, 1859.938117, 8812.342266) in 7.35s 
Iter 52...	Training loss: 11266.005859 (769.329754, 1864.707315, 8631.968193) in 7.25s 
Iter 53...	Training loss: 11062.135742 (758.972999, 1869.370230, 8433.793518) in 7.23s 
Iter 54...	Training loss: 10781.123047 (751.517142, 1875.100315, 8154.506351) in 7.36s 
Iter 55...	Training loss: 10508.587891 (743.657802, 1881.780161, 7883.150143) in 7.22s 
Top-1 Recall: 0.029319 Precision: 0.029319 NDCG: 0.029319 HR: 0.029319
Top-5 Recall: 0.080911 Precision: 0.016182 NDCG: 0.055513 HR: 0.080911
Top-10 Recall: 0.113250 Precision: 0.011325 NDCG: 0.065983 HR: 0.113250
Eval costs: 1.007331 s
Iter 56...	Training loss: 10396.837891 (733.763141, 1885.668018, 7777.406662) in 7.37s 
Iter 57...	Training loss: 10218.017578 (726.218382, 1889.372762, 7602.426323) in 7.27s 
Iter 58...	Training loss: 10067.134766 (719.232063, 1894.763844, 7453.139240) in 7.40s 
Iter 59...	Training loss: 9885.631836 (709.940782, 1896.537812, 7279.153725) in 7.23s 
Iter 60...	Training loss: 7517.630859 (0.000000, 1901.595559, 5616.035011) in 6.93s 
Top-1 Recall: 0.030074 Precision: 0.030074 NDCG: 0.030074 HR: 0.030074
Top-5 Recall: 0.080156 Precision: 0.016031 NDCG: 0.055544 HR: 0.080156
Top-10 Recall: 0.112244 Precision: 0.011224 NDCG: 0.065930 HR: 0.112244
Eval costs: 1.009067 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1835875.125000 (101191.387390, 109232.549979, 1625451.370605) in 7.69s 
Iter 2...	Training loss: 941246.625000 (23499.861107, 0.000000, 917746.789062) in 4.63s 
Iter 3...	Training loss: 678078.187500 (13905.050705, 23876.283623, 640296.715088) in 10.11s 
Iter 4...	Training loss: 502110.593750 (8724.288641, 5865.172520, 487521.141113) in 7.28s 
Iter 5...	Training loss: 376697.437500 (0.000000, 4407.355054, 372290.093750) in 6.94s 
Top-1 Recall: 0.007173 Precision: 0.007173 NDCG: 0.007173 HR: 0.007173
Top-5 Recall: 0.020888 Precision: 0.004178 NDCG: 0.014181 HR: 0.020888
Top-10 Recall: 0.032591 Precision: 0.003259 NDCG: 0.017935 HR: 0.032591
Eval costs: 1.028550 s
Iter 6...	Training loss: 368103.718750 (10179.645297, 3532.655453, 354391.400391) in 7.52s 
Iter 7...	Training loss: 313883.656250 (4000.553029, 2987.213223, 306895.886719) in 7.36s 
Iter 8...	Training loss: 283199.375000 (3298.013934, 2610.112608, 277291.226440) in 7.21s 
Iter 9...	Training loss: 250935.281250 (0.000000, 2347.250006, 248588.031372) in 6.91s 
Iter 10...	Training loss: 244966.703125 (4907.143898, 2157.599867, 237901.971924) in 7.67s 
Top-1 Recall: 0.013968 Precision: 0.013968 NDCG: 0.013968 HR: 0.013968
Top-5 Recall: 0.041022 Precision: 0.008204 NDCG: 0.027947 HR: 0.041022
Top-10 Recall: 0.060526 Precision: 0.006053 NDCG: 0.034217 HR: 0.060526
Eval costs: 0.908573 s
Iter 11...	Training loss: 218380.703125 (2087.753874, 2020.237313, 214272.701538) in 7.34s 
Iter 12...	Training loss: 199013.046875 (1809.388789, 1913.242157, 195290.430298) in 7.25s 
Iter 13...	Training loss: 181341.750000 (1599.137908, 1833.702598, 177908.907471) in 7.26s 
Iter 14...	Training loss: 164847.906250 (1441.576270, 1778.785552, 161627.536987) in 7.35s 
Iter 15...	Training loss: 149285.718750 (1330.398551, 1729.357217, 146225.961792) in 7.21s 
Top-1 Recall: 0.023405 Precision: 0.023405 NDCG: 0.023405 HR: 0.023405
Top-5 Recall: 0.062791 Precision: 0.012558 NDCG: 0.043638 HR: 0.062791
Top-10 Recall: 0.091104 Precision: 0.009110 NDCG: 0.052733 HR: 0.091104
Eval costs: 0.939410 s
Iter 16...	Training loss: 135037.375000 (1249.634348, 1692.265965, 132095.477112) in 7.38s 
Iter 17...	Training loss: 121983.023438 (1195.081880, 1663.232457, 119124.713257) in 7.20s 
Iter 18...	Training loss: 109900.257812 (1158.788703, 1638.949472, 107102.522949) in 7.34s 
Iter 19...	Training loss: 99231.585938 (1135.781469, 1617.829288, 96477.960999) in 7.21s 
Iter 20...	Training loss: 89659.234375 (1116.126303, 1606.921523, 86936.192688) in 7.24s 
Top-1 Recall: 0.024286 Precision: 0.024286 NDCG: 0.024286 HR: 0.024286
Top-5 Recall: 0.070215 Precision: 0.014043 NDCG: 0.047748 HR: 0.070215
Top-10 Recall: 0.100164 Precision: 0.010016 NDCG: 0.057398 HR: 0.100164
Eval costs: 1.106331 s
Iter 21...	Training loss: 81109.515625 (1100.166114, 1593.056390, 78416.282837) in 7.22s 
Iter 22...	Training loss: 73569.718750 (1092.307190, 1586.314632, 70891.084045) in 7.24s 
Iter 23...	Training loss: 66580.742188 (1088.146899, 1580.509809, 63912.093994) in 7.32s 
Iter 24...	Training loss: 60604.582031 (1079.806935, 1577.324592, 57947.454315) in 7.23s 
Iter 25...	Training loss: 55027.078125 (1071.353167, 1577.181765, 52378.546051) in 7.19s 
Top-1 Recall: 0.026425 Precision: 0.026425 NDCG: 0.026425 HR: 0.026425
Top-5 Recall: 0.074871 Precision: 0.014974 NDCG: 0.051212 HR: 0.074871
Top-10 Recall: 0.111111 Precision: 0.011111 NDCG: 0.062825 HR: 0.111111
Eval costs: 1.121737 s
Iter 26...	Training loss: 50145.417969 (1064.958704, 1576.645096, 47503.813873) in 7.20s 
Iter 27...	Training loss: 45990.734375 (1056.352348, 1572.612573, 43361.766174) in 7.35s 
Iter 28...	Training loss: 42145.390625 (1048.147210, 1573.839862, 39523.401825) in 7.20s 
Iter 29...	Training loss: 38879.890625 (1037.412984, 1578.541888, 36263.936035) in 7.20s 
Iter 30...	Training loss: 35944.109375 (1030.263872, 1583.539197, 33330.305771) in 7.35s 
Top-1 Recall: 0.024412 Precision: 0.024412 NDCG: 0.024412 HR: 0.024412
Top-5 Recall: 0.079275 Precision: 0.015855 NDCG: 0.052446 HR: 0.079275
Top-10 Recall: 0.114005 Precision: 0.011401 NDCG: 0.063516 HR: 0.114005
Eval costs: 0.992982 s
Iter 31...	Training loss: 33068.054688 (1021.720901, 1580.529908, 30465.805359) in 7.20s 
Iter 32...	Training loss: 30813.761719 (1010.636374, 1584.674434, 28218.453247) in 7.39s 
Iter 33...	Training loss: 25549.908203 (0.000000, 1588.020684, 23961.889221) in 6.93s 
Iter 34...	Training loss: 30083.919922 (1872.449403, 1591.739996, 26619.730621) in 7.66s 
Iter 35...	Training loss: 25964.462891 (1005.844882, 1595.709131, 23362.905411) in 7.20s 
Top-1 Recall: 0.025544 Precision: 0.025544 NDCG: 0.025544 HR: 0.025544
Top-5 Recall: 0.082799 Precision: 0.016560 NDCG: 0.054804 HR: 0.082799
Top-10 Recall: 0.116522 Precision: 0.011652 NDCG: 0.065704 HR: 0.116522
Eval costs: 0.997797 s
Iter 36...	Training loss: 23963.746094 (977.391108, 1596.701234, 21389.655060) in 7.35s 
Iter 37...	Training loss: 22801.183594 (958.831246, 1598.648337, 20243.702065) in 7.24s 
Iter 38...	Training loss: 21500.566406 (941.484924, 1600.837894, 18958.244835) in 7.25s 
Iter 39...	Training loss: 20660.298828 (928.079710, 1605.853840, 18126.363937) in 7.36s 
Iter 40...	Training loss: 19695.119141 (916.711707, 1606.429121, 17171.976135) in 7.21s 
Top-1 Recall: 0.028438 Precision: 0.028438 NDCG: 0.028438 HR: 0.028438
Top-5 Recall: 0.080659 Precision: 0.016132 NDCG: 0.055416 HR: 0.080659
Top-10 Recall: 0.118032 Precision: 0.011803 NDCG: 0.067496 HR: 0.118032
Eval costs: 1.007619 s
Iter 41...	Training loss: 18857.908203 (905.291162, 1611.139658, 16341.478302) in 7.36s 
Iter 42...	Training loss: 18214.968750 (895.295966, 1611.606802, 15708.066833) in 7.26s 
Iter 43...	Training loss: 17492.238281 (884.378908, 1609.625928, 14998.233215) in 7.37s 
Iter 44...	Training loss: 16830.164062 (872.370677, 1611.923685, 14345.871941) in 7.26s 
Iter 45...	Training loss: 16436.031250 (864.189104, 1614.931250, 13956.912674) in 7.23s 
Top-1 Recall: 0.027558 Precision: 0.027558 NDCG: 0.027558 HR: 0.027558
Top-5 Recall: 0.081163 Precision: 0.016233 NDCG: 0.055171 HR: 0.081163
Top-10 Recall: 0.114886 Precision: 0.011489 NDCG: 0.066042 HR: 0.114886
Eval costs: 1.147309 s
Iter 46...	Training loss: 15911.304688 (852.683280, 1612.221284, 13446.399452) in 7.21s 
Iter 47...	Training loss: 15545.776367 (843.445098, 1613.136404, 13089.194527) in 7.24s 
Iter 48...	Training loss: 14974.851562 (833.338687, 1615.278157, 12526.235718) in 7.34s 
Iter 49...	Training loss: 14542.955078 (823.442296, 1614.268699, 12105.243622) in 7.20s 
Iter 50...	Training loss: 14200.007812 (813.488380, 1614.698492, 11771.821373) in 7.23s 
Top-1 Recall: 0.026803 Precision: 0.026803 NDCG: 0.026803 HR: 0.026803
Top-5 Recall: 0.082044 Precision: 0.016409 NDCG: 0.055316 HR: 0.082044
Top-10 Recall: 0.115641 Precision: 0.011564 NDCG: 0.066153 HR: 0.115641
Eval costs: 1.149228 s
Iter 51...	Training loss: 13889.669922 (804.664182, 1613.090972, 11471.914864) in 7.21s 
Iter 52...	Training loss: 13634.178711 (796.114610, 1611.037579, 11227.026772) in 7.36s 
Iter 53...	Training loss: 13301.585938 (788.140184, 1613.465529, 10899.979954) in 7.21s 
Iter 54...	Training loss: 13024.418945 (780.480351, 1612.320569, 10631.618973) in 7.20s 
Iter 55...	Training loss: 12617.396484 (770.922344, 1609.378391, 10237.094738) in 7.35s 
Top-1 Recall: 0.029571 Precision: 0.029571 NDCG: 0.029571 HR: 0.029571
Top-5 Recall: 0.082169 Precision: 0.016434 NDCG: 0.056642 HR: 0.082169
Top-10 Recall: 0.116396 Precision: 0.011640 NDCG: 0.067659 HR: 0.116396
Eval costs: 1.007964 s
Iter 56...	Training loss: 12377.145508 (764.474066, 1608.279469, 10004.391819) in 7.22s 
Iter 57...	Training loss: 12221.716797 (755.910660, 1607.343580, 9858.461716) in 7.35s 
Iter 58...	Training loss: 11943.306641 (747.906504, 1603.935255, 9591.465229) in 7.21s 
Iter 59...	Training loss: 11855.468750 (738.321619, 1604.430029, 9512.716549) in 7.22s 
Iter 60...	Training loss: 11634.409180 (731.945374, 1602.477025, 9299.986828) in 7.33s 
Top-1 Recall: 0.029068 Precision: 0.029068 NDCG: 0.029068 HR: 0.029068
Top-5 Recall: 0.081792 Precision: 0.016358 NDCG: 0.056572 HR: 0.081792
Top-10 Recall: 0.113754 Precision: 0.011375 NDCG: 0.066837 HR: 0.113754
Eval costs: 1.009369 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1996242.875000 (60241.811699, 109318.945406, 1826682.193359) in 7.54s 
Iter 2...	Training loss: 1059937.000000 (44695.842529, 13950.558883, 1001290.526855) in 7.38s 
Iter 3...	Training loss: 758392.187500 (28270.700649, 7671.552194, 722450.080078) in 7.21s 
Iter 4...	Training loss: 587716.625000 (15566.189518, 5071.003314, 567079.464355) in 7.33s 
Iter 5...	Training loss: 472760.937500 (9106.668596, 3748.914967, 459905.366211) in 7.21s 
Top-1 Recall: 0.005159 Precision: 0.005159 NDCG: 0.005159 HR: 0.005159
Top-5 Recall: 0.017113 Precision: 0.003423 NDCG: 0.011175 HR: 0.017113
Top-10 Recall: 0.024286 Precision: 0.002429 NDCG: 0.013489 HR: 0.024286
Eval costs: 1.031399 s
Iter 6...	Training loss: 397099.968750 (6133.663124, 2978.832482, 387987.500977) in 7.22s 
Iter 7...	Training loss: 345875.781250 (4609.747305, 2498.409585, 338767.576904) in 7.22s 
Iter 8...	Training loss: 308060.343750 (3707.941878, 2170.832718, 302181.596436) in 7.36s 
Iter 9...	Training loss: 278484.312500 (3074.356049, 1941.861371, 273468.135620) in 7.21s 
Iter 10...	Training loss: 253336.890625 (2583.580814, 1774.953603, 248978.364868) in 7.35s 
Top-1 Recall: 0.011703 Precision: 0.011703 NDCG: 0.011703 HR: 0.011703
Top-5 Recall: 0.039889 Precision: 0.007978 NDCG: 0.026085 HR: 0.039889
Top-10 Recall: 0.057506 Precision: 0.005751 NDCG: 0.031757 HR: 0.057506
Eval costs: 0.911818 s
Iter 11...	Training loss: 231148.343750 (2193.171892, 1648.408684, 227306.765869) in 7.22s 
Iter 12...	Training loss: 211426.687500 (1893.315572, 1546.031879, 207987.337158) in 7.36s 
Iter 13...	Training loss: 193739.218750 (1666.168962, 1468.262647, 190604.789917) in 7.21s 
Iter 14...	Training loss: 178235.031250 (1497.257429, 1402.002049, 175335.772583) in 7.23s 
Iter 15...	Training loss: 163727.078125 (1373.702831, 1350.847963, 161002.529785) in 7.38s 
Top-1 Recall: 0.021769 Precision: 0.021769 NDCG: 0.021769 HR: 0.021769
Top-5 Recall: 0.063294 Precision: 0.012659 NDCG: 0.042854 HR: 0.063294
Top-10 Recall: 0.086699 Precision: 0.008670 NDCG: 0.050324 HR: 0.086699
Eval costs: 0.939490 s
Iter 16...	Training loss: 150619.734375 (1276.877227, 1305.987135, 148036.869995) in 7.23s 
Iter 17...	Training loss: 134274.359375 (0.000000, 1270.313963, 133004.036377) in 7.06s 
Iter 18...	Training loss: 130834.367188 (2268.814260, 1239.073718, 127326.483032) in 7.55s 
Iter 19...	Training loss: 117700.109375 (1160.724370, 1214.398840, 115324.992676) in 7.39s 
Iter 20...	Training loss: 108333.078125 (1102.798980, 1192.722439, 106037.542969) in 7.23s 
Top-1 Recall: 0.028187 Precision: 0.028187 NDCG: 0.028187 HR: 0.028187
Top-5 Recall: 0.074745 Precision: 0.014949 NDCG: 0.051951 HR: 0.074745
Top-10 Recall: 0.105700 Precision: 0.010570 NDCG: 0.061942 HR: 0.105700
Eval costs: 0.964138 s
Iter 21...	Training loss: 99372.429688 (1074.086073, 1173.696133, 97124.639893) in 7.37s 
Iter 22...	Training loss: 91783.796875 (1049.568508, 1159.193244, 89575.026611) in 7.24s 
Iter 23...	Training loss: 84269.101562 (1037.929942, 1146.191748, 82084.983398) in 7.25s 
Iter 24...	Training loss: 77920.882812 (1027.884701, 1133.614029, 75759.376221) in 7.37s 
Iter 25...	Training loss: 67099.148438 (0.000000, 1124.731566, 65974.414703) in 6.92s 
Top-1 Recall: 0.030074 Precision: 0.030074 NDCG: 0.030074 HR: 0.030074
Top-5 Recall: 0.083176 Precision: 0.016635 NDCG: 0.057227 HR: 0.083176
Top-10 Recall: 0.115138 Precision: 0.011514 NDCG: 0.067537 HR: 0.115138
Eval costs: 0.983363 s
Iter 26...	Training loss: 69431.351562 (1929.593597, 1115.748918, 66386.022400) in 7.69s 
Iter 27...	Training loss: 61831.839844 (1051.393178, 1109.298423, 59671.147858) in 7.23s 
Iter 28...	Training loss: 57131.757812 (1017.559112, 1104.050064, 55010.147522) in 7.38s 
Iter 29...	Training loss: 52780.031250 (998.977005, 1098.367601, 50682.686218) in 7.25s 
Iter 30...	Training loss: 48974.429688 (986.755170, 1094.102318, 46893.573090) in 7.27s 
Top-1 Recall: 0.031081 Precision: 0.031081 NDCG: 0.031081 HR: 0.031081
Top-5 Recall: 0.087580 Precision: 0.017516 NDCG: 0.060170 HR: 0.087580
Top-10 Recall: 0.119416 Precision: 0.011942 NDCG: 0.070358 HR: 0.119416
Eval costs: 1.133202 s
Iter 31...	Training loss: 45393.011719 (975.546159, 1088.580815, 43328.883179) in 7.22s 
Iter 32...	Training loss: 42388.281250 (970.905732, 1084.639920, 40332.735321) in 7.22s 
Iter 33...	Training loss: 39534.519531 (963.220585, 1080.993250, 37490.299774) in 7.37s 
Iter 34...	Training loss: 36973.468750 (955.994163, 1077.799092, 34939.674805) in 7.25s 
Iter 35...	Training loss: 34895.031250 (950.224828, 1073.839327, 32870.969559) in 7.27s 
Top-1 Recall: 0.030200 Precision: 0.030200 NDCG: 0.030200 HR: 0.030200
Top-5 Recall: 0.085441 Precision: 0.017088 NDCG: 0.058824 HR: 0.085441
Top-10 Recall: 0.119794 Precision: 0.011979 NDCG: 0.069840 HR: 0.119794
Eval costs: 1.139211 s
Iter 36...	Training loss: 32887.085938 (943.882668, 1069.817737, 30873.385269) in 7.21s 
Iter 37...	Training loss: 30845.746094 (941.331667, 1066.635575, 28837.777740) in 7.34s 
Iter 38...	Training loss: 29322.605469 (936.159531, 1063.935145, 27322.509903) in 7.22s 
Iter 39...	Training loss: 27819.710938 (929.709610, 1061.726378, 25828.274139) in 7.22s 
Iter 40...	Training loss: 26302.460938 (925.430085, 1055.920506, 24321.113724) in 7.37s 
Top-1 Recall: 0.028061 Precision: 0.028061 NDCG: 0.028061 HR: 0.028061
Top-5 Recall: 0.084938 Precision: 0.016988 NDCG: 0.057650 HR: 0.084938
Top-10 Recall: 0.118787 Precision: 0.011879 NDCG: 0.068612 HR: 0.118787
Eval costs: 1.005574 s
Iter 41...	Training loss: 25283.937500 (919.631332, 1051.738704, 23312.568802) in 7.22s 
Iter 42...	Training loss: 24176.505859 (915.667590, 1046.779049, 22214.059998) in 7.38s 
Iter 43...	Training loss: 23203.074219 (912.598746, 1044.178016, 21246.295212) in 7.22s 
Iter 44...	Training loss: 22257.597656 (906.760012, 1038.998421, 20311.840889) in 7.23s 
Iter 45...	Training loss: 21470.908203 (901.957491, 1035.226101, 19533.726913) in 7.40s 
Top-1 Recall: 0.030200 Precision: 0.030200 NDCG: 0.030200 HR: 0.030200
Top-5 Recall: 0.087077 Precision: 0.017415 NDCG: 0.059258 HR: 0.087077
Top-10 Recall: 0.120800 Precision: 0.012080 NDCG: 0.070114 HR: 0.120800
Eval costs: 1.008051 s
Iter 46...	Training loss: 20612.914062 (896.872042, 1030.985590, 18685.055397) in 7.44s 
Iter 47...	Training loss: 19988.398438 (892.989171, 1024.695635, 18070.714462) in 7.22s 
Iter 48...	Training loss: 19350.019531 (886.262527, 1021.124322, 17442.632324) in 7.24s 
Iter 49...	Training loss: 18749.310547 (882.733415, 1016.576091, 16849.999451) in 7.39s 
Iter 50...	Training loss: 18041.839844 (877.143288, 1011.584656, 16153.111542) in 7.25s 
Top-1 Recall: 0.029445 Precision: 0.029445 NDCG: 0.029445 HR: 0.029445
Top-5 Recall: 0.084686 Precision: 0.016937 NDCG: 0.057837 HR: 0.084686
Top-10 Recall: 0.117654 Precision: 0.011765 NDCG: 0.068504 HR: 0.117654
Eval costs: 1.007250 s
Iter 51...	Training loss: 17676.595703 (872.333928, 1008.904592, 15795.357056) in 7.41s 
Iter 52...	Training loss: 17223.914062 (867.702495, 1003.257882, 15352.954468) in 7.23s 
Iter 53...	Training loss: 16721.585938 (864.451314, 999.600023, 14857.534271) in 7.37s 
Iter 54...	Training loss: 16370.588867 (858.948667, 994.841400, 14516.799042) in 7.24s 
Iter 55...	Training loss: 15759.179688 (853.554042, 989.785034, 13915.839741) in 7.23s 
Top-1 Recall: 0.027432 Precision: 0.027432 NDCG: 0.027432 HR: 0.027432
Top-5 Recall: 0.083050 Precision: 0.016610 NDCG: 0.056127 HR: 0.083050
Top-10 Recall: 0.114005 Precision: 0.011401 NDCG: 0.066148 HR: 0.114005
Eval costs: 1.151504 s
Iter 56...	Training loss: 15508.824219 (849.272689, 984.598957, 13674.952736) in 7.20s 
Iter 57...	Training loss: 15200.603516 (843.325942, 981.999629, 13375.277821) in 7.21s 
Iter 58...	Training loss: 14834.751953 (837.797876, 976.238710, 13020.714638) in 7.38s 
Iter 59...	Training loss: 14686.619141 (835.148093, 971.993039, 12879.480148) in 7.20s 
Iter 60...	Training loss: 14227.833008 (828.117290, 967.926418, 12431.790245) in 7.24s 
Top-1 Recall: 0.028187 Precision: 0.028187 NDCG: 0.028187 HR: 0.028187
Top-5 Recall: 0.083679 Precision: 0.016736 NDCG: 0.056461 HR: 0.083679
Top-10 Recall: 0.117025 Precision: 0.011703 NDCG: 0.067277 HR: 0.117025
Eval costs: 1.147696 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 5195612.000000 (0.000000, 108913.915874, 5086697.871094) in 7.19s 
Iter 2...	Training loss: 3053695.250000 (95642.670620, 13604.385852, 2944448.093750) in 7.70s 
Iter 3...	Training loss: 2025663.500000 (20101.717844, 6975.144054, 1998586.611328) in 7.27s 
Iter 4...	Training loss: 1443726.000000 (10764.476265, 4417.929714, 1428543.563477) in 7.40s 
Iter 5...	Training loss: 1054449.875000 (6819.954592, 3174.678885, 1044455.229492) in 7.26s 
Top-1 Recall: 0.000629 Precision: 0.000629 NDCG: 0.000629 HR: 0.000629
Top-5 Recall: 0.001888 Precision: 0.000378 NDCG: 0.001298 HR: 0.001888
Top-10 Recall: 0.003272 Precision: 0.000327 NDCG: 0.001756 HR: 0.003272
Eval costs: 1.023721 s
Iter 6...	Training loss: 794620.437500 (5020.713787, 2467.884868, 787131.716309) in 7.24s 
Iter 7...	Training loss: 621722.875000 (4039.991933, 2029.248128, 615653.610107) in 7.22s 
Iter 8...	Training loss: 494764.281250 (0.000000, 1733.263499, 493031.053711) in 6.94s 
Iter 9...	Training loss: 437367.656250 (5969.267020, 1524.829782, 429873.545410) in 7.71s 
Iter 10...	Training loss: 372001.718750 (2520.884896, 1368.302530, 368112.515869) in 7.23s 
Top-1 Recall: 0.005285 Precision: 0.005285 NDCG: 0.005285 HR: 0.005285
Top-5 Recall: 0.015478 Precision: 0.003096 NDCG: 0.010337 HR: 0.015478
Top-10 Recall: 0.024412 Precision: 0.002441 NDCG: 0.013184 HR: 0.024412
Eval costs: 1.038677 s
Iter 11...	Training loss: 329691.812500 (2170.983311, 1250.549240, 326270.218262) in 7.20s 
Iter 12...	Training loss: 298352.687500 (1888.413718, 1156.699474, 295307.557617) in 7.20s 
Iter 13...	Training loss: 273320.687500 (1664.123398, 1081.245643, 270575.315430) in 7.35s 
Iter 14...	Training loss: 253217.671875 (1490.529459, 1019.535653, 250707.584595) in 7.24s 
Iter 15...	Training loss: 236366.531250 (1352.736792, 968.040537, 234045.778320) in 7.34s 
Top-1 Recall: 0.011199 Precision: 0.011199 NDCG: 0.011199 HR: 0.011199
Top-5 Recall: 0.036114 Precision: 0.007223 NDCG: 0.024057 HR: 0.036114
Top-10 Recall: 0.050711 Precision: 0.005071 NDCG: 0.028707 HR: 0.050711
Eval costs: 0.925852 s
Iter 16...	Training loss: 222497.265625 (1248.431936, 925.886018, 220322.957153) in 7.26s 
Iter 17...	Training loss: 210615.421875 (1167.053492, 891.264211, 208557.109253) in 7.39s 
Iter 18...	Training loss: 200187.156250 (1101.765464, 859.142333, 198226.251099) in 7.24s 
Iter 19...	Training loss: 190822.375000 (1050.807386, 833.128197, 188938.459351) in 7.22s 
Iter 20...	Training loss: 182450.968750 (1008.816430, 811.345109, 180630.798584) in 7.41s 
Top-1 Recall: 0.020133 Precision: 0.020133 NDCG: 0.020133 HR: 0.020133
Top-5 Recall: 0.052095 Precision: 0.010419 NDCG: 0.036660 HR: 0.052095
Top-10 Recall: 0.073361 Precision: 0.007336 NDCG: 0.043511 HR: 0.073361
Eval costs: 0.943606 s
Iter 21...	Training loss: 174196.593750 (977.328502, 790.563508, 172428.712891) in 7.23s 
Iter 22...	Training loss: 162191.890625 (0.000000, 773.890672, 161418.005249) in 7.12s 
Iter 23...	Training loss: 162843.265625 (1811.991373, 759.569891, 160271.708374) in 7.54s 
Iter 24...	Training loss: 153878.046875 (990.876395, 746.562550, 152140.599243) in 7.40s 
Iter 25...	Training loss: 147299.734375 (941.733780, 735.705172, 145622.299316) in 7.24s 
Top-1 Recall: 0.024663 Precision: 0.024663 NDCG: 0.024663 HR: 0.024663
Top-5 Recall: 0.064804 Precision: 0.012961 NDCG: 0.045100 HR: 0.064804
Top-10 Recall: 0.086825 Precision: 0.008683 NDCG: 0.052131 HR: 0.086825
Eval costs: 0.959806 s
Iter 26...	Training loss: 140704.562500 (924.948631, 726.068807, 139053.536377) in 7.35s 
Iter 27...	Training loss: 134434.640625 (914.310581, 717.119033, 132803.205811) in 7.23s 
Iter 28...	Training loss: 129120.164062 (909.574648, 709.627075, 127500.952148) in 7.23s 
Iter 29...	Training loss: 123315.671875 (912.268919, 704.039198, 121699.361206) in 7.38s 
Iter 30...	Training loss: 117469.820312 (917.074430, 695.138858, 115857.606567) in 7.24s 
Top-1 Recall: 0.025293 Precision: 0.025293 NDCG: 0.025293 HR: 0.025293
Top-5 Recall: 0.070593 Precision: 0.014119 NDCG: 0.048565 HR: 0.070593
Top-10 Recall: 0.097144 Precision: 0.009714 NDCG: 0.057054 HR: 0.097144
Eval costs: 0.977256 s
Iter 31...	Training loss: 111987.468750 (925.147901, 689.877475, 110372.440918) in 7.36s 
Iter 32...	Training loss: 106936.796875 (934.229353, 684.102890, 105318.466492) in 7.25s 
Iter 33...	Training loss: 96862.585938 (0.000000, 680.063643, 96182.513184) in 6.97s 
Iter 34...	Training loss: 99886.609375 (1803.037876, 675.263151, 97408.302734) in 7.67s 
Iter 35...	Training loss: 93146.367188 (1035.001508, 670.521563, 91440.836304) in 7.25s 
Top-1 Recall: 0.026173 Precision: 0.026173 NDCG: 0.026173 HR: 0.026173
Top-5 Recall: 0.074242 Precision: 0.014848 NDCG: 0.050874 HR: 0.074242
Top-10 Recall: 0.105449 Precision: 0.010545 NDCG: 0.060924 HR: 0.105449
Eval costs: 1.124726 s
Iter 36...	Training loss: 82751.828125 (0.000000, 666.333584, 82085.496552) in 6.92s 
Iter 37...	Training loss: 87014.242188 (1893.616692, 662.299780, 84458.329163) in 7.56s 
Iter 38...	Training loss: 80643.398438 (1069.178662, 658.673072, 78915.543304) in 7.37s 
Iter 39...	Training loss: 54832.707031 (1034.992329, 0.000000, 53797.718964) in 4.56s 
Iter 40...	Training loss: 76125.015625 (1021.328496, 1380.667575, 73723.019684) in 10.01s 
Top-1 Recall: 0.029445 Precision: 0.029445 NDCG: 0.029445 HR: 0.029445
Top-5 Recall: 0.077639 Precision: 0.015528 NDCG: 0.053728 HR: 0.077639
Top-10 Recall: 0.107714 Precision: 0.010771 NDCG: 0.063417 HR: 0.107714
Eval costs: 1.133982 s
Iter 41...	Training loss: 65937.796875 (1018.052575, 656.422370, 64263.314514) in 7.24s 
Iter 42...	Training loss: 62304.531250 (1022.135272, 642.322485, 60640.077667) in 7.36s 
Iter 43...	Training loss: 61898.753906 (1034.987651, 643.420948, 60220.344299) in 7.26s 
Iter 44...	Training loss: 61192.066406 (1041.755339, 643.681054, 59506.632629) in 7.24s 
Iter 45...	Training loss: 58883.347656 (1051.204767, 641.932742, 57190.217010) in 7.39s 
Top-1 Recall: 0.029948 Precision: 0.029948 NDCG: 0.029948 HR: 0.029948
Top-5 Recall: 0.079779 Precision: 0.015956 NDCG: 0.055129 HR: 0.079779
Top-10 Recall: 0.109475 Precision: 0.010948 NDCG: 0.064684 HR: 0.109475
Eval costs: 0.995554 s
Iter 46...	Training loss: 56115.183594 (1059.138088, 637.523652, 54418.520691) in 7.24s 
Iter 47...	Training loss: 49477.152344 (0.000000, 634.543987, 48842.601166) in 6.96s 
Iter 48...	Training loss: 55006.757812 (2027.543706, 630.874704, 52348.338150) in 7.69s 
Iter 49...	Training loss: 50991.011719 (1129.764425, 629.316591, 49231.928619) in 7.36s 
Iter 50...	Training loss: 49071.468750 (1108.414841, 626.516184, 47336.542603) in 7.23s 
Top-1 Recall: 0.029068 Precision: 0.029068 NDCG: 0.029068 HR: 0.029068
Top-5 Recall: 0.077262 Precision: 0.015452 NDCG: 0.053505 HR: 0.077262
Top-10 Recall: 0.109224 Precision: 0.010922 NDCG: 0.063817 HR: 0.109224
Eval costs: 1.004720 s
Iter 51...	Training loss: 47275.718750 (1103.552278, 625.299881, 45546.862579) in 7.41s 
Iter 52...	Training loss: 45832.898438 (1100.117433, 622.347667, 44110.435165) in 7.22s 
Iter 53...	Training loss: 44716.593750 (1101.035862, 620.646028, 42994.909683) in 7.24s 
Iter 54...	Training loss: 43516.015625 (1102.942287, 617.752626, 41795.326096) in 7.37s 
Iter 55...	Training loss: 42444.722656 (1105.501623, 617.036719, 40722.179947) in 7.24s 
Top-1 Recall: 0.027935 Precision: 0.027935 NDCG: 0.027935 HR: 0.027935
Top-5 Recall: 0.075878 Precision: 0.015176 NDCG: 0.052437 HR: 0.075878
Top-10 Recall: 0.110356 Precision: 0.011036 NDCG: 0.063590 HR: 0.110356
Eval costs: 1.003518 s
Iter 56...	Training loss: 41781.929688 (1111.216861, 615.165100, 40055.549454) in 7.39s 
Iter 57...	Training loss: 40691.675781 (1115.230791, 613.107356, 38963.334930) in 7.24s 
Iter 58...	Training loss: 39777.652344 (1120.404044, 611.107321, 38046.141144) in 7.39s 
Iter 59...	Training loss: 38979.945312 (1123.409410, 609.579534, 37246.958374) in 7.21s 
Iter 60...	Training loss: 38255.222656 (1126.521477, 607.418771, 36521.280090) in 7.28s 
Top-1 Recall: 0.028438 Precision: 0.028438 NDCG: 0.028438 HR: 0.028438
Top-5 Recall: 0.074494 Precision: 0.014899 NDCG: 0.052136 HR: 0.074494
Top-10 Recall: 0.107084 Precision: 0.010708 NDCG: 0.062686 HR: 0.107084
Eval costs: 1.143891 s
