############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2000784.000000  in 2.56s 
Iter 2...	Training loss: 1839919.875000  in 2.59s 
Iter 3...	Training loss: 1778095.625000  in 2.52s 
Iter 4...	Training loss: 1730568.875000  in 2.52s 
Iter 5...	Training loss: 1685790.000000  in 2.50s 
Top-1 Recall: 0.014263 Precision: 0.014263 NDCG: 0.014263 HR: 0.014263
Top-5 Recall: 0.060222 Precision: 0.012044 NDCG: 0.037450 HR: 0.060222
Top-10 Recall: 0.086635 Precision: 0.008663 NDCG: 0.046036 HR: 0.086635
Eval costs: 0.170704 s
Iter 6...	Training loss: 1638874.875000  in 2.49s 
Iter 7...	Training loss: 1584754.875000  in 2.49s 
Iter 8...	Training loss: 1520259.500000  in 2.49s 
Iter 9...	Training loss: 1441289.375000  in 2.49s 
Iter 10...	Training loss: 1341069.375000  in 2.49s 
Top-1 Recall: 0.031167 Precision: 0.031167 NDCG: 0.031167 HR: 0.031167
Top-5 Recall: 0.092446 Precision: 0.018489 NDCG: 0.062766 HR: 0.092446
Top-10 Recall: 0.135763 Precision: 0.013576 NDCG: 0.076765 HR: 0.135763
Eval costs: 0.168475 s
Iter 11...	Training loss: 1227424.500000  in 2.49s 
Iter 12...	Training loss: 1112441.250000  in 2.51s 
Iter 13...	Training loss: 996398.187500  in 2.50s 
Iter 14...	Training loss: 879012.000000  in 2.50s 
Iter 15...	Training loss: 764241.125000  in 2.52s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.121500 Precision: 0.024300 NDCG: 0.082406 HR: 0.121500
Top-10 Recall: 0.169044 Precision: 0.016904 NDCG: 0.097526 HR: 0.169044
Eval costs: 0.188625 s
Iter 16...	Training loss: 661907.375000  in 2.53s 
Iter 17...	Training loss: 573463.937500  in 2.51s 
Iter 18...	Training loss: 497583.562500  in 2.51s 
Iter 19...	Training loss: 433641.531250  in 2.52s 
Iter 20...	Training loss: 384027.531250  in 2.51s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.137876 Precision: 0.027575 NDCG: 0.092092 HR: 0.137876
Top-10 Recall: 0.190703 Precision: 0.019070 NDCG: 0.109009 HR: 0.190703
Eval costs: 0.273842 s
Iter 21...	Training loss: 340256.062500  in 2.53s 
Iter 22...	Training loss: 304213.437500  in 2.53s 
Iter 23...	Training loss: 275219.281250  in 2.53s 
Iter 24...	Training loss: 247765.125000  in 2.55s 
Iter 25...	Training loss: 228278.937500  in 2.54s 
Top-1 Recall: 0.048600 Precision: 0.048600 NDCG: 0.048600 HR: 0.048600
Top-5 Recall: 0.152139 Precision: 0.030428 NDCG: 0.101494 HR: 0.152139
Top-10 Recall: 0.206022 Precision: 0.020602 NDCG: 0.118852 HR: 0.206022
Eval costs: 0.205080 s
Iter 26...	Training loss: 207188.968750  in 2.54s 
Iter 27...	Training loss: 191180.343750  in 2.55s 
Iter 28...	Training loss: 178421.984375  in 2.55s 
Iter 29...	Training loss: 166214.703125  in 2.55s 
Iter 30...	Training loss: 155006.109375  in 2.56s 
Top-1 Recall: 0.048072 Precision: 0.048072 NDCG: 0.048072 HR: 0.048072
Top-5 Recall: 0.154253 Precision: 0.030851 NDCG: 0.103893 HR: 0.154253
Top-10 Recall: 0.213418 Precision: 0.021342 NDCG: 0.123066 HR: 0.213418
Eval costs: 0.210531 s
Iter 31...	Training loss: 145746.062500  in 2.53s 
Iter 32...	Training loss: 137033.828125  in 2.52s 
Iter 33...	Training loss: 129261.320312  in 2.55s 
Iter 34...	Training loss: 121975.773438  in 2.55s 
Iter 35...	Training loss: 116170.367188  in 2.56s 
Top-1 Recall: 0.057581 Precision: 0.057581 NDCG: 0.057581 HR: 0.057581
Top-5 Recall: 0.161648 Precision: 0.032330 NDCG: 0.111018 HR: 0.161648
Top-10 Recall: 0.214474 Precision: 0.021447 NDCG: 0.128174 HR: 0.214474
Eval costs: 0.227615 s
Iter 36...	Training loss: 109029.828125  in 2.52s 
Iter 37...	Training loss: 104876.312500  in 2.51s 
Iter 38...	Training loss: 98834.234375  in 2.54s 
Iter 39...	Training loss: 95497.023438  in 2.53s 
Iter 40...	Training loss: 90796.421875  in 2.53s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.112626 HR: 0.162176
Top-10 Recall: 0.213946 Precision: 0.021395 NDCG: 0.129304 HR: 0.213946
Eval costs: 0.218621 s
Iter 41...	Training loss: 87763.156250  in 2.53s 
Iter 42...	Training loss: 82613.109375  in 2.56s 
Iter 43...	Training loss: 80554.273438  in 2.52s 
Iter 44...	Training loss: 76814.875000  in 2.55s 
Iter 45...	Training loss: 75478.757812  in 2.54s 
Top-1 Recall: 0.059694 Precision: 0.059694 NDCG: 0.059694 HR: 0.059694
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.116447 HR: 0.169044
Top-10 Recall: 0.216059 Precision: 0.021606 NDCG: 0.131564 HR: 0.216059
Eval costs: 0.221865 s
Iter 46...	Training loss: 70602.289062  in 2.55s 
Iter 47...	Training loss: 68843.437500  in 2.53s 
Iter 48...	Training loss: 66542.664062  in 2.53s 
Iter 49...	Training loss: 63583.906250  in 2.54s 
Iter 50...	Training loss: 61929.253906  in 2.54s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.116912 HR: 0.165874
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.134023 HR: 0.219229
Eval costs: 0.224972 s
Iter 51...	Training loss: 59357.449219  in 2.54s 
Iter 52...	Training loss: 58839.691406  in 2.55s 
Iter 53...	Training loss: 56430.128906  in 2.54s 
Iter 54...	Training loss: 53498.164062  in 2.52s 
Iter 55...	Training loss: 53334.765625  in 2.54s 
Top-1 Recall: 0.063920 Precision: 0.063920 NDCG: 0.063920 HR: 0.063920
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.116917 HR: 0.166931
Top-10 Recall: 0.216587 Precision: 0.021659 NDCG: 0.132930 HR: 0.216587
Eval costs: 0.226395 s
Iter 56...	Training loss: 50553.253906  in 2.54s 
Iter 57...	Training loss: 51625.527344  in 2.54s 
Iter 58...	Training loss: 48615.742188  in 2.55s 
Iter 59...	Training loss: 47066.695312  in 2.53s 
Iter 60...	Training loss: 45692.464844  in 2.55s 
Top-1 Recall: 0.065504 Precision: 0.065504 NDCG: 0.065504 HR: 0.065504
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.116518 HR: 0.165874
Top-10 Recall: 0.212361 Precision: 0.021236 NDCG: 0.131622 HR: 0.212361
Eval costs: 0.231920 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 399203.375000 (193009.122192, 206194.244507) in 3.94s 
Iter 2...	Training loss: 205656.296875 (16110.080093, 189546.240845) in 3.95s 
Iter 3...	Training loss: 195262.953125 (12433.681030, 182829.271973) in 3.87s 
Iter 4...	Training loss: 188527.093750 (10487.512243, 178039.591919) in 3.94s 
Iter 5...	Training loss: 182268.937500 (8906.650790, 173362.259399) in 3.85s 
Top-1 Recall: 0.013207 Precision: 0.013207 NDCG: 0.013207 HR: 0.013207
Top-5 Recall: 0.058637 Precision: 0.011727 NDCG: 0.035848 HR: 0.058637
Top-10 Recall: 0.084522 Precision: 0.008452 NDCG: 0.044319 HR: 0.084522
Eval costs: 0.173342 s
Iter 6...	Training loss: 176203.609375 (7639.081886, 168564.532349) in 3.96s 
Iter 7...	Training loss: 169766.546875 (6633.646326, 163132.893555) in 3.83s 
Iter 8...	Training loss: 162359.281250 (5802.050872, 156557.227905) in 3.95s 
Iter 9...	Training loss: 153651.625000 (5108.150946, 148543.460815) in 3.83s 
Iter 10...	Training loss: 142593.140625 (4547.241899, 138045.890869) in 3.93s 
Top-1 Recall: 0.032224 Precision: 0.032224 NDCG: 0.032224 HR: 0.032224
Top-5 Recall: 0.090333 Precision: 0.018067 NDCG: 0.061615 HR: 0.090333
Top-10 Recall: 0.136820 Precision: 0.013682 NDCG: 0.076734 HR: 0.136820
Eval costs: 0.170984 s
Iter 11...	Training loss: 131085.984375 (4089.514058, 126996.461792) in 3.86s 
Iter 12...	Training loss: 119544.554688 (3718.052840, 115826.510742) in 3.96s 
Iter 13...	Training loss: 108086.554688 (3450.981164, 104635.569763) in 3.84s 
Iter 14...	Training loss: 96374.125000 (3264.977568, 93109.149719) in 3.96s 
Iter 15...	Training loss: 85435.070312 (3147.092860, 82287.984192) in 3.85s 
Top-1 Recall: 0.036450 Precision: 0.036450 NDCG: 0.036450 HR: 0.036450
Top-5 Recall: 0.115161 Precision: 0.023032 NDCG: 0.076865 HR: 0.115161
Top-10 Recall: 0.168516 Precision: 0.016852 NDCG: 0.094219 HR: 0.168516
Eval costs: 0.191039 s
Iter 16...	Training loss: 75286.695312 (3087.806371, 72198.896545) in 3.95s 
Iter 17...	Training loss: 63297.425781 (0.000000, 63297.427856) in 2.72s 
Iter 18...	Training loss: 62052.386719 (5906.127722, 56146.254333) in 5.00s 
Iter 19...	Training loss: 52579.789062 (3059.372322, 49520.417633) in 3.96s 
Iter 20...	Training loss: 47463.480469 (3181.740746, 44281.741089) in 3.86s 
Top-1 Recall: 0.046487 Precision: 0.046487 NDCG: 0.046487 HR: 0.046487
Top-5 Recall: 0.137348 Precision: 0.027470 NDCG: 0.093075 HR: 0.137348
Top-10 Recall: 0.194400 Precision: 0.019440 NDCG: 0.111602 HR: 0.194400
Eval costs: 0.204684 s
Iter 21...	Training loss: 43068.886719 (3275.937621, 39792.948578) in 3.95s 
Iter 22...	Training loss: 39412.390625 (3374.236658, 36038.149200) in 3.86s 
Iter 23...	Training loss: 36118.675781 (3476.720534, 32641.952576) in 3.97s 
Iter 24...	Training loss: 33749.460938 (3579.935850, 30169.526443) in 3.85s 
Iter 25...	Training loss: 31194.773438 (3676.271022, 27518.499252) in 3.96s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.150555 Precision: 0.030111 NDCG: 0.101557 HR: 0.150555
Top-10 Recall: 0.211833 Precision: 0.021183 NDCG: 0.121229 HR: 0.211833
Eval costs: 0.209671 s
Iter 26...	Training loss: 29414.058594 (3773.972512, 25640.088928) in 3.85s 
Iter 27...	Training loss: 27712.351562 (3871.516789, 23840.835373) in 3.93s 
Iter 28...	Training loss: 26155.611328 (3963.067785, 22192.540619) in 3.84s 
Iter 29...	Training loss: 24849.677734 (4057.056010, 20792.622894) in 3.84s 
Iter 30...	Training loss: 23818.312500 (4144.831060, 19673.479324) in 3.94s 
Top-1 Recall: 0.054411 Precision: 0.054411 NDCG: 0.054411 HR: 0.054411
Top-5 Recall: 0.157950 Precision: 0.031590 NDCG: 0.107160 HR: 0.157950
Top-10 Recall: 0.213418 Precision: 0.021342 NDCG: 0.125223 HR: 0.213418
Eval costs: 0.216411 s
Iter 31...	Training loss: 22417.013672 (4225.815398, 18191.197159) in 3.86s 
Iter 32...	Training loss: 21854.320312 (4307.626286, 17546.695923) in 4.00s 
Iter 33...	Training loss: 20725.900391 (4382.164897, 16343.736900) in 3.86s 
Iter 34...	Training loss: 20351.253906 (4453.975544, 15897.280212) in 3.96s 
Iter 35...	Training loss: 19321.521484 (4523.055660, 14798.465637) in 3.83s 
Top-1 Recall: 0.055468 Precision: 0.055468 NDCG: 0.055468 HR: 0.055468
Top-5 Recall: 0.160592 Precision: 0.032118 NDCG: 0.110061 HR: 0.160592
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.130948 HR: 0.225568
Eval costs: 0.220500 s
Iter 36...	Training loss: 18788.462891 (4593.264379, 14195.200050) in 3.95s 
Iter 37...	Training loss: 18443.261719 (4656.807377, 13786.454994) in 3.91s 
Iter 38...	Training loss: 17784.691406 (4720.616212, 13064.075844) in 3.95s 
Iter 39...	Training loss: 17289.107422 (4782.991985, 12506.115387) in 3.89s 
Iter 40...	Training loss: 16900.546875 (4839.169940, 12061.375999) in 3.87s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.114871 HR: 0.165346
Top-10 Recall: 0.220814 Precision: 0.022081 NDCG: 0.132698 HR: 0.220814
Eval costs: 0.224895 s
Iter 41...	Training loss: 16441.318359 (4891.206930, 11550.112518) in 3.95s 
Iter 42...	Training loss: 16304.388672 (4938.178318, 11366.210533) in 3.88s 
Iter 43...	Training loss: 15873.051758 (4990.465322, 10882.587273) in 3.93s 
Iter 44...	Training loss: 15577.148438 (5040.113983, 10537.033913) in 3.89s 
Iter 45...	Training loss: 15271.581055 (5092.444049, 10179.137550) in 3.94s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.160063 Precision: 0.032013 NDCG: 0.117693 HR: 0.160063
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.138104 HR: 0.222398
Eval costs: 0.225395 s
Iter 46...	Training loss: 14916.991211 (5134.980469, 9782.011024) in 3.85s 
Iter 47...	Training loss: 14517.480469 (5179.435702, 9338.046188) in 3.95s 
Iter 48...	Training loss: 14409.052734 (5214.893957, 9194.158638) in 3.85s 
Iter 49...	Training loss: 14156.752930 (5251.564378, 8905.188148) in 3.97s 
Iter 50...	Training loss: 14009.777344 (5288.202735, 8721.574547) in 3.83s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.120051 HR: 0.169044
Top-10 Recall: 0.218700 Precision: 0.021870 NDCG: 0.136110 HR: 0.218700
Eval costs: 0.229174 s
Iter 51...	Training loss: 13694.855469 (5324.670124, 8370.184326) in 3.97s 
Iter 52...	Training loss: 13652.469727 (5357.371383, 8295.097900) in 3.83s 
Iter 53...	Training loss: 13488.242188 (5397.169298, 8091.073036) in 3.85s 
Iter 54...	Training loss: 13225.207031 (5426.924401, 7798.281609) in 3.97s 
Iter 55...	Training loss: 13216.573242 (5458.830335, 7757.743233) in 3.83s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.163233 Precision: 0.032647 NDCG: 0.116855 HR: 0.163233
Top-10 Recall: 0.220285 Precision: 0.022029 NDCG: 0.135254 HR: 0.220285
Eval costs: 0.233208 s
Iter 56...	Training loss: 12830.460938 (5492.268731, 7338.191914) in 3.94s 
Iter 57...	Training loss: 12793.018555 (5521.568662, 7271.450024) in 3.88s 
Iter 58...	Training loss: 12395.000000 (5555.641863, 6839.359585) in 3.99s 
Iter 59...	Training loss: 12457.456055 (5570.945286, 6886.510284) in 3.92s 
Iter 60...	Training loss: 12241.757812 (5597.974948, 6643.782749) in 4.00s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.119250 HR: 0.164818
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.136733 HR: 0.219229
Eval costs: 0.241515 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 413112.312500 (192627.961912, 220484.348755) in 4.00s 
Iter 2...	Training loss: 215797.718750 (16051.826553, 199745.883423) in 3.86s 
Iter 3...	Training loss: 203324.312500 (12311.796455, 191012.511230) in 3.97s 
Iter 4...	Training loss: 194809.468750 (10236.545398, 184572.934937) in 3.86s 
Iter 5...	Training loss: 187230.906250 (8573.221968, 178657.661865) in 3.99s 
Top-1 Recall: 0.019017 Precision: 0.019017 NDCG: 0.019017 HR: 0.019017
Top-5 Recall: 0.071315 Precision: 0.014263 NDCG: 0.045885 HR: 0.071315
Top-10 Recall: 0.104596 Precision: 0.010460 NDCG: 0.056768 HR: 0.104596
Eval costs: 0.173524 s
Iter 6...	Training loss: 179336.593750 (7257.033072, 172079.560425) in 3.86s 
Iter 7...	Training loss: 170496.468750 (6201.567457, 164294.883545) in 3.96s 
Iter 8...	Training loss: 160132.015625 (5345.165086, 154786.875000) in 3.86s 
Iter 9...	Training loss: 148180.250000 (4666.466798, 143513.785767) in 3.96s 
Iter 10...	Training loss: 137005.968750 (4134.476610, 132871.471436) in 3.86s 
Top-1 Recall: 0.036978 Precision: 0.036978 NDCG: 0.036978 HR: 0.036978
Top-5 Recall: 0.101955 Precision: 0.020391 NDCG: 0.069750 HR: 0.101955
Top-10 Recall: 0.143687 Precision: 0.014369 NDCG: 0.083350 HR: 0.143687
Eval costs: 0.171393 s
Iter 11...	Training loss: 126505.203125 (3752.670261, 122752.536621) in 3.97s 
Iter 12...	Training loss: 115474.750000 (3477.919671, 111996.840759) in 3.86s 
Iter 13...	Training loss: 104687.257812 (3281.227824, 101406.033691) in 3.96s 
Iter 14...	Training loss: 93917.210938 (3149.940933, 90767.274902) in 3.86s 
Iter 15...	Training loss: 83796.671875 (3075.294739, 80721.384460) in 3.87s 
Top-1 Recall: 0.045959 Precision: 0.045959 NDCG: 0.045959 HR: 0.045959
Top-5 Recall: 0.125198 Precision: 0.025040 NDCG: 0.086040 HR: 0.125198
Top-10 Recall: 0.177496 Precision: 0.017750 NDCG: 0.102865 HR: 0.177496
Eval costs: 0.296964 s
Iter 16...	Training loss: 74314.289062 (3045.534110, 71268.761230) in 3.87s 
Iter 17...	Training loss: 66038.929688 (3059.485294, 62979.445618) in 3.95s 
Iter 18...	Training loss: 58811.992188 (3098.978178, 55713.013611) in 4.07s 
Iter 19...	Training loss: 52645.769531 (3164.152393, 49481.619781) in 3.88s 
Iter 20...	Training loss: 47497.214844 (3244.802335, 44252.417084) in 3.93s 
Top-1 Recall: 0.054411 Precision: 0.054411 NDCG: 0.054411 HR: 0.054411
Top-5 Recall: 0.146857 Precision: 0.029371 NDCG: 0.101909 HR: 0.146857
Top-10 Recall: 0.200211 Precision: 0.020021 NDCG: 0.119356 HR: 0.200211
Eval costs: 0.200424 s
Iter 21...	Training loss: 43237.777344 (3336.810912, 39900.965668) in 3.90s 
Iter 22...	Training loss: 39348.171875 (3431.496420, 35916.676758) in 3.95s 
Iter 23...	Training loss: 36239.351562 (3530.774855, 32708.580292) in 3.86s 
Iter 24...	Training loss: 33374.699219 (3628.206941, 29746.493164) in 4.02s 
Iter 25...	Training loss: 31824.265625 (3723.883743, 28100.382141) in 3.85s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.160063 Precision: 0.032013 NDCG: 0.114148 HR: 0.160063
Top-10 Recall: 0.209192 Precision: 0.020919 NDCG: 0.130091 HR: 0.209192
Eval costs: 0.209940 s
Iter 26...	Training loss: 29524.150391 (3815.127469, 25709.021179) in 3.99s 
Iter 27...	Training loss: 27936.617188 (3897.147617, 24039.471848) in 3.97s 
Iter 28...	Training loss: 26489.279297 (3978.270101, 22511.009521) in 3.96s 
Iter 29...	Training loss: 25433.029297 (4049.480454, 21383.547043) in 3.91s 
Iter 30...	Training loss: 24420.509766 (4123.766803, 20296.740921) in 3.88s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.119709 HR: 0.169044
Top-10 Recall: 0.218172 Precision: 0.021817 NDCG: 0.135524 HR: 0.218172
Eval costs: 0.216092 s
Iter 31...	Training loss: 23311.777344 (4178.634325, 19133.141464) in 3.98s 
Iter 32...	Training loss: 22374.914062 (4238.487997, 18136.422562) in 3.90s 
Iter 33...	Training loss: 21603.462891 (4293.602473, 17309.863022) in 3.94s 
Iter 34...	Training loss: 20683.894531 (4337.873014, 16346.022629) in 3.89s 
Iter 35...	Training loss: 20068.205078 (4379.965850, 15688.241699) in 3.97s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.123130 HR: 0.173270
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.139167 HR: 0.222927
Eval costs: 0.219249 s
Iter 36...	Training loss: 19771.519531 (4425.512387, 15346.007675) in 3.84s 
Iter 37...	Training loss: 19143.734375 (4454.254911, 14689.478065) in 3.97s 
Iter 38...	Training loss: 18888.144531 (4482.421550, 14405.724266) in 3.84s 
Iter 39...	Training loss: 18253.166016 (4514.133257, 13739.032364) in 3.99s 
Iter 40...	Training loss: 18106.478516 (4536.627519, 13569.850685) in 3.84s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.124764 HR: 0.169572
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.144212 HR: 0.230322
Eval costs: 0.225276 s
Iter 41...	Training loss: 17635.097656 (4561.892901, 13073.203117) in 3.95s 
Iter 42...	Training loss: 17045.712891 (4576.436343, 12469.275246) in 3.86s 
Iter 43...	Training loss: 16863.359375 (4599.558960, 12263.802002) in 3.84s 
Iter 44...	Training loss: 16494.552734 (4616.750904, 11877.802689) in 3.96s 
Iter 45...	Training loss: 16201.030273 (4636.040471, 11564.989937) in 3.86s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.126749 HR: 0.171157
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.143431 HR: 0.222398
Eval costs: 0.228857 s
Iter 46...	Training loss: 15890.339844 (4646.262938, 11244.076050) in 3.96s 
Iter 47...	Training loss: 15591.631836 (4653.974605, 10937.656845) in 3.84s 
Iter 48...	Training loss: 15315.564453 (4665.846383, 10649.717125) in 3.95s 
Iter 49...	Training loss: 15158.610352 (4668.532769, 10490.076988) in 3.83s 
Iter 50...	Training loss: 14845.470703 (4673.004635, 10172.465912) in 3.96s 
Top-1 Recall: 0.083465 Precision: 0.083465 NDCG: 0.083465 HR: 0.083465
Top-5 Recall: 0.175383 Precision: 0.035077 NDCG: 0.130608 HR: 0.175383
Top-10 Recall: 0.220285 Precision: 0.022029 NDCG: 0.145087 HR: 0.220285
Eval costs: 0.230520 s
Iter 51...	Training loss: 14810.163086 (4679.799967, 10130.364143) in 3.86s 
Iter 52...	Training loss: 14407.657227 (4677.333124, 9730.322258) in 3.97s 
Iter 53...	Training loss: 14110.902344 (4690.413947, 9420.488739) in 3.86s 
Iter 54...	Training loss: 14077.279297 (4684.476762, 9392.801918) in 3.84s 
Iter 55...	Training loss: 13870.557617 (4683.601300, 9186.956688) in 3.98s 
Top-1 Recall: 0.080296 Precision: 0.080296 NDCG: 0.080296 HR: 0.080296
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.128537 HR: 0.173798
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.145299 HR: 0.226096
Eval costs: 0.235618 s
Iter 56...	Training loss: 13649.544922 (4688.497454, 8961.048248) in 3.86s 
Iter 57...	Training loss: 13506.135742 (4692.687170, 8813.448303) in 3.95s 
Iter 58...	Training loss: 13303.077148 (4689.927993, 8613.148926) in 3.86s 
Iter 59...	Training loss: 13163.433594 (4687.220683, 8476.212120) in 3.97s 
Iter 60...	Training loss: 12887.966797 (4690.868297, 8197.097294) in 3.84s 
Top-1 Recall: 0.081352 Precision: 0.081352 NDCG: 0.081352 HR: 0.081352
Top-5 Recall: 0.166403 Precision: 0.033281 NDCG: 0.125581 HR: 0.166403
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.142842 HR: 0.219757
Eval costs: 0.237328 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 538562.875000 (193302.575113, 345260.251221) in 4.07s 
Iter 2...	Training loss: 282513.718750 (15859.866743, 266653.898438) in 3.86s 
Iter 3...	Training loss: 239247.531250 (11598.740737, 227648.765991) in 3.96s 
Iter 4...	Training loss: 210078.531250 (9130.058796, 200948.487061) in 3.90s 
Iter 5...	Training loss: 185885.015625 (7251.060216, 178633.963257) in 3.98s 
Top-1 Recall: 0.035394 Precision: 0.035394 NDCG: 0.035394 HR: 0.035394
Top-5 Recall: 0.096672 Precision: 0.019334 NDCG: 0.066789 HR: 0.096672
Top-10 Recall: 0.133122 Precision: 0.013312 NDCG: 0.078478 HR: 0.133122
Eval costs: 0.176083 s
Iter 6...	Training loss: 166216.109375 (5864.025982, 160352.069824) in 3.87s 
Iter 7...	Training loss: 151104.390625 (4912.150278, 146192.244141) in 3.96s 
Iter 8...	Training loss: 139134.890625 (4243.243719, 134891.652466) in 3.84s 
Iter 9...	Training loss: 129222.554688 (3764.051845, 125458.512451) in 3.97s 
Iter 10...	Training loss: 120056.250000 (3426.261747, 116629.994141) in 3.86s 
Top-1 Recall: 0.049128 Precision: 0.049128 NDCG: 0.049128 HR: 0.049128
Top-5 Recall: 0.127839 Precision: 0.025568 NDCG: 0.088683 HR: 0.127839
Top-10 Recall: 0.170629 Precision: 0.017063 NDCG: 0.102668 HR: 0.170629
Eval costs: 0.177389 s
Iter 11...	Training loss: 111774.843750 (3177.745973, 108597.094421) in 3.95s 
Iter 12...	Training loss: 103978.976562 (2999.422453, 100979.561340) in 3.85s 
Iter 13...	Training loss: 96216.726562 (2870.748186, 93345.984680) in 3.86s 
Iter 14...	Training loss: 88853.234375 (2780.750129, 86072.487488) in 3.95s 
Iter 15...	Training loss: 81438.375000 (2717.219369, 78721.148193) in 3.85s 
Top-1 Recall: 0.059694 Precision: 0.059694 NDCG: 0.059694 HR: 0.059694
Top-5 Recall: 0.154253 Precision: 0.030851 NDCG: 0.108039 HR: 0.154253
Top-10 Recall: 0.212890 Precision: 0.021289 NDCG: 0.126684 HR: 0.212890
Eval costs: 0.187510 s
Iter 16...	Training loss: 74302.765625 (2676.422148, 71626.339905) in 3.98s 
Iter 17...	Training loss: 67643.335938 (2660.283955, 64983.051270) in 3.88s 
Iter 18...	Training loss: 61579.449219 (2653.578776, 58925.867676) in 3.95s 
Iter 19...	Training loss: 56212.617188 (2664.257425, 53548.363922) in 3.86s 
Iter 20...	Training loss: 51061.121094 (2680.404439, 48380.716644) in 3.95s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.118050 HR: 0.166931
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.137353 HR: 0.227153
Eval costs: 0.200404 s
Iter 21...	Training loss: 46731.539062 (2706.637177, 44024.906555) in 3.84s 
Iter 22...	Training loss: 43282.414062 (2730.729874, 40551.690674) in 4.01s 
Iter 23...	Training loss: 40190.738281 (2755.861567, 37434.878357) in 3.89s 
Iter 24...	Training loss: 37227.046875 (2775.333321, 34451.706024) in 3.89s 
Iter 25...	Training loss: 34931.980469 (2795.997393, 32135.983063) in 3.99s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.124958 HR: 0.173798
Top-10 Recall: 0.229266 Precision: 0.022927 NDCG: 0.143006 HR: 0.229266
Eval costs: 0.209508 s
Iter 26...	Training loss: 33207.726562 (2801.258561, 30406.466675) in 3.87s 
Iter 27...	Training loss: 30781.207031 (2809.857976, 27971.349030) in 3.98s 
Iter 28...	Training loss: 30093.173828 (2814.432003, 27278.742493) in 4.01s 
Iter 29...	Training loss: 28294.265625 (2816.448672, 25477.816986) in 3.97s 
Iter 30...	Training loss: 27000.458984 (2817.656497, 24182.801666) in 3.85s 
Top-1 Recall: 0.075541 Precision: 0.075541 NDCG: 0.075541 HR: 0.075541
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.127625 HR: 0.177496
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.145932 HR: 0.234020
Eval costs: 0.216834 s
Iter 31...	Training loss: 25966.457031 (2810.019150, 23156.437988) in 3.95s 
Iter 32...	Training loss: 25253.679688 (2805.953804, 22447.726349) in 3.90s 
Iter 33...	Training loss: 24235.191406 (2796.872108, 21438.316681) in 3.96s 
Iter 34...	Training loss: 23039.066406 (2788.204942, 20250.857986) in 3.87s 
Iter 35...	Training loss: 22356.498047 (2779.373797, 19577.126114) in 3.96s 
Top-1 Recall: 0.076070 Precision: 0.076070 NDCG: 0.076070 HR: 0.076070
Top-5 Recall: 0.178024 Precision: 0.035605 NDCG: 0.127840 HR: 0.178024
Top-10 Recall: 0.236133 Precision: 0.023613 NDCG: 0.146598 HR: 0.236133
Eval costs: 0.223634 s
Iter 36...	Training loss: 21684.458984 (2768.004478, 18916.450867) in 3.84s 
Iter 37...	Training loss: 20811.251953 (2757.620193, 18053.632294) in 3.90s 
Iter 38...	Training loss: 20256.814453 (2746.641228, 17510.171829) in 3.95s 
Iter 39...	Training loss: 19726.546875 (2734.492607, 16992.054962) in 3.90s 
Iter 40...	Training loss: 19120.320312 (2719.277224, 16401.043091) in 4.01s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.127229 HR: 0.176440
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.144687 HR: 0.230322
Eval costs: 0.228986 s
Iter 41...	Training loss: 18446.156250 (2705.958678, 15740.195511) in 3.85s 
Iter 42...	Training loss: 18199.732422 (2694.168026, 15505.564011) in 4.00s 
Iter 43...	Training loss: 17576.351562 (2679.983975, 14896.366554) in 3.87s 
Iter 44...	Training loss: 17284.996094 (2665.483726, 14619.512215) in 3.95s 
Iter 45...	Training loss: 16762.431641 (2648.397572, 14114.035431) in 3.84s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.179609 Precision: 0.035922 NDCG: 0.129016 HR: 0.179609
Top-10 Recall: 0.232964 Precision: 0.023296 NDCG: 0.146220 HR: 0.232964
Eval costs: 0.231467 s
Iter 46...	Training loss: 16480.078125 (2639.324237, 13840.754173) in 3.96s 
Iter 47...	Training loss: 15959.015625 (2625.490081, 13333.525612) in 3.85s 
Iter 48...	Training loss: 15658.732422 (2613.173392, 13045.558418) in 3.96s 
Iter 49...	Training loss: 15295.385742 (2599.549688, 12695.836113) in 3.87s 
Iter 50...	Training loss: 14919.811523 (2588.834176, 12330.977623) in 3.93s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.126221 HR: 0.174855
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.145369 HR: 0.234548
Eval costs: 0.339194 s
Iter 51...	Training loss: 14720.886719 (2572.982320, 12147.904678) in 3.84s 
Iter 52...	Training loss: 14242.332031 (2563.326139, 11679.005745) in 3.83s 
Iter 53...	Training loss: 14142.125000 (2551.588898, 11590.536606) in 3.97s 
Iter 54...	Training loss: 13879.115234 (2541.778331, 11337.336060) in 3.86s 
Iter 55...	Training loss: 13728.779297 (2530.465580, 11198.313164) in 3.95s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.124050 HR: 0.175911
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.141507 HR: 0.229794
Eval costs: 0.236255 s
Iter 56...	Training loss: 13334.068359 (2519.031288, 10815.037628) in 3.84s 
Iter 57...	Training loss: 12926.923828 (2508.201031, 10418.722130) in 3.95s 
Iter 58...	Training loss: 12959.766602 (2495.752915, 10464.013611) in 3.85s 
Iter 59...	Training loss: 12670.875977 (2488.502820, 10182.372803) in 3.94s 
Iter 60...	Training loss: 12412.492188 (2477.929481, 9934.561829) in 3.84s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.122956 HR: 0.171685
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.142619 HR: 0.232435
Eval costs: 0.244705 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1763929.125000 (193458.631688, 1570470.368164) in 4.09s 
Iter 2...	Training loss: 916491.500000 (15537.420971, 900954.033203) in 3.88s 
Iter 3...	Training loss: 584257.687500 (10793.764522, 573463.917969) in 3.98s 
Iter 4...	Training loss: 400133.468750 (8192.867602, 391940.613281) in 3.87s 
Iter 5...	Training loss: 289885.875000 (6328.649974, 283557.275024) in 3.87s 
Top-1 Recall: 0.036450 Precision: 0.036450 NDCG: 0.036450 HR: 0.036450
Top-5 Recall: 0.105652 Precision: 0.021130 NDCG: 0.072501 HR: 0.105652
Top-10 Recall: 0.146329 Precision: 0.014633 NDCG: 0.085493 HR: 0.146329
Eval costs: 0.279471 s
Iter 6...	Training loss: 222087.453125 (5071.020408, 217016.429199) in 3.87s 
Iter 7...	Training loss: 181343.906250 (4207.549051, 177136.331665) in 3.88s 
Iter 8...	Training loss: 155949.312500 (3592.938852, 152356.348022) in 3.95s 
Iter 9...	Training loss: 139383.062500 (3161.259818, 136221.812866) in 3.86s 
Iter 10...	Training loss: 127482.507812 (2845.180462, 124637.328247) in 3.98s 
Top-1 Recall: 0.056524 Precision: 0.056524 NDCG: 0.056524 HR: 0.056524
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.098254 HR: 0.136820
Top-10 Recall: 0.192816 Precision: 0.019282 NDCG: 0.116336 HR: 0.192816
Eval costs: 0.178310 s
Iter 11...	Training loss: 117912.984375 (2603.234866, 115309.744019) in 3.88s 
Iter 12...	Training loss: 110140.226562 (2410.966946, 107729.257446) in 3.96s 
Iter 13...	Training loss: 103242.304688 (2258.086565, 100984.210938) in 3.86s 
Iter 14...	Training loss: 97105.187500 (2130.681471, 94974.502808) in 3.97s 
Iter 15...	Training loss: 91155.250000 (2023.811918, 89131.430237) in 3.86s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.116663 HR: 0.163761
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.136019 HR: 0.223455
Eval costs: 0.188540 s
Iter 16...	Training loss: 85359.539062 (1933.755738, 83425.791565) in 3.99s 
Iter 17...	Training loss: 79782.257812 (1857.063204, 77925.191895) in 3.89s 
Iter 18...	Training loss: 74213.406250 (1793.284009, 72420.133362) in 3.88s 
Iter 19...	Training loss: 69388.960938 (1740.183776, 67648.784424) in 3.96s 
Iter 20...	Training loss: 64705.957031 (1697.383007, 63008.573792) in 3.86s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.123562 HR: 0.173798
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.142910 HR: 0.233492
Eval costs: 0.197498 s
Iter 21...	Training loss: 60401.085938 (1659.382232, 58741.706482) in 3.96s 
Iter 22...	Training loss: 56618.031250 (1627.916938, 54990.112457) in 3.85s 
Iter 23...	Training loss: 52536.230469 (1602.039792, 50934.185028) in 3.96s 
Iter 24...	Training loss: 49211.511719 (1579.451165, 47632.058105) in 3.85s 
Iter 25...	Training loss: 46500.253906 (1558.890743, 44941.362427) in 3.97s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.124728 HR: 0.177496
Top-10 Recall: 0.243529 Precision: 0.024353 NDCG: 0.146076 HR: 0.243529
Eval costs: 0.208833 s
Iter 26...	Training loss: 43687.839844 (1542.704309, 42145.132751) in 3.87s 
Iter 27...	Training loss: 41326.691406 (1527.227395, 39799.467194) in 3.97s 
Iter 28...	Training loss: 39224.058594 (1512.232168, 37711.828522) in 3.86s 
Iter 29...	Training loss: 37227.226562 (1498.606483, 35728.622253) in 3.85s 
Iter 30...	Training loss: 35341.609375 (1485.061199, 33856.544281) in 3.97s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.124146 HR: 0.177496
Top-10 Recall: 0.242472 Precision: 0.024247 NDCG: 0.144817 HR: 0.242472
Eval costs: 0.218671 s
Iter 31...	Training loss: 33852.199219 (1474.212379, 32377.985626) in 3.87s 
Iter 32...	Training loss: 32382.632812 (1464.496661, 30918.134949) in 3.96s 
Iter 33...	Training loss: 30848.488281 (1453.437422, 29395.054962) in 3.86s 
Iter 34...	Training loss: 25103.380859 (0.000000, 25103.379822) in 2.73s 
Iter 35...	Training loss: 32656.046875 (2827.935553, 29828.112198) in 5.13s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.122766 HR: 0.175911
Top-10 Recall: 0.245642 Precision: 0.024564 NDCG: 0.145341 HR: 0.245642
Eval costs: 0.223639 s
Iter 36...	Training loss: 27788.869141 (1444.039396, 26344.828857) in 3.96s 
Iter 37...	Training loss: 26831.593750 (1425.939478, 25405.655167) in 3.88s 
Iter 38...	Training loss: 25797.890625 (1413.767205, 24384.124542) in 4.00s 
Iter 39...	Training loss: 24754.236328 (1404.464000, 23349.771088) in 3.86s 
Iter 40...	Training loss: 24165.531250 (1395.773893, 22769.758224) in 3.96s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.123793 HR: 0.172742
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.144075 HR: 0.235077
Eval costs: 0.228501 s
Iter 41...	Training loss: 23422.501953 (1388.408248, 22034.095001) in 3.88s 
Iter 42...	Training loss: 22939.251953 (1381.926159, 21557.326782) in 3.87s 
Iter 43...	Training loss: 22159.548828 (1376.939632, 20782.606293) in 3.99s 
Iter 44...	Training loss: 21413.603516 (1371.004360, 20042.598495) in 3.86s 
Iter 45...	Training loss: 20922.181641 (1365.217310, 19556.965256) in 3.98s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.122184 HR: 0.175911
Top-10 Recall: 0.243001 Precision: 0.024300 NDCG: 0.143906 HR: 0.243001
Eval costs: 0.232620 s
Iter 46...	Training loss: 20335.732422 (1359.343226, 18976.386414) in 3.85s 
Iter 47...	Training loss: 19922.013672 (1356.055626, 18565.957748) in 3.96s 
Iter 48...	Training loss: 19234.712891 (1351.163499, 17883.548042) in 3.86s 
Iter 49...	Training loss: 18905.357422 (1346.500767, 17558.856064) in 3.99s 
Iter 50...	Training loss: 18375.136719 (1343.696808, 17031.441559) in 3.87s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.117988 HR: 0.167987
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.139923 HR: 0.235077
Eval costs: 0.235679 s
Iter 51...	Training loss: 17819.958984 (1339.731406, 16480.226349) in 3.97s 
Iter 52...	Training loss: 17806.537109 (1335.621098, 16470.915413) in 3.87s 
Iter 53...	Training loss: 17362.318359 (1331.431674, 16030.886612) in 3.98s 
Iter 54...	Training loss: 16993.255859 (1330.496400, 15662.759659) in 3.87s 
Iter 55...	Training loss: 16519.814453 (1326.952725, 15192.860916) in 3.86s 
Top-1 Recall: 0.065504 Precision: 0.065504 NDCG: 0.065504 HR: 0.065504
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.118707 HR: 0.170629
Top-10 Recall: 0.238774 Precision: 0.023877 NDCG: 0.140600 HR: 0.238774
Eval costs: 0.238196 s
Iter 56...	Training loss: 16256.391602 (1324.222136, 14932.170319) in 3.96s 
Iter 57...	Training loss: 15802.901367 (1322.242480, 14480.658165) in 3.86s 
Iter 58...	Training loss: 15596.875977 (1318.623581, 14278.250603) in 3.96s 
Iter 59...	Training loss: 15350.257812 (1316.732778, 14033.526245) in 3.87s 
Iter 60...	Training loss: 15109.164062 (1314.596727, 13794.567169) in 3.96s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.118132 HR: 0.166931
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.137777 HR: 0.228209
Eval costs: 0.238392 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 315239.125000 (107728.537176, 207510.576416) in 5.72s 
Iter 2...	Training loss: 210539.234375 (19913.658010, 190625.576172) in 5.85s 
Iter 3...	Training loss: 195955.390625 (11880.953870, 184074.437256) in 5.84s 
Iter 4...	Training loss: 187191.203125 (8238.541657, 178952.685181) in 5.87s 
Iter 5...	Training loss: 181012.375000 (6565.815455, 174446.549072) in 5.84s 
Top-1 Recall: 0.008980 Precision: 0.008980 NDCG: 0.008980 HR: 0.008980
Top-5 Recall: 0.060750 Precision: 0.012150 NDCG: 0.035376 HR: 0.060750
Top-10 Recall: 0.089805 Precision: 0.008980 NDCG: 0.044758 HR: 0.089805
Eval costs: 0.172351 s
Iter 6...	Training loss: 175186.328125 (5624.124401, 169562.192627) in 5.84s 
Iter 7...	Training loss: 169043.625000 (4989.828783, 164053.802124) in 5.68s 
Iter 8...	Training loss: 162019.656250 (4543.196591, 157476.443848) in 5.85s 
Iter 9...	Training loss: 153377.203125 (4191.453648, 149185.754517) in 5.85s 
Iter 10...	Training loss: 142847.656250 (3932.254804, 138915.403564) in 5.68s 
Top-1 Recall: 0.029054 Precision: 0.029054 NDCG: 0.029054 HR: 0.029054
Top-5 Recall: 0.096144 Precision: 0.019229 NDCG: 0.062705 HR: 0.096144
Top-10 Recall: 0.138933 Precision: 0.013893 NDCG: 0.076460 HR: 0.138933
Eval costs: 0.171544 s
Iter 11...	Training loss: 131381.328125 (3716.548763, 127664.777344) in 5.83s 
Iter 12...	Training loss: 120235.343750 (3558.725600, 116676.623535) in 5.84s 
Iter 13...	Training loss: 108589.007812 (3436.046928, 105152.966980) in 5.87s 
Iter 14...	Training loss: 97355.375000 (3338.357158, 94017.018433) in 5.72s 
Iter 15...	Training loss: 86278.445312 (3254.373807, 83024.073547) in 5.85s 
Top-1 Recall: 0.043317 Precision: 0.043317 NDCG: 0.043317 HR: 0.043317
Top-5 Recall: 0.116746 Precision: 0.023349 NDCG: 0.081442 HR: 0.116746
Top-10 Recall: 0.166403 Precision: 0.016640 NDCG: 0.097339 HR: 0.166403
Eval costs: 0.190754 s
Iter 16...	Training loss: 76304.515625 (3190.194465, 73114.331909) in 5.84s 
Iter 17...	Training loss: 67251.804688 (3145.338146, 64106.467651) in 5.87s 
Iter 18...	Training loss: 59712.402344 (3097.106026, 56615.294830) in 5.70s 
Iter 19...	Training loss: 53131.933594 (3062.044400, 50069.891632) in 5.85s 
Iter 20...	Training loss: 44553.933594 (0.000000, 44553.936035) in 3.04s 
Top-1 Recall: 0.047015 Precision: 0.047015 NDCG: 0.047015 HR: 0.047015
Top-5 Recall: 0.133122 Precision: 0.026624 NDCG: 0.091239 HR: 0.133122
Top-10 Recall: 0.189118 Precision: 0.018912 NDCG: 0.109410 HR: 0.189118
Eval costs: 0.203448 s
Iter 21...	Training loss: 46721.093750 (6030.662578, 40690.426331) in 8.66s 
Iter 22...	Training loss: 39603.191406 (2972.403759, 36630.790344) in 5.87s 
Iter 23...	Training loss: 36029.960938 (2989.137491, 33040.822235) in 5.70s 
Iter 24...	Training loss: 33572.613281 (2978.496272, 30594.118347) in 5.86s 
Iter 25...	Training loss: 31034.103516 (2971.753819, 28062.348358) in 5.86s 
Top-1 Recall: 0.049657 Precision: 0.049657 NDCG: 0.049657 HR: 0.049657
Top-5 Recall: 0.145800 Precision: 0.029160 NDCG: 0.100098 HR: 0.145800
Top-10 Recall: 0.206022 Precision: 0.020602 NDCG: 0.119643 HR: 0.206022
Eval costs: 0.209810 s
Iter 26...	Training loss: 29169.796875 (2969.239748, 26200.557266) in 5.87s 
Iter 27...	Training loss: 27309.177734 (2962.979946, 24346.198578) in 5.68s 
Iter 28...	Training loss: 25732.617188 (2962.731854, 22769.885025) in 5.83s 
Iter 29...	Training loss: 24364.597656 (2960.243070, 21404.355743) in 5.85s 
Iter 30...	Training loss: 23409.445312 (2952.048504, 20457.399460) in 5.71s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.153196 Precision: 0.030639 NDCG: 0.104398 HR: 0.153196
Top-10 Recall: 0.211305 Precision: 0.021130 NDCG: 0.123287 HR: 0.211305
Eval costs: 0.378234 s
Iter 31...	Training loss: 22064.861328 (2949.253575, 19115.606857) in 5.67s 
Iter 32...	Training loss: 20972.568359 (2949.744498, 18022.825562) in 5.82s 
Iter 33...	Training loss: 20302.984375 (2947.263454, 17355.718918) in 5.83s 
Iter 34...	Training loss: 19389.031250 (2942.282944, 16446.747208) in 5.83s 
Iter 35...	Training loss: 18623.390625 (2948.275949, 15675.113968) in 5.69s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.116635 HR: 0.167459
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.133547 HR: 0.219757
Eval costs: 0.221370 s
Iter 36...	Training loss: 17979.041016 (2953.661990, 15025.378586) in 5.85s 
Iter 37...	Training loss: 17345.914062 (2947.255872, 14398.657486) in 5.85s 
Iter 38...	Training loss: 16561.269531 (2951.763073, 13609.506363) in 5.83s 
Iter 39...	Training loss: 16154.208984 (2959.717188, 13194.492271) in 5.66s 
Iter 40...	Training loss: 15636.273438 (2949.174349, 12687.097954) in 5.87s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.117577 HR: 0.167987
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.135472 HR: 0.222927
Eval costs: 0.222793 s
Iter 41...	Training loss: 15307.359375 (2952.854666, 12354.503708) in 5.85s 
Iter 42...	Training loss: 15026.113281 (2961.112455, 12065.000237) in 5.84s 
Iter 43...	Training loss: 14309.275391 (2957.381121, 11351.893974) in 5.70s 
Iter 44...	Training loss: 14100.370117 (2958.983537, 11141.386200) in 5.83s 
Iter 45...	Training loss: 13513.914062 (2964.044677, 10549.869354) in 5.85s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.119313 HR: 0.170100
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.135453 HR: 0.219757
Eval costs: 0.226716 s
Iter 46...	Training loss: 13222.733398 (2968.292801, 10254.441856) in 5.84s 
Iter 47...	Training loss: 13283.116211 (2968.745221, 10314.370590) in 5.71s 
Iter 48...	Training loss: 9564.904297 (0.000000, 9564.904213) in 3.09s 
Iter 49...	Training loss: 15427.190430 (5834.291132, 9592.900421) in 8.64s 
Iter 50...	Training loss: 12323.874023 (2930.120855, 9393.753700) in 5.83s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.166403 Precision: 0.033281 NDCG: 0.119294 HR: 0.166403
Top-10 Recall: 0.215531 Precision: 0.021553 NDCG: 0.135228 HR: 0.215531
Eval costs: 0.230116 s
Iter 51...	Training loss: 11955.431641 (2967.662317, 8987.769157) in 5.69s 
Iter 52...	Training loss: 11887.728516 (2979.795315, 8907.933388) in 5.84s 
Iter 53...	Training loss: 11714.735352 (2989.855519, 8724.881401) in 5.83s 
Iter 54...	Training loss: 11284.611328 (2995.350605, 8289.261108) in 5.82s 
Iter 55...	Training loss: 11226.604492 (2999.027727, 8227.576302) in 5.70s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.163233 Precision: 0.032647 NDCG: 0.117475 HR: 0.163233
Top-10 Recall: 0.215003 Precision: 0.021500 NDCG: 0.134276 HR: 0.215003
Eval costs: 0.233390 s
Iter 56...	Training loss: 11029.439453 (3000.006952, 8029.431892) in 5.83s 
Iter 57...	Training loss: 10767.272461 (2999.667266, 7767.605484) in 5.84s 
Iter 58...	Training loss: 10731.233398 (3004.512902, 7726.719299) in 5.86s 
Iter 59...	Training loss: 10490.439453 (2998.832414, 7491.606804) in 5.69s 
Iter 60...	Training loss: 10251.844727 (3007.264210, 7244.580303) in 5.84s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.119032 HR: 0.166931
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.136527 HR: 0.221342
Eval costs: 0.235250 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 341328.875000 (107706.486906, 233622.412109) in 5.96s 
Iter 2...	Training loss: 231032.859375 (19773.184277, 211259.673950) in 5.86s 
Iter 3...	Training loss: 214145.390625 (11745.914593, 202399.483643) in 5.84s 
Iter 4...	Training loss: 203693.500000 (8118.241988, 195575.260620) in 5.71s 
Iter 5...	Training loss: 195755.625000 (6405.699326, 189349.934570) in 5.88s 
Top-1 Recall: 0.014263 Precision: 0.014263 NDCG: 0.014263 HR: 0.014263
Top-5 Recall: 0.070787 Precision: 0.014157 NDCG: 0.042093 HR: 0.070787
Top-10 Recall: 0.095615 Precision: 0.009562 NDCG: 0.050267 HR: 0.095615
Eval costs: 0.176020 s
Iter 6...	Training loss: 188076.453125 (5413.986232, 182662.450439) in 5.85s 
Iter 7...	Training loss: 179998.781250 (4774.380594, 175224.419067) in 5.85s 
Iter 8...	Training loss: 170767.046875 (4292.192904, 166474.845947) in 5.87s 
Iter 9...	Training loss: 160110.812500 (3960.864849, 156149.951294) in 5.69s 
Iter 10...	Training loss: 147513.656250 (3690.822881, 143822.832275) in 5.85s 
Top-1 Recall: 0.033281 Precision: 0.033281 NDCG: 0.033281 HR: 0.033281
Top-5 Recall: 0.096144 Precision: 0.019229 NDCG: 0.064222 HR: 0.096144
Top-10 Recall: 0.143159 Precision: 0.014316 NDCG: 0.079409 HR: 0.143159
Eval costs: 0.178706 s
Iter 11...	Training loss: 135292.296875 (3497.787136, 131794.508423) in 5.88s 
Iter 12...	Training loss: 123445.937500 (3349.996210, 120095.940430) in 5.86s 
Iter 13...	Training loss: 111339.468750 (3234.412585, 108105.064270) in 5.68s 
Iter 14...	Training loss: 99358.906250 (3146.058968, 96212.837708) in 5.86s 
Iter 15...	Training loss: 88560.421875 (3084.794884, 85475.625305) in 5.88s 
Top-1 Recall: 0.042261 Precision: 0.042261 NDCG: 0.042261 HR: 0.042261
Top-5 Recall: 0.121500 Precision: 0.024300 NDCG: 0.082149 HR: 0.121500
Top-10 Recall: 0.183835 Precision: 0.018384 NDCG: 0.102187 HR: 0.183835
Eval costs: 0.193958 s
Iter 16...	Training loss: 78597.375000 (3020.487803, 75576.889709) in 5.86s 
Iter 17...	Training loss: 69973.117188 (2976.719129, 66996.409424) in 5.72s 
Iter 18...	Training loss: 62804.492188 (2944.312932, 59860.185364) in 5.84s 
Iter 19...	Training loss: 56609.117188 (2912.809246, 53696.307678) in 5.86s 
Iter 20...	Training loss: 51404.003906 (2890.690458, 48513.312744) in 5.84s 
Top-1 Recall: 0.049128 Precision: 0.049128 NDCG: 0.049128 HR: 0.049128
Top-5 Recall: 0.139461 Precision: 0.027892 NDCG: 0.095580 HR: 0.139461
Top-10 Recall: 0.202853 Precision: 0.020285 NDCG: 0.116116 HR: 0.202853
Eval costs: 0.205224 s
Iter 21...	Training loss: 47097.523438 (2864.864113, 44232.658234) in 5.69s 
Iter 22...	Training loss: 43561.511719 (2847.680092, 40713.835815) in 5.85s 
Iter 23...	Training loss: 40127.304688 (2834.397523, 37292.913483) in 5.86s 
Iter 24...	Training loss: 37607.457031 (2817.436106, 34790.020355) in 5.84s 
Iter 25...	Training loss: 35104.667969 (2811.700968, 32292.968842) in 5.70s 
Top-1 Recall: 0.057052 Precision: 0.057052 NDCG: 0.057052 HR: 0.057052
Top-5 Recall: 0.160063 Precision: 0.032013 NDCG: 0.109365 HR: 0.160063
Top-10 Recall: 0.215531 Precision: 0.021553 NDCG: 0.127225 HR: 0.215531
Eval costs: 0.211039 s
Iter 26...	Training loss: 33200.949219 (2800.554205, 30400.393951) in 5.86s 
Iter 27...	Training loss: 31164.667969 (2786.715694, 28377.952728) in 5.88s 
Iter 28...	Training loss: 29633.644531 (2779.837601, 26853.804626) in 5.84s 
Iter 29...	Training loss: 28177.400391 (2771.972398, 25405.428085) in 5.69s 
Iter 30...	Training loss: 27049.609375 (2762.159285, 24287.451462) in 5.85s 
Top-1 Recall: 0.058637 Precision: 0.058637 NDCG: 0.058637 HR: 0.058637
Top-5 Recall: 0.161120 Precision: 0.032224 NDCG: 0.111384 HR: 0.161120
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.131026 HR: 0.221870
Eval costs: 0.219044 s
Iter 31...	Training loss: 25852.152344 (2761.200409, 23090.952744) in 5.85s 
Iter 32...	Training loss: 24653.712891 (2757.504303, 21896.207443) in 5.87s 
Iter 33...	Training loss: 23729.091797 (2742.608520, 20986.482788) in 5.71s 
Iter 34...	Training loss: 22821.357422 (2742.359028, 20078.998016) in 5.86s 
Iter 35...	Training loss: 22092.783203 (2737.205904, 19355.577805) in 5.88s 
Top-1 Recall: 0.060750 Precision: 0.060750 NDCG: 0.060750 HR: 0.060750
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.116141 HR: 0.168516
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.133809 HR: 0.223455
Eval costs: 0.222713 s
Iter 36...	Training loss: 21457.080078 (2731.284758, 18725.795349) in 5.87s 
Iter 37...	Training loss: 20653.894531 (2724.336571, 17929.555923) in 5.85s 
Iter 38...	Training loss: 20008.376953 (2724.495630, 17283.880997) in 5.69s 
Iter 39...	Training loss: 19162.720703 (2721.075032, 16441.647491) in 5.84s 
Iter 40...	Training loss: 18826.007812 (2715.778290, 16110.228592) in 5.85s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.116916 HR: 0.167987
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.135648 HR: 0.225568
Eval costs: 0.223278 s
Iter 41...	Training loss: 18122.808594 (2711.135193, 15411.673676) in 5.86s 
Iter 42...	Training loss: 17551.486328 (2706.519928, 14844.966400) in 5.70s 
Iter 43...	Training loss: 17294.644531 (2705.133598, 14589.509979) in 5.86s 
Iter 44...	Training loss: 16712.533203 (2699.402297, 14013.130508) in 5.85s 
Iter 45...	Training loss: 16239.718750 (2695.602613, 13544.115860) in 5.85s 
Top-1 Recall: 0.064448 Precision: 0.064448 NDCG: 0.064448 HR: 0.064448
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.117635 HR: 0.169044
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.136391 HR: 0.227153
Eval costs: 0.228894 s
Iter 46...	Training loss: 11586.803711 (0.000000, 11586.802780) in 3.08s 
Iter 47...	Training loss: 18391.255859 (5213.736748, 13177.520164) in 8.49s 
Iter 48...	Training loss: 15153.541992 (2654.206943, 12499.334755) in 5.86s 
Iter 49...	Training loss: 14745.157227 (2672.599599, 12072.557716) in 5.86s 
Iter 50...	Training loss: 14367.925781 (2677.339320, 11690.585533) in 5.70s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.115237 HR: 0.162176
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.135481 HR: 0.225040
Eval costs: 0.230555 s
Iter 51...	Training loss: 13877.730469 (2674.384736, 11203.345406) in 5.88s 
Iter 52...	Training loss: 13663.462891 (2672.314000, 10991.149170) in 5.85s 
Iter 53...	Training loss: 13330.212891 (2669.852992, 10660.358635) in 5.85s 
Iter 54...	Training loss: 13113.438477 (2659.750090, 10453.689072) in 5.70s 
Iter 55...	Training loss: 12825.941406 (2661.317258, 10164.625313) in 5.84s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.118213 HR: 0.165346
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.138083 HR: 0.227153
Eval costs: 0.234758 s
Iter 56...	Training loss: 12302.293945 (2658.035376, 9644.258308) in 5.86s 
Iter 57...	Training loss: 12276.128906 (2654.037892, 9622.092255) in 5.84s 
Iter 58...	Training loss: 11935.348633 (2646.374379, 9288.973892) in 5.69s 
Iter 59...	Training loss: 11752.536133 (2642.851418, 9109.685486) in 5.84s 
Iter 60...	Training loss: 11264.622070 (2636.577157, 8628.043770) in 5.85s 
Top-1 Recall: 0.064448 Precision: 0.064448 NDCG: 0.064448 HR: 0.064448
Top-5 Recall: 0.163233 Precision: 0.032647 NDCG: 0.115902 HR: 0.163233
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.134951 HR: 0.222398
Eval costs: 0.236307 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 580329.000000 (108034.472263, 472294.545898) in 5.96s 
Iter 2...	Training loss: 388377.375000 (19662.367863, 368715.025146) in 5.86s 
Iter 3...	Training loss: 332544.093750 (11121.582316, 321422.498047) in 5.70s 
Iter 4...	Training loss: 294890.281250 (7324.636669, 287565.600830) in 5.87s 
Iter 5...	Training loss: 264131.687500 (5594.899334, 258536.770508) in 5.85s 
Top-1 Recall: 0.029054 Precision: 0.029054 NDCG: 0.029054 HR: 0.029054
Top-5 Recall: 0.095087 Precision: 0.019017 NDCG: 0.062691 HR: 0.095087
Top-10 Recall: 0.134707 Precision: 0.013471 NDCG: 0.075441 HR: 0.134707
Eval costs: 0.178694 s
Iter 6...	Training loss: 235442.578125 (4643.766881, 230798.822998) in 5.86s 
Iter 7...	Training loss: 208196.140625 (4063.182263, 204132.951294) in 5.83s 
Iter 8...	Training loss: 183132.375000 (3654.185088, 179478.214844) in 5.71s 
Iter 9...	Training loss: 160890.875000 (3370.326443, 157520.543945) in 5.85s 
Iter 10...	Training loss: 141943.000000 (3157.805959, 138785.171753) in 5.85s 
Top-1 Recall: 0.049657 Precision: 0.049657 NDCG: 0.049657 HR: 0.049657
Top-5 Recall: 0.137348 Precision: 0.027470 NDCG: 0.093675 HR: 0.137348
Top-10 Recall: 0.197570 Precision: 0.019757 NDCG: 0.112902 HR: 0.197570
Eval costs: 0.189412 s
Iter 11...	Training loss: 125772.968750 (2999.197049, 122773.774902) in 5.85s 
Iter 12...	Training loss: 112422.398438 (2868.235403, 109554.171265) in 5.70s 
Iter 13...	Training loss: 100385.976562 (2762.336826, 97623.638855) in 5.86s 
Iter 14...	Training loss: 90080.367188 (2677.031705, 87403.333374) in 5.87s 
Iter 15...	Training loss: 80977.640625 (2607.475078, 78370.158691) in 5.86s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.159007 Precision: 0.031801 NDCG: 0.113205 HR: 0.159007
Top-10 Recall: 0.220814 Precision: 0.022081 NDCG: 0.133169 HR: 0.220814
Eval costs: 0.193513 s
Iter 16...	Training loss: 72923.476562 (2550.224596, 70373.252747) in 5.71s 
Iter 17...	Training loss: 66174.859375 (2492.333511, 63682.524292) in 5.92s 
Iter 18...	Training loss: 60017.890625 (2447.261519, 57570.630707) in 5.87s 
Iter 19...	Training loss: 54298.179688 (2407.519460, 51890.660583) in 5.91s 
Iter 20...	Training loss: 49619.910156 (2374.132168, 47245.777466) in 5.71s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.120151 HR: 0.167459
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.141882 HR: 0.235077
Eval costs: 0.203118 s
Iter 21...	Training loss: 45073.871094 (2343.176770, 42730.697296) in 5.88s 
Iter 22...	Training loss: 41357.195312 (2313.020674, 39044.179993) in 5.86s 
Iter 23...	Training loss: 37914.695312 (2284.847175, 35629.850800) in 5.86s 
Iter 24...	Training loss: 35050.277344 (2265.735471, 32784.540863) in 5.69s 
Iter 25...	Training loss: 32578.542969 (2241.145905, 30337.398193) in 5.88s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.122313 HR: 0.173270
Top-10 Recall: 0.239303 Precision: 0.023930 NDCG: 0.143441 HR: 0.239303
Eval costs: 0.211648 s
Iter 26...	Training loss: 30434.501953 (2224.549358, 28209.952454) in 5.87s 
Iter 27...	Training loss: 28347.902344 (2202.907357, 26144.994751) in 5.87s 
Iter 28...	Training loss: 26869.994141 (2186.324690, 24683.669800) in 5.72s 
Iter 29...	Training loss: 25286.554688 (2161.533948, 23125.017715) in 5.84s 
Iter 30...	Training loss: 23651.642578 (2151.362945, 21500.279327) in 5.84s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.124387 HR: 0.175911
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.143408 HR: 0.234548
Eval costs: 0.215599 s
Iter 31...	Training loss: 22503.730469 (2137.342190, 20366.388474) in 5.83s 
Iter 32...	Training loss: 21310.355469 (2121.412635, 19188.940826) in 5.68s 
Iter 33...	Training loss: 20331.703125 (2105.250890, 18226.451675) in 5.84s 
Iter 34...	Training loss: 19550.578125 (2095.730702, 17454.847809) in 5.85s 
Iter 35...	Training loss: 18657.548828 (2082.947285, 16574.601021) in 5.83s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.122511 HR: 0.173798
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.140085 HR: 0.228209
Eval costs: 0.221684 s
Iter 36...	Training loss: 17993.496094 (2067.480450, 15926.015289) in 5.82s 
Iter 37...	Training loss: 17157.667969 (2057.776039, 15099.891876) in 5.67s 
Iter 38...	Training loss: 16420.031250 (2042.928101, 14377.103905) in 5.81s 
Iter 39...	Training loss: 16005.276367 (2031.820817, 13973.455902) in 5.81s 
Iter 40...	Training loss: 15352.214844 (2020.460370, 13331.755287) in 5.67s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.121991 HR: 0.169572
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.141985 HR: 0.231907
Eval costs: 0.385905 s
Iter 41...	Training loss: 14779.122070 (2011.733235, 12767.389000) in 5.69s 
Iter 42...	Training loss: 14335.836914 (2002.233146, 12333.603981) in 5.81s 
Iter 43...	Training loss: 14080.564453 (1989.820433, 12090.743744) in 5.81s 
Iter 44...	Training loss: 13608.073242 (1981.391296, 11626.682304) in 5.83s 
Iter 45...	Training loss: 13255.414062 (1971.200152, 11284.215019) in 5.66s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.118636 HR: 0.163761
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.138675 HR: 0.225040
Eval costs: 0.230380 s
Iter 46...	Training loss: 13035.682617 (1961.761290, 11073.921913) in 5.82s 
Iter 47...	Training loss: 12495.787109 (1950.417480, 10545.370560) in 5.81s 
Iter 48...	Training loss: 12098.855469 (1943.696575, 10155.157806) in 5.81s 
Iter 49...	Training loss: 12107.478516 (1934.953031, 10172.526657) in 5.66s 
Iter 50...	Training loss: 11857.046875 (1926.956239, 9930.090088) in 5.82s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.118305 HR: 0.165346
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.138008 HR: 0.226096
Eval costs: 0.236942 s
Iter 51...	Training loss: 11366.482422 (1917.165329, 9449.317440) in 5.83s 
Iter 52...	Training loss: 11053.278320 (1909.236671, 9144.041389) in 5.81s 
Iter 53...	Training loss: 10908.176758 (1903.588066, 9004.589859) in 5.67s 
Iter 54...	Training loss: 10525.389648 (1895.611679, 8629.778896) in 5.82s 
Iter 55...	Training loss: 10359.845703 (1888.436982, 8471.408241) in 5.83s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.119177 HR: 0.165346
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.139066 HR: 0.227153
Eval costs: 0.247427 s
Iter 56...	Training loss: 10311.468750 (1877.968632, 8433.500248) in 5.83s 
Iter 57...	Training loss: 10060.247070 (1871.476850, 8188.770401) in 5.67s 
Iter 58...	Training loss: 9746.042969 (1866.665814, 7879.377567) in 5.83s 
Iter 59...	Training loss: 9655.144531 (1860.024574, 7795.119808) in 5.83s 
Iter 60...	Training loss: 9457.590820 (1852.390265, 7605.199673) in 5.82s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.119133 HR: 0.165874
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.137532 HR: 0.222927
Eval costs: 0.240210 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2856737.000000 (108350.004383, 2748387.177734) in 5.78s 
Iter 2...	Training loss: 1819949.875000 (19102.888335, 1800847.043945) in 5.84s 
Iter 3...	Training loss: 1346677.750000 (10029.870498, 1336647.945312) in 5.86s 
Iter 4...	Training loss: 1033573.937500 (6289.719561, 1027284.177734) in 5.85s 
Iter 5...	Training loss: 799601.000000 (4716.290123, 794884.658691) in 5.85s 
Top-1 Recall: 0.011622 Precision: 0.011622 NDCG: 0.011622 HR: 0.011622
Top-5 Recall: 0.039091 Precision: 0.007818 NDCG: 0.025197 HR: 0.039091
Top-10 Recall: 0.063391 Precision: 0.006339 NDCG: 0.032870 HR: 0.063391
Eval costs: 0.173077 s
Iter 6...	Training loss: 615364.812500 (3892.575592, 611472.337402) in 5.84s 
Iter 7...	Training loss: 472968.625000 (3384.751155, 469583.861816) in 5.69s 
Iter 8...	Training loss: 366106.656250 (3053.414242, 363053.260010) in 5.85s 
Iter 9...	Training loss: 288893.375000 (2830.226582, 286063.138916) in 5.83s 
Iter 10...	Training loss: 235734.125000 (2650.728017, 233083.360596) in 5.68s 
Top-1 Recall: 0.049657 Precision: 0.049657 NDCG: 0.049657 HR: 0.049657
Top-5 Recall: 0.142631 Precision: 0.028526 NDCG: 0.097592 HR: 0.142631
Top-10 Recall: 0.206022 Precision: 0.020602 NDCG: 0.118224 HR: 0.206022
Eval costs: 0.343018 s
Iter 11...	Training loss: 197151.765625 (2512.388744, 194639.381836) in 5.67s 
Iter 12...	Training loss: 168691.828125 (2388.891240, 166302.933350) in 5.83s 
Iter 13...	Training loss: 147079.937500 (2291.814243, 144788.107178) in 5.92s 
Iter 14...	Training loss: 129850.671875 (2202.152318, 127648.512695) in 5.83s 
Iter 15...	Training loss: 116574.304688 (2122.243158, 114452.071777) in 5.69s 
Top-1 Recall: 0.060750 Precision: 0.060750 NDCG: 0.060750 HR: 0.060750
Top-5 Recall: 0.164289 Precision: 0.032858 NDCG: 0.113090 HR: 0.164289
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.134217 HR: 0.230322
Eval costs: 0.193360 s
Iter 16...	Training loss: 105215.421875 (2053.840901, 103161.583984) in 5.87s 
Iter 17...	Training loss: 96200.656250 (1995.225669, 94205.431519) in 5.86s 
Iter 18...	Training loss: 88111.031250 (1936.310211, 86174.727722) in 5.83s 
Iter 19...	Training loss: 81512.867188 (1888.491249, 79624.378662) in 5.69s 
Iter 20...	Training loss: 75506.789062 (1847.143504, 73659.645081) in 5.86s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.118069 HR: 0.165874
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.137680 HR: 0.226096
Eval costs: 0.198128 s
Iter 21...	Training loss: 70072.195312 (1796.852765, 68275.339111) in 5.84s 
Iter 22...	Training loss: 65400.082031 (1764.910645, 63635.172516) in 5.84s 
Iter 23...	Training loss: 61496.203125 (1734.825215, 59761.379700) in 5.68s 
Iter 24...	Training loss: 57557.402344 (1702.741087, 55854.655945) in 5.83s 
Iter 25...	Training loss: 54309.410156 (1672.850215, 52636.561066) in 5.82s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.118880 HR: 0.166931
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.140372 HR: 0.234020
Eval costs: 0.205205 s
Iter 26...	Training loss: 51259.546875 (1650.809120, 49608.737488) in 5.83s 
Iter 27...	Training loss: 48301.578125 (1627.801640, 46673.774780) in 5.67s 
Iter 28...	Training loss: 45823.984375 (1605.972282, 44218.009338) in 5.83s 
Iter 29...	Training loss: 43509.386719 (1585.508070, 41923.874542) in 5.83s 
Iter 30...	Training loss: 41692.441406 (1567.540138, 40124.904358) in 5.81s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.161648 Precision: 0.032330 NDCG: 0.115958 HR: 0.161648
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.138995 HR: 0.233492
Eval costs: 0.214656 s
Iter 31...	Training loss: 39397.718750 (1554.286625, 37843.430679) in 5.68s 
Iter 32...	Training loss: 37610.589844 (1533.874436, 36076.720428) in 5.82s 
Iter 33...	Training loss: 36289.199219 (1521.732421, 34767.466461) in 5.83s 
Iter 34...	Training loss: 34669.242188 (1510.112446, 33159.130020) in 5.82s 
Iter 35...	Training loss: 33384.101562 (1495.299483, 31888.802277) in 5.66s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.156894 Precision: 0.031379 NDCG: 0.116183 HR: 0.156894
Top-10 Recall: 0.232964 Precision: 0.023296 NDCG: 0.140573 HR: 0.232964
Eval costs: 0.219891 s
Iter 36...	Training loss: 32406.613281 (1483.922671, 30922.691422) in 5.84s 
Iter 37...	Training loss: 31180.343750 (1472.516603, 29707.825851) in 5.82s 
Iter 38...	Training loss: 30021.353516 (1461.849081, 28559.505203) in 5.83s 
Iter 39...	Training loss: 29387.632812 (1450.713377, 27936.918076) in 5.69s 
Iter 40...	Training loss: 28446.423828 (1443.205345, 27003.218887) in 5.82s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.116345 HR: 0.162705
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.137074 HR: 0.227153
Eval costs: 0.227161 s
Iter 41...	Training loss: 27833.617188 (1434.027559, 26399.590134) in 5.84s 
Iter 42...	Training loss: 27070.656250 (1426.309333, 25644.346649) in 5.85s 
Iter 43...	Training loss: 26378.511719 (1418.324920, 24960.187515) in 5.67s 
Iter 44...	Training loss: 25851.384766 (1408.474679, 24442.909088) in 5.83s 
Iter 45...	Training loss: 25413.740234 (1401.988427, 24011.752411) in 5.83s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.156366 Precision: 0.031273 NDCG: 0.114491 HR: 0.156366
Top-10 Recall: 0.228737 Precision: 0.022874 NDCG: 0.137830 HR: 0.228737
Eval costs: 0.230662 s
Iter 46...	Training loss: 24877.853516 (1393.360168, 23484.492935) in 5.84s 
Iter 47...	Training loss: 24628.916016 (1386.430707, 23242.487312) in 5.82s 
Iter 48...	Training loss: 24099.324219 (1381.903605, 22717.419495) in 5.69s 
Iter 49...	Training loss: 23638.238281 (1372.753741, 22265.483559) in 5.84s 
Iter 50...	Training loss: 23239.761719 (1369.323568, 21870.439781) in 5.84s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.159535 Precision: 0.031907 NDCG: 0.114279 HR: 0.159535
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.134322 HR: 0.221342
Eval costs: 0.234824 s
Iter 51...	Training loss: 23052.138672 (1361.557546, 21690.581665) in 5.82s 
Iter 52...	Training loss: 22905.683594 (1356.350237, 21549.333977) in 5.66s 
Iter 53...	Training loss: 22308.771484 (1350.237930, 20958.533997) in 5.82s 
Iter 54...	Training loss: 22190.765625 (1345.181242, 20845.583885) in 5.82s 
Iter 55...	Training loss: 21947.009766 (1339.482554, 20607.528862) in 5.84s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.160063 Precision: 0.032013 NDCG: 0.113835 HR: 0.160063
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.133150 HR: 0.219757
Eval costs: 0.237441 s
Iter 56...	Training loss: 21731.367188 (1333.903058, 20397.463371) in 5.67s 
Iter 57...	Training loss: 21424.937500 (1332.644240, 20092.291885) in 5.85s 
Iter 58...	Training loss: 21206.009766 (1324.067942, 19881.941498) in 5.85s 
Iter 59...	Training loss: 21051.083984 (1323.566565, 19727.517517) in 5.84s 
Iter 60...	Training loss: 20938.777344 (1318.195296, 19620.581848) in 5.67s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.159007 Precision: 0.031801 NDCG: 0.110259 HR: 0.159007
Top-10 Recall: 0.218172 Precision: 0.021817 NDCG: 0.129413 HR: 0.218172
Eval costs: 0.240832 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 509651.125000 (192979.338980, 107541.507261, 209130.278564) in 7.57s 
Iter 2...	Training loss: 227890.234375 (16111.016389, 19905.140591, 191874.080811) in 7.21s 
Iter 3...	Training loss: 196652.718750 (0.000000, 11863.683454, 184789.020264) in 6.01s 
Iter 4...	Training loss: 213990.296875 (25700.167592, 8237.862881, 180052.261719) in 8.43s 
Iter 5...	Training loss: 191081.906250 (9148.553963, 6572.595616, 175360.763184) in 7.22s 
Top-1 Recall: 0.015848 Precision: 0.015848 NDCG: 0.015848 HR: 0.015848
Top-5 Recall: 0.060750 Precision: 0.012150 NDCG: 0.038164 HR: 0.060750
Top-10 Recall: 0.090861 Precision: 0.009086 NDCG: 0.047890 HR: 0.090861
Eval costs: 0.172543 s
Iter 6...	Training loss: 183699.015625 (7751.248915, 5637.633116, 170310.133667) in 7.40s 
Iter 7...	Training loss: 176518.625000 (6691.259378, 5004.563009, 164822.809937) in 7.22s 
Iter 8...	Training loss: 168668.468750 (5825.929626, 4549.958234, 158292.594971) in 7.22s 
Iter 9...	Training loss: 159292.875000 (5124.389829, 4200.803782, 149967.678955) in 7.22s 
Iter 10...	Training loss: 147983.984375 (4555.039545, 3927.322674, 139501.621338) in 7.26s 
Top-1 Recall: 0.031167 Precision: 0.031167 NDCG: 0.031167 HR: 0.031167
Top-5 Recall: 0.090861 Precision: 0.018172 NDCG: 0.061974 HR: 0.090861
Top-10 Recall: 0.136292 Precision: 0.013629 NDCG: 0.076511 HR: 0.136292
Eval costs: 0.171899 s
Iter 11...	Training loss: 135887.187500 (4071.854851, 3709.950832, 128105.382202) in 7.21s 
Iter 12...	Training loss: 124295.171875 (3705.312648, 3553.181931, 117036.674927) in 7.22s 
Iter 13...	Training loss: 112523.546875 (3433.596977, 3435.489975, 105654.455200) in 7.24s 
Iter 14...	Training loss: 101175.031250 (3250.116923, 3329.981405, 94594.928345) in 7.24s 
Iter 15...	Training loss: 89648.515625 (3133.292175, 3254.528496, 83260.689636) in 7.24s 
Top-1 Recall: 0.040148 Precision: 0.040148 NDCG: 0.040148 HR: 0.040148
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.080203 HR: 0.118331
Top-10 Recall: 0.167987 Precision: 0.016799 NDCG: 0.096095 HR: 0.167987
Eval costs: 0.189977 s
Iter 16...	Training loss: 76237.890625 (0.000000, 3181.203609, 73056.684937) in 6.04s 
Iter 17...	Training loss: 73631.625000 (5898.059565, 3135.671335, 64597.893005) in 8.45s 
Iter 18...	Training loss: 63191.191406 (3008.687847, 3094.316747, 57088.183319) in 7.41s 
Iter 19...	Training loss: 56820.769531 (3113.428595, 3067.964548, 50639.378174) in 7.24s 
Iter 20...	Training loss: 51428.058594 (3199.734941, 3037.470511, 45190.853790) in 7.24s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.139461 Precision: 0.027892 NDCG: 0.092815 HR: 0.139461
Top-10 Recall: 0.193872 Precision: 0.019387 NDCG: 0.110345 HR: 0.193872
Eval costs: 0.202126 s
Iter 21...	Training loss: 46585.855469 (3289.795285, 3013.940281, 40282.117310) in 7.24s 
Iter 22...	Training loss: 43436.945312 (3389.662546, 3000.032287, 37047.248444) in 7.25s 
Iter 23...	Training loss: 40072.566406 (3490.862234, 2985.394857, 33596.308044) in 7.24s 
Iter 24...	Training loss: 37402.125000 (3592.563271, 2977.801153, 30831.757751) in 7.25s 
Iter 25...	Training loss: 35253.199219 (3693.017519, 2977.579687, 28582.599915) in 7.22s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.153196 Precision: 0.030639 NDCG: 0.103245 HR: 0.153196
Top-10 Recall: 0.207079 Precision: 0.020708 NDCG: 0.120653 HR: 0.207079
Eval costs: 0.210342 s
Iter 26...	Training loss: 33294.820312 (3790.577373, 2959.288212, 26544.954895) in 7.24s 
Iter 27...	Training loss: 31607.960938 (3893.010728, 2954.066410, 24760.885834) in 7.20s 
Iter 28...	Training loss: 30150.349609 (3985.890217, 2949.930261, 23214.528946) in 7.24s 
Iter 29...	Training loss: 28813.703125 (4076.978895, 2947.061592, 21789.665512) in 7.41s 
Iter 30...	Training loss: 27683.470703 (4163.478492, 2940.985025, 20579.007690) in 7.21s 
Top-1 Recall: 0.057052 Precision: 0.057052 NDCG: 0.057052 HR: 0.057052
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.111765 HR: 0.164818
Top-10 Recall: 0.216587 Precision: 0.021659 NDCG: 0.128328 HR: 0.216587
Eval costs: 0.215773 s
Iter 31...	Training loss: 26453.251953 (4250.598435, 2941.719664, 19260.932816) in 7.26s 
Iter 32...	Training loss: 25586.593750 (4328.825760, 2941.256828, 18316.512497) in 7.23s 
Iter 33...	Training loss: 25083.923828 (4410.298017, 2939.614705, 17734.010269) in 7.22s 
Iter 34...	Training loss: 23897.292969 (4482.477893, 2945.140929, 16469.674942) in 7.22s 
Iter 35...	Training loss: 23489.861328 (4548.042269, 2934.892351, 16006.925919) in 7.23s 
Top-1 Recall: 0.055468 Precision: 0.055468 NDCG: 0.055468 HR: 0.055468
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.112677 HR: 0.164818
Top-10 Recall: 0.218700 Precision: 0.021870 NDCG: 0.130152 HR: 0.218700
Eval costs: 0.221427 s
Iter 36...	Training loss: 22903.152344 (4620.858907, 2939.545497, 15342.749664) in 7.22s 
Iter 37...	Training loss: 22326.861328 (4679.783556, 2941.051133, 14706.025116) in 7.21s 
Iter 38...	Training loss: 21736.457031 (4747.356279, 2940.870886, 14048.228745) in 7.23s 
Iter 39...	Training loss: 21215.539062 (4802.197383, 2945.113499, 13468.228676) in 7.24s 
Iter 40...	Training loss: 20931.142578 (4859.422066, 2942.275639, 13129.444298) in 7.21s 
Top-1 Recall: 0.062335 Precision: 0.062335 NDCG: 0.062335 HR: 0.062335
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.115270 HR: 0.163761
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.134091 HR: 0.221870
Eval costs: 0.381980 s
Iter 41...	Training loss: 20530.839844 (4905.730519, 2947.626705, 12677.484810) in 7.21s 
Iter 42...	Training loss: 20281.152344 (4956.756463, 2942.653042, 12381.743767) in 7.24s 
Iter 43...	Training loss: 19926.531250 (5008.069174, 2945.113582, 11973.346581) in 7.21s 
Iter 44...	Training loss: 19442.525391 (5056.880366, 2954.084876, 11431.560524) in 7.22s 
Iter 45...	Training loss: 19252.791016 (5106.936670, 2953.035260, 11192.819237) in 7.21s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.124011 HR: 0.173270
Top-10 Recall: 0.220285 Precision: 0.022029 NDCG: 0.139065 HR: 0.220285
Eval costs: 0.226099 s
Iter 46...	Training loss: 18967.591797 (5146.792605, 2953.214777, 10867.583557) in 7.23s 
Iter 47...	Training loss: 18655.289062 (5187.377504, 2954.120260, 10513.790428) in 7.21s 
Iter 48...	Training loss: 13046.666016 (0.000000, 2963.342362, 10083.323532) in 6.01s 
Iter 49...	Training loss: 23207.953125 (10101.569654, 2966.910567, 10139.474174) in 8.44s 
Iter 50...	Training loss: 17655.187500 (5016.185996, 2965.442192, 9673.559273) in 7.23s 
Top-1 Recall: 0.072372 Precision: 0.072372 NDCG: 0.072372 HR: 0.072372
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.121534 HR: 0.169572
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.138634 HR: 0.222398
Eval costs: 0.229527 s
Iter 51...	Training loss: 18042.636719 (5247.743219, 2969.210544, 9825.682953) in 7.39s 
Iter 52...	Training loss: 17591.421875 (5329.146590, 2974.366208, 9287.909050) in 7.21s 
Iter 53...	Training loss: 17234.576172 (5380.384609, 2977.145618, 8877.044937) in 7.23s 
Iter 54...	Training loss: 17222.050781 (5432.319047, 2978.246230, 8811.483292) in 7.22s 
Iter 55...	Training loss: 17123.470703 (5471.016323, 2981.326698, 8671.128517) in 7.24s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.122825 HR: 0.173270
Top-10 Recall: 0.217644 Precision: 0.021764 NDCG: 0.137120 HR: 0.217644
Eval costs: 0.232453 s
Iter 56...	Training loss: 16984.562500 (5509.760129, 2984.394631, 8490.407471) in 7.21s 
Iter 57...	Training loss: 16891.199219 (5540.985674, 2981.670625, 8368.544174) in 7.22s 
Iter 58...	Training loss: 16599.808594 (5578.662487, 2984.054495, 8037.090698) in 7.20s 
Iter 59...	Training loss: 16625.753906 (5609.135466, 2988.176848, 8028.441818) in 7.24s 
Iter 60...	Training loss: 16369.152344 (5632.849114, 2987.590358, 7748.711800) in 7.24s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.122657 HR: 0.171157
Top-10 Recall: 0.220814 Precision: 0.022081 NDCG: 0.138700 HR: 0.220814
Eval costs: 0.234500 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 535607.812500 (192529.194768, 107807.661602, 235270.952148) in 7.54s 
Iter 2...	Training loss: 248283.781250 (16092.482562, 19847.004974, 212344.291870) in 7.22s 
Iter 3...	Training loss: 227646.593750 (12435.955197, 11846.680175, 203363.968262) in 7.20s 
Iter 4...	Training loss: 215121.906250 (10465.040802, 8088.856356, 196568.005981) in 7.21s 
Iter 5...	Training loss: 205420.687500 (8885.306406, 6416.554522, 190118.846558) in 7.21s 
Top-1 Recall: 0.016376 Precision: 0.016376 NDCG: 0.016376 HR: 0.016376
Top-5 Recall: 0.069202 Precision: 0.013840 NDCG: 0.042546 HR: 0.069202
Top-10 Recall: 0.096672 Precision: 0.009667 NDCG: 0.051440 HR: 0.096672
Eval costs: 0.173341 s
Iter 6...	Training loss: 196601.109375 (7597.926363, 5416.905172, 183586.282959) in 7.39s 
Iter 7...	Training loss: 187350.125000 (6570.415181, 4764.146530, 176015.579834) in 7.22s 
Iter 8...	Training loss: 177145.921875 (5734.383746, 4309.897820, 167101.625366) in 7.22s 
Iter 9...	Training loss: 165715.250000 (5030.194930, 3942.606512, 156742.450317) in 7.24s 
Iter 10...	Training loss: 152660.062500 (4434.112281, 3679.510064, 144546.449341) in 7.21s 
Top-1 Recall: 0.032752 Precision: 0.032752 NDCG: 0.032752 HR: 0.032752
Top-5 Recall: 0.101955 Precision: 0.020391 NDCG: 0.066722 HR: 0.101955
Top-10 Recall: 0.147913 Precision: 0.014791 NDCG: 0.081508 HR: 0.147913
Eval costs: 0.176737 s
Iter 11...	Training loss: 139934.171875 (3958.624710, 3491.802382, 132483.749512) in 7.22s 
Iter 12...	Training loss: 127565.101562 (3609.528634, 3340.260597, 120615.326172) in 7.21s 
Iter 13...	Training loss: 115557.648438 (3352.342580, 3233.433942, 108971.870361) in 7.23s 
Iter 14...	Training loss: 103398.867188 (3182.814150, 3148.438167, 97067.616943) in 7.23s 
Iter 15...	Training loss: 92094.554688 (3083.173958, 3072.957296, 85938.421448) in 7.21s 
Top-1 Recall: 0.038563 Precision: 0.038563 NDCG: 0.038563 HR: 0.038563
Top-5 Recall: 0.123085 Precision: 0.024617 NDCG: 0.082162 HR: 0.123085
Top-10 Recall: 0.182779 Precision: 0.018278 NDCG: 0.101481 HR: 0.182779
Eval costs: 0.193730 s
Iter 16...	Training loss: 82062.765625 (3043.974709, 3028.726642, 75990.063293) in 7.24s 
Iter 17...	Training loss: 73687.593750 (3053.487007, 2978.025864, 67656.083313) in 7.22s 
Iter 18...	Training loss: 66134.546875 (3098.764377, 2938.828697, 60096.954407) in 7.40s 
Iter 19...	Training loss: 60191.351562 (3163.914738, 2909.719913, 54117.719025) in 7.24s 
Iter 20...	Training loss: 55027.617188 (3256.095452, 2890.993594, 48880.529449) in 7.23s 
Top-1 Recall: 0.043317 Precision: 0.043317 NDCG: 0.043317 HR: 0.043317
Top-5 Recall: 0.145800 Precision: 0.029160 NDCG: 0.096967 HR: 0.145800
Top-10 Recall: 0.204966 Precision: 0.020497 NDCG: 0.115865 HR: 0.204966
Eval costs: 0.202569 s
Iter 21...	Training loss: 50662.140625 (3360.456921, 2866.358854, 44435.328918) in 7.22s 
Iter 22...	Training loss: 47081.593750 (3467.709156, 2844.651095, 40769.237091) in 7.25s 
Iter 23...	Training loss: 44137.968750 (3578.671086, 2830.881776, 37728.415558) in 7.26s 
Iter 24...	Training loss: 41557.972656 (3693.162497, 2817.217435, 35047.590820) in 7.23s 
Iter 25...	Training loss: 39511.265625 (3806.767339, 2806.735145, 32897.761353) in 7.27s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.157950 Precision: 0.031590 NDCG: 0.106116 HR: 0.157950
Top-10 Recall: 0.216587 Precision: 0.021659 NDCG: 0.125036 HR: 0.216587
Eval costs: 0.210036 s
Iter 26...	Training loss: 37013.300781 (3914.916987, 2790.906384, 30307.477966) in 7.21s 
Iter 27...	Training loss: 35857.515625 (4019.289362, 2790.038549, 29048.186584) in 7.23s 
Iter 28...	Training loss: 34034.398438 (4129.130830, 2782.144673, 27123.123779) in 7.25s 
Iter 29...	Training loss: 32880.738281 (4233.233979, 2769.800257, 25877.703018) in 7.22s 
Iter 30...	Training loss: 31622.210938 (4331.889095, 2768.369452, 24521.949249) in 7.39s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.115653 HR: 0.167987
Top-10 Recall: 0.217116 Precision: 0.021712 NDCG: 0.131501 HR: 0.217116
Eval costs: 0.216659 s
Iter 31...	Training loss: 30743.855469 (4417.594751, 2757.998503, 23568.261246) in 7.25s 
Iter 32...	Training loss: 29504.847656 (4505.960335, 2749.815620, 22249.071518) in 7.24s 
Iter 33...	Training loss: 28650.554688 (4588.211825, 2741.451877, 21320.889801) in 7.22s 
Iter 34...	Training loss: 27984.683594 (4672.092181, 2741.020481, 20571.570389) in 7.21s 
Iter 35...	Training loss: 27216.437500 (4743.932372, 2732.436111, 19740.067780) in 7.21s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.120788 HR: 0.172213
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.137911 HR: 0.225568
Eval costs: 0.220001 s
Iter 36...	Training loss: 26477.703125 (4824.661328, 2727.272519, 18925.770340) in 7.24s 
Iter 37...	Training loss: 26055.835938 (4899.620499, 2723.790828, 18432.427078) in 7.23s 
Iter 38...	Training loss: 25373.859375 (4972.662388, 2715.521354, 17685.674896) in 7.22s 
Iter 39...	Training loss: 24874.023438 (5035.921173, 2715.782337, 17122.319092) in 7.22s 
Iter 40...	Training loss: 24453.308594 (5099.229496, 2714.455759, 16639.623260) in 7.22s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.178553 Precision: 0.035711 NDCG: 0.125514 HR: 0.178553
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.140480 HR: 0.225568
Eval costs: 0.224175 s
Iter 41...	Training loss: 23847.724609 (5157.530557, 2711.583438, 15978.609848) in 7.39s 
Iter 42...	Training loss: 23405.408203 (5227.830205, 2706.415463, 15471.163498) in 7.24s 
Iter 43...	Training loss: 23003.078125 (5288.187598, 2704.684523, 15010.208466) in 7.22s 
Iter 44...	Training loss: 22609.140625 (5348.145440, 2701.885980, 14559.108536) in 7.25s 
Iter 45...	Training loss: 22201.613281 (5401.609235, 2693.912544, 14106.090454) in 7.24s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.124794 HR: 0.177496
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.139367 HR: 0.222927
Eval costs: 0.228522 s
Iter 46...	Training loss: 21711.244141 (5456.016567, 2692.404809, 13562.823654) in 7.24s 
Iter 47...	Training loss: 21464.789062 (5510.882321, 2690.976490, 13262.929848) in 7.26s 
Iter 48...	Training loss: 21141.849609 (5570.335145, 2683.213270, 12888.302277) in 7.22s 
Iter 49...	Training loss: 20827.449219 (5611.996467, 2679.638530, 12535.813591) in 7.21s 
Iter 50...	Training loss: 20471.904297 (5664.912984, 2672.980719, 12134.011826) in 7.22s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.127078 HR: 0.176440
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.143675 HR: 0.228209
Eval costs: 0.230874 s
Iter 51...	Training loss: 20267.958984 (5711.264119, 2667.684097, 11889.009850) in 7.25s 
Iter 52...	Training loss: 20176.667969 (5767.356954, 2666.600451, 11742.711006) in 7.37s 
Iter 53...	Training loss: 19665.677734 (5811.903775, 2666.160440, 11187.614670) in 7.19s 
Iter 54...	Training loss: 19546.308594 (5850.193627, 2656.958305, 11039.156944) in 7.24s 
Iter 55...	Training loss: 19139.150391 (5891.650096, 2655.113760, 10592.387726) in 7.23s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.124513 HR: 0.173270
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.140605 HR: 0.222927
Eval costs: 0.234014 s
Iter 56...	Training loss: 19043.324219 (5934.486380, 2649.601494, 10459.236359) in 7.23s 
Iter 57...	Training loss: 18707.324219 (5979.136552, 2643.485659, 10084.701874) in 7.22s 
Iter 58...	Training loss: 18687.214844 (6019.642889, 2639.088853, 10028.481712) in 7.24s 
Iter 59...	Training loss: 18419.039062 (6054.820246, 2637.115662, 9727.104095) in 7.21s 
Iter 60...	Training loss: 18333.367188 (6101.097547, 2631.591005, 9600.678429) in 7.22s 
Top-1 Recall: 0.079239 Precision: 0.079239 NDCG: 0.079239 HR: 0.079239
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.126914 HR: 0.172742
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.144095 HR: 0.226096
Eval costs: 0.238361 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 775080.812500 (192953.663694, 108946.795822, 473180.328857) in 7.55s 
Iter 2...	Training loss: 406150.000000 (16144.189558, 19761.332861, 370244.469238) in 7.21s 
Iter 3...	Training loss: 345775.343750 (12450.784460, 11196.642101, 322127.931396) in 7.20s 
Iter 4...	Training loss: 306401.500000 (10427.762667, 7335.190423, 288638.552002) in 7.23s 
Iter 5...	Training loss: 273578.312500 (8716.981410, 5598.293027, 259263.055908) in 7.20s 
Top-1 Recall: 0.028526 Precision: 0.028526 NDCG: 0.028526 HR: 0.028526
Top-5 Recall: 0.094031 Precision: 0.018806 NDCG: 0.062175 HR: 0.094031
Top-10 Recall: 0.133650 Precision: 0.013365 NDCG: 0.074868 HR: 0.133650
Eval costs: 0.179095 s
Iter 6...	Training loss: 243532.218750 (7239.422743, 4646.305218, 231646.481445) in 7.21s 
Iter 7...	Training loss: 214994.906250 (6027.961175, 4051.760207, 204915.170654) in 7.38s 
Iter 8...	Training loss: 188324.843750 (5053.628942, 3654.166459, 179617.057495) in 7.24s 
Iter 9...	Training loss: 165533.203125 (4299.662148, 3371.191651, 157862.348877) in 7.22s 
Iter 10...	Training loss: 145926.796875 (3766.287341, 3159.801138, 139000.703369) in 7.22s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.139461 Precision: 0.027892 NDCG: 0.092430 HR: 0.139461
Top-10 Recall: 0.192287 Precision: 0.019229 NDCG: 0.109528 HR: 0.192287
Eval costs: 0.187790 s
Iter 11...	Training loss: 129804.968750 (3414.203432, 3001.625571, 123389.116882) in 7.23s 
Iter 12...	Training loss: 115635.343750 (3198.537676, 2873.018215, 109563.798035) in 7.23s 
Iter 13...	Training loss: 104095.335938 (3082.630086, 2763.969244, 98248.731323) in 7.20s 
Iter 14...	Training loss: 93632.632812 (3034.972033, 2682.201704, 87915.458374) in 7.21s 
Iter 15...	Training loss: 84410.656250 (3043.404031, 2607.142751, 78760.109009) in 7.21s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.152139 Precision: 0.030428 NDCG: 0.108256 HR: 0.152139
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.131010 HR: 0.221870
Eval costs: 0.193785 s
Iter 16...	Training loss: 76534.726562 (3084.367815, 2553.252000, 70897.097412) in 7.23s 
Iter 17...	Training loss: 69474.523438 (3159.205867, 2495.279310, 63820.040222) in 7.22s 
Iter 18...	Training loss: 55895.941406 (3261.869305, 0.000000, 52634.072144) in 4.60s 
Iter 19...	Training loss: 63391.964844 (3374.866687, 4746.015843, 55271.076141) in 10.03s 
Iter 20...	Training loss: 53994.613281 (3505.525063, 2373.655477, 48115.431610) in 7.21s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.116676 HR: 0.165346
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.136507 HR: 0.226624
Eval costs: 0.201135 s
Iter 21...	Training loss: 49690.488281 (3647.974941, 2346.017995, 43696.494904) in 7.22s 
Iter 22...	Training loss: 45489.265625 (3792.963521, 2315.020113, 39381.280487) in 7.21s 
Iter 23...	Training loss: 42806.531250 (3950.434595, 2293.302796, 36562.796387) in 7.23s 
Iter 24...	Training loss: 39710.312500 (4103.083703, 2265.947089, 33341.285248) in 7.28s 
Iter 25...	Training loss: 37193.136719 (4261.226110, 2242.910402, 30689.002487) in 7.24s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.119148 HR: 0.167987
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.138913 HR: 0.229794
Eval costs: 0.209426 s
Iter 26...	Training loss: 35221.800781 (4408.105655, 2220.323770, 28593.370865) in 7.23s 
Iter 27...	Training loss: 33494.875000 (4557.230245, 2204.362208, 26733.286118) in 7.24s 
Iter 28...	Training loss: 32063.570312 (4700.686543, 2182.420035, 25180.466965) in 7.22s 
Iter 29...	Training loss: 30431.988281 (4834.219478, 2166.187373, 23431.580750) in 7.23s 
Iter 30...	Training loss: 29247.964844 (4966.510882, 2152.985759, 22128.467361) in 7.38s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.123093 HR: 0.171685
Top-10 Recall: 0.227681 Precision: 0.022768 NDCG: 0.141064 HR: 0.227681
Eval costs: 0.216308 s
Iter 31...	Training loss: 28145.917969 (5093.568370, 2134.879318, 20917.471039) in 7.25s 
Iter 32...	Training loss: 27053.070312 (5221.025852, 2116.729947, 19715.319183) in 7.25s 
Iter 33...	Training loss: 26174.066406 (5349.494599, 2104.856759, 18719.714462) in 7.26s 
Iter 34...	Training loss: 25410.332031 (5455.433275, 2093.180984, 17861.718056) in 7.24s 
Iter 35...	Training loss: 24659.445312 (5574.214090, 2077.105655, 17008.127174) in 7.35s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.122589 HR: 0.169572
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.142297 HR: 0.230851
Eval costs: 0.220726 s
Iter 36...	Training loss: 23962.054688 (5677.807033, 2066.006139, 16218.239151) in 7.25s 
Iter 37...	Training loss: 23365.906250 (5778.133429, 2052.210659, 15535.563507) in 7.24s 
Iter 38...	Training loss: 23183.369141 (5891.314242, 2042.081228, 15249.973206) in 7.27s 
Iter 39...	Training loss: 22547.925781 (5983.813240, 2030.848475, 14533.262779) in 7.28s 
Iter 40...	Training loss: 22133.005859 (6072.065411, 2016.361517, 14044.579582) in 7.24s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.123607 HR: 0.174855
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.141147 HR: 0.229794
Eval costs: 0.228148 s
Iter 41...	Training loss: 21704.113281 (6173.724041, 2008.371385, 13522.019005) in 7.41s 
Iter 42...	Training loss: 21404.236328 (6258.067076, 2000.758510, 13145.411217) in 7.24s 
Iter 43...	Training loss: 20979.699219 (6349.428280, 1989.520591, 12640.751022) in 7.21s 
Iter 44...	Training loss: 20682.369141 (6438.922507, 1979.373798, 12264.072922) in 7.24s 
Iter 45...	Training loss: 20464.322266 (6515.772465, 1970.830374, 11977.719421) in 7.28s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.120981 HR: 0.169044
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.139218 HR: 0.225568
Eval costs: 0.231442 s
Iter 46...	Training loss: 20193.558594 (6610.707639, 1961.834493, 11621.015778) in 7.25s 
Iter 47...	Training loss: 20015.628906 (6693.321581, 1954.643032, 11367.662300) in 7.22s 
Iter 48...	Training loss: 19749.914062 (6770.127965, 1944.460830, 11035.326836) in 7.23s 
Iter 49...	Training loss: 19402.181641 (6859.929959, 1934.936692, 10607.314507) in 7.28s 
Iter 50...	Training loss: 19274.783203 (6948.511488, 1926.846630, 10399.425072) in 7.25s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.122281 HR: 0.174326
Top-10 Recall: 0.228737 Precision: 0.022874 NDCG: 0.139710 HR: 0.228737
Eval costs: 0.235114 s
Iter 51...	Training loss: 19112.996094 (7027.850443, 1918.884463, 10166.262245) in 7.23s 
Iter 52...	Training loss: 18962.923828 (7106.546557, 1912.305976, 9944.071198) in 7.41s 
Iter 53...	Training loss: 18856.000000 (7182.813562, 1901.767571, 9771.417721) in 7.33s 
Iter 54...	Training loss: 18681.994141 (7258.004510, 1894.208261, 9529.782341) in 7.25s 
Iter 55...	Training loss: 18628.501953 (7327.703316, 1888.082162, 9412.716187) in 7.29s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.118867 HR: 0.165874
Top-10 Recall: 0.228737 Precision: 0.022874 NDCG: 0.139168 HR: 0.228737
Eval costs: 0.235979 s
Iter 56...	Training loss: 18335.671875 (7407.774945, 1882.631634, 9045.266987) in 7.27s 
Iter 57...	Training loss: 18451.781250 (7475.814276, 1875.537929, 9100.430496) in 7.22s 
Iter 58...	Training loss: 18178.482422 (7553.244652, 1868.955590, 8756.281059) in 7.26s 
Iter 59...	Training loss: 18214.724609 (7633.068897, 1862.963984, 8718.691196) in 7.29s 
Iter 60...	Training loss: 18074.714844 (7705.254413, 1857.586689, 8511.873837) in 7.23s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.164289 Precision: 0.032858 NDCG: 0.119097 HR: 0.164289
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.139763 HR: 0.228209
Eval costs: 0.239440 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 3050511.750000 (193010.090708, 108002.192160, 2749499.578125) in 7.59s 
Iter 2...	Training loss: 1834096.250000 (16152.662370, 19045.115010, 1798898.381836) in 7.20s 
Iter 3...	Training loss: 1359720.875000 (12416.338408, 10008.560264, 1337295.908203) in 7.19s 
Iter 4...	Training loss: 1044048.437500 (10239.252114, 6285.775523, 1027523.323242) in 7.23s 
Iter 5...	Training loss: 808305.625000 (8239.961456, 4712.503224, 795353.035156) in 7.20s 
Top-1 Recall: 0.008452 Precision: 0.008452 NDCG: 0.008452 HR: 0.008452
Top-5 Recall: 0.040676 Precision: 0.008135 NDCG: 0.024994 HR: 0.040676
Top-10 Recall: 0.066561 Precision: 0.006656 NDCG: 0.033267 HR: 0.066561
Eval costs: 0.172506 s
Iter 6...	Training loss: 623304.000000 (6544.946146, 3885.522618, 612873.524414) in 7.21s 
Iter 7...	Training loss: 476938.187500 (5266.000948, 3385.646352, 468286.557129) in 7.20s 
Iter 8...	Training loss: 370563.562500 (4414.735327, 3062.732916, 363086.115479) in 7.37s 
Iter 9...	Training loss: 294020.437500 (3891.113594, 2825.631388, 287303.679688) in 7.24s 
Iter 10...	Training loss: 200937.140625 (3611.951543, 0.000000, 197325.199341) in 4.46s 
Top-1 Recall: 0.052826 Precision: 0.052826 NDCG: 0.052826 HR: 0.052826
Top-5 Recall: 0.142102 Precision: 0.028420 NDCG: 0.098789 HR: 0.142102
Top-10 Recall: 0.206550 Precision: 0.020655 NDCG: 0.119514 HR: 0.206550
Eval costs: 0.185117 s
Iter 11...	Training loss: 229017.578125 (3472.153872, 5085.532199, 220459.901245) in 10.00s 
Iter 12...	Training loss: 179071.671875 (3402.324458, 2399.320964, 173270.031250) in 7.24s 
Iter 13...	Training loss: 153629.453125 (3407.081766, 2288.263908, 147934.107422) in 7.29s 
Iter 14...	Training loss: 135437.359375 (3460.324142, 2200.613523, 129776.413208) in 7.24s 
Iter 15...	Training loss: 122060.507812 (3522.729610, 2120.728136, 116417.058777) in 7.22s 
Top-1 Recall: 0.064448 Precision: 0.064448 NDCG: 0.064448 HR: 0.064448
Top-5 Recall: 0.159535 Precision: 0.031907 NDCG: 0.112762 HR: 0.159535
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.134310 HR: 0.225568
Eval costs: 0.193399 s
Iter 16...	Training loss: 110093.156250 (3600.282140, 2051.719730, 104441.153015) in 7.21s 
Iter 17...	Training loss: 100918.679688 (3700.189396, 1987.757755, 95230.739868) in 7.30s 
Iter 18...	Training loss: 92847.953125 (3808.378556, 1934.868253, 87104.697754) in 7.21s 
Iter 19...	Training loss: 85995.835938 (3912.599816, 1881.849576, 80201.386841) in 7.38s 
Iter 20...	Training loss: 80231.046875 (4051.134795, 1836.859337, 74343.044800) in 7.21s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.120739 HR: 0.173270
Top-10 Recall: 0.227681 Precision: 0.022768 NDCG: 0.138241 HR: 0.227681
Eval costs: 0.198720 s
Iter 21...	Training loss: 75251.929688 (4167.365017, 1796.542384, 69288.024323) in 7.23s 
Iter 22...	Training loss: 70378.101562 (4293.711628, 1760.530440, 64323.863983) in 7.24s 
Iter 23...	Training loss: 66628.929688 (4428.772248, 1729.510059, 60470.645020) in 7.25s 
Iter 24...	Training loss: 62985.484375 (4571.160934, 1696.864601, 56717.458435) in 7.21s 
Iter 25...	Training loss: 59348.312500 (4703.539552, 1670.183748, 52974.592529) in 7.22s 
Top-1 Recall: 0.072372 Precision: 0.072372 NDCG: 0.072372 HR: 0.072372
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.122076 HR: 0.169572
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.142195 HR: 0.231907
Eval costs: 0.206563 s
Iter 26...	Training loss: 56586.464844 (4853.248826, 1646.300098, 50086.910889) in 7.23s 
Iter 27...	Training loss: 53941.871094 (4999.272651, 1624.664620, 47317.936218) in 7.22s 
Iter 28...	Training loss: 51634.960938 (5133.214039, 1598.545822, 44903.202576) in 7.28s 
Iter 29...	Training loss: 49213.980469 (5284.152685, 1578.249654, 42351.577423) in 7.22s 
Iter 30...	Training loss: 41537.507812 (0.000000, 1564.065713, 39973.441559) in 6.00s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.166403 Precision: 0.033281 NDCG: 0.120498 HR: 0.166403
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.141434 HR: 0.231907
Eval costs: 0.214468 s
Iter 31...	Training loss: 50968.062500 (10868.100698, 1546.679110, 38553.279648) in 8.60s 
Iter 32...	Training loss: 44090.585938 (5621.449936, 1532.345555, 36936.782608) in 7.20s 
Iter 33...	Training loss: 42750.089844 (5935.423330, 1517.126938, 35297.539978) in 7.24s 
Iter 34...	Training loss: 41251.671875 (6103.115874, 1503.481228, 33645.073883) in 7.24s 
Iter 35...	Training loss: 40196.468750 (6285.861753, 1489.763879, 32420.841736) in 7.21s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.121142 HR: 0.165346
Top-10 Recall: 0.236661 Precision: 0.023666 NDCG: 0.144033 HR: 0.236661
Eval costs: 0.220439 s
Iter 36...	Training loss: 39262.589844 (6427.592206, 1481.307520, 31353.694427) in 7.23s 
Iter 37...	Training loss: 38390.343750 (6577.229360, 1470.454645, 30342.658218) in 7.22s 
Iter 38...	Training loss: 37661.011719 (6710.752230, 1457.894522, 29492.363785) in 7.23s 
Iter 39...	Training loss: 36912.003906 (6859.889398, 1447.008983, 28605.107742) in 7.25s 
Iter 40...	Training loss: 36199.015625 (7016.550587, 1437.808616, 27744.654068) in 7.26s 
Top-1 Recall: 0.072372 Precision: 0.072372 NDCG: 0.072372 HR: 0.072372
Top-5 Recall: 0.161120 Precision: 0.032224 NDCG: 0.118470 HR: 0.161120
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.142023 HR: 0.234548
Eval costs: 0.227787 s
Iter 41...	Training loss: 35467.757812 (7141.194755, 1428.652291, 26897.912323) in 7.39s 
Iter 42...	Training loss: 35100.160156 (7297.994435, 1420.412789, 26381.754364) in 7.20s 
Iter 43...	Training loss: 34625.007812 (7423.714200, 1411.862716, 25789.433197) in 7.24s 
Iter 44...	Training loss: 34186.500000 (7571.434560, 1403.650474, 25211.416122) in 7.29s 
Iter 45...	Training loss: 33629.527344 (7710.229874, 1396.308662, 24522.988251) in 7.23s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.119015 HR: 0.164818
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.139876 HR: 0.229794
Eval costs: 0.230834 s
Iter 46...	Training loss: 33624.449219 (7828.385073, 1391.775411, 24404.289032) in 7.23s 
Iter 47...	Training loss: 33224.125000 (7991.576147, 1380.787907, 23851.763100) in 7.22s 
Iter 48...	Training loss: 32926.289062 (8115.370461, 1375.113044, 23435.805122) in 7.22s 
Iter 49...	Training loss: 32673.478516 (8256.001918, 1371.216987, 23046.259514) in 7.22s 
Iter 50...	Training loss: 32446.355469 (8392.325292, 1362.812554, 22691.217003) in 7.21s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.155837 Precision: 0.031167 NDCG: 0.114475 HR: 0.155837
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.137720 HR: 0.227153
Eval costs: 0.234993 s
Iter 51...	Training loss: 32437.548828 (8511.589529, 1360.638440, 22565.321480) in 7.22s 
Iter 52...	Training loss: 32261.074219 (8638.316942, 1354.235266, 22268.523659) in 7.22s 
Iter 53...	Training loss: 31980.402344 (8775.006552, 1344.738281, 21860.654701) in 7.39s 
Iter 54...	Training loss: 31869.464844 (8894.171879, 1344.439776, 21630.851685) in 7.20s 
Iter 55...	Training loss: 31817.156250 (9042.026589, 1338.674190, 21436.456009) in 7.22s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.154781 Precision: 0.030956 NDCG: 0.112569 HR: 0.154781
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.134344 HR: 0.221342
Eval costs: 0.237385 s
Iter 56...	Training loss: 31540.748047 (9170.410211, 1332.474491, 21037.863167) in 7.24s 
Iter 57...	Training loss: 31613.828125 (9302.717074, 1329.297010, 20981.814423) in 7.21s 
Iter 58...	Training loss: 31568.480469 (9429.456278, 1321.970529, 20817.053680) in 7.23s 
Iter 59...	Training loss: 31528.212891 (9555.156288, 1317.126199, 20655.929855) in 7.20s 
Iter 60...	Training loss: 31536.410156 (9662.775197, 1316.655853, 20556.979576) in 7.21s 
Top-1 Recall: 0.062863 Precision: 0.062863 NDCG: 0.062863 HR: 0.062863
Top-5 Recall: 0.156366 Precision: 0.031273 NDCG: 0.111605 HR: 0.156366
Top-10 Recall: 0.216059 Precision: 0.021606 NDCG: 0.130789 HR: 0.216059
Eval costs: 0.239920 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 524461.000000 (192602.833084, 108416.042253, 223442.130493) in 7.58s 
Iter 2...	Training loss: 238090.609375 (16067.393502, 19902.022410, 202121.190674) in 7.19s 
Iter 3...	Training loss: 217294.406250 (12315.340285, 11841.271252, 193137.800171) in 7.18s 
Iter 4...	Training loss: 205172.437500 (10262.634685, 8247.288901, 186662.484741) in 7.21s 
Iter 5...	Training loss: 195823.750000 (8594.228657, 6559.715462, 180669.812134) in 7.19s 
Top-1 Recall: 0.017433 Precision: 0.017433 NDCG: 0.017433 HR: 0.017433
Top-5 Recall: 0.077655 Precision: 0.015531 NDCG: 0.047814 HR: 0.077655
Top-10 Recall: 0.105652 Precision: 0.010565 NDCG: 0.056924 HR: 0.105652
Eval costs: 0.173816 s
Iter 6...	Training loss: 186882.250000 (7273.688771, 5587.235562, 174021.326660) in 7.21s 
Iter 7...	Training loss: 177403.437500 (6201.917926, 4982.426892, 166219.080811) in 7.37s 
Iter 8...	Training loss: 166280.703125 (5343.282388, 4499.266526, 156438.156616) in 7.22s 
Iter 9...	Training loss: 154100.078125 (4664.196561, 4131.622640, 145304.253052) in 7.19s 
Iter 10...	Training loss: 142324.281250 (4134.007020, 3853.269812, 134337.014526) in 7.23s 
Top-1 Recall: 0.037507 Precision: 0.037507 NDCG: 0.037507 HR: 0.037507
Top-5 Recall: 0.102483 Precision: 0.020497 NDCG: 0.070615 HR: 0.102483
Top-10 Recall: 0.138933 Precision: 0.013893 NDCG: 0.082348 HR: 0.138933
Eval costs: 0.172441 s
Iter 11...	Training loss: 131541.750000 (3749.491384, 3636.354225, 124155.912842) in 7.20s 
Iter 12...	Training loss: 120426.765625 (3476.460195, 3473.906787, 113476.395935) in 7.22s 
Iter 13...	Training loss: 105259.382812 (0.000000, 3337.102935, 101922.274475) in 6.00s 
Iter 14...	Training loss: 101439.429688 (6156.672383, 3231.443574, 92051.309448) in 8.45s 
Iter 15...	Training loss: 87789.210938 (3016.138592, 3149.023788, 81624.044373) in 7.22s 
Top-1 Recall: 0.045959 Precision: 0.045959 NDCG: 0.045959 HR: 0.045959
Top-5 Recall: 0.129952 Precision: 0.025990 NDCG: 0.088842 HR: 0.129952
Top-10 Recall: 0.182779 Precision: 0.018278 NDCG: 0.105699 HR: 0.182779
Eval costs: 0.188993 s
Iter 16...	Training loss: 78457.093750 (3025.763137, 3090.558135, 72340.770996) in 7.23s 
Iter 17...	Training loss: 70032.632812 (3043.756245, 3039.742716, 63949.132324) in 7.22s 
Iter 18...	Training loss: 62686.335938 (3085.957967, 2991.784164, 56608.595154) in 7.40s 
Iter 19...	Training loss: 56656.363281 (3154.055136, 2965.576380, 50536.731720) in 7.21s 
Iter 20...	Training loss: 51227.191406 (3233.303412, 2944.147435, 45049.738617) in 7.25s 
Top-1 Recall: 0.048072 Precision: 0.048072 NDCG: 0.048072 HR: 0.048072
Top-5 Recall: 0.145272 Precision: 0.029054 NDCG: 0.098371 HR: 0.145272
Top-10 Recall: 0.201796 Precision: 0.020180 NDCG: 0.116674 HR: 0.201796
Eval costs: 0.200506 s
Iter 21...	Training loss: 46584.820312 (3323.838182, 2927.772805, 40333.205414) in 7.21s 
Iter 22...	Training loss: 42942.996094 (3421.393156, 2913.522605, 36608.079895) in 7.23s 
Iter 23...	Training loss: 39839.878906 (3522.455730, 2897.306636, 33420.116791) in 7.24s 
Iter 24...	Training loss: 37437.699219 (3622.454122, 2890.790549, 30924.454926) in 7.22s 
Iter 25...	Training loss: 35116.332031 (3718.502335, 2885.885193, 28511.945847) in 7.22s 
Top-1 Recall: 0.058109 Precision: 0.058109 NDCG: 0.058109 HR: 0.058109
Top-5 Recall: 0.159535 Precision: 0.031907 NDCG: 0.111060 HR: 0.159535
Top-10 Recall: 0.215531 Precision: 0.021553 NDCG: 0.128842 HR: 0.215531
Eval costs: 0.210805 s
Iter 26...	Training loss: 33281.921875 (3807.819425, 2880.397825, 26593.705307) in 7.24s 
Iter 27...	Training loss: 31755.832031 (3895.417581, 2878.998337, 24981.416412) in 7.25s 
Iter 28...	Training loss: 30287.955078 (3974.267802, 2870.694959, 23442.991104) in 7.26s 
Iter 29...	Training loss: 29347.101562 (4049.689443, 2869.282814, 22428.128586) in 7.25s 
Iter 30...	Training loss: 28058.775391 (4121.364224, 2870.247066, 21067.161682) in 7.38s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.119010 HR: 0.169572
Top-10 Recall: 0.217116 Precision: 0.021712 NDCG: 0.134334 HR: 0.217116
Eval costs: 0.215225 s
Iter 31...	Training loss: 27078.628906 (4188.895524, 2863.499783, 20026.231415) in 7.22s 
Iter 32...	Training loss: 26130.693359 (4246.340883, 2867.844535, 19016.505280) in 7.24s 
Iter 33...	Training loss: 25274.177734 (4298.144898, 2864.337708, 18111.695114) in 7.22s 
Iter 34...	Training loss: 24616.486328 (4345.361426, 2862.288405, 17408.836700) in 7.22s 
Iter 35...	Training loss: 24081.031250 (4392.885126, 2864.191389, 16823.951904) in 7.21s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.122800 HR: 0.174326
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.137997 HR: 0.221870
Eval costs: 0.222215 s
Iter 36...	Training loss: 23341.568359 (4427.223924, 2863.479574, 16050.867096) in 7.22s 
Iter 37...	Training loss: 22829.191406 (4467.116677, 2871.554366, 15490.521820) in 7.24s 
Iter 38...	Training loss: 22082.580078 (4498.204737, 2873.796016, 14710.580109) in 7.21s 
Iter 39...	Training loss: 22046.136719 (4525.309062, 2874.932174, 14645.897034) in 7.24s 
Iter 40...	Training loss: 21584.835938 (4546.308185, 2875.253036, 14163.274078) in 7.20s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.123069 HR: 0.171157
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.139680 HR: 0.222398
Eval costs: 0.382801 s
Iter 41...	Training loss: 21105.841797 (4574.588852, 2877.993062, 13653.259079) in 7.23s 
Iter 42...	Training loss: 20781.794922 (4595.914583, 2882.991592, 13302.888908) in 7.23s 
Iter 43...	Training loss: 20419.328125 (4614.646289, 2881.860339, 12922.820190) in 7.21s 
Iter 44...	Training loss: 20155.417969 (4629.709802, 2879.427744, 12646.283096) in 7.22s 
Iter 45...	Training loss: 19778.355469 (4642.210624, 2890.832740, 12245.311523) in 7.22s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.127638 HR: 0.176440
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.142212 HR: 0.221342
Eval costs: 0.228163 s
Iter 46...	Training loss: 19665.320312 (4657.928959, 2895.198779, 12112.192291) in 7.20s 
Iter 47...	Training loss: 19223.230469 (4669.204942, 2897.192265, 11656.832687) in 7.20s 
Iter 48...	Training loss: 19187.339844 (4672.687218, 2900.612971, 11614.040031) in 7.21s 
Iter 49...	Training loss: 18952.068359 (4687.700410, 2904.555466, 11359.812973) in 7.23s 
Iter 50...	Training loss: 18603.591797 (4692.145311, 2903.151010, 11008.295624) in 7.20s 
Top-1 Recall: 0.083465 Precision: 0.083465 NDCG: 0.083465 HR: 0.083465
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.130530 HR: 0.174855
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.145686 HR: 0.221870
Eval costs: 0.231998 s
Iter 51...	Training loss: 18579.494141 (4698.528410, 2914.042506, 10966.923782) in 7.37s 
Iter 52...	Training loss: 18170.736328 (4701.725366, 2913.754776, 10555.255188) in 7.23s 
Iter 53...	Training loss: 18123.919922 (4705.028660, 2920.613970, 10498.277481) in 7.22s 
Iter 54...	Training loss: 17959.253906 (4711.938433, 2919.781209, 10327.535370) in 7.24s 
Iter 55...	Training loss: 17798.964844 (4714.501274, 2917.740095, 10166.721710) in 7.25s 
Top-1 Recall: 0.080824 Precision: 0.080824 NDCG: 0.080824 HR: 0.080824
Top-5 Recall: 0.178553 Precision: 0.035711 NDCG: 0.130673 HR: 0.178553
Top-10 Recall: 0.223983 Precision: 0.022398 NDCG: 0.145275 HR: 0.223983
Eval costs: 0.238380 s
Iter 56...	Training loss: 17451.435547 (4719.107500, 2928.349494, 9803.978027) in 7.24s 
Iter 57...	Training loss: 17317.511719 (4723.101810, 2934.873273, 9659.534660) in 7.22s 
Iter 58...	Training loss: 17094.126953 (4718.387069, 2938.992772, 9436.747177) in 7.21s 
Iter 59...	Training loss: 17047.966797 (4722.796708, 2941.617593, 9383.551826) in 7.24s 
Iter 60...	Training loss: 17018.902344 (4724.474216, 2940.539759, 9353.887627) in 7.20s 
Top-1 Recall: 0.076070 Precision: 0.076070 NDCG: 0.076070 HR: 0.076070
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.127568 HR: 0.176440
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.143126 HR: 0.225040
Eval costs: 0.238679 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 550342.250000 (192428.139889, 108559.019302, 249355.044434) in 7.55s 
Iter 2...	Training loss: 258638.796875 (16015.978540, 20058.549112, 222564.254028) in 7.23s 
Iter 3...	Training loss: 235471.453125 (12306.011924, 11869.284907, 211296.156250) in 7.21s 
Iter 4...	Training loss: 221403.125000 (10246.807511, 8157.860458, 202998.456177) in 7.21s 
Iter 5...	Training loss: 210222.968750 (8586.027742, 6409.525588, 195227.429810) in 7.20s 
Top-1 Recall: 0.019017 Precision: 0.019017 NDCG: 0.019017 HR: 0.019017
Top-5 Recall: 0.081352 Precision: 0.016270 NDCG: 0.050744 HR: 0.081352
Top-10 Recall: 0.109878 Precision: 0.010988 NDCG: 0.059989 HR: 0.109878
Eval costs: 0.175090 s
Iter 6...	Training loss: 199655.750000 (7240.352385, 5410.020231, 187005.385864) in 7.22s 
Iter 7...	Training loss: 188096.437500 (6169.511580, 4746.954377, 177179.978149) in 7.21s 
Iter 8...	Training loss: 174987.906250 (5303.865346, 4252.982856, 165431.048950) in 7.38s 
Iter 9...	Training loss: 161147.296875 (4600.553030, 3903.121494, 152643.618652) in 7.25s 
Iter 10...	Training loss: 148284.203125 (4062.393470, 3634.473989, 140587.340210) in 7.23s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.107765 Precision: 0.021553 NDCG: 0.074043 HR: 0.107765
Top-10 Recall: 0.152668 Precision: 0.015267 NDCG: 0.088489 HR: 0.152668
Eval costs: 0.176119 s
Iter 11...	Training loss: 136353.375000 (3680.061778, 3450.124663, 129223.189453) in 7.24s 
Iter 12...	Training loss: 124355.953125 (3411.598239, 3297.510368, 117646.840454) in 7.24s 
Iter 13...	Training loss: 112824.171875 (3223.466322, 3183.153239, 106417.555908) in 7.20s 
Iter 14...	Training loss: 101425.226562 (3104.692330, 3088.412121, 95232.114868) in 7.27s 
Iter 15...	Training loss: 91127.453125 (3042.807297, 3019.790555, 85064.859558) in 7.23s 
Top-1 Recall: 0.046487 Precision: 0.046487 NDCG: 0.046487 HR: 0.046487
Top-5 Recall: 0.139989 Precision: 0.027998 NDCG: 0.094222 HR: 0.139989
Top-10 Recall: 0.201796 Precision: 0.020180 NDCG: 0.114049 HR: 0.201796
Eval costs: 0.192006 s
Iter 16...	Training loss: 81743.437500 (3024.937968, 2963.465883, 75755.025085) in 7.23s 
Iter 17...	Training loss: 73406.054688 (3044.133175, 2916.811105, 67445.112488) in 7.23s 
Iter 18...	Training loss: 65864.359375 (3096.208611, 2883.899104, 59884.250793) in 7.24s 
Iter 19...	Training loss: 60118.078125 (3168.532723, 2854.793092, 54094.749847) in 7.38s 
Iter 20...	Training loss: 54726.996094 (3261.552261, 2829.325749, 48636.123291) in 7.24s 
Top-1 Recall: 0.054939 Precision: 0.054939 NDCG: 0.054939 HR: 0.054939
Top-5 Recall: 0.156894 Precision: 0.031379 NDCG: 0.106837 HR: 0.156894
Top-10 Recall: 0.216059 Precision: 0.021606 NDCG: 0.125962 HR: 0.216059
Eval costs: 0.202691 s
Iter 21...	Training loss: 50512.539062 (3361.017021, 2817.404891, 44334.112274) in 7.22s 
Iter 22...	Training loss: 46592.234375 (3464.391310, 2802.165295, 40325.674927) in 7.28s 
Iter 23...	Training loss: 43696.187500 (3575.716980, 2787.438620, 37333.033508) in 7.24s 
Iter 24...	Training loss: 40911.546875 (3678.878220, 2772.101200, 34460.570831) in 7.24s 
Iter 25...	Training loss: 38970.292969 (3780.534524, 2757.621860, 32432.133545) in 7.22s 
Top-1 Recall: 0.061278 Precision: 0.061278 NDCG: 0.061278 HR: 0.061278
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.117555 HR: 0.171157
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.134380 HR: 0.222927
Eval costs: 0.209932 s
Iter 26...	Training loss: 37166.355469 (3878.759901, 2744.820428, 30542.779602) in 7.24s 
Iter 27...	Training loss: 35330.902344 (3970.171120, 2742.226014, 28618.506516) in 7.24s 
Iter 28...	Training loss: 34177.070312 (4054.510234, 2729.553410, 27393.007050) in 7.23s 
Iter 29...	Training loss: 32454.910156 (4129.440483, 2715.286231, 25610.185379) in 7.26s 
Iter 30...	Training loss: 31372.406250 (4206.156225, 2715.502920, 24450.745819) in 7.37s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.175383 Precision: 0.035077 NDCG: 0.123688 HR: 0.175383
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.140866 HR: 0.228209
Eval costs: 0.217857 s
Iter 31...	Training loss: 30400.566406 (4272.595915, 2708.590554, 23419.378647) in 7.23s 
Iter 32...	Training loss: 29677.707031 (4331.699983, 2704.037174, 22641.970734) in 7.23s 
Iter 33...	Training loss: 28656.404297 (4389.222103, 2699.881929, 21567.300537) in 7.21s 
Iter 34...	Training loss: 27980.335938 (4434.023729, 2694.397936, 20851.913284) in 7.22s 
Iter 35...	Training loss: 27585.511719 (4488.459295, 2691.501925, 20405.550644) in 7.25s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.182250 Precision: 0.036450 NDCG: 0.128559 HR: 0.182250
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.144508 HR: 0.231907
Eval costs: 0.220747 s
Iter 36...	Training loss: 26568.312500 (4528.723005, 2687.689506, 19351.897461) in 7.23s 
Iter 37...	Training loss: 25995.410156 (4573.266079, 2678.730183, 18743.415527) in 7.21s 
Iter 38...	Training loss: 25820.759766 (4611.500721, 2673.917168, 18535.341354) in 7.22s 
Iter 39...	Training loss: 25197.126953 (4638.903075, 2668.593283, 17889.629715) in 7.20s 
Iter 40...	Training loss: 24463.412109 (4678.533210, 2667.071102, 17117.809097) in 7.21s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.178024 Precision: 0.035605 NDCG: 0.129719 HR: 0.178024
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.147624 HR: 0.234020
Eval costs: 0.226057 s
Iter 41...	Training loss: 24133.093750 (4710.816056, 2664.241796, 16758.033920) in 7.38s 
Iter 42...	Training loss: 23788.416016 (4732.527009, 2663.530027, 16392.360352) in 7.21s 
Iter 43...	Training loss: 23306.738281 (4753.827630, 2656.547108, 15896.363182) in 7.25s 
Iter 44...	Training loss: 23086.968750 (4774.024171, 2655.840279, 15657.104889) in 7.24s 
Iter 45...	Training loss: 22545.203125 (4794.127448, 2646.834977, 15104.241318) in 7.21s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.179081 Precision: 0.035816 NDCG: 0.128891 HR: 0.179081
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.146466 HR: 0.233492
Eval costs: 0.229054 s
Iter 46...	Training loss: 22443.640625 (4812.342850, 2642.437231, 14988.860229) in 7.24s 
Iter 47...	Training loss: 22226.832031 (4825.066738, 2639.928316, 14761.835037) in 7.23s 
Iter 48...	Training loss: 21634.347656 (4846.613694, 2635.940770, 14151.792770) in 7.22s 
Iter 49...	Training loss: 21349.929688 (4861.030124, 2636.829747, 13852.068947) in 7.21s 
Iter 50...	Training loss: 21239.123047 (4874.838878, 2630.795746, 13733.488953) in 7.26s 
Top-1 Recall: 0.085578 Precision: 0.085578 NDCG: 0.085578 HR: 0.085578
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.130152 HR: 0.173270
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.150023 HR: 0.235605
Eval costs: 0.233133 s
Iter 51...	Training loss: 21019.310547 (4882.308993, 2630.974658, 13506.025932) in 7.24s 
Iter 52...	Training loss: 20666.162109 (4899.963973, 2632.798624, 13133.398842) in 7.38s 
Iter 53...	Training loss: 20390.281250 (4912.676983, 2627.543475, 12850.059494) in 7.20s 
Iter 54...	Training loss: 20182.500000 (4920.539581, 2624.671053, 12637.290329) in 7.22s 
Iter 55...	Training loss: 19834.566406 (4931.219656, 2621.815938, 12281.529915) in 7.22s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.180666 Precision: 0.036133 NDCG: 0.131556 HR: 0.180666
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.147380 HR: 0.229794
Eval costs: 0.235235 s
Iter 56...	Training loss: 19627.796875 (4939.658861, 2617.069422, 12071.067917) in 7.23s 
Iter 57...	Training loss: 19403.810547 (4947.964731, 2614.520234, 11841.326309) in 7.24s 
Iter 58...	Training loss: 19310.738281 (4952.050189, 2611.587772, 11747.098877) in 7.25s 
Iter 59...	Training loss: 18940.390625 (4955.806904, 2612.468083, 11372.114571) in 7.20s 
Iter 60...	Training loss: 18850.671875 (4969.043765, 2608.157300, 11273.471825) in 7.22s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.127134 HR: 0.170629
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.145389 HR: 0.226624
Eval costs: 0.237798 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 789389.250000 (192963.098707, 109007.715443, 487418.426758) in 7.55s 
Iter 2...	Training loss: 414805.656250 (16122.113364, 19743.196350, 378940.317383) in 7.20s 
Iter 3...	Training loss: 352648.312500 (12318.961637, 11199.862287, 329129.479492) in 7.20s 
Iter 4...	Training loss: 312022.656250 (10207.689822, 7324.762726, 294490.162598) in 7.21s 
Iter 5...	Training loss: 277903.187500 (8437.892067, 5590.014540, 263875.255127) in 7.21s 
Top-1 Recall: 0.035394 Precision: 0.035394 NDCG: 0.035394 HR: 0.035394
Top-5 Recall: 0.104068 Precision: 0.020814 NDCG: 0.070057 HR: 0.104068
Top-10 Recall: 0.143159 Precision: 0.014316 NDCG: 0.082501 HR: 0.143159
Eval costs: 0.181155 s
Iter 6...	Training loss: 245966.281250 (6953.846120, 4634.019360, 234378.430542) in 7.37s 
Iter 7...	Training loss: 215901.312500 (5748.130204, 4040.271545, 206112.917358) in 7.21s 
Iter 8...	Training loss: 189130.718750 (4814.402770, 3637.969937, 180678.342163) in 7.22s 
Iter 9...	Training loss: 166174.015625 (4134.237886, 3359.465165, 158680.316528) in 7.22s 
Iter 10...	Training loss: 146890.562500 (3669.163267, 3143.944076, 140077.446411) in 7.23s 
Top-1 Recall: 0.053883 Precision: 0.053883 NDCG: 0.053883 HR: 0.053883
Top-5 Recall: 0.143159 Precision: 0.028632 NDCG: 0.099427 HR: 0.143159
Top-10 Recall: 0.202853 Precision: 0.020285 NDCG: 0.118675 HR: 0.202853
Eval costs: 0.190159 s
Iter 11...	Training loss: 130636.976562 (3357.043301, 2975.834085, 124304.105957) in 7.22s 
Iter 12...	Training loss: 113649.664062 (0.000000, 2856.836755, 110792.819641) in 6.00s 
Iter 13...	Training loss: 108619.789062 (5936.411459, 2747.700282, 99935.653931) in 8.44s 
Iter 14...	Training loss: 95379.367188 (2964.516277, 2664.812182, 89750.042786) in 7.21s 
Iter 15...	Training loss: 86613.734375 (2986.697578, 2596.721528, 81030.317505) in 7.20s 
Top-1 Recall: 0.061807 Precision: 0.061807 NDCG: 0.061807 HR: 0.061807
Top-5 Recall: 0.157422 Precision: 0.031484 NDCG: 0.111493 HR: 0.157422
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.132646 HR: 0.223455
Eval costs: 0.193650 s
Iter 16...	Training loss: 78986.421875 (3017.497244, 2534.065943, 73434.867188) in 7.25s 
Iter 17...	Training loss: 71890.046875 (3076.552601, 2486.176571, 66327.318787) in 7.25s 
Iter 18...	Training loss: 65824.445312 (3146.931729, 2435.812612, 60241.702026) in 7.40s 
Iter 19...	Training loss: 60726.777344 (3241.116280, 2397.587046, 55088.082367) in 7.24s 
Iter 20...	Training loss: 55942.273438 (3346.356712, 2363.282271, 50232.634033) in 7.24s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.121608 HR: 0.167987
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.141753 HR: 0.230322
Eval costs: 0.207766 s
Iter 21...	Training loss: 47184.632812 (0.000000, 2335.078650, 44849.552155) in 5.84s 
Iter 22...	Training loss: 51275.714844 (6590.063892, 2307.070685, 42378.580566) in 8.61s 
Iter 23...	Training loss: 44589.839844 (3669.092523, 2280.625201, 38640.117157) in 7.21s 
Iter 24...	Training loss: 42251.035156 (3849.046981, 2252.055310, 36149.926971) in 7.25s 
Iter 25...	Training loss: 39495.273438 (3976.181970, 2233.907941, 33285.186218) in 7.24s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.178024 Precision: 0.035605 NDCG: 0.125377 HR: 0.178024
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.142619 HR: 0.231907
Eval costs: 0.211925 s
Iter 26...	Training loss: 37495.929688 (4104.299172, 2212.128232, 31179.499451) in 7.25s 
Iter 27...	Training loss: 35694.207031 (4210.372054, 2191.304885, 29292.530609) in 7.24s 
Iter 28...	Training loss: 34038.664062 (4301.107605, 2176.801767, 27560.755753) in 7.24s 
Iter 29...	Training loss: 32482.740234 (4403.008916, 2159.895596, 25919.834656) in 7.23s 
Iter 30...	Training loss: 31408.632812 (4497.606386, 2141.799309, 24769.225830) in 7.39s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.126354 HR: 0.175911
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.146450 HR: 0.238246
Eval costs: 0.216741 s
Iter 31...	Training loss: 30273.636719 (4583.910965, 2128.470780, 23561.252869) in 7.25s 
Iter 32...	Training loss: 29247.779297 (4670.316681, 2115.814831, 22461.649597) in 7.25s 
Iter 33...	Training loss: 28333.240234 (4750.060571, 2101.137330, 21482.042465) in 7.26s 
Iter 34...	Training loss: 27482.195312 (4831.308063, 2085.791086, 20565.095367) in 7.19s 
Iter 35...	Training loss: 26762.980469 (4902.235904, 2075.056621, 19785.687988) in 7.34s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.129070 HR: 0.177496
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.148749 HR: 0.237718
Eval costs: 0.223311 s
Iter 36...	Training loss: 26278.140625 (4966.064348, 2062.055267, 19250.021484) in 7.30s 
Iter 37...	Training loss: 25524.126953 (5018.140384, 2048.386735, 18457.600510) in 7.25s 
Iter 38...	Training loss: 25125.093750 (5080.354993, 2035.371803, 18009.366180) in 7.25s 
Iter 39...	Training loss: 24524.859375 (5135.625190, 2028.096155, 17361.137466) in 7.25s 
Iter 40...	Training loss: 24113.355469 (5190.744050, 2016.072034, 16906.537766) in 7.25s 
Top-1 Recall: 0.075541 Precision: 0.075541 NDCG: 0.075541 HR: 0.075541
Top-5 Recall: 0.179609 Precision: 0.035922 NDCG: 0.129156 HR: 0.179609
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.145994 HR: 0.231379
Eval costs: 0.229145 s
Iter 41...	Training loss: 23681.343750 (5234.881335, 2006.451007, 16440.010056) in 7.40s 
Iter 42...	Training loss: 23245.400391 (5276.490374, 1998.747059, 15970.161461) in 7.23s 
Iter 43...	Training loss: 22788.675781 (5330.473122, 1987.060176, 15471.143082) in 7.23s 
Iter 44...	Training loss: 22589.738281 (5367.834905, 1978.042602, 15243.857620) in 7.24s 
Iter 45...	Training loss: 22333.503906 (5408.807748, 1966.543026, 14958.154633) in 7.24s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.127216 HR: 0.177496
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.143068 HR: 0.226096
Eval costs: 0.231692 s
Iter 46...	Training loss: 21747.267578 (5446.490747, 1957.943169, 14342.833420) in 7.24s 
Iter 47...	Training loss: 21814.144531 (5487.247967, 1952.355236, 14374.542946) in 7.23s 
Iter 48...	Training loss: 21400.636719 (5526.791327, 1942.838191, 13931.006500) in 7.23s 
Iter 49...	Training loss: 21078.207031 (5569.834264, 1935.839727, 13572.532425) in 7.24s 
Iter 50...	Training loss: 16269.152344 (5606.218275, 0.000000, 10662.933144) in 4.60s 
Top-1 Recall: 0.077655 Precision: 0.077655 NDCG: 0.077655 HR: 0.077655
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.126242 HR: 0.173270
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.144801 HR: 0.230851
Eval costs: 0.236465 s
Iter 51...	Training loss: 24131.630859 (5633.332258, 3715.105133, 14783.192429) in 9.89s 
Iter 52...	Training loss: 13353.198242 (0.000000, 1928.040525, 11425.157639) in 6.03s 
Iter 53...	Training loss: 25681.750000 (10524.598829, 1912.978786, 13244.171600) in 8.60s 
Iter 54...	Training loss: 19990.539062 (5437.200988, 1905.930493, 12647.408691) in 7.23s 
Iter 55...	Training loss: 19904.101562 (5665.726694, 1898.343090, 12340.032516) in 7.24s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.124375 HR: 0.169044
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.142589 HR: 0.225568
Eval costs: 0.238899 s
Iter 56...	Training loss: 19664.480469 (5732.083606, 1891.402364, 12040.993843) in 7.23s 
Iter 57...	Training loss: 19641.054688 (5783.061661, 1881.438218, 11976.553955) in 7.24s 
Iter 58...	Training loss: 19516.421875 (5816.771873, 1876.465137, 11823.184082) in 7.25s 
Iter 59...	Training loss: 19249.953125 (5858.074640, 1872.676832, 11519.202805) in 7.26s 
Iter 60...	Training loss: 19238.435547 (5882.371697, 1864.774221, 11491.288300) in 7.23s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.123337 HR: 0.167987
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.140942 HR: 0.222398
Eval costs: 0.240170 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 3060014.250000 (192345.272905, 108561.478642, 2759107.484375) in 7.59s 
Iter 2...	Training loss: 1836308.750000 (16020.434885, 19196.483113, 1801091.908203) in 7.24s 
Iter 3...	Training loss: 1360614.625000 (12272.648296, 10065.544718, 1338276.528320) in 7.23s 
Iter 4...	Training loss: 1047706.437500 (10045.593384, 6296.146057, 1031364.710938) in 7.25s 
Iter 5...	Training loss: 817697.687500 (8045.242950, 4723.599517, 804928.872559) in 7.24s 
Top-1 Recall: 0.010037 Precision: 0.010037 NDCG: 0.010037 HR: 0.010037
Top-5 Recall: 0.041733 Precision: 0.008347 NDCG: 0.025988 HR: 0.041733
Top-10 Recall: 0.070259 Precision: 0.007026 NDCG: 0.035018 HR: 0.070259
Eval costs: 0.172818 s
Iter 6...	Training loss: 624282.125000 (0.000000, 3895.274879, 620386.951172) in 6.08s 
Iter 7...	Training loss: 491073.031250 (11041.755737, 3396.992139, 476634.240479) in 8.48s 
Iter 8...	Training loss: 376066.312500 (4301.888464, 3059.836820, 368704.604004) in 7.42s 
Iter 9...	Training loss: 297906.937500 (3828.406434, 2831.276201, 291247.230957) in 7.24s 
Iter 10...	Training loss: 243908.093750 (3567.016088, 2652.330355, 237688.745972) in 7.25s 
Top-1 Recall: 0.052826 Precision: 0.052826 NDCG: 0.052826 HR: 0.052826
Top-5 Recall: 0.142102 Precision: 0.028420 NDCG: 0.099356 HR: 0.142102
Top-10 Recall: 0.206022 Precision: 0.020602 NDCG: 0.120015 HR: 0.206022
Eval costs: 0.187841 s
Iter 11...	Training loss: 204508.546875 (3432.759980, 2508.909152, 198566.883301) in 7.26s 
Iter 12...	Training loss: 175539.078125 (3388.452964, 2389.681361, 169760.965210) in 7.25s 
Iter 13...	Training loss: 153960.078125 (3387.602931, 2291.468379, 148280.992065) in 7.25s 
Iter 14...	Training loss: 137070.781250 (3415.215538, 2202.785199, 131452.795349) in 7.26s 
Iter 15...	Training loss: 123531.507812 (3466.189302, 2123.169097, 117942.150635) in 7.23s 
Top-1 Recall: 0.065504 Precision: 0.065504 NDCG: 0.065504 HR: 0.065504
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.116793 HR: 0.168516
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.136588 HR: 0.229794
Eval costs: 0.193202 s
Iter 16...	Training loss: 112773.664062 (3530.859058, 2054.260490, 107188.543823) in 7.23s 
Iter 17...	Training loss: 103645.093750 (3586.856157, 1995.511162, 98062.726379) in 7.23s 
Iter 18...	Training loss: 96002.039062 (3658.143958, 1938.450524, 90405.442993) in 7.28s 
Iter 19...	Training loss: 89205.570312 (3758.498520, 1889.822914, 83557.258972) in 7.42s 
Iter 20...	Training loss: 83419.031250 (3839.166237, 1844.993289, 77734.873901) in 7.23s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.118902 HR: 0.170100
Top-10 Recall: 0.232964 Precision: 0.023296 NDCG: 0.138951 HR: 0.232964
Eval costs: 0.199584 s
Iter 21...	Training loss: 78305.250000 (3939.112494, 1802.266531, 72563.873871) in 7.25s 
Iter 22...	Training loss: 73807.875000 (4027.232099, 1769.983212, 68010.661713) in 7.26s 
Iter 23...	Training loss: 70057.867188 (4110.259563, 1734.788434, 64212.820587) in 7.26s 
Iter 24...	Training loss: 66211.960938 (4220.705444, 1705.147455, 60286.108124) in 7.26s 
Iter 25...	Training loss: 63065.613281 (4317.435258, 1677.164411, 57071.018280) in 7.26s 
Top-1 Recall: 0.063920 Precision: 0.063920 NDCG: 0.063920 HR: 0.063920
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.118060 HR: 0.168516
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.136882 HR: 0.226624
Eval costs: 0.208657 s
Iter 26...	Training loss: 60068.679688 (4419.459915, 1652.100515, 53997.119110) in 7.24s 
Iter 27...	Training loss: 57338.984375 (4517.244980, 1629.320156, 51192.422424) in 7.25s 
Iter 28...	Training loss: 55153.050781 (4639.717273, 1606.618666, 48906.712006) in 7.24s 
Iter 29...	Training loss: 52871.593750 (4739.345486, 1587.418779, 46544.831177) in 7.25s 
Iter 30...	Training loss: 50865.648438 (4856.395746, 1566.360586, 44442.891327) in 7.23s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.119485 HR: 0.165874
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.140536 HR: 0.231379
Eval costs: 0.374283 s
Iter 31...	Training loss: 48890.242188 (4953.779789, 1553.947624, 42382.522827) in 7.25s 
Iter 32...	Training loss: 47463.562500 (5073.854783, 1538.167138, 40851.537842) in 7.25s 
Iter 33...	Training loss: 45979.070312 (5187.419338, 1523.142771, 39268.505478) in 7.26s 
Iter 34...	Training loss: 44769.437500 (5298.387672, 1507.408376, 37963.643646) in 7.24s 
Iter 35...	Training loss: 43799.656250 (5412.957811, 1498.310532, 36888.388367) in 7.23s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.121033 HR: 0.165346
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.142645 HR: 0.231907
Eval costs: 0.222751 s
Iter 36...	Training loss: 42456.792969 (5513.307107, 1484.982407, 35458.504532) in 7.24s 
Iter 37...	Training loss: 41768.460938 (5626.283863, 1473.407239, 34668.770950) in 7.23s 
Iter 38...	Training loss: 40731.070312 (5729.530165, 1462.949937, 33538.585403) in 7.23s 
Iter 39...	Training loss: 40030.085938 (5832.255767, 1452.703211, 32745.123260) in 7.24s 
Iter 40...	Training loss: 39189.914062 (5946.712478, 1442.681526, 31800.517914) in 7.23s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.119621 HR: 0.163761
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.141588 HR: 0.231907
Eval costs: 0.229600 s
Iter 41...	Training loss: 38744.710938 (6030.451914, 1437.807458, 31276.453156) in 7.40s 
Iter 42...	Training loss: 37977.828125 (6135.836322, 1427.663410, 30414.328461) in 7.23s 
Iter 43...	Training loss: 37648.519531 (6237.203557, 1421.030230, 29990.285706) in 7.23s 
Iter 44...	Training loss: 36947.230469 (6336.624612, 1411.496695, 29199.109314) in 7.26s 
Iter 45...	Training loss: 36770.082031 (6425.761063, 1405.637045, 28938.680740) in 7.24s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.118671 HR: 0.164818
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.138711 HR: 0.227153
Eval costs: 0.234909 s
Iter 46...	Training loss: 27592.187500 (0.000000, 1400.474576, 26191.712570) in 6.02s 
Iter 47...	Training loss: 42185.992188 (12394.349041, 1393.041832, 28398.599060) in 8.48s 
Iter 48...	Training loss: 35171.312500 (6356.719982, 1386.196977, 27428.394379) in 7.25s 
Iter 49...	Training loss: 35123.960938 (6688.767134, 1379.956919, 27055.239029) in 7.23s 
Iter 50...	Training loss: 34910.867188 (6824.838868, 1373.890995, 26712.137787) in 7.24s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.118326 HR: 0.164818
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.136994 HR: 0.223455
Eval costs: 0.240103 s
Iter 51...	Training loss: 34718.160156 (6925.353503, 1368.932670, 26423.873581) in 7.25s 
Iter 52...	Training loss: 34445.007812 (7008.530092, 1363.133037, 26073.344193) in 7.23s 
Iter 53...	Training loss: 34228.765625 (7079.027541, 1356.632842, 25793.105820) in 7.41s 
Iter 54...	Training loss: 34159.394531 (7157.362166, 1352.052094, 25649.980362) in 7.24s 
Iter 55...	Training loss: 33920.882812 (7220.532562, 1346.617039, 25353.733215) in 7.26s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.116009 HR: 0.162176
Top-10 Recall: 0.215003 Precision: 0.021500 NDCG: 0.132995 HR: 0.215003
Eval costs: 0.242651 s
Iter 56...	Training loss: 33790.136719 (7295.164681, 1346.953375, 25148.019699) in 7.26s 
Iter 57...	Training loss: 33568.113281 (7352.142441, 1342.903925, 24873.067924) in 7.25s 
Iter 58...	Training loss: 33412.972656 (7424.169738, 1337.742664, 24651.058807) in 7.25s 
Iter 59...	Training loss: 33278.093750 (7471.957930, 1331.256634, 24474.876717) in 7.25s 
Iter 60...	Training loss: 33151.109375 (7524.110630, 1327.453070, 24299.545738) in 7.25s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.164289 Precision: 0.032858 NDCG: 0.118348 HR: 0.164289
Top-10 Recall: 0.218172 Precision: 0.021817 NDCG: 0.135564 HR: 0.218172
Eval costs: 0.242908 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 649564.375000 (192584.210973, 108084.040369, 348896.085693) in 7.57s 
Iter 2...	Training loss: 304866.500000 (15776.551530, 19851.245259, 269238.754150) in 7.22s 
Iter 3...	Training loss: 253433.625000 (11554.933769, 11795.305462, 230083.373657) in 7.21s 
Iter 4...	Training loss: 220556.109375 (9122.408339, 8130.565020, 203303.143921) in 7.21s 
Iter 5...	Training loss: 194337.921875 (7238.682096, 6392.393498, 180706.846680) in 7.21s 
Top-1 Recall: 0.034337 Precision: 0.034337 NDCG: 0.034337 HR: 0.034337
Top-5 Recall: 0.098257 Precision: 0.019651 NDCG: 0.066751 HR: 0.098257
Top-10 Recall: 0.129952 Precision: 0.012995 NDCG: 0.077039 HR: 0.129952
Eval costs: 0.175626 s
Iter 6...	Training loss: 173368.781250 (5868.378330, 5381.126377, 162119.273438) in 7.38s 
Iter 7...	Training loss: 157292.296875 (4908.087595, 4679.755687, 147704.436279) in 7.23s 
Iter 8...	Training loss: 144532.921875 (4234.161456, 4204.458189, 136094.302979) in 7.23s 
Iter 9...	Training loss: 134073.546875 (3762.308692, 3837.847857, 126473.394897) in 7.21s 
Iter 10...	Training loss: 124845.320312 (3422.788702, 3578.149826, 117844.380981) in 7.23s 
Top-1 Recall: 0.053883 Precision: 0.053883 NDCG: 0.053883 HR: 0.053883
Top-5 Recall: 0.130481 Precision: 0.026096 NDCG: 0.092310 HR: 0.130481
Top-10 Recall: 0.178553 Precision: 0.017855 NDCG: 0.107665 HR: 0.178553
Eval costs: 0.176515 s
Iter 11...	Training loss: 116155.640625 (3179.059776, 3376.354782, 109600.222656) in 7.23s 
Iter 12...	Training loss: 108078.593750 (3001.499865, 3239.598660, 101837.496094) in 7.23s 
Iter 13...	Training loss: 100176.656250 (2873.161804, 3131.163275, 94172.337402) in 7.23s 
Iter 14...	Training loss: 92441.953125 (2782.007932, 3052.919945, 86607.033447) in 7.24s 
Iter 15...	Training loss: 84972.718750 (2717.969420, 2990.530574, 79264.218079) in 7.23s 
Top-1 Recall: 0.059165 Precision: 0.059165 NDCG: 0.059165 HR: 0.059165
Top-5 Recall: 0.156366 Precision: 0.031273 NDCG: 0.108064 HR: 0.156366
Top-10 Recall: 0.214474 Precision: 0.021447 NDCG: 0.126900 HR: 0.214474
Eval costs: 0.188613 s
Iter 16...	Training loss: 78246.617188 (2680.785239, 2938.816372, 72627.021606) in 7.25s 
Iter 17...	Training loss: 71334.968750 (2660.298751, 2900.029412, 65774.631165) in 7.25s 
Iter 18...	Training loss: 64965.617188 (2657.290093, 2874.891132, 59433.435120) in 7.39s 
Iter 19...	Training loss: 59367.894531 (2664.892590, 2852.963566, 53850.035156) in 7.27s 
Iter 20...	Training loss: 54587.425781 (2681.803045, 2825.626442, 49079.990326) in 7.25s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.119425 HR: 0.169572
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.139348 HR: 0.231379
Eval costs: 0.200263 s
Iter 21...	Training loss: 50165.078125 (2702.172761, 2815.621534, 44647.284882) in 7.22s 
Iter 22...	Training loss: 46475.734375 (2729.336320, 2801.122406, 40945.278381) in 7.25s 
Iter 23...	Training loss: 43587.546875 (2751.247860, 2789.823830, 38046.479187) in 7.25s 
Iter 24...	Training loss: 40696.761719 (2769.355674, 2786.051693, 35141.355774) in 7.26s 
Iter 25...	Training loss: 38426.578125 (2788.285211, 2782.862880, 32855.428558) in 7.24s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.175383 Precision: 0.035077 NDCG: 0.124226 HR: 0.175383
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.142023 HR: 0.230851
Eval costs: 0.210199 s
Iter 26...	Training loss: 36421.070312 (2804.153612, 2772.733381, 30844.183319) in 7.23s 
Iter 27...	Training loss: 34825.964844 (2811.818367, 2772.077668, 29242.068100) in 7.26s 
Iter 28...	Training loss: 33303.007812 (2815.144089, 2765.079306, 27722.782104) in 7.25s 
Iter 29...	Training loss: 31551.812500 (2819.866272, 2766.829953, 25965.114670) in 7.39s 
Iter 30...	Training loss: 30401.517578 (2815.143319, 2765.056924, 24821.317230) in 7.24s 
Top-1 Recall: 0.078183 Precision: 0.078183 NDCG: 0.078183 HR: 0.078183
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.129902 HR: 0.177496
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.147076 HR: 0.230851
Eval costs: 0.218588 s
Iter 31...	Training loss: 29669.824219 (2808.118677, 2760.700468, 24101.004730) in 7.27s 
Iter 32...	Training loss: 28372.476562 (2804.029401, 2762.242782, 22806.205795) in 7.23s 
Iter 33...	Training loss: 27395.666016 (2796.901585, 2759.431671, 21839.333176) in 7.24s 
Iter 34...	Training loss: 26440.039062 (2789.966079, 2761.788125, 20888.282608) in 7.25s 
Iter 35...	Training loss: 25771.070312 (2779.950788, 2766.182190, 20224.937042) in 7.24s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.184892 Precision: 0.036978 NDCG: 0.132605 HR: 0.184892
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.148377 HR: 0.234020
Eval costs: 0.226984 s
Iter 36...	Training loss: 25008.515625 (2766.966381, 2766.414050, 19475.138245) in 7.24s 
Iter 37...	Training loss: 24395.037109 (2756.573384, 2768.491130, 18869.973099) in 7.25s 
Iter 38...	Training loss: 23651.007812 (2743.526535, 2772.125027, 18135.355499) in 7.23s 
Iter 39...	Training loss: 23213.728516 (2728.103758, 2781.314229, 17704.311676) in 7.24s 
Iter 40...	Training loss: 22633.457031 (2715.954283, 2785.805652, 17131.695831) in 7.39s 
Top-1 Recall: 0.080296 Precision: 0.080296 NDCG: 0.080296 HR: 0.080296
Top-5 Recall: 0.180137 Precision: 0.036027 NDCG: 0.131455 HR: 0.180137
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.148892 HR: 0.234548
Eval costs: 0.229532 s
Iter 41...	Training loss: 22024.660156 (2702.999316, 2789.359910, 16532.301132) in 7.27s 
Iter 42...	Training loss: 21712.464844 (2691.673213, 2796.376291, 16224.414780) in 7.24s 
Iter 43...	Training loss: 21018.166016 (2680.024912, 2798.218801, 15539.919937) in 7.21s 
Iter 44...	Training loss: 20593.279297 (2668.614730, 2805.041511, 15119.622452) in 7.24s 
Iter 45...	Training loss: 20716.011719 (2656.791653, 2814.500694, 15244.721039) in 7.24s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.127057 HR: 0.173798
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.145227 HR: 0.229794
Eval costs: 0.232460 s
Iter 46...	Training loss: 19953.625000 (2644.574045, 2820.996216, 14488.054367) in 7.25s 
Iter 47...	Training loss: 19577.958984 (2630.245171, 2824.331207, 14123.381271) in 7.26s 
Iter 48...	Training loss: 19230.683594 (2616.223733, 2835.023054, 13779.435974) in 7.25s 
Iter 49...	Training loss: 18988.722656 (2603.397099, 2843.013981, 13542.311737) in 7.24s 
Iter 50...	Training loss: 18694.162109 (2598.093486, 2848.788728, 13247.280251) in 7.24s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.178024 Precision: 0.035605 NDCG: 0.125864 HR: 0.178024
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.143873 HR: 0.233492
Eval costs: 0.237494 s
Iter 51...	Training loss: 18358.666016 (2584.049659, 2859.622770, 12914.994209) in 7.40s 
Iter 52...	Training loss: 18228.890625 (2574.327629, 2867.905223, 12786.657227) in 7.26s 
Iter 53...	Training loss: 17791.173828 (2562.339980, 2877.440179, 12351.394089) in 7.25s 
Iter 54...	Training loss: 17532.148438 (2551.766708, 2886.418781, 12093.964493) in 7.24s 
Iter 55...	Training loss: 17536.261719 (2541.224055, 2891.961128, 12103.077675) in 7.27s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.126524 HR: 0.173270
Top-10 Recall: 0.238774 Precision: 0.023877 NDCG: 0.147771 HR: 0.238774
Eval costs: 0.239196 s
Iter 56...	Training loss: 16919.347656 (2528.128808, 2904.791371, 11486.428909) in 7.25s 
Iter 57...	Training loss: 16781.445312 (2518.422481, 2909.599857, 11353.421349) in 7.24s 
Iter 58...	Training loss: 16745.169922 (2507.588642, 2918.362544, 11319.218109) in 7.22s 
Iter 59...	Training loss: 16648.343750 (2496.495697, 2926.011825, 11225.837349) in 7.22s 
Iter 60...	Training loss: 16377.644531 (2488.408455, 2938.501453, 10950.733734) in 7.25s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.123710 HR: 0.172742
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.142184 HR: 0.229794
Eval costs: 0.240451 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 676208.125000 (192869.784061, 108853.312208, 374485.050293) in 7.58s 
Iter 2...	Training loss: 325100.812500 (15784.477837, 19967.820002, 289348.494385) in 7.24s 
Iter 3...	Training loss: 271172.687500 (11554.682428, 11814.870913, 247803.117065) in 7.23s 
Iter 4...	Training loss: 236338.484375 (9128.731829, 8061.389719, 219148.369507) in 7.25s 
Iter 5...	Training loss: 208459.875000 (7240.841719, 6262.546655, 194956.481689) in 7.22s 
Top-1 Recall: 0.036450 Precision: 0.036450 NDCG: 0.036450 HR: 0.036450
Top-5 Recall: 0.101426 Precision: 0.020285 NDCG: 0.069093 HR: 0.101426
Top-10 Recall: 0.134707 Precision: 0.013471 NDCG: 0.079680 HR: 0.134707
Eval costs: 0.176670 s
Iter 6...	Training loss: 185487.703125 (5862.320649, 5222.541619, 174402.857300) in 7.41s 
Iter 7...	Training loss: 167864.562500 (4895.014403, 4533.590976, 158435.955933) in 7.23s 
Iter 8...	Training loss: 153618.953125 (4224.557472, 4054.803719, 145339.608643) in 7.25s 
Iter 9...	Training loss: 141436.390625 (3745.531801, 3715.277206, 133975.577637) in 7.24s 
Iter 10...	Training loss: 131160.734375 (3405.167042, 3472.210658, 124283.361938) in 7.24s 
Top-1 Recall: 0.052298 Precision: 0.052298 NDCG: 0.052298 HR: 0.052298
Top-5 Recall: 0.132066 Precision: 0.026413 NDCG: 0.093028 HR: 0.132066
Top-10 Recall: 0.179609 Precision: 0.017961 NDCG: 0.108589 HR: 0.179609
Eval costs: 0.178189 s
Iter 11...	Training loss: 121466.507812 (3163.580056, 3283.918831, 115018.996338) in 7.23s 
Iter 12...	Training loss: 112918.578125 (2984.504170, 3148.483297, 106785.578552) in 7.24s 
Iter 13...	Training loss: 104501.710938 (2861.245207, 3048.534806, 98591.923340) in 7.24s 
Iter 14...	Training loss: 96623.437500 (2766.147271, 2974.138195, 90883.159424) in 7.23s 
Iter 15...	Training loss: 89085.601562 (2706.825911, 2904.886727, 83473.889954) in 7.26s 
Top-1 Recall: 0.061807 Precision: 0.061807 NDCG: 0.061807 HR: 0.061807
Top-5 Recall: 0.160592 Precision: 0.032118 NDCG: 0.112046 HR: 0.160592
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.131873 HR: 0.222398
Eval costs: 0.190637 s
Iter 16...	Training loss: 81495.679688 (2665.770478, 2857.768038, 75972.139771) in 7.23s 
Iter 17...	Training loss: 74616.125000 (2644.964241, 2816.313678, 69154.849182) in 7.40s 
Iter 18...	Training loss: 68194.773438 (2642.661167, 2788.878090, 62763.238586) in 7.26s 
Iter 19...	Training loss: 63014.738281 (2654.261765, 2760.322800, 57600.150208) in 7.24s 
Iter 20...	Training loss: 57888.667969 (2669.441454, 2734.608534, 52484.617676) in 7.24s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.121992 HR: 0.174326
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.141809 HR: 0.235605
Eval costs: 0.202501 s
Iter 21...	Training loss: 53641.644531 (2692.813737, 2718.558441, 48230.272888) in 7.25s 
Iter 22...	Training loss: 49915.140625 (2715.658681, 2700.309169, 44499.169647) in 7.24s 
Iter 23...	Training loss: 46905.382812 (2739.760090, 2687.905630, 41477.720825) in 7.26s 
Iter 24...	Training loss: 43913.625000 (2761.487316, 2678.520539, 38473.618408) in 7.24s 
Iter 25...	Training loss: 41606.445312 (2778.569192, 2664.362005, 36163.514557) in 7.24s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.182250 Precision: 0.036450 NDCG: 0.129335 HR: 0.182250
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.147159 HR: 0.238246
Eval costs: 0.211000 s
Iter 26...	Training loss: 39517.726562 (2790.709333, 2652.568722, 34074.450989) in 7.26s 
Iter 27...	Training loss: 37695.667969 (2798.338170, 2647.229511, 32250.102585) in 7.25s 
Iter 28...	Training loss: 36031.703125 (2808.591783, 2636.231646, 30586.881912) in 7.25s 
Iter 29...	Training loss: 34811.847656 (2808.865342, 2630.466586, 29372.516113) in 7.45s 
Iter 30...	Training loss: 33492.601562 (2809.886512, 2624.737505, 28057.978165) in 7.26s 
Top-1 Recall: 0.079239 Precision: 0.079239 NDCG: 0.079239 HR: 0.079239
Top-5 Recall: 0.182250 Precision: 0.036450 NDCG: 0.131423 HR: 0.182250
Top-10 Recall: 0.238774 Precision: 0.023877 NDCG: 0.149462 HR: 0.238774
Eval costs: 0.219444 s
Iter 31...	Training loss: 32321.623047 (2807.711434, 2625.087625, 26888.821976) in 7.25s 
Iter 32...	Training loss: 31201.365234 (2800.841112, 2616.329664, 25784.194107) in 7.26s 
Iter 33...	Training loss: 30371.363281 (2798.720206, 2608.734129, 24963.910385) in 7.26s 
Iter 34...	Training loss: 29379.283203 (2790.071952, 2608.130436, 23981.081650) in 7.25s 
Iter 35...	Training loss: 28661.525391 (2785.151086, 2605.036663, 23271.337631) in 7.24s 
Top-1 Recall: 0.080296 Precision: 0.080296 NDCG: 0.080296 HR: 0.080296
Top-5 Recall: 0.183835 Precision: 0.036767 NDCG: 0.133098 HR: 0.183835
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.150673 HR: 0.238246
Eval costs: 0.226137 s
Iter 36...	Training loss: 27975.380859 (2777.275399, 2606.114908, 22591.990768) in 7.27s 
Iter 37...	Training loss: 27283.617188 (2767.712213, 2597.581674, 21918.322540) in 7.23s 
Iter 38...	Training loss: 26653.177734 (2755.913110, 2597.052024, 21300.212738) in 7.23s 
Iter 39...	Training loss: 26013.880859 (2747.015985, 2595.326254, 20671.538849) in 7.23s 
Iter 40...	Training loss: 25512.361328 (2734.649190, 2596.128148, 20181.583771) in 7.39s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.181194 Precision: 0.036239 NDCG: 0.131172 HR: 0.181194
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.148642 HR: 0.235605
Eval costs: 0.228513 s
Iter 41...	Training loss: 24961.869141 (2725.518659, 2591.846223, 19644.504791) in 7.26s 
Iter 42...	Training loss: 24481.800781 (2717.485004, 2588.639173, 19175.676285) in 7.24s 
Iter 43...	Training loss: 23919.062500 (2707.657553, 2589.692471, 18621.711792) in 7.27s 
Iter 44...	Training loss: 23448.769531 (2695.141751, 2594.853691, 18158.772964) in 7.23s 
Iter 45...	Training loss: 23155.994141 (2683.366828, 2593.628480, 17879.001587) in 7.25s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.182779 Precision: 0.036556 NDCG: 0.130531 HR: 0.182779
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.147553 HR: 0.235077
Eval costs: 0.234123 s
Iter 46...	Training loss: 22803.347656 (2674.530860, 2591.703310, 17537.113083) in 7.27s 
Iter 47...	Training loss: 22496.433594 (2666.009090, 2595.821217, 17234.601654) in 7.28s 
Iter 48...	Training loss: 22038.171875 (2655.700475, 2594.732668, 16787.737320) in 7.27s 
Iter 49...	Training loss: 21715.683594 (2648.119410, 2595.660989, 16471.903442) in 7.26s 
Iter 50...	Training loss: 21423.781250 (2639.108365, 2593.711648, 16190.959747) in 7.29s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.127486 HR: 0.176440
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.146470 HR: 0.235077
Eval costs: 0.237029 s
Iter 51...	Training loss: 21101.767578 (2628.151444, 2597.693579, 15875.922005) in 7.41s 
Iter 52...	Training loss: 20750.228516 (2621.232257, 2595.854666, 15533.141891) in 7.24s 
Iter 53...	Training loss: 20592.050781 (2612.356648, 2597.866118, 15381.826897) in 7.25s 
Iter 54...	Training loss: 20225.660156 (2603.370923, 2603.171177, 15019.117287) in 7.26s 
Iter 55...	Training loss: 20060.953125 (2596.873116, 2604.605067, 14859.476242) in 7.25s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.126380 HR: 0.172213
Top-10 Recall: 0.232964 Precision: 0.023296 NDCG: 0.146203 HR: 0.232964
Eval costs: 0.238856 s
Iter 56...	Training loss: 19858.160156 (2589.260808, 2606.876079, 14662.023216) in 7.27s 
Iter 57...	Training loss: 19564.263672 (2582.004693, 2606.372827, 14375.885780) in 7.26s 
Iter 58...	Training loss: 19330.011719 (2577.027642, 2604.236763, 14148.745796) in 7.26s 
Iter 59...	Training loss: 19286.369141 (2570.780287, 2608.347320, 14107.241447) in 7.25s 
Iter 60...	Training loss: 18985.205078 (2564.761615, 2604.234070, 13816.209335) in 7.23s 
Top-1 Recall: 0.079239 Precision: 0.079239 NDCG: 0.079239 HR: 0.079239
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.129751 HR: 0.176968
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.146116 HR: 0.228209
Eval costs: 0.242679 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 911788.625000 (192954.676612, 108045.963278, 610788.061035) in 7.58s 
Iter 2...	Training loss: 479027.562500 (15806.952395, 19657.848677, 443562.807373) in 7.21s 
Iter 3...	Training loss: 388278.906250 (11561.120506, 11083.599626, 365634.207520) in 7.22s 
Iter 4...	Training loss: 328459.937500 (9076.334893, 7222.028238, 312161.588867) in 7.22s 
Iter 5...	Training loss: 278197.562500 (7167.729003, 5461.557973, 265568.282715) in 7.21s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.106181 Precision: 0.021236 NDCG: 0.074251 HR: 0.106181
Top-10 Recall: 0.140518 Precision: 0.014052 NDCG: 0.085296 HR: 0.140518
Eval costs: 0.177586 s
Iter 6...	Training loss: 235303.843750 (5751.457719, 4531.236019, 225021.139282) in 7.22s 
Iter 7...	Training loss: 202320.546875 (4772.520650, 3951.693616, 193596.357056) in 7.37s 
Iter 8...	Training loss: 176472.968750 (4101.405291, 3544.757836, 168826.805908) in 7.24s 
Iter 9...	Training loss: 156730.062500 (3640.791097, 3270.175951, 149819.091187) in 7.24s 
Iter 10...	Training loss: 140646.781250 (3318.486566, 3067.979725, 134260.311890) in 7.24s 
Top-1 Recall: 0.059694 Precision: 0.059694 NDCG: 0.059694 HR: 0.059694
Top-5 Recall: 0.153724 Precision: 0.030745 NDCG: 0.107109 HR: 0.153724
Top-10 Recall: 0.208663 Precision: 0.020866 NDCG: 0.124714 HR: 0.208663
Eval costs: 0.182584 s
Iter 11...	Training loss: 127898.437500 (3093.154871, 2908.684957, 121896.588135) in 7.24s 
Iter 12...	Training loss: 116833.500000 (2935.553477, 2794.548110, 111103.394104) in 7.22s 
Iter 13...	Training loss: 107328.585938 (2819.200024, 2703.514281, 101805.879883) in 7.23s 
Iter 14...	Training loss: 98778.406250 (2738.742983, 2623.749404, 93415.913452) in 7.25s 
Iter 15...	Training loss: 91019.695312 (2681.299232, 2556.977426, 85781.419250) in 7.24s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.119753 HR: 0.167459
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.141201 HR: 0.235077
Eval costs: 0.192289 s
Iter 16...	Training loss: 84544.187500 (2645.725482, 2496.479986, 79401.988281) in 7.25s 
Iter 17...	Training loss: 78302.179688 (2620.268783, 2450.877950, 73231.024841) in 7.25s 
Iter 18...	Training loss: 72861.570312 (2611.249663, 2406.323791, 67843.996521) in 7.41s 
Iter 19...	Training loss: 67590.882812 (2611.037067, 2365.153974, 62614.684052) in 7.25s 
Iter 20...	Training loss: 62993.015625 (2624.394394, 2333.054403, 58035.567047) in 7.22s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.127449 HR: 0.176968
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.147141 HR: 0.238246
Eval costs: 0.203288 s
Iter 21...	Training loss: 59270.648438 (2638.120368, 2300.658010, 54331.870667) in 7.23s 
Iter 22...	Training loss: 55518.953125 (2657.069382, 2274.745415, 50587.136169) in 7.27s 
Iter 23...	Training loss: 46354.687500 (0.000000, 2253.417466, 44101.275726) in 6.02s 
Iter 24...	Training loss: 52674.316406 (4950.713040, 2225.461756, 45498.143280) in 8.48s 
Iter 25...	Training loss: 47128.953125 (2799.833381, 2201.364397, 42127.751953) in 7.25s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.179609 Precision: 0.035922 NDCG: 0.129420 HR: 0.179609
Top-10 Recall: 0.244585 Precision: 0.024459 NDCG: 0.150091 HR: 0.244585
Eval costs: 0.212074 s
Iter 26...	Training loss: 44510.742188 (2812.176581, 2188.158992, 39510.409943) in 7.25s 
Iter 27...	Training loss: 42635.687500 (2815.004109, 2165.604234, 37655.077698) in 7.28s 
Iter 28...	Training loss: 40569.250000 (2826.870607, 2150.674783, 35591.704834) in 7.25s 
Iter 29...	Training loss: 38973.957031 (2835.756584, 2127.627214, 34010.574615) in 7.24s 
Iter 30...	Training loss: 37431.890625 (2841.469217, 2117.848712, 32472.571747) in 7.41s 
Top-1 Recall: 0.081352 Precision: 0.081352 NDCG: 0.081352 HR: 0.081352
Top-5 Recall: 0.180137 Precision: 0.036027 NDCG: 0.132167 HR: 0.180137
Top-10 Recall: 0.243529 Precision: 0.024353 NDCG: 0.152610 HR: 0.243529
Eval costs: 0.221705 s
Iter 31...	Training loss: 35980.679688 (2850.519491, 2107.143019, 31023.020477) in 7.26s 
Iter 32...	Training loss: 28664.890625 (0.000000, 2088.625611, 26576.267029) in 5.85s 
Iter 33...	Training loss: 37767.074219 (5153.326615, 2078.648794, 30535.098495) in 8.63s 
Iter 34...	Training loss: 32929.218750 (2924.259284, 2061.912178, 27943.045273) in 7.25s 
Iter 35...	Training loss: 31984.294922 (2926.558536, 2052.837458, 27004.901352) in 7.26s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.179609 Precision: 0.035922 NDCG: 0.130837 HR: 0.179609
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.148465 HR: 0.234020
Eval costs: 0.225617 s
Iter 36...	Training loss: 30965.099609 (2914.977895, 2042.516914, 26007.604080) in 7.24s 
Iter 37...	Training loss: 30246.173828 (2910.963375, 2033.853272, 25301.358566) in 7.24s 
Iter 38...	Training loss: 29531.357422 (2897.134034, 2023.599791, 24610.623901) in 7.24s 
Iter 39...	Training loss: 28809.662109 (2894.942266, 2012.956861, 23901.760498) in 7.24s 
Iter 40...	Training loss: 28273.267578 (2886.999815, 2003.293920, 23382.975800) in 7.24s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.180137 Precision: 0.036027 NDCG: 0.128676 HR: 0.180137
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.146083 HR: 0.234020
Eval costs: 0.232012 s
Iter 41...	Training loss: 27568.316406 (2884.061854, 1994.358249, 22689.896759) in 7.42s 
Iter 42...	Training loss: 26985.962891 (2882.946068, 1990.717130, 22112.301529) in 7.24s 
Iter 43...	Training loss: 26597.726562 (2879.321889, 1979.289859, 21739.114838) in 7.25s 
Iter 44...	Training loss: 26158.117188 (2876.300284, 1973.460401, 21308.357346) in 7.23s 
Iter 45...	Training loss: 25618.582031 (2874.811770, 1962.545041, 20781.224197) in 7.23s 
Top-1 Recall: 0.078183 Precision: 0.078183 NDCG: 0.078183 HR: 0.078183
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.128584 HR: 0.175911
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.146913 HR: 0.232435
Eval costs: 0.235070 s
Iter 46...	Training loss: 25188.937500 (2871.472724, 1957.214987, 20360.251328) in 7.26s 
Iter 47...	Training loss: 24720.861328 (2871.108912, 1951.888352, 19897.862625) in 7.25s 
Iter 48...	Training loss: 24368.277344 (2870.402156, 1942.534930, 19555.340546) in 7.25s 
Iter 49...	Training loss: 23964.375000 (2866.249475, 1941.746942, 19156.380859) in 7.26s 
Iter 50...	Training loss: 23735.722656 (2866.588052, 1937.058882, 18932.074097) in 7.25s 
Top-1 Recall: 0.081881 Precision: 0.081881 NDCG: 0.081881 HR: 0.081881
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.129456 HR: 0.174855
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.148787 HR: 0.235077
Eval costs: 0.239000 s
Iter 51...	Training loss: 23281.447266 (2865.207778, 1928.774943, 18487.464340) in 7.26s 
Iter 52...	Training loss: 23059.208984 (2867.414208, 1925.653718, 18266.140923) in 7.39s 
Iter 53...	Training loss: 22570.296875 (2866.853759, 1913.690969, 17789.751137) in 7.24s 
Iter 54...	Training loss: 22324.427734 (2865.496138, 1909.358881, 17549.572113) in 7.26s 
Iter 55...	Training loss: 22239.558594 (2865.438113, 1906.342546, 17467.779327) in 7.25s 
Top-1 Recall: 0.079239 Precision: 0.079239 NDCG: 0.079239 HR: 0.079239
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.126974 HR: 0.172742
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.145710 HR: 0.230851
Eval costs: 0.238654 s
Iter 56...	Training loss: 21905.771484 (2863.567035, 1901.711521, 17140.492386) in 7.26s 
Iter 57...	Training loss: 21590.007812 (2864.194173, 1894.928865, 16830.885101) in 7.25s 
Iter 58...	Training loss: 21182.328125 (2862.335157, 1889.488260, 16430.503952) in 7.26s 
Iter 59...	Training loss: 21163.777344 (2862.373415, 1886.900762, 16414.504349) in 7.24s 
Iter 60...	Training loss: 20790.619141 (2863.025838, 1882.954322, 16044.639008) in 7.25s 
Top-1 Recall: 0.081881 Precision: 0.081881 NDCG: 0.081881 HR: 0.081881
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.126186 HR: 0.168516
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.143781 HR: 0.223455
Eval costs: 0.242236 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 3167552.500000 (192056.562864, 107602.406498, 2867893.412109) in 7.57s 
Iter 2...	Training loss: 1873224.125000 (15696.815108, 19028.112687, 1838499.162109) in 7.21s 
Iter 3...	Training loss: 1398516.625000 (11553.486843, 9995.141143, 1376967.949219) in 7.26s 
Iter 4...	Training loss: 1094851.250000 (9065.614854, 6272.086694, 1079513.645508) in 7.25s 
Iter 5...	Training loss: 847857.625000 (7106.245050, 4723.458244, 836027.933105) in 7.23s 
Top-1 Recall: 0.014263 Precision: 0.014263 NDCG: 0.014263 HR: 0.014263
Top-5 Recall: 0.048072 Precision: 0.009614 NDCG: 0.031915 HR: 0.048072
Top-10 Recall: 0.083465 Precision: 0.008347 NDCG: 0.043064 HR: 0.083465
Eval costs: 0.170162 s
Iter 6...	Training loss: 648001.250000 (5665.376054, 3894.958090, 638440.895996) in 7.23s 
Iter 7...	Training loss: 493180.187500 (4701.668487, 3395.736188, 485082.817871) in 7.40s 
Iter 8...	Training loss: 380441.437500 (4100.582543, 3060.861708, 373280.033936) in 7.25s 
Iter 9...	Training loss: 302462.562500 (3729.793225, 2826.842943, 295905.894287) in 7.25s 
Iter 10...	Training loss: 248864.296875 (3497.266255, 2649.321292, 242717.688599) in 7.29s 
Top-1 Recall: 0.050713 Precision: 0.050713 NDCG: 0.050713 HR: 0.050713
Top-5 Recall: 0.139989 Precision: 0.027998 NDCG: 0.096769 HR: 0.139989
Top-10 Recall: 0.208135 Precision: 0.020814 NDCG: 0.118691 HR: 0.208135
Eval costs: 0.185457 s
Iter 11...	Training loss: 211699.515625 (3348.713033, 2510.754257, 205840.053223) in 7.23s 
Iter 12...	Training loss: 183782.906250 (3235.605467, 2392.754906, 178154.536011) in 7.25s 
Iter 13...	Training loss: 162428.234375 (3160.014226, 2294.510935, 156973.716797) in 7.25s 
Iter 14...	Training loss: 146498.375000 (3095.331702, 2212.794385, 141190.249878) in 7.24s 
Iter 15...	Training loss: 133152.593750 (3038.783613, 2133.863319, 127979.932251) in 7.24s 
Top-1 Recall: 0.061807 Precision: 0.061807 NDCG: 0.061807 HR: 0.061807
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.113162 HR: 0.163761
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.133621 HR: 0.228209
Eval costs: 0.190516 s
Iter 16...	Training loss: 122782.898438 (2990.320348, 2068.748819, 117723.826660) in 7.26s 
Iter 17...	Training loss: 113746.328125 (2958.550925, 2006.262022, 108781.515564) in 7.28s 
Iter 18...	Training loss: 106398.718750 (2931.992841, 1951.607881, 101515.121155) in 7.43s 
Iter 19...	Training loss: 99853.625000 (2906.399412, 1901.833485, 95045.390015) in 7.26s 
Iter 20...	Training loss: 94248.414062 (2898.991159, 1857.730090, 89491.686279) in 7.25s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.118949 HR: 0.171157
Top-10 Recall: 0.232964 Precision: 0.023296 NDCG: 0.138694 HR: 0.232964
Eval costs: 0.198824 s
Iter 21...	Training loss: 89421.648438 (2891.747151, 1818.718260, 84711.179871) in 7.24s 
Iter 22...	Training loss: 85118.820312 (2881.880908, 1783.086359, 80453.852661) in 7.25s 
Iter 23...	Training loss: 81163.523438 (2885.704639, 1751.848009, 76525.967468) in 7.27s 
Iter 24...	Training loss: 77720.710938 (2899.272689, 1716.894752, 73104.538757) in 7.27s 
Iter 25...	Training loss: 74437.242188 (2902.600466, 1689.669629, 69844.967896) in 7.25s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.117206 HR: 0.165346
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.140623 HR: 0.238246
Eval costs: 0.206175 s
Iter 26...	Training loss: 71672.375000 (2916.648062, 1664.149481, 67091.571411) in 7.27s 
Iter 27...	Training loss: 68707.890625 (2934.185008, 1641.653010, 64132.055267) in 7.25s 
Iter 28...	Training loss: 66260.328125 (2953.027590, 1618.886918, 61688.416260) in 7.26s 
Iter 29...	Training loss: 64300.699219 (2973.162088, 1602.336343, 59725.207458) in 7.28s 
Iter 30...	Training loss: 62151.234375 (2986.357151, 1583.480482, 57581.396179) in 7.41s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.118290 HR: 0.164818
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.139400 HR: 0.229794
Eval costs: 0.213984 s
Iter 31...	Training loss: 59985.648438 (3003.672811, 1565.725198, 55416.248505) in 7.29s 
Iter 32...	Training loss: 58335.714844 (3042.594573, 1553.194786, 53739.932373) in 7.26s 
Iter 33...	Training loss: 56551.093750 (3061.343091, 1534.005031, 51955.744476) in 7.25s 
Iter 34...	Training loss: 55044.390625 (3083.214714, 1520.912429, 50440.268677) in 7.26s 
Iter 35...	Training loss: 53540.121094 (3103.124318, 1510.009340, 48926.988220) in 7.26s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.120179 HR: 0.171157
Top-10 Recall: 0.229266 Precision: 0.022927 NDCG: 0.138837 HR: 0.229266
Eval costs: 0.220168 s
Iter 36...	Training loss: 52107.898438 (3130.663229, 1497.414161, 47479.818665) in 7.25s 
Iter 37...	Training loss: 50987.148438 (3155.976009, 1489.022873, 46342.147278) in 7.26s 
Iter 38...	Training loss: 49760.675781 (3175.826550, 1476.108041, 45108.746460) in 7.26s 
Iter 39...	Training loss: 48680.445312 (3195.559800, 1466.787577, 44018.102829) in 7.26s 
Iter 40...	Training loss: 47751.074219 (3214.453098, 1457.317185, 43079.304779) in 7.28s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.118382 HR: 0.163761
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.139828 HR: 0.230322
Eval costs: 0.380787 s
Iter 41...	Training loss: 46731.738281 (3240.397466, 1450.393550, 42040.944061) in 7.25s 
Iter 42...	Training loss: 45842.863281 (3259.037387, 1440.717462, 41143.111603) in 7.25s 
Iter 43...	Training loss: 44936.882812 (3283.007527, 1435.109557, 40218.766510) in 7.24s 
Iter 44...	Training loss: 44207.753906 (3297.910043, 1426.290040, 39483.556061) in 7.26s 
Iter 45...	Training loss: 43493.445312 (3318.552402, 1418.295969, 38756.599487) in 7.25s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.118012 HR: 0.162705
Top-10 Recall: 0.223983 Precision: 0.022398 NDCG: 0.137723 HR: 0.223983
Eval costs: 0.230671 s
Iter 46...	Training loss: 42914.828125 (3339.503824, 1414.984373, 38160.341110) in 7.27s 
Iter 47...	Training loss: 42106.843750 (3361.153030, 1407.529688, 37338.172592) in 7.28s 
Iter 48...	Training loss: 41782.601562 (3373.601189, 1401.447488, 37007.550125) in 7.24s 
Iter 49...	Training loss: 40842.980469 (3393.831612, 1396.789503, 36052.359711) in 7.25s 
Iter 50...	Training loss: 40680.375000 (3404.437008, 1392.479541, 35883.453979) in 7.27s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.161120 Precision: 0.032224 NDCG: 0.117238 HR: 0.161120
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.137136 HR: 0.222927
Eval costs: 0.231044 s
Iter 51...	Training loss: 39939.992188 (3423.324917, 1384.918997, 35131.752121) in 7.27s 
Iter 52...	Training loss: 39532.636719 (3438.062452, 1379.162654, 34715.411407) in 7.42s 
Iter 53...	Training loss: 38911.992188 (3450.458370, 1376.609813, 34084.922974) in 7.26s 
Iter 54...	Training loss: 38709.710938 (3465.138106, 1372.753919, 33871.818863) in 7.24s 
Iter 55...	Training loss: 38443.820312 (3479.754727, 1366.266277, 33597.803619) in 7.25s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.163233 Precision: 0.032647 NDCG: 0.120718 HR: 0.163233
Top-10 Recall: 0.215003 Precision: 0.021500 NDCG: 0.137191 HR: 0.215003
Eval costs: 0.234263 s
Iter 56...	Training loss: 38014.152344 (3491.957143, 1364.641183, 33157.558258) in 7.26s 
Iter 57...	Training loss: 37760.941406 (3509.788437, 1359.249639, 32891.899307) in 7.25s 
Iter 58...	Training loss: 37301.183594 (3519.644689, 1357.600983, 32423.936172) in 7.26s 
Iter 59...	Training loss: 37167.031250 (3530.375005, 1353.481381, 32283.172791) in 7.25s 
Iter 60...	Training loss: 36777.222656 (3538.165626, 1347.089728, 31891.965164) in 7.25s 
Top-1 Recall: 0.072372 Precision: 0.072372 NDCG: 0.072372 HR: 0.072372
Top-5 Recall: 0.155309 Precision: 0.031062 NDCG: 0.116511 HR: 0.155309
Top-10 Recall: 0.213946 Precision: 0.021395 NDCG: 0.135537 HR: 0.213946
Eval costs: 0.234962 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1880466.250000 (192961.552433, 108506.582333, 1578998.145508) in 7.56s 
Iter 2...	Training loss: 938300.062500 (15519.465062, 19942.978592, 902837.645020) in 7.22s 
Iter 3...	Training loss: 597039.000000 (10817.901020, 11840.135447, 574381.020264) in 7.21s 
Iter 4...	Training loss: 409568.625000 (8186.058267, 8125.385917, 393257.182129) in 7.23s 
Iter 5...	Training loss: 297223.406250 (6334.796775, 6348.515460, 284540.107178) in 7.23s 
Top-1 Recall: 0.039091 Precision: 0.039091 NDCG: 0.039091 HR: 0.039091
Top-5 Recall: 0.104068 Precision: 0.020814 NDCG: 0.073335 HR: 0.104068
Top-10 Recall: 0.141574 Precision: 0.014157 NDCG: 0.085541 HR: 0.141574
Eval costs: 0.176101 s
Iter 6...	Training loss: 228566.750000 (5071.474638, 5293.943360, 218201.358032) in 7.22s 
Iter 7...	Training loss: 187106.046875 (4206.245858, 4598.831211, 178300.970215) in 7.43s 
Iter 8...	Training loss: 161337.343750 (3593.853337, 4119.155025, 153624.336670) in 7.24s 
Iter 9...	Training loss: 130883.078125 (0.000000, 3756.096215, 127126.977295) in 5.86s 
Iter 10...	Training loss: 148267.781250 (5810.073789, 3505.521625, 138952.195190) in 8.62s 
Top-1 Recall: 0.057581 Precision: 0.057581 NDCG: 0.057581 HR: 0.057581
Top-5 Recall: 0.135763 Precision: 0.027153 NDCG: 0.098371 HR: 0.135763
Top-10 Recall: 0.189118 Precision: 0.018912 NDCG: 0.115584 HR: 0.189118
Eval costs: 0.174602 s
Iter 11...	Training loss: 124535.359375 (2612.194422, 3324.847817, 118598.315918) in 7.25s 
Iter 12...	Training loss: 115239.765625 (2410.414828, 3178.802427, 109650.541504) in 7.26s 
Iter 13...	Training loss: 107767.609375 (2249.526089, 3075.334907, 102442.746765) in 7.24s 
Iter 14...	Training loss: 100952.914062 (2119.732883, 2990.101454, 95843.076233) in 7.26s 
Iter 15...	Training loss: 95382.226562 (2012.150139, 2928.514517, 90441.562378) in 7.23s 
Top-1 Recall: 0.065504 Precision: 0.065504 NDCG: 0.065504 HR: 0.065504
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.114634 HR: 0.162705
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.135041 HR: 0.225568
Eval costs: 0.185266 s
Iter 16...	Training loss: 89226.359375 (1921.319449, 2874.969846, 84430.063965) in 7.25s 
Iter 17...	Training loss: 83348.382812 (1846.290000, 2824.400151, 78677.679504) in 7.28s 
Iter 18...	Training loss: 78077.296875 (1783.964562, 2796.336848, 73496.995850) in 7.25s 
Iter 19...	Training loss: 73234.390625 (1730.530684, 2762.096631, 68741.766907) in 7.41s 
Iter 20...	Training loss: 68525.109375 (1686.344063, 2739.358613, 64099.409668) in 7.25s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.121889 HR: 0.171685
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.142110 HR: 0.234020
Eval costs: 0.196467 s
Iter 21...	Training loss: 63798.656250 (1649.905498, 2715.266068, 59433.478821) in 7.24s 
Iter 22...	Training loss: 59748.882812 (1619.232943, 2690.806597, 55438.840851) in 7.25s 
Iter 23...	Training loss: 56171.886719 (1593.671976, 2678.506698, 51899.704956) in 7.24s 
Iter 24...	Training loss: 52744.894531 (1571.240191, 2664.341748, 48509.310760) in 7.24s 
Iter 25...	Training loss: 49499.550781 (1552.592893, 2650.756232, 45296.204193) in 7.25s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.181194 Precision: 0.036239 NDCG: 0.128265 HR: 0.181194
Top-10 Recall: 0.237190 Precision: 0.023719 NDCG: 0.146294 HR: 0.237190
Eval costs: 0.206801 s
Iter 26...	Training loss: 47181.761719 (1535.762955, 2642.934060, 43003.064392) in 7.29s 
Iter 27...	Training loss: 44598.531250 (1521.318814, 2635.997074, 40441.215973) in 7.26s 
Iter 28...	Training loss: 42427.886719 (1505.747527, 2630.033011, 38292.108002) in 7.24s 
Iter 29...	Training loss: 40343.652344 (1494.628922, 2623.133921, 36225.888489) in 7.26s 
Iter 30...	Training loss: 38605.140625 (1482.239883, 2620.016531, 34502.878662) in 7.40s 
Top-1 Recall: 0.072372 Precision: 0.072372 NDCG: 0.072372 HR: 0.072372
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.123998 HR: 0.173270
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.144018 HR: 0.235605
Eval costs: 0.215903 s
Iter 31...	Training loss: 37036.375000 (1468.980160, 2608.540910, 32958.854004) in 7.24s 
Iter 32...	Training loss: 35425.964844 (1460.010151, 2605.666313, 31360.288513) in 7.24s 
Iter 33...	Training loss: 34439.554688 (1449.020835, 2606.750152, 30383.783173) in 7.26s 
Iter 34...	Training loss: 33009.890625 (1440.036746, 2607.140403, 28962.712799) in 7.26s 
Iter 35...	Training loss: 31941.021484 (1431.816856, 2607.023571, 27902.179459) in 7.22s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.180666 Precision: 0.036133 NDCG: 0.126922 HR: 0.180666
Top-10 Recall: 0.236661 Precision: 0.023666 NDCG: 0.145022 HR: 0.236661
Eval costs: 0.220869 s
Iter 36...	Training loss: 30698.923828 (1423.433822, 2610.038118, 26665.450363) in 7.22s 
Iter 37...	Training loss: 29892.851562 (1416.245227, 2612.507886, 25864.102859) in 7.21s 
Iter 38...	Training loss: 28955.652344 (1408.890038, 2616.865190, 24929.896729) in 7.24s 
Iter 39...	Training loss: 28255.074219 (1402.474195, 2615.076220, 24237.523895) in 7.25s 
Iter 40...	Training loss: 27443.767578 (1393.921518, 2619.055679, 23430.791580) in 7.27s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.125201 HR: 0.176968
Top-10 Recall: 0.241416 Precision: 0.024142 NDCG: 0.145905 HR: 0.241416
Eval costs: 0.226716 s
Iter 41...	Training loss: 26699.621094 (1387.451187, 2620.603935, 22691.565918) in 7.39s 
Iter 42...	Training loss: 26049.126953 (1382.928774, 2629.673721, 22036.525116) in 7.23s 
Iter 43...	Training loss: 25395.396484 (1376.761770, 2629.338420, 21389.297363) in 7.24s 
Iter 44...	Training loss: 24953.687500 (1369.791494, 2635.120790, 20948.775101) in 7.24s 
Iter 45...	Training loss: 24390.476562 (1366.260499, 2642.917175, 20381.298126) in 7.25s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.122745 HR: 0.171685
Top-10 Recall: 0.241944 Precision: 0.024194 NDCG: 0.145548 HR: 0.241944
Eval costs: 0.229223 s
Iter 46...	Training loss: 23594.296875 (1361.118961, 2648.325117, 19584.852814) in 7.24s 
Iter 47...	Training loss: 23148.542969 (1357.475837, 2658.677372, 19132.388565) in 7.21s 
Iter 48...	Training loss: 22703.857422 (1353.150534, 2662.747095, 18687.959122) in 7.24s 
Iter 49...	Training loss: 22373.640625 (1348.889314, 2676.760778, 18347.991913) in 7.25s 
Iter 50...	Training loss: 22109.078125 (1345.042406, 2682.923887, 18081.110397) in 7.24s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.118778 HR: 0.167987
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.141423 HR: 0.238246
Eval costs: 0.232075 s
Iter 51...	Training loss: 21608.443359 (1341.479876, 2691.168843, 17575.794144) in 7.24s 
Iter 52...	Training loss: 21131.736328 (1339.124890, 2699.334498, 17093.278336) in 7.38s 
Iter 53...	Training loss: 20646.738281 (1334.612220, 2706.456038, 16605.668747) in 7.24s 
Iter 54...	Training loss: 20369.417969 (1331.609712, 2712.933827, 16324.875336) in 7.24s 
Iter 55...	Training loss: 20373.029297 (1329.656774, 2726.825654, 16316.547462) in 7.24s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.120851 HR: 0.170100
Top-10 Recall: 0.236133 Precision: 0.023613 NDCG: 0.141970 HR: 0.236133
Eval costs: 0.233296 s
Iter 56...	Training loss: 19966.443359 (1326.130572, 2736.263671, 15904.047470) in 7.22s 
Iter 57...	Training loss: 19825.587891 (1323.046177, 2747.424032, 15755.118546) in 7.25s 
Iter 58...	Training loss: 19234.363281 (1320.799899, 2754.480170, 15159.082909) in 7.24s 
Iter 59...	Training loss: 19023.542969 (1317.484881, 2761.809571, 14944.249992) in 7.23s 
Iter 60...	Training loss: 18812.089844 (1315.660029, 2774.768833, 14721.660828) in 7.27s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.119216 HR: 0.169572
Top-10 Recall: 0.229266 Precision: 0.022927 NDCG: 0.138757 HR: 0.229266
Eval costs: 0.236378 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1792224.875000 (192910.988263, 0.000000, 1599313.912109) in 4.73s 
Iter 2...	Training loss: 1048243.937500 (15559.642813, 110052.535169, 922631.764648) in 10.04s 
Iter 3...	Training loss: 614202.812500 (10812.415593, 10481.322612, 592908.966553) in 7.24s 
Iter 4...	Training loss: 426208.156250 (8190.691885, 7473.202621, 410544.307861) in 7.23s 
Iter 5...	Training loss: 311923.625000 (6322.177152, 5920.407452, 299681.002930) in 7.25s 
Top-1 Recall: 0.037507 Precision: 0.037507 NDCG: 0.037507 HR: 0.037507
Top-5 Recall: 0.104068 Precision: 0.020814 NDCG: 0.071946 HR: 0.104068
Top-10 Recall: 0.144744 Precision: 0.014474 NDCG: 0.085028 HR: 0.144744
Eval costs: 0.175220 s
Iter 6...	Training loss: 240827.140625 (5055.094321, 5001.711046, 230770.358765) in 7.23s 
Iter 7...	Training loss: 197695.984375 (4188.991350, 4378.867735, 189128.150146) in 7.40s 
Iter 8...	Training loss: 170585.171875 (3585.178351, 3938.025334, 163061.978882) in 7.25s 
Iter 9...	Training loss: 152238.734375 (3153.673637, 3620.737852, 145464.323975) in 7.24s 
Iter 10...	Training loss: 138967.046875 (2838.574565, 3395.826300, 132732.643799) in 7.25s 
Top-1 Recall: 0.055996 Precision: 0.055996 NDCG: 0.055996 HR: 0.055996
Top-5 Recall: 0.144216 Precision: 0.028843 NDCG: 0.100743 HR: 0.144216
Top-10 Recall: 0.196513 Precision: 0.019651 NDCG: 0.117481 HR: 0.196513
Eval costs: 0.177438 s
Iter 11...	Training loss: 128684.070312 (2599.447542, 3221.640610, 122862.994629) in 7.25s 
Iter 12...	Training loss: 119620.492188 (2409.015818, 3096.319330, 114115.162720) in 7.27s 
Iter 13...	Training loss: 112244.054688 (2255.206834, 3000.717871, 106988.132080) in 7.25s 
Iter 14...	Training loss: 105323.929688 (2127.388046, 2924.681020, 100271.856750) in 7.26s 
Iter 15...	Training loss: 99072.359375 (2018.826514, 2860.679091, 94192.859558) in 7.25s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.117537 HR: 0.166931
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.136997 HR: 0.227153
Eval costs: 0.186936 s
Iter 16...	Training loss: 93244.835938 (1930.322879, 2808.592088, 88505.914673) in 7.28s 
Iter 17...	Training loss: 87102.476562 (1855.221757, 2763.366371, 82483.890991) in 7.27s 
Iter 18...	Training loss: 81677.281250 (1790.958593, 2723.618597, 77162.696289) in 7.43s 
Iter 19...	Training loss: 76656.617188 (1736.706945, 2691.747825, 72228.164124) in 7.29s 
Iter 20...	Training loss: 71775.515625 (1692.980093, 2661.282251, 67421.264465) in 7.26s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.175383 Precision: 0.035077 NDCG: 0.123580 HR: 0.175383
Top-10 Recall: 0.243001 Precision: 0.024300 NDCG: 0.145223 HR: 0.243001
Eval costs: 0.197012 s
Iter 21...	Training loss: 67329.718750 (1657.384290, 2646.032406, 63026.299866) in 7.24s 
Iter 22...	Training loss: 63289.644531 (1624.547394, 2627.380560, 59037.716797) in 7.24s 
Iter 23...	Training loss: 59521.656250 (1598.619896, 2602.387241, 55320.644867) in 7.26s 
Iter 24...	Training loss: 56090.941406 (1577.209864, 2584.980243, 51928.752747) in 7.28s 
Iter 25...	Training loss: 53089.058594 (1557.603119, 2569.253206, 48962.205780) in 7.25s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.179081 Precision: 0.035816 NDCG: 0.123965 HR: 0.179081
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.142783 HR: 0.237718
Eval costs: 0.208428 s
Iter 26...	Training loss: 50486.609375 (1540.519195, 2551.910857, 46394.182648) in 7.28s 
Iter 27...	Training loss: 47922.785156 (1525.102186, 2543.766224, 43853.916779) in 7.25s 
Iter 28...	Training loss: 45882.625000 (1510.921732, 2532.859108, 41838.847412) in 7.27s 
Iter 29...	Training loss: 44003.480469 (1497.544780, 2522.806694, 39983.135071) in 7.25s 
Iter 30...	Training loss: 42296.859375 (1486.380622, 2517.130522, 38293.350830) in 7.41s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.182779 Precision: 0.036556 NDCG: 0.129831 HR: 0.182779
Top-10 Recall: 0.241416 Precision: 0.024142 NDCG: 0.148553 HR: 0.241416
Eval costs: 0.215686 s
Iter 31...	Training loss: 40499.769531 (1474.985111, 2503.823818, 36520.959930) in 7.25s 
Iter 32...	Training loss: 39229.261719 (1464.900528, 2496.483947, 35267.880524) in 7.26s 
Iter 33...	Training loss: 37924.832031 (1454.912486, 2490.586438, 33979.330536) in 7.25s 
Iter 34...	Training loss: 36595.582031 (1445.884549, 2483.537987, 32666.160767) in 7.26s 
Iter 35...	Training loss: 35652.382812 (1437.385693, 2482.421672, 31732.574799) in 7.26s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.125845 HR: 0.176968
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.144791 HR: 0.235605
Eval costs: 0.222347 s
Iter 36...	Training loss: 34462.589844 (1428.712656, 2479.656183, 30554.219543) in 7.27s 
Iter 37...	Training loss: 33586.515625 (1421.209631, 2476.897535, 29688.407471) in 7.28s 
Iter 38...	Training loss: 33035.746094 (1414.492783, 2472.462260, 29148.790192) in 7.25s 
Iter 39...	Training loss: 32065.714844 (1406.348736, 2467.868722, 28191.493042) in 7.25s 
Iter 40...	Training loss: 31380.929688 (1400.268879, 2470.209469, 27510.450775) in 7.27s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.180137 Precision: 0.036027 NDCG: 0.126603 HR: 0.180137
Top-10 Recall: 0.236661 Precision: 0.023666 NDCG: 0.144804 HR: 0.236661
Eval costs: 0.382792 s
Iter 41...	Training loss: 30604.429688 (1395.566317, 2467.034084, 26741.827652) in 7.27s 
Iter 42...	Training loss: 30160.498047 (1389.196269, 2471.480309, 26299.820374) in 7.24s 
Iter 43...	Training loss: 29282.937500 (1383.972284, 2469.279580, 25429.686066) in 7.23s 
Iter 44...	Training loss: 28777.503906 (1379.118074, 2461.619139, 24936.767212) in 7.24s 
Iter 45...	Training loss: 28244.314453 (1374.415281, 2469.833727, 24400.065231) in 7.24s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.124088 HR: 0.176968
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.142901 HR: 0.235605
Eval costs: 0.230430 s
Iter 46...	Training loss: 27744.851562 (1369.847544, 2463.019315, 23911.985092) in 7.23s 
Iter 47...	Training loss: 27268.955078 (1366.792390, 2469.939477, 23432.221146) in 7.25s 
Iter 48...	Training loss: 26952.767578 (1362.628341, 2469.772202, 23120.367630) in 7.26s 
Iter 49...	Training loss: 26305.419922 (1359.562176, 2473.461080, 22472.396851) in 7.27s 
Iter 50...	Training loss: 26103.820312 (1355.417023, 2471.224310, 22277.180267) in 7.24s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.122459 HR: 0.171685
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.143848 HR: 0.237718
Eval costs: 0.233650 s
Iter 51...	Training loss: 25570.371094 (1351.329192, 2473.665957, 21745.377106) in 7.41s 
Iter 52...	Training loss: 25252.396484 (1349.028315, 2479.097433, 21424.271790) in 7.27s 
Iter 53...	Training loss: 24655.347656 (1345.623769, 2478.561250, 20831.163925) in 7.27s 
Iter 54...	Training loss: 24583.617188 (1342.720660, 2487.750974, 20753.144836) in 7.26s 
Iter 55...	Training loss: 24132.597656 (1340.712070, 2480.916760, 20310.967484) in 7.28s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.122159 HR: 0.172213
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.141877 HR: 0.234020
Eval costs: 0.235705 s
Iter 56...	Training loss: 23782.609375 (1339.150168, 2483.889506, 19959.568787) in 7.26s 
Iter 57...	Training loss: 23637.072266 (1335.888324, 2483.123466, 19818.059235) in 7.25s 
Iter 58...	Training loss: 19399.197266 (0.000000, 2490.035347, 16909.164108) in 6.01s 
Iter 59...	Training loss: 26479.437500 (2615.245405, 2490.854378, 21373.336304) in 8.47s 
Iter 60...	Training loss: 18637.078125 (0.000000, 2492.943207, 16144.135025) in 6.01s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.123289 HR: 0.173798
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.142831 HR: 0.235077
Eval costs: 0.239177 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2287791.500000 (205086.269700, 108393.629080, 1974311.786133) in 8.83s 
Iter 2...	Training loss: 1161817.875000 (10269.043038, 19652.933320, 1131895.820801) in 7.24s 
Iter 3...	Training loss: 772164.062500 (8109.560566, 11047.976183, 753006.586426) in 7.23s 
Iter 4...	Training loss: 545705.437500 (6326.232003, 7221.303941, 532157.923584) in 7.26s 
Iter 5...	Training loss: 399227.468750 (5069.486934, 5477.284358, 388680.739014) in 7.25s 
Top-1 Recall: 0.048072 Precision: 0.048072 NDCG: 0.048072 HR: 0.048072
Top-5 Recall: 0.117802 Precision: 0.023560 NDCG: 0.083755 HR: 0.117802
Top-10 Recall: 0.151083 Precision: 0.015108 NDCG: 0.094440 HR: 0.151083
Eval costs: 0.335495 s
Iter 6...	Training loss: 304083.781250 (4188.521129, 4555.259138, 295339.990967) in 7.27s 
Iter 7...	Training loss: 243076.671875 (3570.503642, 3964.380165, 235541.783447) in 7.23s 
Iter 8...	Training loss: 202899.375000 (3145.617273, 3563.789554, 196189.980347) in 7.24s 
Iter 9...	Training loss: 176350.890625 (2833.868077, 3295.569648, 170221.463135) in 7.25s 
Iter 10...	Training loss: 157608.484375 (2599.683139, 3089.520723, 151919.300537) in 7.25s 
Top-1 Recall: 0.060750 Precision: 0.060750 NDCG: 0.060750 HR: 0.060750
Top-5 Recall: 0.147385 Precision: 0.029477 NDCG: 0.104600 HR: 0.147385
Top-10 Recall: 0.209192 Precision: 0.020919 NDCG: 0.124672 HR: 0.209192
Eval costs: 0.180976 s
Iter 11...	Training loss: 143452.046875 (2412.663981, 2945.063542, 138094.322754) in 7.23s 
Iter 12...	Training loss: 132123.203125 (2261.209722, 2830.177737, 127031.805786) in 7.22s 
Iter 13...	Training loss: 122975.117188 (2134.619845, 2731.214505, 118109.279541) in 7.22s 
Iter 14...	Training loss: 115087.062500 (2026.602198, 2657.189510, 110403.271606) in 7.25s 
Iter 15...	Training loss: 107977.156250 (1936.527482, 2590.472289, 103450.144775) in 7.25s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.116863 HR: 0.166931
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.138265 HR: 0.233492
Eval costs: 0.190517 s
Iter 16...	Training loss: 101611.218750 (1856.815174, 2533.146345, 97221.258362) in 7.40s 
Iter 17...	Training loss: 89555.437500 (0.000000, 2482.292195, 87073.154846) in 5.88s 
Iter 18...	Training loss: 97586.570312 (3453.525159, 2432.176209, 91700.870056) in 8.64s 
Iter 19...	Training loss: 86495.148438 (1701.916009, 2394.347516, 82398.875732) in 7.24s 
Iter 20...	Training loss: 81820.460938 (1651.689491, 2357.187432, 77811.587219) in 7.24s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.121126 HR: 0.171685
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.141842 HR: 0.235077
Eval costs: 0.199184 s
Iter 21...	Training loss: 77467.140625 (1614.911939, 2324.943982, 73527.280518) in 7.25s 
Iter 22...	Training loss: 74241.664062 (1582.891501, 2293.888959, 70364.890930) in 7.25s 
Iter 23...	Training loss: 70315.343750 (1557.395221, 2266.422559, 66491.524719) in 7.24s 
Iter 24...	Training loss: 67185.351562 (1537.362096, 2237.137796, 63410.853638) in 7.25s 
Iter 25...	Training loss: 64006.199219 (1518.983763, 2213.777864, 60273.441376) in 7.25s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.122383 HR: 0.174326
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.140614 HR: 0.230851
Eval costs: 0.208849 s
Iter 26...	Training loss: 61220.621094 (1505.134208, 2190.764490, 57524.723816) in 7.26s 
Iter 27...	Training loss: 58691.855469 (1493.173025, 2168.999826, 55029.679932) in 7.28s 
Iter 28...	Training loss: 56393.703125 (1484.541649, 2149.893950, 52759.263000) in 7.42s 
Iter 29...	Training loss: 54215.570312 (1475.410785, 2128.469619, 50611.688446) in 7.27s 
Iter 30...	Training loss: 52012.710938 (1467.223296, 2118.242745, 48427.248993) in 7.27s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.125573 HR: 0.172742
Top-10 Recall: 0.240887 Precision: 0.024089 NDCG: 0.147564 HR: 0.240887
Eval costs: 0.217026 s
Iter 31...	Training loss: 50252.406250 (1461.289499, 2094.878694, 46696.240479) in 7.26s 
Iter 32...	Training loss: 48557.070312 (1454.464421, 2078.028808, 45024.579987) in 7.27s 
Iter 33...	Training loss: 47101.582031 (1448.697195, 2071.582192, 43581.303833) in 7.24s 
Iter 34...	Training loss: 45612.761719 (1444.216498, 2050.024725, 42118.519684) in 7.26s 
Iter 35...	Training loss: 44442.218750 (1438.848598, 2041.697697, 40961.670990) in 7.25s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.126016 HR: 0.173270
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.146016 HR: 0.235077
Eval costs: 0.222579 s
Iter 36...	Training loss: 43091.394531 (1434.856123, 2025.935866, 39630.607239) in 7.26s 
Iter 37...	Training loss: 41961.542969 (1429.603971, 2016.430825, 38515.505188) in 7.29s 
Iter 38...	Training loss: 40680.531250 (1427.970751, 2008.047805, 37244.515350) in 7.30s 
Iter 39...	Training loss: 39681.074219 (1422.154474, 1994.579678, 36264.343628) in 7.41s 
Iter 40...	Training loss: 38892.859375 (1419.768296, 1982.310256, 35490.784424) in 7.25s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.123281 HR: 0.170629
Top-10 Recall: 0.240887 Precision: 0.024089 NDCG: 0.145907 HR: 0.240887
Eval costs: 0.227259 s
Iter 41...	Training loss: 37859.562500 (1416.159168, 1972.995253, 34470.402054) in 7.26s 
Iter 42...	Training loss: 37105.234375 (1413.152666, 1968.583890, 33723.501129) in 7.24s 
Iter 43...	Training loss: 36225.941406 (1410.319572, 1962.286775, 32853.337387) in 7.26s 
Iter 44...	Training loss: 35740.871094 (1406.051259, 1949.646566, 32385.174194) in 7.24s 
Iter 45...	Training loss: 34764.164062 (1403.994038, 1943.504057, 31416.664810) in 7.27s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.125378 HR: 0.177496
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.143820 HR: 0.234548
Eval costs: 0.229638 s
Iter 46...	Training loss: 34369.621094 (1402.124532, 1934.360346, 31033.134216) in 7.26s 
Iter 47...	Training loss: 33760.687500 (1400.345016, 1928.879087, 30431.462738) in 7.24s 
Iter 48...	Training loss: 32981.140625 (1398.108038, 1923.822230, 29659.207428) in 7.26s 
Iter 49...	Training loss: 32494.191406 (1395.183018, 1917.264283, 29181.743912) in 7.26s 
Iter 50...	Training loss: 32132.244141 (1393.093897, 1909.640453, 28829.510117) in 7.24s 
Top-1 Recall: 0.080824 Precision: 0.080824 NDCG: 0.080824 HR: 0.080824
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.124922 HR: 0.165874
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.146765 HR: 0.233492
Eval costs: 0.393564 s
Iter 51...	Training loss: 31421.873047 (1391.429796, 1903.467579, 28126.974152) in 7.25s 
Iter 52...	Training loss: 30989.066406 (1391.602409, 1900.686552, 27696.779343) in 7.24s 
Iter 53...	Training loss: 30475.964844 (1389.496328, 1894.948937, 27191.518051) in 7.24s 
Iter 54...	Training loss: 29935.761719 (1387.970621, 1890.038920, 26657.751511) in 7.27s 
Iter 55...	Training loss: 29616.794922 (1384.908109, 1882.671786, 26349.217758) in 7.25s 
Top-1 Recall: 0.077655 Precision: 0.077655 NDCG: 0.077655 HR: 0.077655
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.125469 HR: 0.171685
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.145431 HR: 0.234020
Eval costs: 0.236052 s
Iter 56...	Training loss: 29579.195312 (1383.964698, 1877.919391, 26317.312408) in 7.24s 
Iter 57...	Training loss: 28766.015625 (1383.746448, 1876.407556, 25505.865372) in 7.23s 
Iter 58...	Training loss: 28603.949219 (1382.326532, 1867.608053, 25354.011948) in 7.27s 
Iter 59...	Training loss: 28246.660156 (1382.134507, 1863.505290, 25001.018799) in 7.25s 
Iter 60...	Training loss: 27963.037109 (1380.941607, 1858.826788, 24723.268738) in 7.24s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.122954 HR: 0.167987
Top-10 Recall: 0.236133 Precision: 0.023613 NDCG: 0.144826 HR: 0.236133
Eval costs: 0.236242 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 4398773.500000 (192875.697717, 107948.534702, 4097949.505859) in 7.57s 
Iter 2...	Training loss: 2518636.250000 (15507.796288, 19055.294071, 2484073.357422) in 7.25s 
Iter 3...	Training loss: 1775726.750000 (10832.578283, 10035.411285, 1754858.624023) in 7.24s 
Iter 4...	Training loss: 1321668.125000 (8225.304769, 6307.095978, 1307135.638672) in 7.23s 
Iter 5...	Training loss: 987637.125000 (6366.632780, 4742.420612, 976528.092773) in 7.23s 
Top-1 Recall: 0.011094 Precision: 0.011094 NDCG: 0.011094 HR: 0.011094
Top-5 Recall: 0.027470 Precision: 0.005494 NDCG: 0.019464 HR: 0.027470
Top-10 Recall: 0.044374 Precision: 0.004437 NDCG: 0.024949 HR: 0.044374
Eval costs: 0.166079 s
Iter 6...	Training loss: 739115.500000 (5095.673225, 3929.296668, 730090.548340) in 7.41s 
Iter 7...	Training loss: 555396.000000 (4225.555318, 3435.564322, 547734.886719) in 7.28s 
Iter 8...	Training loss: 429858.250000 (3627.739171, 3106.511859, 423124.002686) in 7.25s 
Iter 9...	Training loss: 346122.156250 (3220.997303, 2872.978317, 340028.179199) in 7.25s 
Iter 10...	Training loss: 287994.437500 (2934.648811, 2700.356914, 282359.473877) in 7.23s 
Top-1 Recall: 0.034337 Precision: 0.034337 NDCG: 0.034337 HR: 0.034337
Top-5 Recall: 0.114105 Precision: 0.022821 NDCG: 0.074262 HR: 0.114105
Top-10 Recall: 0.172742 Precision: 0.017274 NDCG: 0.093200 HR: 0.172742
Eval costs: 0.177449 s
Iter 11...	Training loss: 248268.265625 (2715.000604, 2560.508212, 242992.761108) in 7.24s 
Iter 12...	Training loss: 218748.203125 (2542.221392, 2445.863758, 213760.121582) in 7.24s 
Iter 13...	Training loss: 196478.046875 (2396.449321, 2345.463969, 191736.130005) in 7.26s 
Iter 14...	Training loss: 179260.140625 (2274.464019, 2261.679059, 174724.004272) in 7.23s 
Iter 15...	Training loss: 165773.031250 (2167.591235, 2188.328405, 161417.127197) in 7.26s 
Top-1 Recall: 0.055996 Precision: 0.055996 NDCG: 0.055996 HR: 0.055996
Top-5 Recall: 0.147385 Precision: 0.029477 NDCG: 0.102448 HR: 0.147385
Top-10 Recall: 0.206022 Precision: 0.020602 NDCG: 0.121475 HR: 0.206022
Eval costs: 0.187989 s
Iter 16...	Training loss: 154449.562500 (2077.768478, 2126.423926, 150245.372681) in 7.25s 
Iter 17...	Training loss: 145195.578125 (1999.296633, 2065.839178, 141130.454712) in 7.25s 
Iter 18...	Training loss: 137327.453125 (1930.182180, 2015.234505, 133382.045898) in 7.44s 
Iter 19...	Training loss: 130624.437500 (1872.239869, 1972.046983, 126780.139771) in 7.27s 
Iter 20...	Training loss: 124742.273438 (1819.760445, 1925.258033, 120997.251831) in 7.25s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.159007 Precision: 0.031801 NDCG: 0.111374 HR: 0.159007
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.130834 HR: 0.219757
Eval costs: 0.194132 s
Iter 21...	Training loss: 119552.218750 (1776.907769, 1882.728968, 115892.590393) in 7.25s 
Iter 22...	Training loss: 114903.125000 (1737.269657, 1848.438145, 111317.417603) in 7.24s 
Iter 23...	Training loss: 110780.468750 (1704.739657, 1815.497602, 107260.223389) in 7.25s 
Iter 24...	Training loss: 106932.820312 (1674.911288, 1783.706264, 103474.211670) in 7.27s 
Iter 25...	Training loss: 103513.023438 (1649.340297, 1756.306929, 100107.377869) in 7.28s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.158479 Precision: 0.031696 NDCG: 0.112751 HR: 0.158479
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.135774 HR: 0.229794
Eval costs: 0.200410 s
Iter 26...	Training loss: 81273.578125 (1628.643741, 0.000000, 79644.921875) in 4.61s 
Iter 27...	Training loss: 110048.210938 (1599.499422, 3404.678733, 105044.046936) in 9.89s 
Iter 28...	Training loss: 95137.468750 (1583.030414, 1694.477395, 91859.952148) in 7.24s 
Iter 29...	Training loss: 92180.109375 (1574.108603, 1662.140537, 88943.867065) in 7.39s 
Iter 30...	Training loss: 90004.835938 (1561.425426, 1640.735773, 86802.671875) in 7.25s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.118062 HR: 0.162705
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.138448 HR: 0.226096
Eval costs: 0.205079 s
Iter 31...	Training loss: 87687.859375 (1550.678185, 1623.991604, 84513.193481) in 7.25s 
Iter 32...	Training loss: 85322.531250 (1544.711743, 1601.844911, 82175.971375) in 7.29s 
Iter 33...	Training loss: 83251.617188 (1536.212322, 1588.090105, 80127.306335) in 7.29s 
Iter 34...	Training loss: 81186.710938 (1529.619443, 1571.441706, 78085.654175) in 7.25s 
Iter 35...	Training loss: 79300.437500 (1522.051599, 1558.020432, 76220.366516) in 7.29s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.163233 Precision: 0.032647 NDCG: 0.118940 HR: 0.163233
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.140493 HR: 0.230322
Eval costs: 0.209404 s
Iter 36...	Training loss: 77487.648438 (1516.766763, 1548.094142, 74422.794617) in 7.27s 
Iter 37...	Training loss: 75878.109375 (1514.855599, 1532.462218, 72830.782898) in 7.27s 
Iter 38...	Training loss: 74124.078125 (1510.561366, 1520.844509, 71092.661407) in 7.24s 
Iter 39...	Training loss: 72615.390625 (1509.309515, 1507.135917, 69598.948608) in 7.27s 
Iter 40...	Training loss: 70895.539062 (1506.174677, 1499.919041, 67889.456909) in 7.24s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.121474 HR: 0.169044
Top-10 Recall: 0.229266 Precision: 0.022927 NDCG: 0.141049 HR: 0.229266
Eval costs: 0.374165 s
Iter 41...	Training loss: 69551.593750 (1504.513272, 1489.309358, 66557.771332) in 7.27s 
Iter 42...	Training loss: 68259.570312 (1504.660774, 1479.100082, 65275.814026) in 7.22s 
Iter 43...	Training loss: 66885.914062 (1500.422102, 1472.201886, 63913.291504) in 7.26s 
Iter 44...	Training loss: 65547.242188 (1501.709227, 1462.521369, 62583.007812) in 7.25s 
Iter 45...	Training loss: 64362.062500 (1502.502643, 1455.911062, 61403.650024) in 7.24s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.122625 HR: 0.170100
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.143345 HR: 0.234548
Eval costs: 0.218974 s
Iter 46...	Training loss: 63111.773438 (1498.735271, 1446.764268, 60166.276520) in 7.25s 
Iter 47...	Training loss: 62149.859375 (1504.047291, 1441.075913, 59204.738373) in 7.25s 
Iter 48...	Training loss: 61014.066406 (1501.406070, 1435.409301, 58077.254944) in 7.23s 
Iter 49...	Training loss: 60193.589844 (1503.348910, 1427.212490, 57263.028503) in 7.25s 
Iter 50...	Training loss: 59218.894531 (1503.757529, 1423.606270, 56291.526947) in 7.22s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.120434 HR: 0.167987
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.140920 HR: 0.231379
Eval costs: 0.221688 s
Iter 51...	Training loss: 57838.109375 (1505.336843, 1416.870276, 54915.901398) in 7.41s 
Iter 52...	Training loss: 57151.773438 (1506.837418, 1412.569184, 54232.370026) in 7.23s 
Iter 53...	Training loss: 56362.484375 (1508.390421, 1403.718289, 53450.371216) in 7.28s 
Iter 54...	Training loss: 55674.656250 (1510.734018, 1398.642930, 52765.281464) in 7.23s 
Iter 55...	Training loss: 54606.183594 (1508.435933, 1396.196676, 51701.551331) in 7.24s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.164289 Precision: 0.032858 NDCG: 0.119775 HR: 0.164289
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.141492 HR: 0.231379
Eval costs: 0.224153 s
Iter 56...	Training loss: 54132.878906 (1511.707830, 1389.657959, 51231.509064) in 7.26s 
Iter 57...	Training loss: 53466.777344 (1512.668785, 1386.893465, 50567.216248) in 7.24s 
Iter 58...	Training loss: 52707.707031 (1514.694476, 1384.674742, 49808.335876) in 7.24s 
Iter 59...	Training loss: 52076.828125 (1513.743536, 1377.929491, 49185.153748) in 7.27s 
Iter 60...	Training loss: 51428.433594 (1514.939717, 1375.262180, 48538.232605) in 7.24s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.121379 HR: 0.168516
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.141750 HR: 0.231907
Eval costs: 0.228867 s
