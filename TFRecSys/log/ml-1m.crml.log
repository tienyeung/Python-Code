############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 17590350.000000  in 33.95s 
Iter 2...	Training loss: 16503748.000000  in 33.86s 
Iter 3...	Training loss: 15867350.000000  in 33.95s 
Iter 4...	Training loss: 14985256.000000  in 34.03s 
Iter 5...	Training loss: 13885310.000000  in 33.79s 
Top-1 Recall: 0.050662 Precision: 0.050662 NDCG: 0.050662 HR: 0.050662
Top-5 Recall: 0.141887 Precision: 0.028377 NDCG: 0.097536 HR: 0.141887
Top-10 Recall: 0.209934 Precision: 0.020993 NDCG: 0.119429 HR: 0.209934
Eval costs: 0.437197 s
Iter 6...	Training loss: 12898916.000000  in 33.83s 
Iter 7...	Training loss: 12073427.000000  in 34.05s 
Iter 8...	Training loss: 11396710.000000  in 33.65s 
Iter 9...	Training loss: 10805328.000000  in 33.92s 
Iter 10...	Training loss: 10317561.000000  in 33.88s 
Top-1 Recall: 0.055960 Precision: 0.055960 NDCG: 0.055960 HR: 0.055960
Top-5 Recall: 0.161424 Precision: 0.032285 NDCG: 0.110094 HR: 0.161424
Top-10 Recall: 0.231623 Precision: 0.023162 NDCG: 0.132644 HR: 0.231623
Eval costs: 0.548192 s
Iter 11...	Training loss: 9897171.000000  in 33.82s 
Iter 12...	Training loss: 9537126.000000  in 33.73s 
Iter 13...	Training loss: 9225680.000000  in 33.84s 
Iter 14...	Training loss: 8947526.000000  in 33.80s 
Iter 15...	Training loss: 8705908.000000  in 34.01s 
Top-1 Recall: 0.056457 Precision: 0.056457 NDCG: 0.056457 HR: 0.056457
Top-5 Recall: 0.157781 Precision: 0.031556 NDCG: 0.108156 HR: 0.157781
Top-10 Recall: 0.228808 Precision: 0.022881 NDCG: 0.131001 HR: 0.228808
Eval costs: 0.608222 s
Iter 16...	Training loss: 8501210.000000  in 33.99s 
Iter 17...	Training loss: 8312168.000000  in 34.05s 
Iter 18...	Training loss: 8147282.500000  in 34.54s 
Iter 19...	Training loss: 7989727.000000  in 34.13s 
Iter 20...	Training loss: 7864286.000000  in 34.31s 
Top-1 Recall: 0.053311 Precision: 0.053311 NDCG: 0.053311 HR: 0.053311
Top-5 Recall: 0.154636 Precision: 0.030927 NDCG: 0.104221 HR: 0.154636
Top-10 Recall: 0.218212 Precision: 0.021821 NDCG: 0.124599 HR: 0.218212
Eval costs: 0.645621 s
Iter 21...	Training loss: 7736877.000000  in 34.45s 
Iter 22...	Training loss: 7622318.000000  in 34.46s 
Iter 23...	Training loss: 7519573.000000  in 34.36s 
Iter 24...	Training loss: 7424808.000000  in 34.59s 
Iter 25...	Training loss: 7344669.000000  in 34.64s 
Top-1 Recall: 0.050828 Precision: 0.050828 NDCG: 0.050828 HR: 0.050828
Top-5 Recall: 0.144536 Precision: 0.028907 NDCG: 0.098119 HR: 0.144536
Top-10 Recall: 0.212914 Precision: 0.021291 NDCG: 0.120127 HR: 0.212914
Eval costs: 0.669673 s
Iter 26...	Training loss: 7261315.500000  in 34.27s 
Iter 27...	Training loss: 7185540.500000  in 34.56s 
Iter 28...	Training loss: 7122403.000000  in 34.61s 
Iter 29...	Training loss: 7057238.000000  in 34.51s 
Iter 30...	Training loss: 6996701.000000  in 34.59s 
Top-1 Recall: 0.047185 Precision: 0.047185 NDCG: 0.047185 HR: 0.047185
Top-5 Recall: 0.143874 Precision: 0.028775 NDCG: 0.096116 HR: 0.143874
Top-10 Recall: 0.203974 Precision: 0.020397 NDCG: 0.115503 HR: 0.203974
Eval costs: 0.680588 s
Iter 31...	Training loss: 6940665.000000  in 34.12s 
Iter 32...	Training loss: 6887050.000000  in 34.57s 
Iter 33...	Training loss: 6842315.000000  in 34.54s 
Iter 34...	Training loss: 6797394.500000  in 34.54s 
Iter 35...	Training loss: 6754945.000000  in 34.33s 
Top-1 Recall: 0.046358 Precision: 0.046358 NDCG: 0.046358 HR: 0.046358
Top-5 Recall: 0.138576 Precision: 0.027715 NDCG: 0.093004 HR: 0.138576
Top-10 Recall: 0.201490 Precision: 0.020149 NDCG: 0.113385 HR: 0.201490
Eval costs: 1.105293 s
Iter 36...	Training loss: 6723120.500000  in 34.29s 
Iter 37...	Training loss: 6670067.000000  in 34.51s 
Iter 38...	Training loss: 6640399.500000  in 34.50s 
Iter 39...	Training loss: 6599568.500000  in 34.46s 
Iter 40...	Training loss: 6570328.000000  in 34.24s 
Top-1 Recall: 0.047848 Precision: 0.047848 NDCG: 0.047848 HR: 0.047848
Top-5 Recall: 0.133444 Precision: 0.026689 NDCG: 0.091326 HR: 0.133444
Top-10 Recall: 0.195199 Precision: 0.019520 NDCG: 0.111281 HR: 0.195199
Eval costs: 0.701518 s
Iter 41...	Training loss: 6536599.000000  in 34.37s 
Iter 42...	Training loss: 6500977.500000  in 34.64s 
Iter 43...	Training loss: 6475314.000000  in 34.68s 
Iter 44...	Training loss: 6454630.000000  in 34.51s 
Iter 45...	Training loss: 6426575.000000  in 34.53s 
Top-1 Recall: 0.045861 Precision: 0.045861 NDCG: 0.045861 HR: 0.045861
Top-5 Recall: 0.133444 Precision: 0.026689 NDCG: 0.089992 HR: 0.133444
Top-10 Recall: 0.194536 Precision: 0.019454 NDCG: 0.109669 HR: 0.194536
Eval costs: 0.708862 s
Iter 46...	Training loss: 6401355.500000  in 34.29s 
Iter 47...	Training loss: 6367812.000000  in 34.52s 
Iter 48...	Training loss: 6354585.500000  in 34.63s 
Iter 49...	Training loss: 6330475.000000  in 34.80s 
Iter 50...	Training loss: 6311663.000000  in 34.89s 
Top-1 Recall: 0.044040 Precision: 0.044040 NDCG: 0.044040 HR: 0.044040
Top-5 Recall: 0.126325 Precision: 0.025265 NDCG: 0.086200 HR: 0.126325
Top-10 Recall: 0.191722 Precision: 0.019172 NDCG: 0.107358 HR: 0.191722
Eval costs: 0.709650 s
Iter 51...	Training loss: 6280766.500000  in 34.52s 
Iter 52...	Training loss: 6275126.000000  in 34.79s 
Iter 53...	Training loss: 6256556.000000  in 34.71s 
Iter 54...	Training loss: 6235107.500000  in 34.35s 
Iter 55...	Training loss: 6210395.000000  in 34.79s 
Top-1 Recall: 0.044702 Precision: 0.044702 NDCG: 0.044702 HR: 0.044702
Top-5 Recall: 0.129470 Precision: 0.025894 NDCG: 0.087603 HR: 0.129470
Top-10 Recall: 0.189570 Precision: 0.018957 NDCG: 0.106858 HR: 0.189570
Eval costs: 1.126394 s
Iter 56...	Training loss: 6192428.000000  in 34.64s 
Iter 57...	Training loss: 6178482.000000  in 34.93s 
Iter 58...	Training loss: 6154859.000000  in 34.96s 
Iter 59...	Training loss: 6146722.500000  in 34.89s 
Iter 60...	Training loss: 6129413.000000  in 34.36s 
Top-1 Recall: 0.045861 Precision: 0.045861 NDCG: 0.045861 HR: 0.045861
Top-5 Recall: 0.125828 Precision: 0.025166 NDCG: 0.086241 HR: 0.125828
Top-10 Recall: 0.185762 Precision: 0.018576 NDCG: 0.105487 HR: 0.185762
Eval costs: 0.719592 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 6107004.500000 (3956556.974044, 2150447.616455) in 111.18s 
Iter 2...	Training loss: 2323978.000000 (311013.472808, 2012964.492310) in 112.36s 
Iter 3...	Training loss: 2178400.000000 (244902.417277, 1933497.499023) in 116.68s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 17587920.000000  in 35.79s 
Iter 2...	Training loss: 16502438.000000  in 35.48s 
Iter 3...	Training loss: 15863712.000000  in 35.55s 
Iter 4...	Training loss: 14984026.000000  in 36.43s 
Iter 5...	Training loss: 13891461.000000  in 36.01s 
Top-1 Recall: 0.051159 Precision: 0.051159 NDCG: 0.051159 HR: 0.051159
Top-5 Recall: 0.144040 Precision: 0.028808 NDCG: 0.098796 HR: 0.144040
Top-10 Recall: 0.208609 Precision: 0.020861 NDCG: 0.119529 HR: 0.208609
Eval costs: 0.879462 s
Iter 6...	Training loss: 12900190.000000  in 36.05s 
Iter 7...	Training loss: 12074352.000000  in 35.41s 
Iter 8...	Training loss: 11396801.000000  in 35.87s 
Iter 9...	Training loss: 10819980.000000  in 35.65s 
Iter 10...	Training loss: 10320670.000000  in 35.29s 
Top-1 Recall: 0.060762 Precision: 0.060762 NDCG: 0.060762 HR: 0.060762
Top-5 Recall: 0.165894 Precision: 0.033179 NDCG: 0.114519 HR: 0.165894
Top-10 Recall: 0.237417 Precision: 0.023742 NDCG: 0.137607 HR: 0.237417
Eval costs: 0.557854 s
Iter 11...	Training loss: 9902834.000000  in 35.25s 
Iter 12...	Training loss: 9539398.000000  in 35.39s 
Iter 13...	Training loss: 9227780.000000  in 35.31s 
Iter 14...	Training loss: 8960858.000000  in 35.39s 
Iter 15...	Training loss: 8720955.000000  in 35.89s 
Top-1 Recall: 0.055795 Precision: 0.055795 NDCG: 0.055795 HR: 0.055795
Top-5 Recall: 0.159437 Precision: 0.031887 NDCG: 0.108222 HR: 0.159437
Top-10 Recall: 0.230960 Precision: 0.023096 NDCG: 0.131374 HR: 0.230960
Eval costs: 0.620021 s
Iter 16...	Training loss: 8500918.000000  in 35.17s 
Iter 17...	Training loss: 8320384.500000  in 35.51s 
Iter 18...	Training loss: 8141657.000000  in 35.45s 
Iter 19...	Training loss: 8000316.500000  in 35.21s 
Iter 20...	Training loss: 7860878.000000  in 35.41s 
Top-1 Recall: 0.050993 Precision: 0.050993 NDCG: 0.050993 HR: 0.050993
Top-5 Recall: 0.154801 Precision: 0.030960 NDCG: 0.103930 HR: 0.154801
Top-10 Recall: 0.225000 Precision: 0.022500 NDCG: 0.126332 HR: 0.225000
Eval costs: 1.072566 s
Iter 21...	Training loss: 7739015.000000  in 35.45s 
Iter 22...	Training loss: 7624656.000000  in 35.30s 
Iter 23...	Training loss: 7525174.500000  in 35.54s 
Iter 24...	Training loss: 7429202.500000  in 35.48s 
Iter 25...	Training loss: 7349561.000000  in 35.06s 
Top-1 Recall: 0.050331 Precision: 0.050331 NDCG: 0.050331 HR: 0.050331
Top-5 Recall: 0.149007 Precision: 0.029801 NDCG: 0.101129 HR: 0.149007
Top-10 Recall: 0.215397 Precision: 0.021540 NDCG: 0.122673 HR: 0.215397
Eval costs: 0.676994 s
Iter 26...	Training loss: 7269832.000000  in 35.27s 
Iter 27...	Training loss: 7181267.000000  in 35.33s 
Iter 28...	Training loss: 7122804.500000  in 35.24s 
Iter 29...	Training loss: 7056582.500000  in 35.23s 
Iter 30...	Training loss: 7000875.500000  in 35.47s 
Top-1 Recall: 0.050662 Precision: 0.050662 NDCG: 0.050662 HR: 0.050662
Top-5 Recall: 0.143543 Precision: 0.028709 NDCG: 0.098464 HR: 0.143543
Top-10 Recall: 0.207781 Precision: 0.020778 NDCG: 0.119091 HR: 0.207781
Eval costs: 0.688713 s
Iter 31...	Training loss: 6946122.000000  in 35.32s 
Iter 32...	Training loss: 6893368.000000  in 35.26s 
Iter 33...	Training loss: 6848232.500000  in 35.11s 
Iter 34...	Training loss: 6805145.000000  in 35.28s 
Iter 35...	Training loss: 6746468.000000  in 35.13s 
Top-1 Recall: 0.046689 Precision: 0.046689 NDCG: 0.046689 HR: 0.046689
Top-5 Recall: 0.140232 Precision: 0.028046 NDCG: 0.094248 HR: 0.140232
Top-10 Recall: 0.205960 Precision: 0.020596 NDCG: 0.115422 HR: 0.205960
Eval costs: 0.700352 s
Iter 36...	Training loss: 6711150.000000  in 35.58s 
Iter 37...	Training loss: 6670938.500000  in 35.58s 
Iter 38...	Training loss: 6626182.000000  in 35.50s 
Iter 39...	Training loss: 6596022.000000  in 35.73s 
Iter 40...	Training loss: 6557295.500000  in 35.40s 
Top-1 Recall: 0.046689 Precision: 0.046689 NDCG: 0.046689 HR: 0.046689
Top-5 Recall: 0.138245 Precision: 0.027649 NDCG: 0.093062 HR: 0.138245
Top-10 Recall: 0.199834 Precision: 0.019983 NDCG: 0.112771 HR: 0.199834
Eval costs: 0.706416 s
Iter 41...	Training loss: 6533772.000000  in 35.46s 
Iter 42...	Training loss: 6499198.000000  in 35.50s 
Iter 43...	Training loss: 6475052.500000  in 35.68s 
Iter 44...	Training loss: 6445864.000000  in 35.60s 
Iter 45...	Training loss: 6421059.000000  in 35.54s 
Top-1 Recall: 0.043543 Precision: 0.043543 NDCG: 0.043543 HR: 0.043543
Top-5 Recall: 0.134934 Precision: 0.026987 NDCG: 0.090075 HR: 0.134934
Top-10 Recall: 0.196854 Precision: 0.019685 NDCG: 0.110002 HR: 0.196854
Eval costs: 0.712423 s
Iter 46...	Training loss: 6395808.000000  in 35.72s 
Iter 47...	Training loss: 6366880.000000  in 35.44s 
Iter 48...	Training loss: 6350180.000000  in 35.58s 
Iter 49...	Training loss: 6336216.500000  in 35.44s 
Iter 50...	Training loss: 6311367.000000  in 35.77s 
Top-1 Recall: 0.042550 Precision: 0.042550 NDCG: 0.042550 HR: 0.042550
Top-5 Recall: 0.128974 Precision: 0.025795 NDCG: 0.086765 HR: 0.128974
Top-10 Recall: 0.190563 Precision: 0.019056 NDCG: 0.106652 HR: 0.190563
Eval costs: 0.719516 s
Iter 51...	Training loss: 6280448.000000  in 35.43s 
Iter 52...	Training loss: 6268166.000000  in 35.68s 
Iter 53...	Training loss: 6248662.000000  in 35.46s 
Iter 54...	Training loss: 6229335.500000  in 35.62s 
Iter 55...	Training loss: 6208114.000000  in 35.58s 
Top-1 Recall: 0.042715 Precision: 0.042715 NDCG: 0.042715 HR: 0.042715
Top-5 Recall: 0.130629 Precision: 0.026126 NDCG: 0.086893 HR: 0.130629
Top-10 Recall: 0.189238 Precision: 0.018924 NDCG: 0.105659 HR: 0.189238
Eval costs: 1.143806 s
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 17587306.000000  in 35.25s 
Iter 2...	Training loss: 16506406.000000  in 34.91s 
Iter 3...	Training loss: 15867160.000000  in 35.20s 
Iter 4...	Training loss: 14988098.000000  in 35.30s 
Iter 5...	Training loss: 13890511.000000  in 35.24s 
Top-1 Recall: 0.054470 Precision: 0.054470 NDCG: 0.054470 HR: 0.054470
Top-5 Recall: 0.146026 Precision: 0.029205 NDCG: 0.100062 HR: 0.146026
Top-10 Recall: 0.212417 Precision: 0.021242 NDCG: 0.121213 HR: 0.212417
Eval costs: 1.249904 s
Iter 6...	Training loss: 12907576.000000  in 35.29s 
Iter 7...	Training loss: 12074265.000000  in 35.31s 
Iter 8...	Training loss: 11394235.000000  in 35.23s 
Iter 9...	Training loss: 10813256.000000  in 35.24s 
Iter 10...	Training loss: 10316024.000000  in 35.22s 
Top-1 Recall: 0.060430 Precision: 0.060430 NDCG: 0.060430 HR: 0.060430
Top-5 Recall: 0.162748 Precision: 0.032550 NDCG: 0.112811 HR: 0.162748
Top-10 Recall: 0.236589 Precision: 0.023659 NDCG: 0.136514 HR: 0.236589
Eval costs: 0.554547 s
Iter 11...	Training loss: 9901942.000000  in 35.42s 
Iter 12...	Training loss: 9535958.000000  in 35.62s 
Iter 13...	Training loss: 9226014.000000  in 35.40s 
Iter 14...	Training loss: 8950354.000000  in 35.41s 
Iter 15...	Training loss: 8715138.000000  in 35.51s 
Top-1 Recall: 0.056126 Precision: 0.056126 NDCG: 0.056126 HR: 0.056126
Top-5 Recall: 0.162748 Precision: 0.032550 NDCG: 0.110339 HR: 0.162748
Top-10 Recall: 0.229801 Precision: 0.022980 NDCG: 0.131965 HR: 0.229801
Eval costs: 0.614891 s
Iter 16...	Training loss: 8499661.000000  in 35.44s 
Iter 17...	Training loss: 8311543.000000  in 35.53s 
Iter 18...	Training loss: 8149040.000000  in 35.87s 
Iter 19...	Training loss: 7993486.000000  in 35.43s 
Iter 20...	Training loss: 7858915.000000  in 35.38s 
Top-1 Recall: 0.053642 Precision: 0.053642 NDCG: 0.053642 HR: 0.053642
Top-5 Recall: 0.152980 Precision: 0.030596 NDCG: 0.104478 HR: 0.152980
Top-10 Recall: 0.219536 Precision: 0.021954 NDCG: 0.125889 HR: 0.219536
Eval costs: 0.655308 s
Iter 21...	Training loss: 7738430.000000  in 35.55s 
Iter 22...	Training loss: 7620486.000000  in 35.40s 
Iter 23...	Training loss: 7527639.000000  in 35.30s 
Iter 24...	Training loss: 7416510.000000  in 35.29s 
Iter 25...	Training loss: 7343483.500000  in 35.50s 
Top-1 Recall: 0.050166 Precision: 0.050166 NDCG: 0.050166 HR: 0.050166
Top-5 Recall: 0.148675 Precision: 0.029735 NDCG: 0.100211 HR: 0.148675
Top-10 Recall: 0.213411 Precision: 0.021341 NDCG: 0.120870 HR: 0.213411
Eval costs: 0.675457 s
Iter 26...	Training loss: 7265269.000000  in 35.38s 
Iter 27...	Training loss: 7187430.500000  in 35.56s 
Iter 28...	Training loss: 7119444.000000  in 35.26s 
Iter 29...	Training loss: 7057744.000000  in 35.57s 
Iter 30...	Training loss: 6999629.500000  in 35.18s 
Top-1 Recall: 0.050497 Precision: 0.050497 NDCG: 0.050497 HR: 0.050497
Top-5 Recall: 0.144371 Precision: 0.028874 NDCG: 0.098296 HR: 0.144371
Top-10 Recall: 0.203808 Precision: 0.020381 NDCG: 0.117299 HR: 0.203808
Eval costs: 1.483324 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 6117234.000000 (3966542.799095, 2150691.279907) in 107.22s 
Iter 2...	Training loss: 2322385.000000 (310018.766185, 2012366.145752) in 109.40s 
Iter 3...	Training loss: 2177878.250000 (245333.288294, 1932544.997925) in 109.28s 
Iter 4...	Training loss: 2002976.000000 (175424.998906, 1827550.890747) in 111.06s 
Iter 5...	Training loss: 1833558.625000 (123705.826557, 1709852.819214) in 109.40s 
Top-1 Recall: 0.047682 Precision: 0.047682 NDCG: 0.047682 HR: 0.047682
Top-5 Recall: 0.140894 Precision: 0.028179 NDCG: 0.095377 HR: 0.140894
Top-10 Recall: 0.210099 Precision: 0.021010 NDCG: 0.117559 HR: 0.210099
Eval costs: 0.441260 s
Iter 6...	Training loss: 1710625.500000 (99187.551024, 1611437.988037) in 109.46s 
Iter 7...	Training loss: 1623895.875000 (91992.701427, 1531903.222534) in 107.70s 
Iter 8...	Training loss: 1560589.000000 (93670.475249, 1466918.425659) in 107.69s 
Iter 9...	Training loss: 1510984.250000 (98643.368151, 1412340.786377) in 107.73s 
Iter 10...	Training loss: 1470851.250000 (105781.122531, 1365070.082275) in 109.31s 
Top-1 Recall: 0.056291 Precision: 0.056291 NDCG: 0.056291 HR: 0.056291
Top-5 Recall: 0.163907 Precision: 0.032781 NDCG: 0.111880 HR: 0.163907
Top-10 Recall: 0.233609 Precision: 0.023361 NDCG: 0.134254 HR: 0.233609
Eval costs: 0.558571 s
Iter 11...	Training loss: 1438618.250000 (113504.499551, 1325113.811768) in 107.69s 
Iter 12...	Training loss: 1411770.000000 (122190.952462, 1289579.138672) in 109.41s 
Iter 13...	Training loss: 1389501.000000 (131216.283434, 1258284.842163) in 107.58s 
Iter 14...	Training loss: 1373225.375000 (141091.529597, 1232133.876953) in 107.53s 
Iter 15...	Training loss: 1359919.250000 (150939.261582, 1208980.055542) in 107.36s 
Top-1 Recall: 0.059768 Precision: 0.059768 NDCG: 0.059768 HR: 0.059768
Top-5 Recall: 0.161093 Precision: 0.032219 NDCG: 0.111126 HR: 0.161093
Top-10 Recall: 0.232285 Precision: 0.023228 NDCG: 0.133955 HR: 0.232285
Eval costs: 2.220033 s
Iter 16...	Training loss: 1349805.625000 (161200.285741, 1188605.345337) in 107.52s 
Iter 17...	Training loss: 1338710.375000 (170851.061829, 1167859.264465) in 107.21s 
Iter 18...	Training loss: 1331416.500000 (180699.316788, 1150717.275391) in 109.02s 
Iter 19...	Training loss: 1326139.125000 (189688.828999, 1136450.304810) in 107.35s 
Iter 20...	Training loss: 1321886.750000 (199357.133168, 1122529.539246) in 107.45s 
Top-1 Recall: 0.053146 Precision: 0.053146 NDCG: 0.053146 HR: 0.053146
Top-5 Recall: 0.156954 Precision: 0.031391 NDCG: 0.106224 HR: 0.156954
Top-10 Recall: 0.224503 Precision: 0.022450 NDCG: 0.127920 HR: 0.224503
Eval costs: 0.662598 s
Iter 21...	Training loss: 1320086.000000 (208634.647324, 1111451.430786) in 109.10s 
Iter 22...	Training loss: 1315371.250000 (217614.780571, 1097756.341309) in 107.43s 
Iter 23...	Training loss: 1314152.500000 (225926.931279, 1088225.487610) in 107.46s 
Iter 24...	Training loss: 1313325.750000 (233795.482769, 1079530.221741) in 109.10s 
Iter 25...	Training loss: 1313622.750000 (241728.507296, 1071894.162292) in 107.38s 
Top-1 Recall: 0.050828 Precision: 0.050828 NDCG: 0.050828 HR: 0.050828
Top-5 Recall: 0.152649 Precision: 0.030530 NDCG: 0.102638 HR: 0.152649
Top-10 Recall: 0.215728 Precision: 0.021573 NDCG: 0.122892 HR: 0.215728
Eval costs: 0.684824 s
Iter 26...	Training loss: 1312917.750000 (249875.226043, 1063042.414001) in 107.77s 
Iter 27...	Training loss: 1312699.750000 (257058.951994, 1055640.884399) in 109.20s 
Iter 28...	Training loss: 1312276.125000 (263768.747293, 1048507.353333) in 107.68s 
Iter 29...	Training loss: 1310779.750000 (270573.001565, 1040206.720825) in 108.39s 
Iter 30...	Training loss: 1312530.500000 (276558.231434, 1035972.324524) in 109.31s 
Top-1 Recall: 0.052483 Precision: 0.052483 NDCG: 0.052483 HR: 0.052483
Top-5 Recall: 0.144536 Precision: 0.028907 NDCG: 0.098836 HR: 0.144536
Top-10 Recall: 0.209106 Precision: 0.020911 NDCG: 0.119687 HR: 0.209106
Eval costs: 0.700847 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 6198498.000000 (3969053.856927, 2229444.071411) in 108.80s 
Iter 2...	Training loss: 2277051.500000 (254531.614697, 2022520.142456) in 108.73s 
Iter 3...	Training loss: 2083754.750000 (177046.441563, 1906708.294312) in 110.51s 
Iter 4...	Training loss: 1910158.375000 (130047.571927, 1780110.756836) in 108.72s 
Iter 5...	Training loss: 1778529.250000 (106398.872689, 1672130.462524) in 108.93s 
Top-1 Recall: 0.053477 Precision: 0.053477 NDCG: 0.053477 HR: 0.053477
Top-5 Recall: 0.148675 Precision: 0.029735 NDCG: 0.102568 HR: 0.148675
Top-10 Recall: 0.217384 Precision: 0.021738 NDCG: 0.124687 HR: 0.217384
Eval costs: 0.448045 s
Iter 6...	Training loss: 1683919.125000 (96867.772936, 1587051.334106) in 109.06s 
Iter 7...	Training loss: 1612151.500000 (94430.291662, 1517721.184082) in 107.43s 
Iter 8...	Training loss: 1553987.250000 (95845.768253, 1458141.334961) in 107.66s 
Iter 9...	Training loss: 1509675.875000 (99796.975961, 1409878.816650) in 109.11s 
Iter 10...	Training loss: 1472386.750000 (105442.134341, 1366944.600830) in 107.56s 
Top-1 Recall: 0.060762 Precision: 0.060762 NDCG: 0.060762 HR: 0.060762
Top-5 Recall: 0.165232 Precision: 0.033046 NDCG: 0.114343 HR: 0.165232
Top-10 Recall: 0.239901 Precision: 0.023990 NDCG: 0.138433 HR: 0.239901
Eval costs: 0.567943 s
Iter 11...	Training loss: 1441796.000000 (111679.989915, 1330116.036743) in 107.60s 
Iter 12...	Training loss: 1419246.750000 (118789.076208, 1300457.831177) in 109.37s 
Iter 13...	Training loss: 1399359.000000 (125632.421464, 1273726.650513) in 107.49s 
Iter 14...	Training loss: 1382923.500000 (132122.518554, 1250800.888062) in 107.64s 
Iter 15...	Training loss: 1368969.750000 (138043.908747, 1230925.931274) in 108.88s 
Top-1 Recall: 0.059272 Precision: 0.059272 NDCG: 0.059272 HR: 0.059272
Top-5 Recall: 0.160265 Precision: 0.032053 NDCG: 0.110951 HR: 0.160265
Top-10 Recall: 0.238742 Precision: 0.023874 NDCG: 0.136076 HR: 0.238742
Eval costs: 0.635477 s
Iter 16...	Training loss: 1356488.375000 (143791.910087, 1212696.432739) in 107.32s 
Iter 17...	Training loss: 1345739.375000 (149386.203079, 1196353.113770) in 107.24s 
Iter 18...	Training loss: 1337160.250000 (153772.128270, 1183388.141113) in 108.94s 
Iter 19...	Training loss: 1328173.250000 (158280.270361, 1169892.881592) in 107.76s 
Iter 20...	Training loss: 1322731.250000 (162076.271483, 1160655.018677) in 107.90s 
Top-1 Recall: 0.056291 Precision: 0.056291 NDCG: 0.056291 HR: 0.056291
Top-5 Recall: 0.155132 Precision: 0.031026 NDCG: 0.106510 HR: 0.155132
Top-10 Recall: 0.225000 Precision: 0.022500 NDCG: 0.129092 HR: 0.225000
Eval costs: 0.664223 s
Iter 21...	Training loss: 1313584.500000 (165296.795867, 1148287.694458) in 109.36s 
Iter 22...	Training loss: 1310431.125000 (168918.709674, 1141512.427917) in 107.67s 
Iter 23...	Training loss: 1303026.500000 (171347.185236, 1131679.268372) in 107.55s 
Iter 24...	Training loss: 1297891.250000 (173841.646356, 1124049.589661) in 109.20s 
Iter 25...	Training loss: 1292813.625000 (176204.716287, 1116608.979553) in 107.38s 
Top-1 Recall: 0.055132 Precision: 0.055132 NDCG: 0.055132 HR: 0.055132
Top-5 Recall: 0.150828 Precision: 0.030166 NDCG: 0.103820 HR: 0.150828
Top-10 Recall: 0.217219 Precision: 0.021722 NDCG: 0.125212 HR: 0.217219
Eval costs: 0.687607 s
Iter 26...	Training loss: 1288225.250000 (178157.273049, 1110067.982605) in 108.00s 
Iter 27...	Training loss: 1284194.250000 (179838.364763, 1104355.922241) in 109.37s 
Iter 28...	Training loss: 1279512.000000 (180935.872154, 1098575.981079) in 107.41s 
Iter 29...	Training loss: 1276389.500000 (182511.409706, 1093878.054077) in 107.48s 
Iter 30...	Training loss: 1271025.000000 (183489.683815, 1087535.351318) in 109.20s 
Top-1 Recall: 0.052815 Precision: 0.052815 NDCG: 0.052815 HR: 0.052815
Top-5 Recall: 0.143377 Precision: 0.028675 NDCG: 0.099433 HR: 0.143377
Top-10 Recall: 0.211755 Precision: 0.021175 NDCG: 0.121440 HR: 0.211755
Eval costs: 0.721482 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 6773887.000000 (3967386.115065, 2806500.494751) in 108.86s 
Iter 2...	Training loss: 2174435.000000 (161556.914297, 2012878.117798) in 110.54s 
Iter 3...	Training loss: 1914698.250000 (105604.188320, 1809094.144653) in 109.38s 
Iter 4...	Training loss: 1785158.625000 (90828.047471, 1694330.677856) in 109.39s 
Iter 5...	Training loss: 1701647.625000 (86775.852730, 1614871.762939) in 109.03s 
Top-1 Recall: 0.061424 Precision: 0.061424 NDCG: 0.061424 HR: 0.061424
Top-5 Recall: 0.164901 Precision: 0.032980 NDCG: 0.113460 HR: 0.164901
Top-10 Recall: 0.236424 Precision: 0.023642 NDCG: 0.136599 HR: 0.236424
Eval costs: 2.070779 s
Iter 6...	Training loss: 1638539.750000 (86578.015308, 1551961.738037) in 107.37s 
Iter 7...	Training loss: 1590259.250000 (88050.602410, 1502208.589355) in 107.77s 
Iter 8...	Training loss: 1550841.000000 (90319.496658, 1460521.481201) in 107.35s 
Iter 9...	Training loss: 1518217.000000 (92713.755814, 1425503.091187) in 108.99s 
Iter 10...	Training loss: 1492278.250000 (95008.146390, 1397270.029053) in 107.54s 
Top-1 Recall: 0.060596 Precision: 0.060596 NDCG: 0.060596 HR: 0.060596
Top-5 Recall: 0.163742 Precision: 0.032748 NDCG: 0.113008 HR: 0.163742
Top-10 Recall: 0.237748 Precision: 0.023775 NDCG: 0.136871 HR: 0.237748
Eval costs: 0.576286 s
Iter 11...	Training loss: 1469357.500000 (96941.269044, 1372416.240234) in 109.24s 
Iter 12...	Training loss: 1450930.250000 (98536.687402, 1352393.682129) in 107.58s 
Iter 13...	Training loss: 1432570.625000 (99766.504765, 1332803.964600) in 107.65s 
Iter 14...	Training loss: 1418257.000000 (100566.687996, 1317690.241089) in 107.33s 
Iter 15...	Training loss: 1404636.000000 (101240.712892, 1303395.221191) in 109.05s 
Top-1 Recall: 0.058775 Precision: 0.058775 NDCG: 0.058775 HR: 0.058775
Top-5 Recall: 0.159934 Precision: 0.031987 NDCG: 0.109218 HR: 0.159934
Top-10 Recall: 0.230298 Precision: 0.023030 NDCG: 0.131948 HR: 0.230298
Eval costs: 0.627873 s
Iter 16...	Training loss: 1391719.500000 (101529.982858, 1290189.540649) in 107.65s 
Iter 17...	Training loss: 1379422.750000 (101840.822594, 1277581.909180) in 109.14s 
Iter 18...	Training loss: 1368848.750000 (102094.413839, 1266754.362671) in 107.40s 
Iter 19...	Training loss: 1358840.250000 (102119.857520, 1256720.493042) in 107.71s 
Iter 20...	Training loss: 1350666.500000 (102052.855431, 1248613.623413) in 107.44s 
Top-1 Recall: 0.054305 Precision: 0.054305 NDCG: 0.054305 HR: 0.054305
Top-5 Recall: 0.150662 Precision: 0.030132 NDCG: 0.102876 HR: 0.150662
Top-10 Recall: 0.221689 Precision: 0.022169 NDCG: 0.125752 HR: 0.221689
Eval costs: 2.254635 s
Iter 21...	Training loss: 1341528.000000 (101939.342925, 1239588.686646) in 107.58s 
Iter 22...	Training loss: 1333447.750000 (101859.011429, 1231588.768555) in 107.74s 
Iter 23...	Training loss: 1325049.375000 (101853.149554, 1223196.262207) in 109.16s 
Iter 24...	Training loss: 1318591.250000 (101544.966673, 1217046.287720) in 107.61s 
Iter 25...	Training loss: 1311192.500000 (101372.549656, 1209819.828369) in 107.43s 
Top-1 Recall: 0.054139 Precision: 0.054139 NDCG: 0.054139 HR: 0.054139
Top-5 Recall: 0.148013 Precision: 0.029603 NDCG: 0.101889 HR: 0.148013
Top-10 Recall: 0.215894 Precision: 0.021589 NDCG: 0.123698 HR: 0.215894
Eval costs: 0.674330 s
Iter 26...	Training loss: 1305858.750000 (101283.855197, 1204574.879639) in 109.38s 
Iter 27...	Training loss: 1299416.750000 (100944.561537, 1198472.242371) in 107.47s 
Iter 28...	Training loss: 1292934.125000 (100794.055702, 1192140.147339) in 107.50s 
Iter 29...	Training loss: 1287331.500000 (100449.536190, 1186881.961975) in 108.95s 
Iter 30...	Training loss: 1283150.125000 (100306.711616, 1182843.476929) in 107.61s 
Top-1 Recall: 0.053477 Precision: 0.053477 NDCG: 0.053477 HR: 0.053477
Top-5 Recall: 0.143543 Precision: 0.028709 NDCG: 0.099094 HR: 0.143543
Top-10 Recall: 0.216391 Precision: 0.021639 NDCG: 0.122293 HR: 0.216391
Eval costs: 0.691508 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 12913573.000000 (3963301.644737, 8950271.593994) in 109.69s 
Iter 2...	Training loss: 2909772.000000 (147169.243571, 2762602.653320) in 111.31s 
Iter 3...	Training loss: 2089990.000000 (95203.359934, 1994786.613281) in 109.92s 
Iter 4...	Training loss: 1851505.250000 (83232.492161, 1768272.652710) in 109.79s 
Iter 5...	Training loss: 1751948.875000 (79678.982844, 1672269.914795) in 109.94s 
Top-1 Recall: 0.056788 Precision: 0.056788 NDCG: 0.056788 HR: 0.056788
Top-5 Recall: 0.158940 Precision: 0.031788 NDCG: 0.108435 HR: 0.158940
Top-10 Recall: 0.229967 Precision: 0.022997 NDCG: 0.131154 HR: 0.229967
Eval costs: 2.060732 s
Iter 6...	Training loss: 1697553.500000 (78720.835008, 1618832.595825) in 108.22s 
Iter 7...	Training loss: 1658798.625000 (78637.323795, 1580161.327026) in 107.83s 
Iter 8...	Training loss: 1630347.500000 (78810.867575, 1551536.774170) in 107.96s 
Iter 9...	Training loss: 1605978.500000 (79007.801066, 1526970.704956) in 109.57s 
Iter 10...	Training loss: 1586914.750000 (79169.465435, 1507745.203857) in 107.73s 
Top-1 Recall: 0.056788 Precision: 0.056788 NDCG: 0.056788 HR: 0.056788
Top-5 Recall: 0.162583 Precision: 0.032517 NDCG: 0.110255 HR: 0.162583
Top-10 Recall: 0.231788 Precision: 0.023179 NDCG: 0.132483 HR: 0.231788
Eval costs: 0.549568 s
Iter 11...	Training loss: 1570209.875000 (79165.100359, 1491044.866699) in 109.48s 
Iter 12...	Training loss: 1554585.500000 (79127.686314, 1475457.823608) in 108.18s 
Iter 13...	Training loss: 1540834.375000 (78952.282052, 1461882.087646) in 107.88s 
Iter 14...	Training loss: 1528597.000000 (78823.681721, 1449773.332031) in 108.05s 
Iter 15...	Training loss: 1516619.625000 (78615.640513, 1438003.982910) in 109.58s 
Top-1 Recall: 0.053974 Precision: 0.053974 NDCG: 0.053974 HR: 0.053974
Top-5 Recall: 0.154470 Precision: 0.030894 NDCG: 0.105455 HR: 0.154470
Top-10 Recall: 0.221689 Precision: 0.022169 NDCG: 0.127053 HR: 0.221689
Eval costs: 0.589463 s
Iter 16...	Training loss: 1505982.000000 (78386.589957, 1427595.410767) in 108.07s 
Iter 17...	Training loss: 1497062.250000 (78199.539366, 1418862.789795) in 109.52s 
Iter 18...	Training loss: 1487907.125000 (78009.285262, 1409897.819946) in 108.02s 
Iter 19...	Training loss: 1478975.375000 (77784.261381, 1401191.207520) in 107.90s 
Iter 20...	Training loss: 1472682.000000 (77583.660667, 1395098.366943) in 108.21s 
Top-1 Recall: 0.054636 Precision: 0.054636 NDCG: 0.054636 HR: 0.054636
Top-5 Recall: 0.149669 Precision: 0.029934 NDCG: 0.103581 HR: 0.149669
Top-10 Recall: 0.220364 Precision: 0.022036 NDCG: 0.126340 HR: 0.220364
Eval costs: 2.203537 s
Iter 21...	Training loss: 1463908.500000 (77387.321435, 1386521.196899) in 107.99s 
Iter 22...	Training loss: 1457739.000000 (77180.844034, 1380558.051025) in 107.99s 
Iter 23...	Training loss: 1451012.500000 (76970.205741, 1374042.415161) in 109.48s 
Iter 24...	Training loss: 1445083.000000 (76788.571755, 1368294.302490) in 107.83s 
Iter 25...	Training loss: 1439336.750000 (76606.321453, 1362730.359985) in 108.09s 
Top-1 Recall: 0.052815 Precision: 0.052815 NDCG: 0.052815 HR: 0.052815
Top-5 Recall: 0.146192 Precision: 0.029238 NDCG: 0.100595 HR: 0.146192
Top-10 Recall: 0.219205 Precision: 0.021921 NDCG: 0.124008 HR: 0.219205
Eval costs: 0.626489 s
Iter 26...	Training loss: 1435208.875000 (76391.465988, 1358817.319336) in 109.62s 
Iter 27...	Training loss: 1429497.625000 (76211.606470, 1353285.952759) in 108.17s 
Iter 28...	Training loss: 1424620.750000 (76023.965102, 1348596.735352) in 108.29s 
Iter 29...	Training loss: 1418754.500000 (75811.995522, 1342942.570679) in 110.06s 
Iter 30...	Training loss: 1415219.500000 (75618.686193, 1339600.800659) in 108.35s 
Top-1 Recall: 0.050828 Precision: 0.050828 NDCG: 0.050828 HR: 0.050828
Top-5 Recall: 0.149172 Precision: 0.029834 NDCG: 0.100322 HR: 0.149172
Top-10 Recall: 0.212748 Precision: 0.021275 NDCG: 0.120787 HR: 0.212748
Eval costs: 0.638233 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 6147915.000000 (3996984.498222, 2150930.644775) in 57.72s 
Iter 2...	Training loss: 2659725.000000 (648788.346081, 2010936.514893) in 59.75s 
Iter 3...	Training loss: 2304548.500000 (371766.621892, 1932781.794922) in 58.09s 
Iter 4...	Training loss: 2029947.000000 (201462.420241, 1828484.636353) in 59.72s 
Iter 5...	Training loss: 1823102.500000 (113559.558241, 1709542.915649) in 58.10s 
Top-1 Recall: 0.051821 Precision: 0.051821 NDCG: 0.051821 HR: 0.051821
Top-5 Recall: 0.138907 Precision: 0.027781 NDCG: 0.096029 HR: 0.138907
Top-10 Recall: 0.207450 Precision: 0.020745 NDCG: 0.118079 HR: 0.207450
Eval costs: 0.439236 s
Iter 6...	Training loss: 1681476.750000 (71780.628726, 1609696.371216) in 59.85s 
Iter 7...	Training loss: 1582098.500000 (51407.803989, 1530690.525146) in 58.73s 
Iter 8...	Training loss: 1506656.375000 (41761.324861, 1464895.054565) in 58.29s 
Iter 9...	Training loss: 1450131.125000 (39828.406406, 1410302.845093) in 58.22s 
Iter 10...	Training loss: 1402822.500000 (41589.724410, 1361232.859131) in 58.84s 
Top-1 Recall: 0.058444 Precision: 0.058444 NDCG: 0.058444 HR: 0.058444
Top-5 Recall: 0.161093 Precision: 0.032219 NDCG: 0.110902 HR: 0.161093
Top-10 Recall: 0.238576 Precision: 0.023858 NDCG: 0.135736 HR: 0.238576
Eval costs: 0.561085 s
Iter 11...	Training loss: 1366611.125000 (44482.336618, 1322128.717285) in 59.88s 
Iter 12...	Training loss: 1334442.375000 (47846.889381, 1286595.458374) in 58.01s 
Iter 13...	Training loss: 1306068.625000 (51483.556045, 1254585.098877) in 58.01s 
Iter 14...	Training loss: 1282212.875000 (55410.057541, 1226802.844849) in 58.50s 
Iter 15...	Training loss: 1263738.500000 (59615.693692, 1204122.902954) in 58.38s 
Top-1 Recall: 0.058444 Precision: 0.058444 NDCG: 0.058444 HR: 0.058444
Top-5 Recall: 0.163907 Precision: 0.032781 NDCG: 0.111536 HR: 0.163907
Top-10 Recall: 0.231457 Precision: 0.023146 NDCG: 0.133183 HR: 0.231457
Eval costs: 0.632273 s
Iter 16...	Training loss: 1245508.000000 (63990.873219, 1181517.147705) in 59.92s 
Iter 17...	Training loss: 1231964.375000 (68354.820392, 1163609.530640) in 58.20s 
Iter 18...	Training loss: 1218576.750000 (72913.415557, 1145663.299438) in 58.22s 
Iter 19...	Training loss: 1207401.500000 (77413.074149, 1129988.302734) in 58.20s 
Iter 20...	Training loss: 1198941.125000 (82143.349513, 1116797.616699) in 58.27s 
Top-1 Recall: 0.052318 Precision: 0.052318 NDCG: 0.052318 HR: 0.052318
Top-5 Recall: 0.153808 Precision: 0.030762 NDCG: 0.104515 HR: 0.153808
Top-10 Recall: 0.222848 Precision: 0.022285 NDCG: 0.126696 HR: 0.222848
Eval costs: 0.665496 s
Iter 21...	Training loss: 1188768.375000 (86700.864818, 1102067.431641) in 59.68s 
Iter 22...	Training loss: 1089726.500000 (0.000000, 1089726.536316) in 39.87s 
Iter 23...	Training loss: 1199504.000000 (118963.895199, 1080540.231934) in 77.20s 
Iter 24...	Training loss: 1168661.000000 (98185.006758, 1070475.979431) in 58.18s 
Iter 25...	Training loss: 1166937.875000 (105509.997685, 1061427.940857) in 57.83s 
Top-1 Recall: 0.051325 Precision: 0.051325 NDCG: 0.051325 HR: 0.051325
Top-5 Recall: 0.150828 Precision: 0.030166 NDCG: 0.102094 HR: 0.150828
Top-10 Recall: 0.213245 Precision: 0.021325 NDCG: 0.122247 HR: 0.213245
Eval costs: 0.690875 s
Iter 26...	Training loss: 1163240.875000 (110077.872360, 1053162.926819) in 59.76s 
Iter 27...	Training loss: 1159756.875000 (114027.858967, 1045729.014160) in 58.36s 
Iter 28...	Training loss: 1156099.250000 (118609.519393, 1037489.709656) in 58.26s 
Iter 29...	Training loss: 1154970.875000 (122651.163672, 1032319.689636) in 58.00s 
Iter 30...	Training loss: 1152108.875000 (126967.599118, 1025141.268799) in 57.85s 
Top-1 Recall: 0.049834 Precision: 0.049834 NDCG: 0.049834 HR: 0.049834
Top-5 Recall: 0.143874 Precision: 0.028775 NDCG: 0.097287 HR: 0.143874
Top-10 Recall: 0.210927 Precision: 0.021093 NDCG: 0.118905 HR: 0.210927
Eval costs: 0.707643 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 6216060.000000 (3983458.966203, 2232601.246460) in 57.72s 
Iter 2...	Training loss: 2440405.750000 (418723.802825, 2021682.078247) in 57.77s 
Iter 3...	Training loss: 2123336.500000 (192183.067584, 1931153.283569) in 59.57s 
Iter 4...	Training loss: 1929460.500000 (120965.612186, 1808495.137451) in 57.92s 
Iter 5...	Training loss: 1780170.375000 (91632.758179, 1688537.687134) in 59.58s 
Top-1 Recall: 0.051159 Precision: 0.051159 NDCG: 0.051159 HR: 0.051159
Top-5 Recall: 0.144205 Precision: 0.028841 NDCG: 0.098486 HR: 0.144205
Top-10 Recall: 0.209934 Precision: 0.020993 NDCG: 0.119752 HR: 0.209934
Eval costs: 0.444369 s
Iter 6...	Training loss: 1668753.625000 (75918.234615, 1592835.390015) in 57.72s 
Iter 7...	Training loss: 1580468.250000 (65653.463158, 1514814.847778) in 57.73s 
Iter 8...	Training loss: 1507162.500000 (58135.364059, 1449027.105469) in 59.44s 
Iter 9...	Training loss: 1446079.625000 (51736.622207, 1394342.970581) in 57.76s 
Iter 10...	Training loss: 1395314.000000 (47784.167408, 1347529.816772) in 57.87s 
Top-1 Recall: 0.058609 Precision: 0.058609 NDCG: 0.058609 HR: 0.058609
Top-5 Recall: 0.161755 Precision: 0.032351 NDCG: 0.111732 HR: 0.161755
Top-10 Recall: 0.237086 Precision: 0.023709 NDCG: 0.135856 HR: 0.237086
Eval costs: 0.573125 s
Iter 11...	Training loss: 1350832.625000 (45415.697371, 1305416.925171) in 57.85s 
Iter 12...	Training loss: 1315487.375000 (44859.406586, 1270627.992188) in 57.65s 
Iter 13...	Training loss: 1285510.375000 (45747.522067, 1239762.993042) in 59.64s 
Iter 14...	Training loss: 1260982.250000 (47708.250943, 1213274.110840) in 57.75s 
Iter 15...	Training loss: 1241372.125000 (50137.319745, 1191234.809814) in 57.50s 
Top-1 Recall: 0.055132 Precision: 0.055132 NDCG: 0.055132 HR: 0.055132
Top-5 Recall: 0.158278 Precision: 0.031656 NDCG: 0.107822 HR: 0.158278
Top-10 Recall: 0.231788 Precision: 0.023179 NDCG: 0.131452 HR: 0.231788
Eval costs: 0.634240 s
Iter 16...	Training loss: 1222610.000000 (52924.903108, 1169685.133118) in 57.74s 
Iter 17...	Training loss: 1208144.375000 (55850.722181, 1152293.683838) in 57.62s 
Iter 18...	Training loss: 1196270.375000 (58844.202302, 1137426.219849) in 59.48s 
Iter 19...	Training loss: 1184638.125000 (61865.059114, 1122772.991638) in 57.65s 
Iter 20...	Training loss: 1173440.625000 (64746.635083, 1108693.986145) in 57.76s 
Top-1 Recall: 0.055132 Precision: 0.055132 NDCG: 0.055132 HR: 0.055132
Top-5 Recall: 0.151987 Precision: 0.030397 NDCG: 0.104076 HR: 0.151987
Top-10 Recall: 0.220364 Precision: 0.022036 NDCG: 0.126198 HR: 0.220364
Eval costs: 0.674304 s
Iter 21...	Training loss: 1164759.375000 (67544.866252, 1097214.589111) in 57.78s 
Iter 22...	Training loss: 1156898.750000 (70132.192913, 1086766.637695) in 57.52s 
Iter 23...	Training loss: 1151144.125000 (73046.290198, 1078097.842773) in 59.50s 
Iter 24...	Training loss: 1143476.875000 (75483.169937, 1067993.748718) in 57.82s 
Iter 25...	Training loss: 1137526.750000 (77759.459241, 1059767.361206) in 57.66s 
Top-1 Recall: 0.052815 Precision: 0.052815 NDCG: 0.052815 HR: 0.052815
Top-5 Recall: 0.149172 Precision: 0.029834 NDCG: 0.101479 HR: 0.149172
Top-10 Recall: 0.217219 Precision: 0.021722 NDCG: 0.123261 HR: 0.217219
Eval costs: 0.694982 s
Iter 26...	Training loss: 1133133.250000 (80120.189783, 1053013.049377) in 57.63s 
Iter 27...	Training loss: 1127486.250000 (81912.225766, 1045574.052490) in 57.78s 
Iter 28...	Training loss: 1121248.875000 (84064.060578, 1037184.831116) in 59.50s 
Iter 29...	Training loss: 1119830.250000 (86173.218537, 1033656.990540) in 57.70s 
Iter 30...	Training loss: 1115502.250000 (88025.960179, 1027476.322327) in 57.72s 
Top-1 Recall: 0.048841 Precision: 0.048841 NDCG: 0.048841 HR: 0.048841
Top-5 Recall: 0.139570 Precision: 0.027914 NDCG: 0.095239 HR: 0.139570
Top-10 Recall: 0.203146 Precision: 0.020315 NDCG: 0.115825 HR: 0.203146
Eval costs: 0.710895 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 6816317.000000 (3998729.069066, 2817588.169800) in 57.58s 
Iter 2...	Training loss: 2257101.750000 (202357.207974, 2054744.591797) in 59.46s 
Iter 3...	Training loss: 1995999.125000 (81566.575327, 1914432.501953) in 57.67s 
Iter 4...	Training loss: 1848865.000000 (58124.357966, 1790740.765747) in 59.44s 
Iter 5...	Training loss: 1736084.625000 (51014.599517, 1685070.134521) in 57.70s 
Top-1 Recall: 0.053477 Precision: 0.053477 NDCG: 0.053477 HR: 0.053477
Top-5 Recall: 0.139901 Precision: 0.027980 NDCG: 0.097513 HR: 0.139901
Top-10 Recall: 0.203311 Precision: 0.020331 NDCG: 0.117902 HR: 0.203311
Eval costs: 0.471988 s
Iter 6...	Training loss: 1641772.000000 (47527.812436, 1594244.146240) in 59.45s 
Iter 7...	Training loss: 1564914.500000 (45350.097807, 1519564.543457) in 57.54s 
Iter 8...	Training loss: 1500518.125000 (44161.806208, 1456356.402588) in 57.59s 
Iter 9...	Training loss: 1445680.500000 (43334.884364, 1402345.473389) in 57.64s 
Iter 10...	Training loss: 1399035.625000 (42474.588042, 1356561.024414) in 57.67s 
Top-1 Recall: 0.055629 Precision: 0.055629 NDCG: 0.055629 HR: 0.055629
Top-5 Recall: 0.159768 Precision: 0.031954 NDCG: 0.108775 HR: 0.159768
Top-10 Recall: 0.226490 Precision: 0.022649 NDCG: 0.130309 HR: 0.226490
Eval costs: 0.577833 s
Iter 11...	Training loss: 1360003.500000 (42031.303596, 1317972.117798) in 59.41s 
Iter 12...	Training loss: 1327554.875000 (41725.281572, 1285829.680908) in 57.67s 
Iter 13...	Training loss: 1298938.875000 (41809.307213, 1257129.633911) in 57.60s 
Iter 14...	Training loss: 1274161.000000 (41909.387182, 1232251.701050) in 57.76s 
Iter 15...	Training loss: 1255414.125000 (42056.437623, 1213357.718262) in 57.59s 
Top-1 Recall: 0.054967 Precision: 0.054967 NDCG: 0.054967 HR: 0.054967
Top-5 Recall: 0.156788 Precision: 0.031358 NDCG: 0.106550 HR: 0.156788
Top-10 Recall: 0.225497 Precision: 0.022550 NDCG: 0.128838 HR: 0.225497
Eval costs: 0.639081 s
Iter 16...	Training loss: 1236112.875000 (42384.595137, 1193728.367004) in 59.71s 
Iter 17...	Training loss: 1220526.875000 (42614.583984, 1177912.399841) in 58.18s 
Iter 18...	Training loss: 1207566.250000 (42953.989156, 1164612.183899) in 57.73s 
Iter 19...	Training loss: 1195462.625000 (43324.923715, 1152137.621460) in 57.98s 
Iter 20...	Training loss: 1184493.000000 (43450.781218, 1141042.147461) in 58.16s 
Top-1 Recall: 0.049172 Precision: 0.049172 NDCG: 0.049172 HR: 0.049172
Top-5 Recall: 0.150993 Precision: 0.030199 NDCG: 0.100553 HR: 0.150993
Top-10 Recall: 0.217550 Precision: 0.021755 NDCG: 0.122082 HR: 0.217550
Eval costs: 0.675508 s
Iter 21...	Training loss: 1088910.500000 (0.000000, 1088910.549561) in 38.92s 
Iter 22...	Training loss: 1192663.250000 (69410.260090, 1123253.033081) in 78.90s 
Iter 23...	Training loss: 1155987.250000 (46330.269460, 1109656.807861) in 58.01s 
Iter 24...	Training loss: 1150118.500000 (46293.975080, 1103824.415527) in 58.08s 
Iter 25...	Training loss: 1141993.750000 (45851.033497, 1096142.682922) in 57.99s 
Top-1 Recall: 0.051490 Precision: 0.051490 NDCG: 0.051490 HR: 0.051490
Top-5 Recall: 0.145199 Precision: 0.029040 NDCG: 0.099143 HR: 0.145199
Top-10 Recall: 0.211424 Precision: 0.021142 NDCG: 0.120504 HR: 0.211424
Eval costs: 0.694782 s
Iter 26...	Training loss: 1135508.000000 (45427.883847, 1090080.069763) in 59.56s 
Iter 27...	Training loss: 1127989.875000 (45074.692026, 1082915.112366) in 57.96s 
Iter 28...	Training loss: 1122658.875000 (44713.795017, 1077945.074829) in 58.30s 
Iter 29...	Training loss: 1116303.375000 (44453.234197, 1071850.082214) in 57.59s 
Iter 30...	Training loss: 1110559.875000 (44211.666664, 1066348.246643) in 58.40s 
Top-1 Recall: 0.050166 Precision: 0.050166 NDCG: 0.050166 HR: 0.050166
Top-5 Recall: 0.145695 Precision: 0.029139 NDCG: 0.098310 HR: 0.145695
Top-10 Recall: 0.210099 Precision: 0.021010 NDCG: 0.118975 HR: 0.210099
Eval costs: 0.709438 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 12681586.000000 (3976646.872501, 8704938.929077) in 60.08s 
Iter 2...	Training loss: 2621020.000000 (169159.709928, 2451860.358032) in 57.74s 
Iter 3...	Training loss: 2107800.000000 (53637.131832, 2054162.948242) in 59.85s 
Iter 4...	Training loss: 1935496.875000 (35662.261006, 1899834.740723) in 57.41s 
Iter 5...	Training loss: 1816613.250000 (31432.904921, 1785180.243896) in 59.54s 
Top-1 Recall: 0.045695 Precision: 0.045695 NDCG: 0.045695 HR: 0.045695
Top-5 Recall: 0.126656 Precision: 0.025331 NDCG: 0.087155 HR: 0.126656
Top-10 Recall: 0.187417 Precision: 0.018742 NDCG: 0.106652 HR: 0.187417
Eval costs: 0.426296 s
Iter 6...	Training loss: 1719271.500000 (29830.134519, 1689441.563965) in 58.07s 
Iter 7...	Training loss: 1638464.625000 (29219.083026, 1609245.473267) in 57.61s 
Iter 8...	Training loss: 1572668.750000 (28923.337194, 1543745.515625) in 59.41s 
Iter 9...	Training loss: 1518803.125000 (28894.564523, 1489908.623169) in 57.72s 
Iter 10...	Training loss: 1476072.000000 (28844.408898, 1447227.600586) in 57.50s 
Top-1 Recall: 0.060762 Precision: 0.060762 NDCG: 0.060762 HR: 0.060762
Top-5 Recall: 0.157450 Precision: 0.031490 NDCG: 0.110216 HR: 0.157450
Top-10 Recall: 0.228808 Precision: 0.022881 NDCG: 0.133193 HR: 0.228808
Eval costs: 0.555266 s
Iter 11...	Training loss: 1439246.000000 (28833.820659, 1410412.191772) in 57.64s 
Iter 12...	Training loss: 1408346.375000 (28773.967785, 1379572.468262) in 57.69s 
Iter 13...	Training loss: 1382697.750000 (28708.093878, 1353989.676392) in 59.26s 
Iter 14...	Training loss: 1357909.500000 (28626.628833, 1329282.745850) in 57.57s 
Iter 15...	Training loss: 1338382.000000 (28496.096838, 1309886.048584) in 57.50s 
Top-1 Recall: 0.057947 Precision: 0.057947 NDCG: 0.057947 HR: 0.057947
Top-5 Recall: 0.163245 Precision: 0.032649 NDCG: 0.111366 HR: 0.163245
Top-10 Recall: 0.236258 Precision: 0.023626 NDCG: 0.134814 HR: 0.236258
Eval costs: 0.611579 s
Iter 16...	Training loss: 1320080.250000 (28358.570707, 1291721.638550) in 57.50s 
Iter 17...	Training loss: 1303324.250000 (28234.635959, 1275089.568237) in 57.62s 
Iter 18...	Training loss: 1287815.625000 (28081.177268, 1259734.450867) in 59.54s 
Iter 19...	Training loss: 1273399.625000 (27983.661945, 1245416.070557) in 57.44s 
Iter 20...	Training loss: 1260434.750000 (27874.676985, 1232560.143799) in 57.52s 
Top-1 Recall: 0.054139 Precision: 0.054139 NDCG: 0.054139 HR: 0.054139
Top-5 Recall: 0.159603 Precision: 0.031921 NDCG: 0.107261 HR: 0.159603
Top-10 Recall: 0.230629 Precision: 0.023063 NDCG: 0.129992 HR: 0.230629
Eval costs: 0.646551 s
Iter 21...	Training loss: 1248410.125000 (27774.816237, 1220635.258972) in 57.57s 
Iter 22...	Training loss: 1237935.125000 (27664.901714, 1210270.310059) in 57.42s 
Iter 23...	Training loss: 1228742.500000 (27566.591076, 1201175.898926) in 59.24s 
Iter 24...	Training loss: 1218213.375000 (27473.915336, 1190739.526245) in 57.54s 
Iter 25...	Training loss: 1208369.375000 (27395.732292, 1180973.653870) in 57.53s 
Top-1 Recall: 0.052815 Precision: 0.052815 NDCG: 0.052815 HR: 0.052815
Top-5 Recall: 0.154470 Precision: 0.030894 NDCG: 0.104275 HR: 0.154470
Top-10 Recall: 0.223013 Precision: 0.022301 NDCG: 0.126453 HR: 0.223013
Eval costs: 0.669740 s
Iter 26...	Training loss: 1201258.375000 (27300.129625, 1173958.117676) in 57.50s 
Iter 27...	Training loss: 1192464.000000 (27204.801400, 1165259.147400) in 57.51s 
Iter 28...	Training loss: 1185798.125000 (27135.169820, 1158662.996216) in 59.43s 
Iter 29...	Training loss: 1179553.750000 (27063.863874, 1152489.919800) in 57.71s 
Iter 30...	Training loss: 1173200.625000 (26980.087650, 1146220.441467) in 57.55s 
Top-1 Recall: 0.049503 Precision: 0.049503 NDCG: 0.049503 HR: 0.049503
Top-5 Recall: 0.152815 Precision: 0.030563 NDCG: 0.102111 HR: 0.152815
Top-10 Recall: 0.225000 Precision: 0.022500 NDCG: 0.125455 HR: 0.225000
Eval costs: 0.682162 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 10138636.000000 (3971652.670871, 4005579.419838, 2161403.480835) in 136.56s 
Iter 2...	Training loss: 2973436.500000 (310167.599095, 648110.263905, 2015158.686646) in 137.85s 
Iter 3...	Training loss: 2551559.750000 (244820.820805, 371750.535849, 1934988.122192) in 136.20s 
Iter 4...	Training loss: 2205465.250000 (175385.957756, 202063.167962, 1828016.267456) in 135.95s 
Iter 5...	Training loss: 1945071.750000 (123254.843161, 114173.481858, 1707643.641357) in 138.26s 
Top-1 Recall: 0.049834 Precision: 0.049834 NDCG: 0.049834 HR: 0.049834
Top-5 Recall: 0.140397 Precision: 0.028079 NDCG: 0.095987 HR: 0.140397
Top-10 Recall: 0.209272 Precision: 0.020927 NDCG: 0.118106 HR: 0.209272
Eval costs: 0.442382 s
Iter 6...	Training loss: 1779402.750000 (99079.684417, 71867.741431, 1608455.378906) in 134.66s 
Iter 7...	Training loss: 1674014.000000 (92254.997375, 51489.286579, 1530269.743652) in 134.54s 
Iter 8...	Training loss: 1600531.500000 (93747.742287, 41674.522331, 1465109.205566) in 135.74s 
Iter 9...	Training loss: 1550472.250000 (99202.390395, 39731.938617, 1411537.860474) in 134.85s 
Iter 10...	Training loss: 1510982.500000 (106380.124870, 41499.271322, 1363103.130249) in 134.61s 
Top-1 Recall: 0.059437 Precision: 0.059437 NDCG: 0.059437 HR: 0.059437
Top-5 Recall: 0.164238 Precision: 0.032848 NDCG: 0.112683 HR: 0.164238
Top-10 Recall: 0.236424 Precision: 0.023642 NDCG: 0.135784 HR: 0.236424
Eval costs: 0.560622 s
Iter 11...	Training loss: 1483175.750000 (114559.891429, 44398.803422, 1324216.967896) in 134.70s 
Iter 12...	Training loss: 1460726.375000 (123674.159877, 47808.635441, 1289243.552002) in 134.85s 
Iter 13...	Training loss: 1443037.500000 (132569.375995, 51440.981852, 1259027.125000) in 134.82s 
Iter 14...	Training loss: 1430485.625000 (142409.101498, 55506.816132, 1232569.765137) in 134.98s 
Iter 15...	Training loss: 1418663.375000 (152557.258217, 59774.164736, 1206331.997925) in 136.87s 
Top-1 Recall: 0.056457 Precision: 0.056457 NDCG: 0.056457 HR: 0.056457
Top-5 Recall: 0.166722 Precision: 0.033344 NDCG: 0.112645 HR: 0.166722
Top-10 Recall: 0.233775 Precision: 0.023377 NDCG: 0.134122 HR: 0.233775
Eval costs: 0.625789 s
Iter 16...	Training loss: 1414117.250000 (162497.197119, 64088.955684, 1187531.094482) in 134.99s 
Iter 17...	Training loss: 1410194.750000 (172602.039026, 68554.699324, 1169037.901794) in 135.09s 
Iter 18...	Training loss: 1407401.875000 (182755.818889, 73055.380443, 1151590.585571) in 135.18s 
Iter 19...	Training loss: 1406449.500000 (192469.895880, 77934.589251, 1136044.899414) in 134.94s 
Iter 20...	Training loss: 1406970.375000 (201572.948061, 82584.131337, 1122813.289978) in 135.16s 
Top-1 Recall: 0.055464 Precision: 0.055464 NDCG: 0.055464 HR: 0.055464
Top-5 Recall: 0.153311 Precision: 0.030662 NDCG: 0.105397 HR: 0.153311
Top-10 Recall: 0.225993 Precision: 0.022599 NDCG: 0.128718 HR: 0.225993
Eval costs: 0.666639 s
Iter 21...	Training loss: 1410946.500000 (211020.597083, 87579.906512, 1112345.920654) in 135.14s 
Iter 22...	Training loss: 1412397.875000 (220863.564882, 92104.203721, 1099430.028992) in 135.07s 
Iter 23...	Training loss: 1415194.000000 (228636.578392, 97202.932154, 1089354.529297) in 135.01s 
Iter 24...	Training loss: 1420823.000000 (238255.274976, 101891.569370, 1080676.196533) in 135.25s 
Iter 25...	Training loss: 1425080.250000 (245355.776829, 106632.421680, 1073092.115784) in 135.07s 
Top-1 Recall: 0.049338 Precision: 0.049338 NDCG: 0.049338 HR: 0.049338
Top-5 Recall: 0.146192 Precision: 0.029238 NDCG: 0.098794 HR: 0.146192
Top-10 Recall: 0.217053 Precision: 0.021705 NDCG: 0.121530 HR: 0.217053
Eval costs: 2.517402 s
Iter 26...	Training loss: 1428823.750000 (253554.053691, 111487.298393, 1063782.324219) in 134.92s 
Iter 27...	Training loss: 1434487.375000 (260854.590997, 116148.401653, 1057484.303528) in 134.87s 
Iter 28...	Training loss: 1440742.375000 (269023.147043, 120799.839440, 1050919.560486) in 134.84s 
Iter 29...	Training loss: 1442865.000000 (274354.611146, 125886.836208, 1042623.582031) in 134.81s 
Iter 30...	Training loss: 1453683.500000 (283692.725520, 130364.851834, 1039625.827881) in 134.94s 
Top-1 Recall: 0.050497 Precision: 0.050497 NDCG: 0.050497 HR: 0.050497
Top-5 Recall: 0.145199 Precision: 0.029040 NDCG: 0.098963 HR: 0.145199
Top-10 Recall: 0.209934 Precision: 0.020993 NDCG: 0.119893 HR: 0.209934
Eval costs: 0.706253 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 10194786.000000 (3961912.622122, 3989766.157361, 2243106.893677) in 136.91s 
Iter 2...	Training loss: 2754023.500000 (309171.667279, 418884.490531, 2025967.422119) in 138.27s 
Iter 3...	Training loss: 2370631.500000 (244790.589117, 192524.406271, 1933316.632446) in 136.72s 
Iter 4...	Training loss: 2102454.750000 (171254.426965, 122127.490027, 1809072.873657) in 136.42s 
Iter 5...	Training loss: 1900891.125000 (120193.316059, 91431.835428, 1689266.027100) in 138.40s 
Top-1 Recall: 0.053146 Precision: 0.053146 NDCG: 0.053146 HR: 0.053146
Top-5 Recall: 0.144205 Precision: 0.028841 NDCG: 0.099770 HR: 0.144205
Top-10 Recall: 0.209603 Precision: 0.020960 NDCG: 0.120824 HR: 0.209603
Eval costs: 0.445026 s
Iter 6...	Training loss: 1768812.500000 (99574.663934, 76312.165954, 1592925.610718) in 135.16s 
Iter 7...	Training loss: 1675721.250000 (94472.143440, 66578.216403, 1514670.910400) in 135.08s 
Iter 8...	Training loss: 1606118.875000 (97455.653465, 58087.876121, 1450575.360352) in 134.77s 
Iter 9...	Training loss: 1551763.750000 (104310.667292, 51794.238877, 1395658.705688) in 134.96s 
Iter 10...	Training loss: 1509965.875000 (112911.431847, 47725.148834, 1349329.227783) in 135.03s 
Top-1 Recall: 0.060265 Precision: 0.060265 NDCG: 0.060265 HR: 0.060265
Top-5 Recall: 0.162086 Precision: 0.032417 NDCG: 0.112163 HR: 0.162086
Top-10 Recall: 0.232450 Precision: 0.023245 NDCG: 0.134672 HR: 0.232450
Eval costs: 0.567914 s
Iter 11...	Training loss: 1477817.875000 (123156.687982, 45434.276453, 1309226.998779) in 134.97s 
Iter 12...	Training loss: 1453553.500000 (134431.619483, 44947.667628, 1274174.208252) in 135.24s 
Iter 13...	Training loss: 1436917.000000 (145621.294880, 46003.512902, 1245292.266846) in 134.99s 
Iter 14...	Training loss: 1424977.750000 (157488.153666, 47997.270387, 1219492.291138) in 136.75s 
Iter 15...	Training loss: 1416275.750000 (169548.754848, 50560.189117, 1196166.805420) in 134.89s 
Top-1 Recall: 0.056954 Precision: 0.056954 NDCG: 0.056954 HR: 0.056954
Top-5 Recall: 0.158278 Precision: 0.031656 NDCG: 0.108580 HR: 0.158278
Top-10 Recall: 0.228146 Precision: 0.022815 NDCG: 0.131108 HR: 0.228146
Eval costs: 0.641185 s
Iter 16...	Training loss: 1412450.375000 (182024.919095, 53496.456738, 1176928.995483) in 135.08s 
Iter 17...	Training loss: 1409658.250000 (193615.035921, 56475.192443, 1159567.943542) in 134.86s 
Iter 18...	Training loss: 1409866.750000 (206422.089430, 59584.723800, 1143859.780396) in 135.02s 
Iter 19...	Training loss: 1411808.625000 (218062.459979, 62846.369148, 1130899.793091) in 134.81s 
Iter 20...	Training loss: 1414970.750000 (230022.731924, 65804.562949, 1119143.585510) in 135.10s 
Top-1 Recall: 0.055629 Precision: 0.055629 NDCG: 0.055629 HR: 0.055629
Top-5 Recall: 0.156291 Precision: 0.031258 NDCG: 0.106627 HR: 0.156291
Top-10 Recall: 0.221358 Precision: 0.022136 NDCG: 0.127646 HR: 0.221358
Eval costs: 0.674252 s
Iter 21...	Training loss: 1417645.625000 (241334.711798, 68657.363866, 1107653.576111) in 135.09s 
Iter 22...	Training loss: 1420356.875000 (250767.455160, 71538.486297, 1098050.860413) in 135.04s 
Iter 23...	Training loss: 1425857.125000 (262839.128675, 74362.708817, 1088655.183533) in 135.07s 
Iter 24...	Training loss: 1431100.250000 (272327.781659, 77239.161304, 1081533.301636) in 134.92s 
Iter 25...	Training loss: 1435653.875000 (282144.848159, 79663.865310, 1073845.020752) in 135.15s 
Top-1 Recall: 0.054139 Precision: 0.054139 NDCG: 0.054139 HR: 0.054139
Top-5 Recall: 0.146026 Precision: 0.029205 NDCG: 0.100658 HR: 0.146026
Top-10 Recall: 0.215894 Precision: 0.021589 NDCG: 0.123190 HR: 0.215894
Eval costs: 2.512416 s
Iter 26...	Training loss: 1440075.000000 (290178.336370, 82258.838487, 1067637.855774) in 135.08s 
Iter 27...	Training loss: 1446016.250000 (299893.715320, 84591.582589, 1061530.978333) in 134.91s 
Iter 28...	Training loss: 1451345.125000 (309002.712614, 86775.962819, 1055566.448181) in 134.61s 
Iter 29...	Training loss: 1456377.250000 (317876.871104, 89225.414087, 1049274.912720) in 134.72s 
Iter 30...	Training loss: 1463261.500000 (327647.202568, 91304.172334, 1044309.970581) in 134.66s 
Top-1 Recall: 0.047185 Precision: 0.047185 NDCG: 0.047185 HR: 0.047185
Top-5 Recall: 0.146192 Precision: 0.029238 NDCG: 0.098098 HR: 0.146192
Top-10 Recall: 0.211589 Precision: 0.021159 NDCG: 0.119188 HR: 0.211589
Eval costs: 0.710648 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 10770034.000000 (3958120.149958, 3985901.472407, 2826012.021484) in 136.40s 
Iter 2...	Training loss: 2561161.000000 (300329.072976, 201982.520283, 2058849.612427) in 137.69s 
Iter 3...	Training loss: 2234578.000000 (236846.188562, 81587.413328, 1916144.364868) in 136.11s 
Iter 4...	Training loss: 2028503.250000 (180289.619802, 58169.144605, 1790044.420654) in 135.96s 
Iter 5...	Training loss: 1866021.250000 (131921.738966, 50654.785632, 1683445.004517) in 137.97s 
Top-1 Recall: 0.052152 Precision: 0.052152 NDCG: 0.052152 HR: 0.052152
Top-5 Recall: 0.146358 Precision: 0.029272 NDCG: 0.100832 HR: 0.146358
Top-10 Recall: 0.206457 Precision: 0.020646 NDCG: 0.120155 HR: 0.206457
Eval costs: 0.451747 s
Iter 6...	Training loss: 1744468.375000 (104114.001284, 47405.300423, 1592949.205688) in 134.86s 
Iter 7...	Training loss: 1660600.750000 (97006.058136, 45531.357483, 1518063.494995) in 137.72s 
Iter 8...	Training loss: 1602957.875000 (101839.751131, 44219.660176, 1456898.456909) in 139.66s 
Iter 9...	Training loss: 1557391.250000 (111581.407485, 43180.492860, 1402629.336426) in 156.48s 
Iter 10...	Training loss: 1523866.500000 (123491.698594, 42330.272179, 1358044.663940) in 156.65s 
Top-1 Recall: 0.059934 Precision: 0.059934 NDCG: 0.059934 HR: 0.059934
Top-5 Recall: 0.160099 Precision: 0.032020 NDCG: 0.110868 HR: 0.160099
Top-10 Recall: 0.231457 Precision: 0.023146 NDCG: 0.133875 HR: 0.231457
Eval costs: 0.672037 s
Iter 11...	Training loss: 1501263.375000 (137265.495760, 42155.794696, 1321841.960938) in 156.78s 
Iter 12...	Training loss: 1483021.000000 (151505.547882, 41836.934667, 1289678.548096) in 156.51s 
Iter 13...	Training loss: 1470854.000000 (167041.539111, 41895.490578, 1261917.124146) in 158.29s 
Iter 14...	Training loss: 1465139.750000 (184200.321310, 41993.027773, 1238946.246155) in 155.85s 
Iter 15...	Training loss: 1464057.500000 (201479.743145, 42302.349838, 1220275.274414) in 155.74s 
Top-1 Recall: 0.057119 Precision: 0.057119 NDCG: 0.057119 HR: 0.057119
Top-5 Recall: 0.159934 Precision: 0.031987 NDCG: 0.108772 HR: 0.159934
Top-10 Recall: 0.228974 Precision: 0.022897 NDCG: 0.130861 HR: 0.228974
Eval costs: 0.715338 s
Iter 16...	Training loss: 1464142.125000 (218679.533112, 42637.572073, 1202825.004028) in 155.85s 
Iter 17...	Training loss: 1468400.000000 (236610.156234, 42937.911571, 1188851.971252) in 156.10s 
Iter 18...	Training loss: 1472246.500000 (253608.834562, 43385.684437, 1175251.983032) in 148.80s 
Iter 19...	Training loss: 1480332.125000 (272522.087495, 43702.444097, 1164107.630615) in 156.13s 
Iter 20...	Training loss: 1484656.375000 (287859.864987, 43918.871914, 1152877.666138) in 156.21s 
Top-1 Recall: 0.051325 Precision: 0.051325 NDCG: 0.051325 HR: 0.051325
Top-5 Recall: 0.155132 Precision: 0.031026 NDCG: 0.103797 HR: 0.155132
Top-10 Recall: 0.221192 Precision: 0.022119 NDCG: 0.125053 HR: 0.221192
Eval costs: 0.765861 s
Iter 21...	Training loss: 1493792.375000 (303770.561269, 44127.468876, 1145894.362427) in 156.27s 
Iter 22...	Training loss: 1503238.250000 (321505.929833, 44340.420796, 1137391.888977) in 156.25s 
Iter 23...	Training loss: 1512161.750000 (337584.812046, 44422.605975, 1130154.249329) in 156.29s 
Iter 24...	Training loss: 1522511.750000 (355069.856883, 44538.875737, 1122903.014893) in 158.49s 
Iter 25...	Training loss: 1530099.000000 (369078.488209, 44623.110018, 1116397.385315) in 156.31s 
Top-1 Recall: 0.050497 Precision: 0.050497 NDCG: 0.050497 HR: 0.050497
Top-5 Recall: 0.150000 Precision: 0.030000 NDCG: 0.100774 HR: 0.150000
Top-10 Recall: 0.217550 Precision: 0.021755 NDCG: 0.122454 HR: 0.217550
Eval costs: 0.775017 s
Iter 26...	Training loss: 1539847.750000 (385618.695844, 44556.429221, 1109672.529114) in 154.60s 
Iter 27...	Training loss: 1550101.250000 (399851.184896, 44688.335873, 1105561.831726) in 154.13s 
Iter 28...	Training loss: 1560164.875000 (414639.388036, 44637.847441, 1100887.582092) in 153.79s 
Iter 29...	Training loss: 1573578.375000 (431767.360641, 44636.119202, 1097174.950928) in 154.40s 
Iter 30...	Training loss: 1580678.625000 (443609.817994, 44612.038001, 1092456.738525) in 153.92s 
Top-1 Recall: 0.049669 Precision: 0.049669 NDCG: 0.049669 HR: 0.049669
Top-5 Recall: 0.144536 Precision: 0.028907 NDCG: 0.097543 HR: 0.144536
Top-10 Recall: 0.209272 Precision: 0.020927 NDCG: 0.118305 HR: 0.209272
Eval costs: 0.777937 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 16642195.000000 (3958806.874686, 3982766.696743, 8700621.390503) in 158.09s 
Iter 2...	Training loss: 2879922.250000 (257665.299529, 169252.730869, 2453004.381348) in 155.28s 
Iter 3...	Training loss: 2280709.750000 (171833.523333, 53779.320589, 2055096.840210) in 154.88s 
Iter 4...	Training loss: 2068919.375000 (132704.626373, 35782.513795, 1900432.231445) in 157.38s 
Iter 5...	Training loss: 1930384.625000 (112210.292287, 31410.930950, 1786763.262695) in 155.02s 
Top-1 Recall: 0.046523 Precision: 0.046523 NDCG: 0.046523 HR: 0.046523
Top-5 Recall: 0.126325 Precision: 0.025265 NDCG: 0.087532 HR: 0.126325
Top-10 Recall: 0.192384 Precision: 0.019238 NDCG: 0.108700 HR: 0.192384
Eval costs: 0.470510 s
Iter 6...	Training loss: 1822973.000000 (102848.827626, 29843.430023, 1690280.712891) in 153.75s 
Iter 7...	Training loss: 1741125.375000 (101236.044688, 29163.662958, 1610725.510864) in 155.71s 
Iter 8...	Training loss: 1679334.750000 (105202.012103, 28829.900253, 1545302.709595) in 155.65s 
Iter 9...	Training loss: 1636017.125000 (114735.848992, 28816.134760, 1492465.221069) in 155.77s 
Iter 10...	Training loss: 1606921.500000 (128457.364338, 28740.533666, 1449723.530029) in 155.63s 
Top-1 Recall: 0.057947 Precision: 0.057947 NDCG: 0.057947 HR: 0.057947
Top-5 Recall: 0.154967 Precision: 0.030993 NDCG: 0.107565 HR: 0.154967
Top-10 Recall: 0.228477 Precision: 0.022848 NDCG: 0.131151 HR: 0.228477
Eval costs: 0.608988 s
Iter 11...	Training loss: 1590088.125000 (145901.523140, 28760.838384, 1415425.689209) in 157.88s 
Iter 12...	Training loss: 1580556.500000 (167289.503421, 28734.245712, 1384532.710083) in 155.54s 
Iter 13...	Training loss: 1580057.000000 (191187.628673, 28673.037845, 1360196.391724) in 156.30s 
Iter 14...	Training loss: 1584121.750000 (217643.972660, 28596.239695, 1337881.595581) in 155.91s 
Iter 15...	Training loss: 1593556.250000 (245038.691035, 28490.698850, 1320026.881836) in 155.64s 
Top-1 Recall: 0.058278 Precision: 0.058278 NDCG: 0.058278 HR: 0.058278
Top-5 Recall: 0.157616 Precision: 0.031523 NDCG: 0.108547 HR: 0.157616
Top-10 Recall: 0.235927 Precision: 0.023593 NDCG: 0.133622 HR: 0.235927
Eval costs: 0.675874 s
Iter 16...	Training loss: 1606172.000000 (275219.330897, 28358.603999, 1302593.997070) in 155.78s 
Iter 17...	Training loss: 1620947.375000 (305030.262341, 28239.920817, 1287677.243774) in 155.70s 
Iter 18...	Training loss: 1640415.250000 (337746.521148, 28153.084400, 1274515.456177) in 155.57s 
Iter 19...	Training loss: 1658569.000000 (369018.328367, 28022.383381, 1261528.201660) in 154.43s 
Iter 20...	Training loss: 1681615.125000 (401009.442317, 27900.609907, 1252704.974243) in 153.88s 
Top-1 Recall: 0.055629 Precision: 0.055629 NDCG: 0.055629 HR: 0.055629
Top-5 Recall: 0.157119 Precision: 0.031424 NDCG: 0.106847 HR: 0.157119
Top-10 Recall: 0.230132 Precision: 0.023013 NDCG: 0.130335 HR: 0.230132
Eval costs: 0.706909 s
Iter 21...	Training loss: 1702227.250000 (432885.225138, 27841.145668, 1241500.908630) in 157.09s 
Iter 22...	Training loss: 1728264.000000 (467166.276734, 27735.702770, 1233361.872314) in 156.46s 
Iter 23...	Training loss: 1750675.875000 (497903.418656, 27655.992389, 1225116.486206) in 155.73s 
Iter 24...	Training loss: 1778830.750000 (532049.590599, 27589.773155, 1219191.368530) in 143.41s 
Iter 25...	Training loss: 1800573.500000 (562815.089628, 27472.338359, 1210286.265259) in 143.84s 
Top-1 Recall: 0.055298 Precision: 0.055298 NDCG: 0.055298 HR: 0.055298
Top-5 Recall: 0.155298 Precision: 0.031060 NDCG: 0.105394 HR: 0.155298
Top-10 Recall: 0.226490 Precision: 0.022649 NDCG: 0.128303 HR: 0.226490
Eval costs: 0.724684 s
Iter 26...	Training loss: 1829999.875000 (596619.638141, 27427.219487, 1205952.926392) in 143.60s 
Iter 27...	Training loss: 1856802.250000 (629746.410740, 27351.242964, 1199704.510986) in 143.47s 
Iter 28...	Training loss: 1882612.500000 (661099.701337, 27281.106612, 1194231.724976) in 143.51s 
Iter 29...	Training loss: 1907350.250000 (690985.850887, 27210.461848, 1189153.742249) in 143.58s 
Iter 30...	Training loss: 1935962.000000 (723242.109439, 27146.905805, 1185573.061218) in 143.37s 
Top-1 Recall: 0.053146 Precision: 0.053146 NDCG: 0.053146 HR: 0.053146
Top-5 Recall: 0.152815 Precision: 0.030563 NDCG: 0.103764 HR: 0.152815
Top-10 Recall: 0.226325 Precision: 0.022632 NDCG: 0.127333 HR: 0.226325
Eval costs: 0.714086 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 10199027.000000 (3969119.182240, 3989433.742743, 2240473.354248) in 145.16s 
Iter 2...	Training loss: 2930251.000000 (255136.366590, 650062.088284, 2025052.575073) in 144.69s 
Iter 3...	Training loss: 2457877.000000 (176545.071580, 373168.473611, 1908163.403076) in 145.23s 
Iter 4...	Training loss: 2112093.250000 (129682.473029, 202506.613983, 1779904.051880) in 146.36s 
Iter 5...	Training loss: 1898166.375000 (106028.472100, 120473.195586, 1671664.697876) in 145.22s 
Top-1 Recall: 0.056954 Precision: 0.056954 NDCG: 0.056954 HR: 0.056954
Top-5 Recall: 0.150331 Precision: 0.030066 NDCG: 0.104274 HR: 0.150331
Top-10 Recall: 0.217384 Precision: 0.021738 NDCG: 0.125967 HR: 0.217384
Eval costs: 0.475523 s
Iter 6...	Training loss: 1759092.750000 (96862.079499, 75321.120182, 1586909.462402) in 142.99s 
Iter 7...	Training loss: 1658820.500000 (94508.505478, 49199.011191, 1515112.889404) in 143.41s 
