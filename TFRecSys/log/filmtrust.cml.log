############################################### 
n_negative=20  
batch_size=1024.00 
embed_dim=100 
margin=2.00 
############################################### 
Iter 1...	Training loss: 575385.437500 in 3.64s
Iter 2...	Training loss: 480885.531250 in 3.93s
Iter 3...	Training loss: 417571.437500 in 3.72s
Iter 4...	Training loss: 360005.937500 in 4.40s
Iter 5...	Training loss: 297440.937500 in 3.81s
Iter 6...	Training loss: 228379.578125 in 4.04s
Iter 7...	Training loss: 184754.937500 in 4.38s
Iter 8...	Training loss: 174531.906250 in 3.78s
Iter 9...	Training loss: 168482.937500 in 4.40s
Iter 10...	Training loss: 167284.515625 in 3.68s
############################################### 
n_negative=20  
batch_size=1024.00 
############################################### 
n_negative=20  
batch_size=1024.00 
embed_dim=100 
margin=2.00 
############################################### 
Iter 1...	Training loss: 566929.750000 in 3.43s
Iter 2...	Training loss: 476398.500000 in 3.14s
Iter 3...	Training loss: 415271.906250 in 3.18s
Iter 4...	Training loss: 358399.500000 in 3.19s
Iter 5...	Training loss: 298683.500000 in 3.16s
Iter 6...	Training loss: 229734.859375 in 3.25s
Iter 7...	Training loss: 185367.421875 in 3.30s
Iter 8...	Training loss: 174092.031250 in 3.28s
Iter 9...	Training loss: 171120.453125 in 3.57s
Iter 10...	Training loss: 167741.140625 in 3.31s
############################################### 
n_negative=20  
batch_size=1024.00 
embed_dim=100 
margin=2.00 
############################################### 
Iter 1...	Training loss: 566980.500000 in 3.20s
Iter 2...	Training loss: 475756.781250 in 3.14s
Iter 3...	Training loss: 414312.531250 in 3.27s
Iter 4...	Training loss: 358481.625000 in 3.13s
Iter 5...	Training loss: 298731.531250 in 3.10s
############################################### 
n_negative=20  
batch_size=1024.00 
embed_dim=100 
margin=2.00 
############################################### 
Iter 1...	Training loss: 569657.312500 in 3.27s
Iter 2...	Training loss: 478078.312500 in 3.12s
Iter 3...	Training loss: 415251.968750 in 3.14s
Iter 4...	Training loss: 359102.937500 in 3.16s
Iter 5...	Training loss: 298563.218750 in 3.11s
Top-5 Recall: 0.294430 Precision: 0.058886 NDCG: 0.239969 HR: 0.294430
Top-10 Recall: 0.410477 Precision: 0.041048 NDCG: 0.276817 HR: 0.410477
Top-20 Recall: 0.588196 Precision: 0.029410 NDCG: 0.321366 HR: 0.588196
Top-50 Recall: 0.842838 Precision: 0.016857 NDCG: 0.372830 HR: 0.842838
Eval costs: 1.520956 s
Iter 6...	Training loss: 229526.312500 in 3.12s
Iter 7...	Training loss: 183423.062500 in 3.19s
Iter 8...	Training loss: 174028.828125 in 3.14s
Iter 9...	Training loss: 168774.437500 in 3.47s
Iter 10...	Training loss: 166186.437500 in 3.19s
Top-5 Recall: 0.381300 Precision: 0.076260 NDCG: 0.293833 HR: 0.381300
Top-10 Recall: 0.527851 Precision: 0.052785 NDCG: 0.340956 HR: 0.527851
Top-20 Recall: 0.722149 Precision: 0.036107 NDCG: 0.390144 HR: 0.722149
Top-50 Recall: 0.847480 Precision: 0.016950 NDCG: 0.416280 HR: 0.847480
Eval costs: 1.743383 s
Iter 11...	Training loss: 165137.437500 in 3.41s
Iter 12...	Training loss: 161105.484375 in 3.49s
Iter 13...	Training loss: 157671.468750 in 3.66s
############################################### 
n_negative=20  
batch_size=1024.00 
embed_dim=100 
margin=2.00 
############################################### 
Iter 1...	Training loss: 569600.187500 in 3.56s
Iter 2...	Training loss: 478106.000000 in 3.28s
Iter 3...	Training loss: 415789.812500 in 3.15s
Iter 4...	Training loss: 359763.718750 in 3.16s
Iter 5...	Training loss: 299325.437500 in 3.07s
Top-1 Recall: 0.180371 Precision: 0.180371 NDCG: 0.180371 HR: 0.180371
Top-5 Recall: 0.291114 Precision: 0.058223 NDCG: 0.236885 HR: 0.291114
Top-10 Recall: 0.411804 Precision: 0.041180 NDCG: 0.275449 HR: 0.411804
Eval costs: 1.610322 s
Iter 6...	Training loss: 229888.031250 in 3.12s
Iter 7...	Training loss: 185044.890625 in 3.21s
Iter 8...	Training loss: 175603.515625 in 3.20s
Iter 9...	Training loss: 171315.437500 in 3.13s
Iter 10...	Training loss: 167007.156250 in 3.20s
Top-1 Recall: 0.201592 Precision: 0.201592 NDCG: 0.201592 HR: 0.201592
Top-5 Recall: 0.381963 Precision: 0.076393 NDCG: 0.292007 HR: 0.381963
Top-10 Recall: 0.532493 Precision: 0.053249 NDCG: 0.340166 HR: 0.532493
Eval costs: 1.496031 s
Iter 11...	Training loss: 163333.609375 in 3.17s
Iter 12...	Training loss: 161578.828125 in 3.14s
Iter 13...	Training loss: 158005.218750 in 3.18s
Iter 14...	Training loss: 154040.296875 in 3.24s
Iter 15...	Training loss: 151254.859375 in 3.11s
Top-1 Recall: 0.224138 Precision: 0.224138 NDCG: 0.224138 HR: 0.224138
Top-5 Recall: 0.454907 Precision: 0.090981 NDCG: 0.340449 HR: 0.454907
Top-10 Recall: 0.608090 Precision: 0.060809 NDCG: 0.389512 HR: 0.608090
Eval costs: 1.498073 s
Iter 16...	Training loss: 147129.843750 in 3.14s
Iter 17...	Training loss: 142019.984375 in 3.09s
Iter 18...	Training loss: 138401.484375 in 3.18s
Iter 19...	Training loss: 133680.625000 in 3.15s
Iter 20...	Training loss: 127732.492188 in 3.11s
Top-1 Recall: 0.246684 Precision: 0.246684 NDCG: 0.246684 HR: 0.246684
Top-5 Recall: 0.475464 Precision: 0.095093 NDCG: 0.364557 HR: 0.475464
Top-10 Recall: 0.625995 Precision: 0.062599 NDCG: 0.412741 HR: 0.625995
Eval costs: 1.501672 s
Iter 21...	Training loss: 122516.648438 in 3.11s
Iter 22...	Training loss: 116593.796875 in 3.23s
Iter 23...	Training loss: 112664.117188 in 3.49s
Iter 24...	Training loss: 105203.906250 in 3.34s
Iter 25...	Training loss: 100212.359375 in 3.50s
Top-1 Recall: 0.261936 Precision: 0.261936 NDCG: 0.261936 HR: 0.261936
Top-5 Recall: 0.486737 Precision: 0.097347 NDCG: 0.378633 HR: 0.486737
Top-10 Recall: 0.625332 Precision: 0.062533 NDCG: 0.423139 HR: 0.625332
Eval costs: 1.864045 s
Iter 26...	Training loss: 93310.406250 in 3.69s
Iter 27...	Training loss: 87962.742188 in 3.41s
Iter 28...	Training loss: 82314.257812 in 3.28s
Iter 29...	Training loss: 76595.070312 in 3.26s
############################################### 
n_negative=20  
batch_size=1024.00 
embed_dim=100 
margin=2.00 
############################################### 
Iter 1...	Training loss: 569393.187500 in 3.26s
Iter 2...	Training loss: 477649.093750 in 3.20s
Iter 3...	Training loss: 415769.000000 in 3.29s
Iter 4...	Training loss: 359004.156250 in 3.30s
Iter 5...	Training loss: 298264.218750 in 3.31s
Top-1 Recall: 0.181698 Precision: 0.181698 NDCG: 0.181698 HR: 0.181698
Top-5 Recall: 0.294430 Precision: 0.058886 NDCG: 0.240015 HR: 0.294430
Top-10 Recall: 0.404509 Precision: 0.040451 NDCG: 0.275291 HR: 0.404509
Eval costs: 1.706575 s
Iter 6...	Training loss: 228715.734375 in 3.58s
Iter 7...	Training loss: 184082.500000 in 3.43s
Iter 8...	Training loss: 173918.781250 in 3.37s
Iter 9...	Training loss: 169682.968750 in 3.44s
Iter 10...	Training loss: 166963.140625 in 3.25s
Top-1 Recall: 0.210875 Precision: 0.210875 NDCG: 0.210875 HR: 0.210875
Top-5 Recall: 0.377321 Precision: 0.075464 NDCG: 0.294193 HR: 0.377321
Top-10 Recall: 0.527851 Precision: 0.052785 NDCG: 0.342865 HR: 0.527851
Eval costs: 1.662997 s
Iter 11...	Training loss: 164120.296875 in 3.42s
Iter 12...	Training loss: 163043.015625 in 3.88s
Iter 13...	Training loss: 157723.250000 in 3.39s
Iter 14...	Training loss: 154312.656250 in 3.42s
Iter 15...	Training loss: 151657.515625 in 3.70s
Top-1 Recall: 0.231432 Precision: 0.231432 NDCG: 0.231432 HR: 0.231432
Top-5 Recall: 0.450265 Precision: 0.090053 NDCG: 0.342519 HR: 0.450265
Top-10 Recall: 0.610080 Precision: 0.061008 NDCG: 0.393861 HR: 0.610080
Eval costs: 1.944219 s
Iter 16...	Training loss: 146487.671875 in 3.64s
Iter 17...	Training loss: 142460.375000 in 3.52s
Iter 18...	Training loss: 137339.515625 in 3.37s
Iter 19...	Training loss: 133101.437500 in 3.30s
Iter 20...	Training loss: 127494.734375 in 3.35s
Top-1 Recall: 0.250663 Precision: 0.250663 NDCG: 0.250663 HR: 0.250663
Top-5 Recall: 0.474801 Precision: 0.094960 NDCG: 0.365761 HR: 0.474801
Top-10 Recall: 0.623342 Precision: 0.062334 NDCG: 0.413355 HR: 0.623342
Eval costs: 2.124215 s
Iter 21...	Training loss: 122731.210938 in 3.57s
Iter 22...	Training loss: 117314.890625 in 3.83s
Iter 23...	Training loss: 112159.640625 in 3.72s
Iter 24...	Training loss: 106000.289062 in 3.61s
Iter 25...	Training loss: 99883.890625 in 3.70s
Top-1 Recall: 0.257958 Precision: 0.257958 NDCG: 0.257958 HR: 0.257958
Top-5 Recall: 0.480769 Precision: 0.096154 NDCG: 0.372783 HR: 0.480769
Top-10 Recall: 0.628647 Precision: 0.062865 NDCG: 0.420330 HR: 0.628647
Eval costs: 1.898840 s
Iter 26...	Training loss: 95226.632812 in 3.28s
Iter 27...	Training loss: 88367.875000 in 3.29s
Iter 28...	Training loss: 83102.148438 in 3.30s
Iter 29...	Training loss: 77886.664062 in 3.44s
Iter 30...	Training loss: 72922.757812 in 3.27s
Top-1 Recall: 0.277188 Precision: 0.277188 NDCG: 0.277188 HR: 0.277188
Top-5 Recall: 0.487401 Precision: 0.097480 NDCG: 0.384199 HR: 0.487401
Top-10 Recall: 0.629310 Precision: 0.062931 NDCG: 0.429829 HR: 0.629310
Eval costs: 1.651514 s
Iter 31...	Training loss: 67777.367188 in 3.27s
Iter 32...	Training loss: 64206.109375 in 3.36s
Iter 33...	Training loss: 59484.996094 in 3.51s
Iter 34...	Training loss: 55371.578125 in 3.41s
Iter 35...	Training loss: 53350.355469 in 3.39s
Top-1 Recall: 0.291114 Precision: 0.291114 NDCG: 0.291114 HR: 0.291114
Top-5 Recall: 0.486737 Precision: 0.097347 NDCG: 0.390776 HR: 0.486737
Top-10 Recall: 0.642573 Precision: 0.064257 NDCG: 0.440909 HR: 0.642573
Eval costs: 1.749332 s
Iter 36...	Training loss: 49449.164062 in 3.85s
Iter 37...	Training loss: 46513.113281 in 4.05s
Iter 38...	Training loss: 44161.710938 in 3.71s
Iter 39...	Training loss: 41666.382812 in 3.74s
Iter 40...	Training loss: 38567.183594 in 3.62s
Top-1 Recall: 0.292440 Precision: 0.292440 NDCG: 0.292440 HR: 0.292440
Top-5 Recall: 0.487401 Precision: 0.097480 NDCG: 0.391724 HR: 0.487401
Top-10 Recall: 0.636605 Precision: 0.063660 NDCG: 0.440100 HR: 0.636605
Eval costs: 1.896656 s
Iter 41...	Training loss: 37486.445312 in 3.60s
Iter 42...	Training loss: 35851.746094 in 3.88s
Iter 43...	Training loss: 34074.773438 in 3.60s
Iter 44...	Training loss: 32455.792969 in 3.42s
Iter 45...	Training loss: 30284.830078 in 3.70s
Top-1 Recall: 0.294430 Precision: 0.294430 NDCG: 0.294430 HR: 0.294430
Top-5 Recall: 0.495358 Precision: 0.099072 NDCG: 0.395582 HR: 0.495358
Top-10 Recall: 0.644562 Precision: 0.064456 NDCG: 0.443920 HR: 0.644562
Eval costs: 1.701849 s
Iter 46...	Training loss: 29919.072266 in 3.25s
Iter 47...	Training loss: 27627.468750 in 3.30s
Iter 48...	Training loss: 27450.933594 in 3.27s
Iter 49...	Training loss: 26136.302734 in 3.26s
Iter 50...	Training loss: 24930.246094 in 3.31s
Top-1 Recall: 0.295093 Precision: 0.295093 NDCG: 0.295093 HR: 0.295093
Top-5 Recall: 0.499337 Precision: 0.099867 NDCG: 0.398852 HR: 0.499337
Top-10 Recall: 0.647215 Precision: 0.064721 NDCG: 0.446700 HR: 0.647215
Eval costs: 1.672286 s
Iter 51...	Training loss: 24076.082031 in 3.25s
Iter 52...	Training loss: 23728.312500 in 3.32s
Iter 53...	Training loss: 22656.720703 in 3.44s
Iter 54...	Training loss: 21377.722656 in 3.37s
Iter 55...	Training loss: 20440.855469 in 3.35s
Top-1 Recall: 0.300398 Precision: 0.300398 NDCG: 0.300398 HR: 0.300398
Top-5 Recall: 0.507294 Precision: 0.101459 NDCG: 0.404319 HR: 0.507294
Top-10 Recall: 0.654509 Precision: 0.065451 NDCG: 0.452173 HR: 0.654509
Eval costs: 1.683339 s
Iter 56...	Training loss: 20099.714844 in 3.27s
Iter 57...	Training loss: 19438.412109 in 3.31s
Iter 58...	Training loss: 19077.203125 in 3.33s
Iter 59...	Training loss: 18222.666016 in 3.26s
Iter 60...	Training loss: 17391.929688 in 3.33s
Top-1 Recall: 0.297082 Precision: 0.297082 NDCG: 0.297082 HR: 0.297082
Top-5 Recall: 0.521220 Precision: 0.104244 NDCG: 0.409960 HR: 0.521220
Top-10 Recall: 0.655836 Precision: 0.065584 NDCG: 0.453864 HR: 0.655836
Eval costs: 1.720537 s
Iter 61...	Training loss: 17493.267578 in 3.55s
Iter 62...	Training loss: 16815.521484 in 3.39s
Iter 63...	Training loss: 16518.671875 in 3.86s
Iter 64...	Training loss: 15996.499023 in 3.68s
Iter 65...	Training loss: 15974.948242 in 3.64s
Top-1 Recall: 0.293767 Precision: 0.293767 NDCG: 0.293767 HR: 0.293767
Top-5 Recall: 0.520557 Precision: 0.104111 NDCG: 0.410658 HR: 0.520557
Top-10 Recall: 0.655172 Precision: 0.065517 NDCG: 0.454352 HR: 0.655172
Eval costs: 1.974741 s
Iter 66...	Training loss: 15097.990234 in 3.66s
Iter 67...	Training loss: 14476.796875 in 3.58s
Iter 68...	Training loss: 13735.219727 in 3.61s
Iter 69...	Training loss: 13643.699219 in 3.59s
Iter 70...	Training loss: 12933.528320 in 3.49s
Top-1 Recall: 0.298408 Precision: 0.298408 NDCG: 0.298408 HR: 0.298408
Top-5 Recall: 0.526525 Precision: 0.105305 NDCG: 0.416080 HR: 0.526525
Top-10 Recall: 0.658488 Precision: 0.065849 NDCG: 0.459001 HR: 0.658488
Eval costs: 1.705573 s
Iter 71...	Training loss: 13322.458008 in 3.44s
Iter 72...	Training loss: 12076.172852 in 3.45s
Iter 73...	Training loss: 11824.923828 in 3.54s
Iter 74...	Training loss: 12147.332031 in 3.63s
Iter 75...	Training loss: 11603.275391 in 3.61s
Top-1 Recall: 0.300398 Precision: 0.300398 NDCG: 0.300398 HR: 0.300398
Top-5 Recall: 0.537798 Precision: 0.107560 NDCG: 0.421605 HR: 0.537798
Top-10 Recall: 0.661804 Precision: 0.066180 NDCG: 0.461740 HR: 0.661804
Eval costs: 1.683903 s
Iter 76...	Training loss: 11166.137695 in 3.32s
Iter 77...	Training loss: 10880.205078 in 3.39s
Iter 78...	Training loss: 10601.774414 in 3.46s
Iter 79...	Training loss: 10317.701172 in 3.36s
Iter 80...	Training loss: 9929.954102 in 3.59s
Top-1 Recall: 0.303050 Precision: 0.303050 NDCG: 0.303050 HR: 0.303050
Top-5 Recall: 0.533156 Precision: 0.106631 NDCG: 0.422961 HR: 0.533156
Top-10 Recall: 0.659151 Precision: 0.065915 NDCG: 0.464040 HR: 0.659151
Eval costs: 1.881502 s
Iter 81...	Training loss: 9404.685547 in 3.45s
Iter 82...	Training loss: 9680.429688 in 3.54s
Iter 83...	Training loss: 9028.575195 in 3.30s
Iter 84...	Training loss: 8650.700195 in 3.28s
Iter 85...	Training loss: 8736.931641 in 3.26s
Top-1 Recall: 0.306366 Precision: 0.306366 NDCG: 0.306366 HR: 0.306366
Top-5 Recall: 0.538462 Precision: 0.107692 NDCG: 0.426548 HR: 0.538462
Top-10 Recall: 0.665782 Precision: 0.066578 NDCG: 0.467642 HR: 0.665782
Eval costs: 1.696707 s
Iter 86...	Training loss: 8509.582031 in 3.26s
Iter 87...	Training loss: 8271.139648 in 3.26s
Iter 88...	Training loss: 8166.142578 in 3.81s
Iter 89...	Training loss: 7256.730957 in 3.66s
Iter 90...	Training loss: 7384.412109 in 3.31s
Top-1 Recall: 0.307029 Precision: 0.307029 NDCG: 0.307029 HR: 0.307029
Top-5 Recall: 0.534483 Precision: 0.106897 NDCG: 0.426674 HR: 0.534483
Top-10 Recall: 0.667109 Precision: 0.066711 NDCG: 0.469565 HR: 0.667109
Eval costs: 1.871315 s
Iter 91...	Training loss: 7214.195801 in 3.28s
Iter 92...	Training loss: 7018.524414 in 3.48s
Iter 93...	Training loss: 6832.683594 in 3.96s
Iter 94...	Training loss: 6747.310059 in 3.63s
Iter 95...	Training loss: 6312.980469 in 3.64s
Top-1 Recall: 0.311008 Precision: 0.311008 NDCG: 0.311008 HR: 0.311008
Top-5 Recall: 0.539788 Precision: 0.107958 NDCG: 0.429151 HR: 0.539788
Top-10 Recall: 0.656499 Precision: 0.065650 NDCG: 0.466896 HR: 0.656499
Eval costs: 1.802254 s
Iter 96...	Training loss: 6176.255371 in 3.58s
Iter 97...	Training loss: 5825.028320 in 3.54s
Iter 98...	Training loss: 5736.491699 in 3.62s
Iter 99...	Training loss: 5357.350586 in 3.76s
Iter 100...	Training loss: 5637.271484 in 3.72s
Top-1 Recall: 0.304377 Precision: 0.304377 NDCG: 0.304377 HR: 0.304377
Top-5 Recall: 0.535146 Precision: 0.107029 NDCG: 0.425818 HR: 0.535146
Top-10 Recall: 0.657825 Precision: 0.065782 NDCG: 0.465358 HR: 0.657825
Eval costs: 1.796330 s
############################################### 
n_negative=20  
batch_size=1024.00 
