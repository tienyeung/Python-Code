############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2000042.750000  in 2.49s 
Iter 2...	Training loss: 1840483.750000  in 2.43s 
Iter 3...	Training loss: 1777224.125000  in 2.42s 
Iter 4...	Training loss: 1729504.250000  in 2.42s 
Iter 5...	Training loss: 1685975.000000  in 2.42s 
Top-1 Recall: 0.018489 Precision: 0.018489 NDCG: 0.018489 HR: 0.018489
Top-5 Recall: 0.062863 Precision: 0.012573 NDCG: 0.039482 HR: 0.062863
Top-10 Recall: 0.092446 Precision: 0.009245 NDCG: 0.048963 HR: 0.092446
Eval costs: 0.171916 s
Iter 6...	Training loss: 1638738.125000  in 2.43s 
Iter 7...	Training loss: 1584545.375000  in 2.43s 
Iter 8...	Training loss: 1520065.500000  in 2.43s 
Iter 9...	Training loss: 1441698.375000  in 2.42s 
Iter 10...	Training loss: 1338573.375000  in 2.41s 
Top-1 Recall: 0.032224 Precision: 0.032224 NDCG: 0.032224 HR: 0.032224
Top-5 Recall: 0.091918 Precision: 0.018384 NDCG: 0.062937 HR: 0.091918
Top-10 Recall: 0.138933 Precision: 0.013893 NDCG: 0.077963 HR: 0.138933
Eval costs: 0.168755 s
Iter 11...	Training loss: 1223688.125000  in 2.41s 
Iter 12...	Training loss: 1110672.750000  in 2.46s 
Iter 13...	Training loss: 992728.937500  in 2.45s 
Iter 14...	Training loss: 877629.750000  in 2.44s 
Iter 15...	Training loss: 760683.687500  in 2.45s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.119387 Precision: 0.023877 NDCG: 0.080578 HR: 0.119387
Top-10 Recall: 0.171157 Precision: 0.017116 NDCG: 0.097132 HR: 0.171157
Eval costs: 0.186968 s
Iter 16...	Training loss: 661892.875000  in 2.44s 
Iter 17...	Training loss: 573165.687500  in 2.46s 
Iter 18...	Training loss: 496463.218750  in 2.45s 
Iter 19...	Training loss: 434027.218750  in 2.43s 
Iter 20...	Training loss: 380125.406250  in 2.45s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.138405 Precision: 0.027681 NDCG: 0.090343 HR: 0.138405
Top-10 Recall: 0.191759 Precision: 0.019176 NDCG: 0.107461 HR: 0.191759
Eval costs: 0.198015 s
Iter 21...	Training loss: 340207.750000  in 2.45s 
Iter 22...	Training loss: 303380.625000  in 2.43s 
Iter 23...	Training loss: 275996.906250  in 2.44s 
Iter 24...	Training loss: 247817.125000  in 2.45s 
Iter 25...	Training loss: 226912.859375  in 2.43s 
Top-1 Recall: 0.047015 Precision: 0.047015 NDCG: 0.047015 HR: 0.047015
Top-5 Recall: 0.152668 Precision: 0.030534 NDCG: 0.100331 HR: 0.152668
Top-10 Recall: 0.206550 Precision: 0.020655 NDCG: 0.117589 HR: 0.206550
Eval costs: 0.206714 s
Iter 26...	Training loss: 210101.531250  in 2.45s 
Iter 27...	Training loss: 192466.546875  in 2.44s 
Iter 28...	Training loss: 176697.187500  in 2.45s 
Iter 29...	Training loss: 166494.312500  in 2.47s 
Iter 30...	Training loss: 154895.593750  in 2.46s 
Top-1 Recall: 0.046487 Precision: 0.046487 NDCG: 0.046487 HR: 0.046487
Top-5 Recall: 0.156366 Precision: 0.031273 NDCG: 0.103331 HR: 0.156366
Top-10 Recall: 0.209192 Precision: 0.020919 NDCG: 0.120453 HR: 0.209192
Eval costs: 0.212181 s
Iter 31...	Training loss: 144359.531250  in 2.47s 
Iter 32...	Training loss: 136372.671875  in 2.47s 
Iter 33...	Training loss: 127957.921875  in 2.43s 
Iter 34...	Training loss: 123008.687500  in 2.46s 
Iter 35...	Training loss: 115293.843750  in 2.44s 
Top-1 Recall: 0.053354 Precision: 0.053354 NDCG: 0.053354 HR: 0.053354
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.110045 HR: 0.162705
Top-10 Recall: 0.216587 Precision: 0.021659 NDCG: 0.127548 HR: 0.216587
Eval costs: 0.215686 s
Iter 36...	Training loss: 109884.515625  in 2.46s 
Iter 37...	Training loss: 104242.835938  in 2.47s 
Iter 38...	Training loss: 100506.632812  in 2.42s 
Iter 39...	Training loss: 95269.359375  in 2.47s 
Iter 40...	Training loss: 91967.101562  in 2.42s 
Top-1 Recall: 0.059165 Precision: 0.059165 NDCG: 0.059165 HR: 0.059165
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.115277 HR: 0.169044
Top-10 Recall: 0.218700 Precision: 0.021870 NDCG: 0.131267 HR: 0.218700
Eval costs: 0.219520 s
Iter 41...	Training loss: 87250.382812  in 2.47s 
Iter 42...	Training loss: 83604.515625  in 2.46s 
Iter 43...	Training loss: 78896.296875  in 2.43s 
Iter 44...	Training loss: 78132.906250  in 2.46s 
Iter 45...	Training loss: 75169.500000  in 2.43s 
Top-1 Recall: 0.061807 Precision: 0.061807 NDCG: 0.061807 HR: 0.061807
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.116835 HR: 0.170100
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.132760 HR: 0.219229
Eval costs: 0.222231 s
Iter 46...	Training loss: 70931.273438  in 2.49s 
Iter 47...	Training loss: 68760.046875  in 2.46s 
Iter 48...	Training loss: 67571.671875  in 2.43s 
Iter 49...	Training loss: 63186.546875  in 2.47s 
Iter 50...	Training loss: 62591.187500  in 2.43s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.118866 HR: 0.170629
Top-10 Recall: 0.220285 Precision: 0.022029 NDCG: 0.134726 HR: 0.220285
Eval costs: 0.286806 s
Iter 51...	Training loss: 60971.738281  in 2.45s 
Iter 52...	Training loss: 58444.074219  in 2.47s 
Iter 53...	Training loss: 56653.917969  in 2.46s 
Iter 54...	Training loss: 55122.707031  in 2.48s 
Iter 55...	Training loss: 52986.167969  in 2.47s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.164289 Precision: 0.032858 NDCG: 0.118769 HR: 0.164289
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.137033 HR: 0.221342
Eval costs: 0.229728 s
Iter 56...	Training loss: 50853.882812  in 2.47s 
Iter 57...	Training loss: 49881.007812  in 2.47s 
Iter 58...	Training loss: 48228.859375  in 2.48s 
Iter 59...	Training loss: 47725.105469  in 2.48s 
Iter 60...	Training loss: 45342.070312  in 2.47s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.119479 HR: 0.165346
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.138147 HR: 0.223455
Eval costs: 0.229320 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 397920.000000 (191735.316079, 206184.699829) in 3.87s 
Iter 2...	Training loss: 205390.187500 (16034.157228, 189356.034302) in 3.84s 
Iter 3...	Training loss: 195323.250000 (12410.725393, 182912.533691) in 3.74s 
Iter 4...	Training loss: 188252.171875 (10430.526859, 177821.644287) in 3.86s 
Iter 5...	Training loss: 182259.515625 (8888.567969, 173370.920410) in 3.75s 
Top-1 Recall: 0.011094 Precision: 0.011094 NDCG: 0.011094 HR: 0.011094
Top-5 Recall: 0.061278 Precision: 0.012256 NDCG: 0.035661 HR: 0.061278
Top-10 Recall: 0.088748 Precision: 0.008875 NDCG: 0.044469 HR: 0.088748
Eval costs: 0.173784 s
Iter 6...	Training loss: 176197.156250 (7610.570436, 168586.582764) in 3.87s 
Iter 7...	Training loss: 169745.265625 (6608.008502, 163137.281860) in 3.78s 
Iter 8...	Training loss: 162497.593750 (5807.071149, 156690.495605) in 3.85s 
Iter 9...	Training loss: 153467.187500 (5132.562185, 148334.624023) in 3.78s 
Iter 10...	Training loss: 142942.656250 (4559.965233, 138382.697632) in 3.78s 
Top-1 Recall: 0.033809 Precision: 0.033809 NDCG: 0.033809 HR: 0.033809
Top-5 Recall: 0.094031 Precision: 0.018806 NDCG: 0.064429 HR: 0.094031
Top-10 Recall: 0.135235 Precision: 0.013524 NDCG: 0.077777 HR: 0.135235
Eval costs: 0.171719 s
Iter 11...	Training loss: 131110.500000 (4089.529133, 127020.979248) in 3.85s 
Iter 12...	Training loss: 119486.523438 (3723.784398, 115762.745850) in 3.77s 
Iter 13...	Training loss: 108246.421875 (3451.336012, 104795.075989) in 3.87s 
Iter 14...	Training loss: 96894.625000 (3269.505266, 93625.122009) in 3.78s 
Iter 15...	Training loss: 85865.890625 (3150.902157, 82714.989929) in 3.84s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.119387 Precision: 0.023877 NDCG: 0.081470 HR: 0.119387
Top-10 Recall: 0.170100 Precision: 0.017010 NDCG: 0.097698 HR: 0.170100
Eval costs: 0.189305 s
Iter 16...	Training loss: 75158.867188 (3087.099452, 72071.766052) in 3.78s 
Iter 17...	Training loss: 66636.390625 (3071.300376, 63565.090210) in 3.85s 
Iter 18...	Training loss: 59193.183594 (3093.895545, 56099.283325) in 3.78s 
Iter 19...	Training loss: 52747.183594 (3145.493275, 49601.689911) in 3.87s 
Iter 20...	Training loss: 47062.167969 (3217.089564, 43845.076752) in 3.79s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.133122 Precision: 0.026624 NDCG: 0.089252 HR: 0.133122
Top-10 Recall: 0.197570 Precision: 0.019757 NDCG: 0.109891 HR: 0.197570
Eval costs: 0.200615 s
Iter 21...	Training loss: 42962.238281 (3299.411879, 39662.831207) in 3.88s 
Iter 22...	Training loss: 39317.671875 (3394.587015, 35923.084869) in 3.78s 
Iter 23...	Training loss: 36068.644531 (3491.286884, 32577.355560) in 3.78s 
Iter 24...	Training loss: 33613.718750 (3589.829714, 30023.889282) in 3.85s 
Iter 25...	Training loss: 31219.406250 (3690.802163, 27528.602509) in 3.76s 
Top-1 Recall: 0.049128 Precision: 0.049128 NDCG: 0.049128 HR: 0.049128
Top-5 Recall: 0.147913 Precision: 0.029583 NDCG: 0.100480 HR: 0.147913
Top-10 Recall: 0.207079 Precision: 0.020708 NDCG: 0.119684 HR: 0.207079
Eval costs: 0.210297 s
Iter 26...	Training loss: 29349.287109 (3788.815985, 25560.468719) in 3.87s 
Iter 27...	Training loss: 27740.867188 (3885.356335, 23855.513794) in 3.79s 
Iter 28...	Training loss: 26265.289062 (3977.483045, 22287.807648) in 3.86s 
Iter 29...	Training loss: 24658.722656 (4071.229699, 20587.493637) in 3.77s 
Iter 30...	Training loss: 23633.419922 (4155.111353, 19478.306061) in 3.87s 
Top-1 Recall: 0.057052 Precision: 0.057052 NDCG: 0.057052 HR: 0.057052
Top-5 Recall: 0.159535 Precision: 0.031907 NDCG: 0.109924 HR: 0.159535
Top-10 Recall: 0.214474 Precision: 0.021447 NDCG: 0.127601 HR: 0.214474
Eval costs: 0.216692 s
Iter 31...	Training loss: 22473.541016 (4233.282994, 18240.259003) in 3.77s 
Iter 32...	Training loss: 21868.640625 (4319.894489, 17548.745499) in 3.86s 
Iter 33...	Training loss: 20893.792969 (4391.115040, 16502.676773) in 3.77s 
Iter 34...	Training loss: 19927.878906 (4463.500724, 15464.376152) in 3.79s 
Iter 35...	Training loss: 19467.810547 (4536.398882, 14931.411636) in 3.85s 
Top-1 Recall: 0.057581 Precision: 0.057581 NDCG: 0.057581 HR: 0.057581
Top-5 Recall: 0.160592 Precision: 0.032118 NDCG: 0.111618 HR: 0.160592
Top-10 Recall: 0.218172 Precision: 0.021817 NDCG: 0.130151 HR: 0.218172
Eval costs: 0.218819 s
Iter 36...	Training loss: 18905.664062 (4597.760941, 14307.901031) in 3.78s 
Iter 37...	Training loss: 18357.937500 (4664.262461, 13693.675034) in 3.87s 
Iter 38...	Training loss: 17940.005859 (4734.349758, 13205.656158) in 3.80s 
Iter 39...	Training loss: 17314.662109 (4791.532712, 12523.127815) in 3.86s 
Iter 40...	Training loss: 16802.486328 (4843.942567, 11958.544907) in 3.75s 
Top-1 Recall: 0.065504 Precision: 0.065504 NDCG: 0.065504 HR: 0.065504
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.120482 HR: 0.172742
Top-10 Recall: 0.217116 Precision: 0.021712 NDCG: 0.134834 HR: 0.217116
Eval costs: 0.223833 s
Iter 41...	Training loss: 16473.437500 (4899.680325, 11573.759193) in 3.85s 
Iter 42...	Training loss: 10906.095703 (0.000000, 10906.095299) in 2.65s 
Iter 43...	Training loss: 20227.841797 (9515.697483, 10712.143555) in 5.02s 
Iter 44...	Training loss: 15312.731445 (4793.968515, 10518.761703) in 3.77s 
Iter 45...	Training loss: 15102.722656 (5009.525583, 10093.197037) in 3.78s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.166403 Precision: 0.033281 NDCG: 0.119473 HR: 0.166403
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.138510 HR: 0.225040
Eval costs: 0.315380 s
Iter 46...	Training loss: 14707.916016 (5098.454682, 9609.461510) in 3.76s 
Iter 47...	Training loss: 14619.076172 (5161.847726, 9457.228264) in 3.76s 
Iter 48...	Training loss: 14263.517578 (5210.294516, 9053.222389) in 3.86s 
Iter 49...	Training loss: 14131.040039 (5263.909683, 8867.129181) in 3.75s 
Iter 50...	Training loss: 14101.132812 (5299.237447, 8801.896362) in 3.86s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.120146 HR: 0.170629
Top-10 Recall: 0.218172 Precision: 0.021817 NDCG: 0.135461 HR: 0.218172
Eval costs: 0.231252 s
Iter 51...	Training loss: 13766.776367 (5334.032855, 8432.743645) in 3.79s 
Iter 52...	Training loss: 7885.284180 (0.000000, 7885.283928) in 2.61s 
Iter 53...	Training loss: 18248.857422 (10406.304086, 7842.554077) in 5.01s 
Iter 54...	Training loss: 12988.623047 (5129.524685, 7859.097954) in 3.86s 
Iter 55...	Training loss: 13019.125000 (5360.582596, 7658.543266) in 3.75s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.121416 HR: 0.169044
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.139546 HR: 0.225040
Eval costs: 0.234175 s
Iter 56...	Training loss: 12809.974609 (5433.869793, 7376.103931) in 3.86s 
Iter 57...	Training loss: 12743.277344 (5499.884418, 7243.392746) in 3.79s 
Iter 58...	Training loss: 12631.477539 (5534.633446, 7096.844921) in 3.78s 
Iter 59...	Training loss: 12559.261719 (5575.384610, 6983.878441) in 3.89s 
Iter 60...	Training loss: 12372.620117 (5611.413650, 6761.206791) in 3.77s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.123113 HR: 0.173270
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.138802 HR: 0.221870
Eval costs: 0.234730 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 413121.437500 (192621.052819, 220500.398071) in 4.02s 
Iter 2...	Training loss: 215855.312500 (16080.399148, 199774.915894) in 3.78s 
Iter 3...	Training loss: 203268.531250 (12331.214800, 190937.302612) in 3.85s 
Iter 4...	Training loss: 194780.500000 (10259.700861, 184520.808716) in 3.76s 
Iter 5...	Training loss: 187231.078125 (8604.677457, 178626.401123) in 3.84s 
Top-1 Recall: 0.018489 Precision: 0.018489 NDCG: 0.018489 HR: 0.018489
Top-5 Recall: 0.073957 Precision: 0.014791 NDCG: 0.046956 HR: 0.073957
Top-10 Recall: 0.105652 Precision: 0.010565 NDCG: 0.057270 HR: 0.105652
Eval costs: 0.172931 s
Iter 6...	Training loss: 179359.937500 (7282.757012, 172077.205688) in 3.81s 
Iter 7...	Training loss: 170669.421875 (6212.073551, 164457.372070) in 3.82s 
Iter 8...	Training loss: 160242.359375 (5353.833158, 154888.523804) in 3.74s 
Iter 9...	Training loss: 148367.531250 (4670.152212, 143697.388916) in 3.84s 
Iter 10...	Training loss: 137237.093750 (4134.769355, 133102.328491) in 3.73s 
Top-1 Recall: 0.035394 Precision: 0.035394 NDCG: 0.035394 HR: 0.035394
Top-5 Recall: 0.101955 Precision: 0.020391 NDCG: 0.068479 HR: 0.101955
Top-10 Recall: 0.144744 Precision: 0.014474 NDCG: 0.082254 HR: 0.144744
Eval costs: 0.171796 s
Iter 11...	Training loss: 126757.593750 (3754.415994, 123003.183105) in 3.87s 
Iter 12...	Training loss: 115718.476562 (3477.682446, 112240.795471) in 3.81s 
Iter 13...	Training loss: 104886.218750 (3282.126875, 101604.093140) in 3.85s 
Iter 14...	Training loss: 94244.656250 (3151.752045, 91092.914978) in 3.76s 
Iter 15...	Training loss: 84158.812500 (3074.898909, 81083.923828) in 3.76s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.130481 Precision: 0.026096 NDCG: 0.090546 HR: 0.130481
Top-10 Recall: 0.188590 Precision: 0.018859 NDCG: 0.109225 HR: 0.188590
Eval costs: 0.277389 s
Iter 16...	Training loss: 74877.812500 (3047.434412, 71830.377808) in 3.81s 
Iter 17...	Training loss: 66309.460938 (3053.463654, 63255.999695) in 3.77s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2000683.375000  in 2.53s 
Iter 2...	Training loss: 1841607.625000  in 2.48s 
Iter 3...	Training loss: 1778878.875000  in 2.48s 
Iter 4...	Training loss: 1730295.875000  in 2.48s 
Iter 5...	Training loss: 1686152.125000  in 2.47s 
Top-1 Recall: 0.013735 Precision: 0.013735 NDCG: 0.013735 HR: 0.013735
Top-5 Recall: 0.062335 Precision: 0.012467 NDCG: 0.038186 HR: 0.062335
Top-10 Recall: 0.088220 Precision: 0.008822 NDCG: 0.046541 HR: 0.088220
Eval costs: 0.169886 s
Iter 6...	Training loss: 1639408.250000  in 2.49s 
Iter 7...	Training loss: 1586599.000000  in 2.47s 
Iter 8...	Training loss: 1522609.875000  in 2.49s 
Iter 9...	Training loss: 1441821.875000  in 2.48s 
Iter 10...	Training loss: 1340953.375000  in 2.49s 
Top-1 Recall: 0.029583 Precision: 0.029583 NDCG: 0.029583 HR: 0.029583
Top-5 Recall: 0.094031 Precision: 0.018806 NDCG: 0.062306 HR: 0.094031
Top-10 Recall: 0.135235 Precision: 0.013524 NDCG: 0.075444 HR: 0.135235
Eval costs: 0.168527 s
Iter 11...	Training loss: 1226537.125000  in 2.51s 
Iter 12...	Training loss: 1110160.250000  in 2.50s 
Iter 13...	Training loss: 995913.687500  in 2.50s 
Iter 14...	Training loss: 877951.625000  in 2.50s 
Iter 15...	Training loss: 763518.500000  in 2.50s 
Top-1 Recall: 0.043317 Precision: 0.043317 NDCG: 0.043317 HR: 0.043317
Top-5 Recall: 0.117274 Precision: 0.023455 NDCG: 0.080334 HR: 0.117274
Top-10 Recall: 0.167987 Precision: 0.016799 NDCG: 0.096497 HR: 0.167987
Eval costs: 0.187191 s
Iter 16...	Training loss: 663296.875000  in 2.50s 
Iter 17...	Training loss: 573117.750000  in 2.51s 
Iter 18...	Training loss: 494878.593750  in 2.50s 
Iter 19...	Training loss: 433334.781250  in 2.53s 
Iter 20...	Training loss: 383399.531250  in 2.50s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.132594 Precision: 0.026519 NDCG: 0.089521 HR: 0.132594
Top-10 Recall: 0.194400 Precision: 0.019440 NDCG: 0.109490 HR: 0.194400
Eval costs: 0.262631 s
Iter 21...	Training loss: 340782.656250  in 2.51s 
Iter 22...	Training loss: 302862.937500  in 2.50s 
Iter 23...	Training loss: 272985.718750  in 2.53s 
Iter 24...	Training loss: 248864.093750  in 2.53s 
Iter 25...	Training loss: 228000.890625  in 2.54s 
Top-1 Recall: 0.043317 Precision: 0.043317 NDCG: 0.043317 HR: 0.043317
Top-5 Recall: 0.141574 Precision: 0.028315 NDCG: 0.093615 HR: 0.141574
Top-10 Recall: 0.206022 Precision: 0.020602 NDCG: 0.114523 HR: 0.206022
Eval costs: 0.204932 s
Iter 26...	Training loss: 209632.437500  in 2.56s 
Iter 27...	Training loss: 193139.015625  in 2.52s 
Iter 28...	Training loss: 179024.437500  in 2.52s 
Iter 29...	Training loss: 165863.281250  in 2.52s 
Iter 30...	Training loss: 153917.437500  in 2.53s 
Top-1 Recall: 0.050713 Precision: 0.050713 NDCG: 0.050713 HR: 0.050713
Top-5 Recall: 0.155837 Precision: 0.031167 NDCG: 0.104882 HR: 0.155837
Top-10 Recall: 0.206550 Precision: 0.020655 NDCG: 0.121257 HR: 0.206550
Eval costs: 0.211653 s
Iter 31...	Training loss: 147383.343750  in 2.53s 
Iter 32...	Training loss: 136435.406250  in 2.52s 
Iter 33...	Training loss: 128045.406250  in 2.48s 
Iter 34...	Training loss: 122990.546875  in 2.53s 
Iter 35...	Training loss: 115066.632812  in 2.49s 
Top-1 Recall: 0.055468 Precision: 0.055468 NDCG: 0.055468 HR: 0.055468
Top-5 Recall: 0.157422 Precision: 0.031484 NDCG: 0.107826 HR: 0.157422
Top-10 Recall: 0.215531 Precision: 0.021553 NDCG: 0.126560 HR: 0.215531
Eval costs: 0.214857 s
Iter 36...	Training loss: 108505.390625  in 2.54s 
Iter 37...	Training loss: 103666.812500  in 2.53s 
Iter 38...	Training loss: 99344.726562  in 2.49s 
Iter 39...	Training loss: 94393.218750  in 2.54s 
Iter 40...	Training loss: 91672.562500  in 2.51s 
Top-1 Recall: 0.059165 Precision: 0.059165 NDCG: 0.059165 HR: 0.059165
Top-5 Recall: 0.161120 Precision: 0.032224 NDCG: 0.111708 HR: 0.161120
Top-10 Recall: 0.217116 Precision: 0.021712 NDCG: 0.129679 HR: 0.217116
Eval costs: 0.220742 s
Iter 41...	Training loss: 87915.101562  in 2.61s 
Iter 42...	Training loss: 82623.679688  in 2.57s 
Iter 43...	Training loss: 81175.609375  in 2.49s 
Iter 44...	Training loss: 76868.000000  in 2.54s 
Iter 45...	Training loss: 74603.343750  in 2.49s 
Top-1 Recall: 0.063920 Precision: 0.063920 NDCG: 0.063920 HR: 0.063920
Top-5 Recall: 0.158479 Precision: 0.031696 NDCG: 0.113380 HR: 0.158479
Top-10 Recall: 0.218700 Precision: 0.021870 NDCG: 0.132716 HR: 0.218700
Eval costs: 0.221900 s
Iter 46...	Training loss: 71370.476562  in 2.53s 
Iter 47...	Training loss: 68381.500000  in 2.54s 
Iter 48...	Training loss: 66939.062500  in 2.49s 
Iter 49...	Training loss: 65750.867188  in 2.53s 
Iter 50...	Training loss: 62253.656250  in 2.49s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.116642 HR: 0.163761
Top-10 Recall: 0.218172 Precision: 0.021817 NDCG: 0.134113 HR: 0.218172
Eval costs: 0.224042 s
Iter 51...	Training loss: 59508.242188  in 2.53s 
Iter 52...	Training loss: 57870.167969  in 2.57s 
Iter 53...	Training loss: 56346.332031  in 2.49s 
Iter 54...	Training loss: 54834.378906  in 2.55s 
Iter 55...	Training loss: 52590.039062  in 2.49s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.159535 Precision: 0.031907 NDCG: 0.115424 HR: 0.159535
Top-10 Recall: 0.215003 Precision: 0.021500 NDCG: 0.133255 HR: 0.215003
Eval costs: 0.227467 s
Iter 56...	Training loss: 51900.226562  in 2.53s 
Iter 57...	Training loss: 50194.054688  in 2.54s 
Iter 58...	Training loss: 49241.515625  in 2.49s 
Iter 59...	Training loss: 48366.339844  in 2.53s 
Iter 60...	Training loss: 46135.886719  in 2.52s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.159535 Precision: 0.031907 NDCG: 0.116398 HR: 0.159535
Top-10 Recall: 0.215003 Precision: 0.021500 NDCG: 0.134204 HR: 0.215003
Eval costs: 0.230509 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 399245.187500 (193024.002201, 206221.201538) in 4.02s 
Iter 2...	Training loss: 205464.796875 (16064.738408, 189400.068726) in 3.80s 
Iter 3...	Training loss: 195260.109375 (12417.998558, 182842.137329) in 3.81s 
Iter 4...	Training loss: 188334.500000 (10464.014145, 177870.473877) in 3.89s 
Iter 5...	Training loss: 182236.312500 (8903.182345, 173333.116821) in 3.81s 
Top-1 Recall: 0.013207 Precision: 0.013207 NDCG: 0.013207 HR: 0.013207
Top-5 Recall: 0.063920 Precision: 0.012784 NDCG: 0.038477 HR: 0.063920
Top-10 Recall: 0.088220 Precision: 0.008822 NDCG: 0.046292 HR: 0.088220
Eval costs: 0.172618 s
Iter 6...	Training loss: 176197.140625 (7644.180374, 168552.969482) in 3.91s 
Iter 7...	Training loss: 169553.984375 (6617.620754, 162936.350098) in 3.81s 
Iter 8...	Training loss: 162455.125000 (5790.754045, 156664.368408) in 3.90s 
Iter 9...	Training loss: 153357.046875 (5108.820462, 148248.231812) in 3.81s 
Iter 10...	Training loss: 142744.718750 (4541.134981, 138203.584717) in 3.90s 
Top-1 Recall: 0.028526 Precision: 0.028526 NDCG: 0.028526 HR: 0.028526
Top-5 Recall: 0.094559 Precision: 0.018912 NDCG: 0.061855 HR: 0.094559
Top-10 Recall: 0.133650 Precision: 0.013365 NDCG: 0.074307 HR: 0.133650
Eval costs: 0.170153 s
Iter 11...	Training loss: 131074.000000 (4085.342402, 126988.657593) in 3.83s 
Iter 12...	Training loss: 119507.898438 (3719.535249, 115788.358337) in 3.91s 
Iter 13...	Training loss: 108223.820312 (3455.705944, 104768.104065) in 3.86s 
Iter 14...	Training loss: 96566.570312 (3264.297873, 93302.278564) in 3.89s 
Iter 15...	Training loss: 85522.093750 (3149.191154, 82372.910889) in 3.80s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.114633 Precision: 0.022927 NDCG: 0.078937 HR: 0.114633
Top-10 Recall: 0.166931 Precision: 0.016693 NDCG: 0.095978 HR: 0.166931
Eval costs: 0.190109 s
Iter 16...	Training loss: 75571.765625 (3088.116636, 72483.636108) in 3.89s 
Iter 17...	Training loss: 66628.945312 (3075.769538, 63553.179993) in 3.81s 
Iter 18...	Training loss: 59429.609375 (3099.682197, 56329.929779) in 3.80s 
Iter 19...	Training loss: 52750.511719 (3148.068892, 49602.447357) in 3.93s 
Iter 20...	Training loss: 47510.031250 (3221.361809, 44288.664124) in 3.83s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.094126 HR: 0.136820
Top-10 Recall: 0.195985 Precision: 0.019599 NDCG: 0.112934 HR: 0.195985
Eval costs: 0.202024 s
Iter 21...	Training loss: 43370.882812 (3305.523976, 40065.361816) in 3.93s 
Iter 22...	Training loss: 39576.542969 (3395.141137, 36181.400299) in 3.81s 
Iter 23...	Training loss: 36171.664062 (3495.099256, 32676.564087) in 3.90s 
Iter 24...	Training loss: 33887.835938 (3598.987877, 30288.848663) in 3.81s 
Iter 25...	Training loss: 31519.259766 (3697.757120, 27821.504028) in 3.89s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.147913 Precision: 0.029583 NDCG: 0.100035 HR: 0.147913
Top-10 Recall: 0.204437 Precision: 0.020444 NDCG: 0.118476 HR: 0.204437
Eval costs: 0.209923 s
Iter 26...	Training loss: 29302.498047 (3796.770135, 25505.730469) in 3.84s 
Iter 27...	Training loss: 27960.535156 (3892.756181, 24067.778427) in 3.91s 
Iter 28...	Training loss: 26361.505859 (3989.976167, 22371.530777) in 3.82s 
Iter 29...	Training loss: 25019.652344 (4077.252718, 20942.403732) in 3.85s 
Iter 30...	Training loss: 23634.667969 (4160.077880, 19474.587967) in 3.91s 
Top-1 Recall: 0.054411 Precision: 0.054411 NDCG: 0.054411 HR: 0.054411
Top-5 Recall: 0.160063 Precision: 0.032013 NDCG: 0.108390 HR: 0.160063
Top-10 Recall: 0.210777 Precision: 0.021078 NDCG: 0.124740 HR: 0.210777
Eval costs: 0.214738 s
Iter 31...	Training loss: 22831.859375 (4245.662100, 18586.198090) in 3.84s 
Iter 32...	Training loss: 21831.265625 (4320.672900, 17510.593246) in 3.90s 
Iter 33...	Training loss: 21033.951172 (4400.877643, 16633.073563) in 3.81s 
Iter 34...	Training loss: 20014.863281 (4475.536697, 15539.328369) in 3.91s 
Iter 35...	Training loss: 19437.933594 (4551.041256, 14886.892403) in 3.84s 
Top-1 Recall: 0.061278 Precision: 0.061278 NDCG: 0.061278 HR: 0.061278
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.115640 HR: 0.167459
Top-10 Recall: 0.214474 Precision: 0.021447 NDCG: 0.130670 HR: 0.214474
Eval costs: 0.218137 s
Iter 36...	Training loss: 19067.925781 (4615.320114, 14452.605515) in 3.91s 
Iter 37...	Training loss: 18365.513672 (4677.737130, 13687.776764) in 3.82s 
Iter 38...	Training loss: 17942.761719 (4738.426909, 13204.335663) in 3.90s 
Iter 39...	Training loss: 17237.800781 (4800.028759, 12437.772476) in 3.84s 
Iter 40...	Training loss: 16841.896484 (4852.384055, 11989.513016) in 3.82s 
Top-1 Recall: 0.065504 Precision: 0.065504 NDCG: 0.065504 HR: 0.065504
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.117475 HR: 0.167459
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.135928 HR: 0.225568
Eval costs: 0.309072 s
Iter 41...	Training loss: 16653.533203 (4910.574042, 11742.958260) in 3.83s 
Iter 42...	Training loss: 16245.150391 (4953.050070, 11292.100349) in 3.81s 
Iter 43...	Training loss: 15949.207031 (5003.469089, 10945.738525) in 3.91s 
Iter 44...	Training loss: 15354.544922 (5047.706785, 10306.837837) in 3.83s 
Iter 45...	Training loss: 15127.167969 (5094.744044, 10032.424057) in 3.92s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.118525 HR: 0.164818
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.137022 HR: 0.222398
Eval costs: 0.226082 s
Iter 46...	Training loss: 14948.388672 (5139.263902, 9809.124565) in 3.82s 
Iter 47...	Training loss: 14575.089844 (5181.190950, 9393.898994) in 3.92s 
Iter 48...	Training loss: 14616.482422 (5225.604084, 9390.877251) in 3.83s 
Iter 49...	Training loss: 13981.548828 (5258.640247, 8722.907906) in 3.92s 
Iter 50...	Training loss: 13995.848633 (5298.936550, 8696.913223) in 3.87s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.119107 HR: 0.165346
Top-10 Recall: 0.220814 Precision: 0.022081 NDCG: 0.137083 HR: 0.220814
Eval costs: 0.228803 s
Iter 51...	Training loss: 13914.867188 (5336.418636, 8578.450127) in 3.96s 
Iter 52...	Training loss: 13556.876953 (5370.538482, 8186.337112) in 3.86s 
Iter 53...	Training loss: 13537.265625 (5396.307056, 8140.958458) in 3.84s 
Iter 54...	Training loss: 13093.210938 (5433.069168, 7660.140831) in 3.92s 
Iter 55...	Training loss: 13135.533203 (5460.063195, 7675.469162) in 3.81s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.166403 Precision: 0.033281 NDCG: 0.118903 HR: 0.166403
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.136818 HR: 0.221342
Eval costs: 0.233784 s
Iter 56...	Training loss: 12899.966797 (5493.884387, 7406.081600) in 3.99s 
Iter 57...	Training loss: 12686.424805 (5519.738028, 7166.686047) in 3.80s 
Iter 58...	Training loss: 12756.611328 (5552.395712, 7204.216080) in 3.91s 
Iter 59...	Training loss: 12457.312500 (5573.512778, 6883.798897) in 3.80s 
Iter 60...	Training loss: 12317.057617 (5600.289368, 6716.768238) in 3.90s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.119989 HR: 0.169044
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.136267 HR: 0.219757
Eval costs: 0.233431 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 413441.812500 (192990.631814, 220451.166870) in 3.92s 
Iter 2...	Training loss: 215767.750000 (16104.297815, 199663.453857) in 3.79s 
Iter 3...	Training loss: 203312.406250 (12330.783863, 190981.633789) in 3.89s 
Iter 4...	Training loss: 194794.281250 (10289.639747, 184504.644165) in 3.79s 
Iter 5...	Training loss: 187355.843750 (8616.414036, 178739.432251) in 3.95s 
Top-1 Recall: 0.015320 Precision: 0.015320 NDCG: 0.015320 HR: 0.015320
Top-5 Recall: 0.073957 Precision: 0.014791 NDCG: 0.045348 HR: 0.073957
Top-10 Recall: 0.106709 Precision: 0.010671 NDCG: 0.055829 HR: 0.106709
Eval costs: 0.175963 s
Iter 6...	Training loss: 179427.250000 (7293.138372, 172134.081177) in 3.80s 
Iter 7...	Training loss: 170821.781250 (6222.934722, 164598.835083) in 4.02s 
Iter 8...	Training loss: 160277.625000 (5359.682699, 154917.928345) in 3.83s 
Iter 9...	Training loss: 148574.187500 (4671.316442, 143902.862061) in 3.91s 
Iter 10...	Training loss: 137387.640625 (4140.774127, 133246.865479) in 3.83s 
Top-1 Recall: 0.038563 Precision: 0.038563 NDCG: 0.038563 HR: 0.038563
Top-5 Recall: 0.103539 Precision: 0.020708 NDCG: 0.072333 HR: 0.103539
Top-10 Recall: 0.144216 Precision: 0.014422 NDCG: 0.085284 HR: 0.144216
Eval costs: 0.171696 s
Iter 11...	Training loss: 126610.828125 (3758.660155, 122852.160645) in 3.92s 
Iter 12...	Training loss: 115698.523438 (3481.301369, 112217.230591) in 3.82s 
Iter 13...	Training loss: 104932.375000 (3283.389980, 101648.976379) in 3.92s 
Iter 14...	Training loss: 94362.109375 (3153.006514, 91209.088135) in 3.82s 
Iter 15...	Training loss: 83941.515625 (3075.720492, 80865.795837) in 3.82s 
Top-1 Recall: 0.047544 Precision: 0.047544 NDCG: 0.047544 HR: 0.047544
Top-5 Recall: 0.133122 Precision: 0.026624 NDCG: 0.091471 HR: 0.133122
Top-10 Recall: 0.183307 Precision: 0.018331 NDCG: 0.107662 HR: 0.183307
Eval costs: 0.279796 s
Iter 16...	Training loss: 74585.781250 (3045.219934, 71540.567261) in 3.80s 
Iter 17...	Training loss: 66268.000000 (3053.450297, 63214.552368) in 3.90s 
Iter 18...	Training loss: 58878.171875 (3089.573357, 55788.604553) in 3.81s 
Iter 19...	Training loss: 52708.015625 (3150.910052, 49557.100342) in 3.86s 
Iter 20...	Training loss: 47516.164062 (3231.723604, 44284.444611) in 3.93s 
Top-1 Recall: 0.056524 Precision: 0.056524 NDCG: 0.056524 HR: 0.056524
Top-5 Recall: 0.148970 Precision: 0.029794 NDCG: 0.104108 HR: 0.148970
Top-10 Recall: 0.195985 Precision: 0.019599 NDCG: 0.119319 HR: 0.195985
Eval costs: 0.200462 s
Iter 21...	Training loss: 43164.500000 (3324.763303, 39839.738861) in 3.82s 
Iter 22...	Training loss: 39345.156250 (3420.404554, 35924.755280) in 3.89s 
Iter 23...	Training loss: 36433.914062 (3521.496241, 32912.420288) in 3.83s 
Iter 24...	Training loss: 33892.171875 (3620.216994, 30271.955994) in 3.90s 
Iter 25...	Training loss: 31585.501953 (3715.499794, 27870.001511) in 3.83s 
Top-1 Recall: 0.064448 Precision: 0.064448 NDCG: 0.064448 HR: 0.064448
Top-5 Recall: 0.157950 Precision: 0.031590 NDCG: 0.112804 HR: 0.157950
Top-10 Recall: 0.212890 Precision: 0.021289 NDCG: 0.130647 HR: 0.212890
Eval costs: 0.209363 s
Iter 26...	Training loss: 29560.990234 (3806.347278, 25754.645874) in 3.89s 
Iter 27...	Training loss: 28043.236328 (3890.666037, 24152.572495) in 3.81s 
Iter 28...	Training loss: 26543.966797 (3973.122592, 22570.844711) in 3.89s 
Iter 29...	Training loss: 25314.207031 (4051.543333, 21262.663086) in 3.82s 
Iter 30...	Training loss: 24471.355469 (4116.931652, 20354.424606) in 3.80s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.118631 HR: 0.165874
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.137246 HR: 0.222927
Eval costs: 0.214387 s
Iter 31...	Training loss: 23553.693359 (4176.922851, 19376.769241) in 3.92s 
Iter 32...	Training loss: 22431.744141 (4235.914607, 18195.832199) in 3.83s 
Iter 33...	Training loss: 21647.519531 (4295.503053, 17352.015198) in 3.89s 
Iter 34...	Training loss: 21051.712891 (4335.317409, 16716.394699) in 3.81s 
Iter 35...	Training loss: 20393.693359 (4380.628739, 16013.065125) in 3.91s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.124253 HR: 0.174326
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.140360 HR: 0.224511
Eval costs: 0.222969 s
Iter 36...	Training loss: 19601.064453 (4417.089892, 15183.975006) in 3.82s 
Iter 37...	Training loss: 19367.710938 (4452.119302, 14915.592804) in 3.90s 
Iter 38...	Training loss: 18649.376953 (4478.619963, 14170.756783) in 3.82s 
Iter 39...	Training loss: 18110.609375 (4506.760052, 13603.850426) in 3.91s 
Iter 40...	Training loss: 17805.937500 (4546.573926, 13259.362961) in 3.81s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.124682 HR: 0.171685
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.141106 HR: 0.222398
Eval costs: 0.223118 s
Iter 41...	Training loss: 17497.128906 (4567.469203, 12929.660698) in 3.91s 
Iter 42...	Training loss: 16991.671875 (4582.176475, 12409.496429) in 3.80s 
Iter 43...	Training loss: 16807.601562 (4601.457311, 12206.143211) in 3.82s 
Iter 44...	Training loss: 16535.128906 (4621.452047, 11913.677414) in 3.90s 
Iter 45...	Training loss: 16205.315430 (4627.686837, 11577.628540) in 3.84s 
Top-1 Recall: 0.076070 Precision: 0.076070 NDCG: 0.076070 HR: 0.076070
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.126711 HR: 0.174855
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.144332 HR: 0.229794
Eval costs: 0.228007 s
Iter 46...	Training loss: 15944.392578 (4639.814239, 11304.578285) in 3.90s 
Iter 47...	Training loss: 15610.915039 (4652.969881, 10957.946144) in 3.81s 
Iter 48...	Training loss: 15394.145508 (4659.316223, 10734.829590) in 3.91s 
Iter 49...	Training loss: 14837.718750 (4667.148114, 10170.569344) in 3.83s 
Iter 50...	Training loss: 14988.664062 (4673.865068, 10314.799866) in 3.89s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.128831 HR: 0.176440
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.146731 HR: 0.232435
Eval costs: 0.232363 s
Iter 51...	Training loss: 14617.507812 (4685.169675, 9932.339172) in 3.82s 
Iter 52...	Training loss: 14439.678711 (4683.877577, 9755.799423) in 3.91s 
Iter 53...	Training loss: 14146.310547 (4687.273115, 9459.037247) in 3.80s 
Iter 54...	Training loss: 14036.433594 (4689.096544, 9347.337410) in 3.81s 
Iter 55...	Training loss: 13985.554688 (4692.085596, 9293.469231) in 3.91s 
Top-1 Recall: 0.077655 Precision: 0.077655 NDCG: 0.077655 HR: 0.077655
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.126305 HR: 0.172213
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.142951 HR: 0.223455
Eval costs: 0.234339 s
Iter 56...	Training loss: 13633.591797 (4692.617385, 8940.973541) in 3.86s 
Iter 57...	Training loss: 13666.627930 (4688.260726, 8978.367592) in 3.91s 
Iter 58...	Training loss: 13318.941406 (4688.550489, 8630.392418) in 3.81s 
Iter 59...	Training loss: 13109.544922 (4687.978213, 8421.567070) in 3.89s 
Iter 60...	Training loss: 12928.356445 (4682.842571, 8245.513130) in 3.83s 
Top-1 Recall: 0.081881 Precision: 0.081881 NDCG: 0.081881 HR: 0.081881
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.128029 HR: 0.173270
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.143997 HR: 0.222398
Eval costs: 0.238322 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 537969.000000 (192019.193498, 345949.835449) in 4.05s 
Iter 2...	Training loss: 282403.437500 (15741.613955, 266661.824951) in 3.82s 
Iter 3...	Training loss: 239259.515625 (11569.669777, 227689.851074) in 3.94s 
Iter 4...	Training loss: 210236.218750 (9129.995674, 201106.234741) in 3.80s 
Iter 5...	Training loss: 185707.296875 (7243.977216, 178463.315552) in 3.89s 
Top-1 Recall: 0.034337 Precision: 0.034337 NDCG: 0.034337 HR: 0.034337
Top-5 Recall: 0.100370 Precision: 0.020074 NDCG: 0.067737 HR: 0.100370
Top-10 Recall: 0.132594 Precision: 0.013259 NDCG: 0.078020 HR: 0.132594
Eval costs: 0.175090 s
Iter 6...	Training loss: 153639.468750 (0.000000, 153639.464478) in 2.65s 
Iter 7...	Training loss: 159747.218750 (10265.336098, 149481.863892) in 5.05s 
Iter 8...	Training loss: 140821.750000 (4251.806313, 136569.960205) in 3.80s 
Iter 9...	Training loss: 130249.648438 (3767.649335, 126482.003052) in 3.91s 
Iter 10...	Training loss: 120842.421875 (3410.088584, 117432.329102) in 3.81s 
Top-1 Recall: 0.047544 Precision: 0.047544 NDCG: 0.047544 HR: 0.047544
Top-5 Recall: 0.131537 Precision: 0.026307 NDCG: 0.090292 HR: 0.131537
Top-10 Recall: 0.177496 Precision: 0.017750 NDCG: 0.105073 HR: 0.177496
Eval costs: 0.175604 s
Iter 11...	Training loss: 112199.992188 (3156.003910, 109043.986877) in 3.80s 
Iter 12...	Training loss: 104179.890625 (2976.363967, 101203.517151) in 3.88s 
Iter 13...	Training loss: 96712.695312 (2847.491709, 93865.201233) in 3.81s 
Iter 14...	Training loss: 89153.085938 (2755.547339, 86397.554382) in 3.89s 
Iter 15...	Training loss: 81765.882812 (2694.308347, 79071.587830) in 3.84s 
Top-1 Recall: 0.062335 Precision: 0.062335 NDCG: 0.062335 HR: 0.062335
Top-5 Recall: 0.154253 Precision: 0.030851 NDCG: 0.108356 HR: 0.154253
Top-10 Recall: 0.211305 Precision: 0.021130 NDCG: 0.126746 HR: 0.211305
Eval costs: 0.187355 s
Iter 16...	Training loss: 74661.593750 (2656.042477, 72005.557739) in 3.88s 
Iter 17...	Training loss: 67886.843750 (2638.072378, 65248.768677) in 3.81s 
Iter 18...	Training loss: 61370.414062 (2634.962522, 58735.447021) in 3.88s 
Iter 19...	Training loss: 55906.351562 (2647.779731, 53258.572510) in 3.80s 
Iter 20...	Training loss: 50997.828125 (2664.835298, 48332.987061) in 3.90s 
Top-1 Recall: 0.065504 Precision: 0.065504 NDCG: 0.065504 HR: 0.065504
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.116246 HR: 0.165346
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.133800 HR: 0.219757
Eval costs: 0.199033 s
Iter 21...	Training loss: 46868.210938 (2685.508487, 44182.699677) in 3.83s 
Iter 22...	Training loss: 43145.519531 (2713.007905, 40432.513153) in 3.92s 
Iter 23...	Training loss: 40362.855469 (2733.879878, 37628.973785) in 3.81s 
Iter 24...	Training loss: 37332.113281 (2756.736844, 34575.380219) in 3.80s 
Iter 25...	Training loss: 35330.253906 (2773.149975, 32557.106598) in 3.90s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.123954 HR: 0.172742
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.140873 HR: 0.225568
Eval costs: 0.208840 s
Iter 26...	Training loss: 32812.820312 (2785.371229, 30027.451599) in 3.80s 
Iter 27...	Training loss: 31358.916016 (2791.248758, 28567.665802) in 3.89s 
Iter 28...	Training loss: 29586.759766 (2798.878844, 26787.881958) in 3.80s 
Iter 29...	Training loss: 28336.642578 (2799.903157, 25536.741104) in 3.92s 
Iter 30...	Training loss: 27175.019531 (2798.525470, 24376.494476) in 3.80s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.128094 HR: 0.177496
Top-10 Recall: 0.236133 Precision: 0.023613 NDCG: 0.146860 HR: 0.236133
Eval costs: 0.215860 s
Iter 31...	Training loss: 25813.460938 (2793.514831, 23019.947235) in 3.92s 
Iter 32...	Training loss: 24889.503906 (2784.322073, 22105.180832) in 3.82s 
Iter 33...	Training loss: 23790.246094 (2779.851378, 21010.395920) in 3.91s 
Iter 34...	Training loss: 22832.988281 (2770.383106, 20062.604599) in 3.82s 
Iter 35...	Training loss: 22277.820312 (2762.260044, 19515.561462) in 3.81s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.127245 HR: 0.173270
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.146809 HR: 0.234020
Eval costs: 0.308578 s
Iter 36...	Training loss: 21449.580078 (2754.114207, 18695.467880) in 3.80s 
Iter 37...	Training loss: 20858.251953 (2742.517214, 18115.734955) in 3.81s 
Iter 38...	Training loss: 20349.031250 (2727.981377, 17621.051636) in 3.90s 
Iter 39...	Training loss: 19778.496094 (2718.225289, 17060.270279) in 3.80s 
Iter 40...	Training loss: 19338.298828 (2707.023977, 16631.275406) in 3.88s 
Top-1 Recall: 0.078183 Precision: 0.078183 NDCG: 0.078183 HR: 0.078183
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.127907 HR: 0.173798
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.146651 HR: 0.231907
Eval costs: 0.226983 s
Iter 41...	Training loss: 18470.160156 (2693.938049, 15776.222534) in 3.80s 
Iter 42...	Training loss: 18139.914062 (2681.881619, 15458.033691) in 3.89s 
Iter 43...	Training loss: 17757.222656 (2668.142369, 15089.081467) in 3.81s 
Iter 44...	Training loss: 17209.574219 (2656.014516, 14553.559227) in 3.89s 
Iter 45...	Training loss: 16684.429688 (2641.489537, 14042.940254) in 3.81s 
Top-1 Recall: 0.075541 Precision: 0.075541 NDCG: 0.075541 HR: 0.075541
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.127391 HR: 0.174326
Top-10 Recall: 0.227681 Precision: 0.022768 NDCG: 0.144646 HR: 0.227681
Eval costs: 0.230000 s
Iter 46...	Training loss: 16511.957031 (2633.064141, 13878.893890) in 3.90s 
Iter 47...	Training loss: 15992.502930 (2620.052783, 13372.449036) in 3.80s 
Iter 48...	Training loss: 15704.002930 (2606.244331, 13097.759193) in 3.81s 
Iter 49...	Training loss: 15331.814453 (2596.287539, 12735.525047) in 3.90s 
Iter 50...	Training loss: 14982.429688 (2583.400142, 12399.029610) in 3.80s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.126164 HR: 0.170629
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.146427 HR: 0.234020
Eval costs: 0.233400 s
Iter 51...	Training loss: 14525.216797 (2572.716370, 11952.501122) in 3.88s 
Iter 52...	Training loss: 14475.634766 (2560.312383, 11915.322029) in 3.81s 
Iter 53...	Training loss: 14122.255859 (2547.936125, 11574.318886) in 3.89s 
Iter 54...	Training loss: 13765.064453 (2536.861858, 11228.202576) in 3.81s 
Iter 55...	Training loss: 13591.945312 (2527.304463, 11064.642738) in 3.89s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.122189 HR: 0.164818
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.142114 HR: 0.226096
Eval costs: 0.236724 s
Iter 56...	Training loss: 13371.033203 (2519.493830, 10851.541145) in 3.80s 
Iter 57...	Training loss: 13172.462891 (2507.164992, 10665.297173) in 3.89s 
Iter 58...	Training loss: 12845.775391 (2499.106174, 10346.668610) in 3.80s 
Iter 59...	Training loss: 12778.608398 (2485.310187, 10293.298363) in 3.79s 
Iter 60...	Training loss: 12538.829102 (2473.651909, 10065.175270) in 3.88s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.123683 HR: 0.169572
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.141032 HR: 0.223455
Eval costs: 0.237132 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1766959.500000 (192588.653415, 1574370.938477) in 3.93s 
Iter 2...	Training loss: 918352.500000 (15494.267015, 902858.257324) in 3.88s 
Iter 3...	Training loss: 584350.812500 (10808.192568, 573542.661865) in 3.80s 
Iter 4...	Training loss: 399068.937500 (8181.815555, 390887.111328) in 3.90s 
Iter 5...	Training loss: 288821.937500 (6325.061953, 282496.906372) in 3.80s 
Top-1 Recall: 0.038035 Precision: 0.038035 NDCG: 0.038035 HR: 0.038035
Top-5 Recall: 0.103011 Precision: 0.020602 NDCG: 0.072146 HR: 0.103011
Top-10 Recall: 0.146857 Precision: 0.014686 NDCG: 0.086267 HR: 0.146857
Eval costs: 0.175755 s
Iter 6...	Training loss: 221527.546875 (5064.148558, 216463.389038) in 3.90s 
Iter 7...	Training loss: 180604.171875 (4201.666284, 176402.500854) in 3.80s 
Iter 8...	Training loss: 155746.296875 (3594.657925, 152151.632324) in 3.91s 
Iter 9...	Training loss: 138947.031250 (3164.422878, 135782.591797) in 3.81s 
Iter 10...	Training loss: 127271.335938 (2846.647250, 124424.682983) in 3.89s 
Top-1 Recall: 0.059165 Precision: 0.059165 NDCG: 0.059165 HR: 0.059165
Top-5 Recall: 0.138405 Precision: 0.027681 NDCG: 0.099338 HR: 0.138405
Top-10 Recall: 0.193872 Precision: 0.019387 NDCG: 0.117137 HR: 0.193872
Eval costs: 0.176430 s
Iter 11...	Training loss: 117845.921875 (2605.945506, 115239.981567) in 3.81s 
Iter 12...	Training loss: 110544.140625 (2414.151150, 108129.990173) in 3.89s 
Iter 13...	Training loss: 103471.835938 (2259.825789, 101212.009094) in 3.80s 
Iter 14...	Training loss: 97118.531250 (2131.576171, 94986.962952) in 3.92s 
Iter 15...	Training loss: 90954.945312 (2024.537809, 88930.410278) in 3.81s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.116112 HR: 0.164818
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.134419 HR: 0.221870
Eval costs: 0.186741 s
Iter 16...	Training loss: 85320.507812 (1935.394156, 83385.122131) in 3.88s 
Iter 17...	Training loss: 79548.953125 (1859.675253, 77689.272888) in 3.79s 
Iter 18...	Training loss: 74654.781250 (1795.070146, 72859.710938) in 3.79s 
Iter 19...	Training loss: 69506.812500 (1742.271538, 67764.543335) in 3.88s 
Iter 20...	Training loss: 64839.265625 (1697.538189, 63141.722595) in 3.80s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.121654 HR: 0.170100
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.142216 HR: 0.234020
Eval costs: 0.197760 s
Iter 21...	Training loss: 60780.261719 (1660.369445, 59119.893616) in 3.90s 
Iter 22...	Training loss: 56530.886719 (1629.160607, 54901.729340) in 3.80s 
Iter 23...	Training loss: 52864.035156 (1602.465874, 51261.578979) in 3.91s 
Iter 24...	Training loss: 49448.507812 (1580.930552, 47867.578094) in 3.81s 
Iter 25...	Training loss: 46253.328125 (1561.210396, 44692.122925) in 3.91s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.125766 HR: 0.177496
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.145248 HR: 0.237718
Eval costs: 0.207946 s
Iter 26...	Training loss: 43602.062500 (1544.290003, 42057.776825) in 3.81s 
Iter 27...	Training loss: 41328.871094 (1529.534252, 39799.337952) in 3.89s 
Iter 28...	Training loss: 39290.308594 (1515.053705, 37775.253021) in 3.80s 
Iter 29...	Training loss: 37185.003906 (1501.469493, 35683.537048) in 3.80s 
Iter 30...	Training loss: 35359.984375 (1489.758619, 33870.223724) in 3.90s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.181722 Precision: 0.036344 NDCG: 0.127974 HR: 0.181722
Top-10 Recall: 0.243001 Precision: 0.024300 NDCG: 0.147717 HR: 0.243001
Eval costs: 0.215979 s
Iter 31...	Training loss: 33721.781250 (1478.135939, 32243.644562) in 3.81s 
Iter 32...	Training loss: 32108.982422 (1468.315121, 30640.665131) in 3.88s 
Iter 33...	Training loss: 31072.111328 (1456.779546, 29615.333618) in 3.80s 
Iter 34...	Training loss: 29567.148438 (1447.634995, 28119.514282) in 3.89s 
Iter 35...	Training loss: 28568.953125 (1437.566223, 27131.386200) in 3.80s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.127314 HR: 0.176968
Top-10 Recall: 0.241944 Precision: 0.024194 NDCG: 0.148219 HR: 0.241944
Eval costs: 0.220705 s
Iter 36...	Training loss: 27613.544922 (1429.596197, 26183.948700) in 3.88s 
Iter 37...	Training loss: 26691.318359 (1421.676114, 25269.639038) in 3.82s 
Iter 38...	Training loss: 25633.312500 (1414.108192, 24219.204559) in 3.88s 
Iter 39...	Training loss: 24966.919922 (1406.434658, 23560.485062) in 3.82s 
Iter 40...	Training loss: 24104.574219 (1399.765383, 22704.810303) in 3.81s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.125278 HR: 0.176440
Top-10 Recall: 0.240359 Precision: 0.024036 NDCG: 0.146110 HR: 0.240359
Eval costs: 0.315011 s
Iter 41...	Training loss: 23333.853516 (1393.677626, 21940.176071) in 3.80s 
Iter 42...	Training loss: 22651.683594 (1387.466415, 21264.218002) in 3.88s 
Iter 43...	Training loss: 22032.410156 (1381.381606, 20651.029037) in 3.78s 
Iter 44...	Training loss: 21469.859375 (1376.481266, 20093.378143) in 3.80s 
Iter 45...	Training loss: 20803.101562 (1370.365506, 19432.734436) in 3.89s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.171685 Precision: 0.034337 NDCG: 0.121710 HR: 0.171685
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.142309 HR: 0.235605
Eval costs: 0.229946 s
Iter 46...	Training loss: 20367.464844 (1366.175445, 19001.287292) in 3.80s 
Iter 47...	Training loss: 19930.728516 (1362.235581, 18568.494583) in 3.88s 
Iter 48...	Training loss: 19183.933594 (1358.060061, 17825.874542) in 3.82s 
Iter 49...	Training loss: 18988.644531 (1352.774088, 17635.871628) in 3.90s 
Iter 50...	Training loss: 18495.703125 (1349.010846, 17146.689545) in 3.81s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.120859 HR: 0.171157
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.142429 HR: 0.238246
Eval costs: 0.232821 s
Iter 51...	Training loss: 18202.390625 (1346.324272, 16856.066666) in 3.89s 
Iter 52...	Training loss: 17569.568359 (1342.255262, 16227.313782) in 3.80s 
Iter 53...	Training loss: 17510.568359 (1339.203465, 16171.364433) in 3.88s 
Iter 54...	Training loss: 16908.445312 (1337.068680, 15571.376099) in 3.79s 
Iter 55...	Training loss: 16378.671875 (1332.218036, 15046.454170) in 3.81s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.122839 HR: 0.173798
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.142382 HR: 0.234548
Eval costs: 0.235003 s
Iter 56...	Training loss: 16255.549805 (1328.179698, 14927.369568) in 3.89s 
Iter 57...	Training loss: 15692.753906 (1326.733444, 14366.019783) in 3.82s 
Iter 58...	Training loss: 15750.135742 (1323.355271, 14426.780502) in 3.87s 
Iter 59...	Training loss: 15276.562500 (1320.573997, 13955.988281) in 3.79s 
Iter 60...	Training loss: 15015.880859 (1318.459871, 13697.419930) in 3.90s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.119906 HR: 0.168516
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.140219 HR: 0.230851
Eval costs: 0.236214 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 325685.531250 (118735.383781, 206950.157227) in 3.12s 
Iter 2...	Training loss: 270425.843750 (80587.103081, 189838.739990) in 3.12s 
Iter 3...	Training loss: 182746.593750 (0.000000, 182746.587769) in 2.62s 
Iter 4...	Training loss: 260974.015625 (82712.815247, 178261.200073) in 3.50s 
Iter 5...	Training loss: 199874.343750 (26329.526931, 173544.833008) in 3.06s 
Top-1 Recall: 0.011622 Precision: 0.011622 NDCG: 0.011622 HR: 0.011622
Top-5 Recall: 0.062863 Precision: 0.012573 NDCG: 0.036980 HR: 0.062863
Top-10 Recall: 0.086107 Precision: 0.008611 NDCG: 0.044349 HR: 0.086107
Eval costs: 0.171908 s
Iter 6...	Training loss: 190807.500000 (22025.415580, 168782.060181) in 3.09s 
Iter 7...	Training loss: 181828.546875 (18597.992951, 163230.538818) in 3.02s 
Iter 8...	Training loss: 172353.828125 (15813.303943, 156540.572144) in 3.09s 
Iter 9...	Training loss: 161972.515625 (13498.159712, 148474.353882) in 3.02s 
Iter 10...	Training loss: 149598.015625 (11363.237437, 138234.778198) in 3.08s 
Top-1 Recall: 0.034865 Precision: 0.034865 NDCG: 0.034865 HR: 0.034865
Top-5 Recall: 0.092446 Precision: 0.018489 NDCG: 0.063469 HR: 0.092446
Top-10 Recall: 0.135763 Precision: 0.013576 NDCG: 0.077304 HR: 0.135763
Eval costs: 0.170813 s
Iter 11...	Training loss: 136582.468750 (9573.172403, 127009.298340) in 3.02s 
Iter 12...	Training loss: 123945.171875 (8152.033279, 115793.139038) in 3.12s 
Iter 13...	Training loss: 111528.203125 (7013.172858, 104515.030762) in 3.05s 
Iter 14...	Training loss: 99125.421875 (6039.814349, 93085.589905) in 3.15s 
Iter 15...	Training loss: 87426.703125 (5214.840750, 82211.851868) in 3.05s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.120972 Precision: 0.024194 NDCG: 0.082428 HR: 0.120972
Top-10 Recall: 0.174855 Precision: 0.017485 NDCG: 0.099750 HR: 0.174855
Eval costs: 0.189276 s
Iter 16...	Training loss: 76715.632812 (4526.030283, 72189.603394) in 3.09s 
Iter 17...	Training loss: 67279.507812 (3969.348922, 63310.156128) in 3.03s 
Iter 18...	Training loss: 59228.066406 (3522.647458, 55705.418610) in 3.15s 
Iter 19...	Training loss: 52602.851562 (3169.923438, 49432.927643) in 3.05s 
Iter 20...	Training loss: 46978.078125 (2880.396235, 44097.678619) in 3.15s 
Top-1 Recall: 0.047544 Precision: 0.047544 NDCG: 0.047544 HR: 0.047544
Top-5 Recall: 0.139461 Precision: 0.027892 NDCG: 0.094776 HR: 0.139461
Top-10 Recall: 0.191759 Precision: 0.019176 NDCG: 0.111622 HR: 0.191759
Eval costs: 0.200270 s
Iter 21...	Training loss: 42436.722656 (2653.254069, 39783.468445) in 3.11s 
Iter 22...	Training loss: 38606.710938 (2487.688300, 36119.022644) in 3.04s 
Iter 23...	Training loss: 34813.835938 (2348.121735, 32465.713593) in 3.11s 
Iter 24...	Training loss: 32230.734375 (2238.798890, 29991.935333) in 3.04s 
Iter 25...	Training loss: 29803.683594 (2153.987826, 27649.696716) in 3.10s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.153196 Precision: 0.030639 NDCG: 0.102459 HR: 0.153196
Top-10 Recall: 0.208135 Precision: 0.020814 NDCG: 0.120064 HR: 0.208135
Eval costs: 0.208612 s
Iter 26...	Training loss: 27700.849609 (2078.182215, 25622.669724) in 3.02s 
Iter 27...	Training loss: 25556.796875 (2027.522375, 23529.275955) in 3.10s 
Iter 28...	Training loss: 24128.212891 (1978.378242, 22149.836700) in 3.04s 
Iter 29...	Training loss: 22528.298828 (1946.878167, 20581.421158) in 3.10s 
Iter 30...	Training loss: 21304.099609 (1917.793887, 19386.304489) in 3.04s 
Top-1 Recall: 0.051770 Precision: 0.051770 NDCG: 0.051770 HR: 0.051770
Top-5 Recall: 0.161648 Precision: 0.032330 NDCG: 0.107723 HR: 0.161648
Top-10 Recall: 0.210248 Precision: 0.021025 NDCG: 0.123439 HR: 0.210248
Eval costs: 0.214480 s
Iter 31...	Training loss: 20324.183594 (1889.148077, 18435.034531) in 3.11s 
Iter 32...	Training loss: 19204.613281 (1863.299044, 17341.313156) in 3.04s 
Iter 33...	Training loss: 18260.238281 (1844.127051, 16416.112381) in 3.11s 
Iter 34...	Training loss: 17263.109375 (1828.225164, 15434.884171) in 3.01s 
Iter 35...	Training loss: 16473.781250 (1817.423208, 14656.357994) in 3.09s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.112174 HR: 0.162176
Top-10 Recall: 0.218172 Precision: 0.021817 NDCG: 0.130324 HR: 0.218172
Eval costs: 0.219146 s
Iter 36...	Training loss: 15911.657227 (1810.160944, 14101.497406) in 3.03s 
Iter 37...	Training loss: 15110.574219 (1804.890955, 13305.682953) in 3.09s 
Iter 38...	Training loss: 14624.437500 (1797.379975, 12827.056587) in 3.03s 
Iter 39...	Training loss: 14137.124023 (1794.397427, 12342.726189) in 3.11s 
Iter 40...	Training loss: 13512.343750 (1790.038056, 11722.305099) in 3.04s 
Top-1 Recall: 0.062335 Precision: 0.062335 NDCG: 0.062335 HR: 0.062335
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.114853 HR: 0.163761
Top-10 Recall: 0.217116 Precision: 0.021712 NDCG: 0.132139 HR: 0.217116
Eval costs: 0.222835 s
Iter 41...	Training loss: 12927.571289 (1784.820537, 11142.750839) in 3.12s 
Iter 42...	Training loss: 12631.022461 (1780.184837, 10850.836823) in 3.05s 
Iter 43...	Training loss: 12224.205078 (1781.102964, 10443.102264) in 3.12s 
Iter 44...	Training loss: 11880.547852 (1782.358672, 10098.189217) in 3.04s 
Iter 45...	Training loss: 11618.772461 (1784.350376, 9834.423607) in 3.14s 
Top-1 Recall: 0.064448 Precision: 0.064448 NDCG: 0.064448 HR: 0.064448
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.114946 HR: 0.162176
Top-10 Recall: 0.216059 Precision: 0.021606 NDCG: 0.132471 HR: 0.216059
Eval costs: 0.224871 s
Iter 46...	Training loss: 11320.809570 (1789.541235, 9531.268929) in 3.07s 
Iter 47...	Training loss: 10919.404297 (1790.164846, 9129.240036) in 3.13s 
Iter 48...	Training loss: 10572.492188 (1795.932334, 8776.559948) in 3.05s 
Iter 49...	Training loss: 10216.609375 (1797.306548, 8419.302162) in 3.13s 
Iter 50...	Training loss: 10114.398438 (1802.810192, 8311.588364) in 3.05s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.117712 HR: 0.162705
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.136114 HR: 0.219229
Eval costs: 0.231489 s
Iter 51...	Training loss: 9846.727539 (1807.971744, 8038.755508) in 3.18s 
Iter 52...	Training loss: 9478.286133 (1818.360409, 7659.926533) in 3.05s 
Iter 53...	Training loss: 9188.054688 (1823.740500, 7364.314060) in 3.14s 
Iter 54...	Training loss: 9151.519531 (1827.495286, 7324.024448) in 3.06s 
Iter 55...	Training loss: 8866.823242 (1829.953434, 7036.869209) in 3.16s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.119929 HR: 0.168516
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.137072 HR: 0.222398
Eval costs: 0.229903 s
Iter 56...	Training loss: 8779.750000 (1834.144045, 6945.605736) in 3.09s 
Iter 57...	Training loss: 8498.063477 (1836.935195, 6661.127766) in 3.03s 
Iter 58...	Training loss: 8375.323242 (1841.935910, 6533.386784) in 3.09s 
Iter 59...	Training loss: 8177.882812 (1851.750600, 6326.131878) in 3.03s 
Iter 60...	Training loss: 8078.200195 (1854.155090, 6224.044899) in 3.05s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.164289 Precision: 0.032858 NDCG: 0.118442 HR: 0.164289
Top-10 Recall: 0.216059 Precision: 0.021606 NDCG: 0.135180 HR: 0.216059
Eval costs: 0.325641 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 346134.781250 (118589.669159, 227545.123413) in 3.26s 
Iter 2...	Training loss: 201706.750000 (0.000000, 201706.745972) in 2.61s 
Iter 3...	Training loss: 314506.312500 (118741.801084, 195764.536255) in 3.51s 
Iter 4...	Training loss: 218306.000000 (29239.645854, 189066.366089) in 3.12s 
Iter 5...	Training loss: 205909.703125 (22694.850600, 183214.869141) in 3.04s 
Top-1 Recall: 0.015320 Precision: 0.015320 NDCG: 0.015320 HR: 0.015320
Top-5 Recall: 0.060750 Precision: 0.012150 NDCG: 0.037804 HR: 0.060750
Top-10 Recall: 0.095087 Precision: 0.009509 NDCG: 0.048967 HR: 0.095087
Eval costs: 0.172035 s
Iter 6...	Training loss: 196035.593750 (18703.084877, 177332.531372) in 3.09s 
Iter 7...	Training loss: 186514.296875 (15783.626324, 170730.669312) in 3.03s 
Iter 8...	Training loss: 176288.953125 (13482.880358, 162806.065063) in 3.08s 
Iter 9...	Training loss: 164969.921875 (11417.644037, 153552.301270) in 3.01s 
Iter 10...	Training loss: 151958.890625 (9667.469492, 142291.421265) in 3.10s 
Top-1 Recall: 0.033281 Precision: 0.033281 NDCG: 0.033281 HR: 0.033281
Top-5 Recall: 0.096144 Precision: 0.019229 NDCG: 0.064548 HR: 0.096144
Top-10 Recall: 0.140518 Precision: 0.014052 NDCG: 0.078765 HR: 0.140518
Eval costs: 0.175521 s
Iter 11...	Training loss: 129422.304688 (0.000000, 129422.303833) in 2.59s 
Iter 12...	Training loss: 134084.828125 (14987.499156, 119097.326050) in 3.50s 
Iter 13...	Training loss: 106915.757812 (0.000000, 106915.758667) in 2.61s 
Iter 14...	Training loss: 107215.859375 (11218.840387, 95997.012024) in 3.48s 
Iter 15...	Training loss: 89522.914062 (4732.576840, 84790.349365) in 3.02s 
Top-1 Recall: 0.042261 Precision: 0.042261 NDCG: 0.042261 HR: 0.042261
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.081280 HR: 0.118331
Top-10 Recall: 0.172213 Precision: 0.017221 NDCG: 0.098626 HR: 0.172213
Eval costs: 0.190985 s
Iter 16...	Training loss: 78577.007812 (4159.516880, 74417.487854) in 3.09s 
Iter 17...	Training loss: 68996.140625 (3666.247428, 65329.899597) in 3.02s 
Iter 18...	Training loss: 60975.351562 (3273.269919, 57702.080627) in 3.11s 
Iter 19...	Training loss: 54030.742188 (2948.041638, 51082.704651) in 3.02s 
Iter 20...	Training loss: 48260.332031 (2707.475738, 45552.863220) in 3.11s 
Top-1 Recall: 0.048600 Precision: 0.048600 NDCG: 0.048600 HR: 0.048600
Top-5 Recall: 0.135235 Precision: 0.027047 NDCG: 0.092137 HR: 0.135235
Top-10 Recall: 0.192287 Precision: 0.019229 NDCG: 0.110441 HR: 0.192287
Eval costs: 0.200377 s
Iter 21...	Training loss: 43547.171875 (2502.116415, 41045.051117) in 3.04s 
Iter 22...	Training loss: 39227.812500 (2334.144276, 36893.674866) in 3.11s 
Iter 23...	Training loss: 36126.250000 (2202.266609, 33923.985840) in 3.05s 
Iter 24...	Training loss: 33274.304688 (2100.076625, 31174.229279) in 3.12s 
Iter 25...	Training loss: 28130.205078 (0.000000, 28130.204102) in 2.63s 
Top-1 Recall: 0.053354 Precision: 0.053354 NDCG: 0.053354 HR: 0.053354
Top-5 Recall: 0.155309 Precision: 0.031062 NDCG: 0.105354 HR: 0.155309
Top-10 Recall: 0.208135 Precision: 0.020814 NDCG: 0.122437 HR: 0.208135
Eval costs: 0.208674 s
Iter 26...	Training loss: 30184.800781 (3584.755604, 26600.047165) in 3.48s 
Iter 27...	Training loss: 26288.179688 (1884.795122, 24403.383591) in 2.99s 
Iter 28...	Training loss: 24552.835938 (1850.984967, 22701.852829) in 3.10s 
Iter 29...	Training loss: 23219.136719 (1811.609944, 21407.528595) in 3.00s 
Iter 30...	Training loss: 19908.886719 (0.000000, 19908.885818) in 2.61s 
Top-1 Recall: 0.054411 Precision: 0.054411 NDCG: 0.054411 HR: 0.054411
Top-5 Recall: 0.161648 Precision: 0.032330 NDCG: 0.109606 HR: 0.161648
Top-10 Recall: 0.216587 Precision: 0.021659 NDCG: 0.127377 HR: 0.216587
Eval costs: 0.214622 s
Iter 31...	Training loss: 21974.056641 (3157.906109, 18816.149918) in 3.55s 
Iter 32...	Training loss: 19718.058594 (1721.670715, 17996.386230) in 3.10s 
Iter 33...	Training loss: 18594.792969 (1711.855980, 16882.936920) in 3.01s 
Iter 34...	Training loss: 17777.140625 (1693.536196, 16083.605682) in 3.10s 
Iter 35...	Training loss: 16904.869141 (1677.829500, 15227.039078) in 3.00s 
Top-1 Recall: 0.063391 Precision: 0.063391 NDCG: 0.063391 HR: 0.063391
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.115175 HR: 0.163761
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.133458 HR: 0.219757
Eval costs: 0.218002 s
Iter 36...	Training loss: 16024.945312 (1666.501757, 14358.443840) in 3.16s 
Iter 37...	Training loss: 15269.978516 (1656.684595, 13613.293221) in 3.04s 
Iter 38...	Training loss: 14851.912109 (1647.421625, 13204.490417) in 3.15s 
Iter 39...	Training loss: 14273.095703 (1640.949482, 12632.146133) in 3.05s 
Iter 40...	Training loss: 13682.887695 (1632.595622, 12050.292572) in 3.14s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.117435 HR: 0.170629
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.135513 HR: 0.226624
Eval costs: 0.221461 s
Iter 41...	Training loss: 13130.925781 (1630.351834, 11500.573647) in 3.10s 
Iter 42...	Training loss: 12577.195312 (1625.060571, 10952.134933) in 3.08s 
Iter 43...	Training loss: 12418.612305 (1620.573473, 10798.038162) in 3.12s 
Iter 44...	Training loss: 11711.891602 (1618.960478, 10092.930626) in 3.03s 
Iter 45...	Training loss: 11390.719727 (1618.361840, 9772.356071) in 3.10s 
Top-1 Recall: 0.062863 Precision: 0.062863 NDCG: 0.062863 HR: 0.062863
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.118897 HR: 0.170629
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.136169 HR: 0.224511
Eval costs: 0.224675 s
Iter 46...	Training loss: 11157.293945 (1617.321967, 9539.971802) in 3.04s 
Iter 47...	Training loss: 10657.755859 (1613.935418, 9043.821243) in 3.13s 
Iter 48...	Training loss: 10388.689453 (1615.595791, 8773.093163) in 3.06s 
Iter 49...	Training loss: 10236.455078 (1614.590323, 8621.863678) in 3.12s 
Iter 50...	Training loss: 10109.754883 (1612.966353, 8496.788712) in 3.06s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.119977 HR: 0.167459
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.138411 HR: 0.224511
Eval costs: 0.227767 s
Iter 51...	Training loss: 9598.509766 (1612.736468, 7985.774368) in 3.11s 
Iter 52...	Training loss: 9396.626953 (1609.985250, 7786.642666) in 3.00s 
Iter 53...	Training loss: 9340.138672 (1615.322823, 7724.816322) in 3.12s 
Iter 54...	Training loss: 8892.765625 (1612.296920, 7280.468414) in 3.01s 
Iter 55...	Training loss: 8800.967773 (1615.821347, 7185.146534) in 3.11s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.119443 HR: 0.166931
Top-10 Recall: 0.220814 Precision: 0.022081 NDCG: 0.136883 HR: 0.220814
Eval costs: 0.229896 s
Iter 56...	Training loss: 8665.537109 (1620.807073, 7044.729412) in 3.02s 
Iter 57...	Training loss: 8399.774414 (1620.513976, 6779.260326) in 3.09s 
Iter 58...	Training loss: 8328.026367 (1620.427858, 6707.599052) in 3.03s 
Iter 59...	Training loss: 7955.298340 (1626.822543, 6328.475418) in 3.09s 
Iter 60...	Training loss: 7835.540039 (1625.559790, 6209.980309) in 3.02s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.118753 HR: 0.165346
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.136880 HR: 0.221870
Eval costs: 0.231787 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 533856.937500 (118647.445549, 415209.504395) in 3.24s 
Iter 2...	Training loss: 388555.750000 (79911.847155, 308643.906982) in 3.03s 
Iter 3...	Training loss: 318513.656250 (45870.157168, 272643.528076) in 3.15s 
Iter 4...	Training loss: 275267.031250 (27240.668432, 248026.361816) in 3.05s 
Iter 5...	Training loss: 245784.406250 (19023.841652, 226760.549927) in 3.14s 
Top-1 Recall: 0.024300 Precision: 0.024300 NDCG: 0.024300 HR: 0.024300
Top-5 Recall: 0.075541 Precision: 0.015108 NDCG: 0.049888 HR: 0.075541
Top-10 Recall: 0.103011 Precision: 0.010301 NDCG: 0.058769 HR: 0.103011
Eval costs: 0.172931 s
Iter 6...	Training loss: 223395.125000 (14630.437280, 208764.693481) in 3.10s 
Iter 7...	Training loss: 205029.375000 (11948.306048, 193081.090088) in 3.02s 
Iter 8...	Training loss: 188563.671875 (9963.733142, 178599.942505) in 3.10s 
Iter 9...	Training loss: 172434.218750 (8353.374135, 164080.831299) in 3.01s 
Iter 10...	Training loss: 157363.421875 (7016.526901, 150346.894897) in 3.09s 
Top-1 Recall: 0.027470 Precision: 0.027470 NDCG: 0.027470 HR: 0.027470
Top-5 Recall: 0.092446 Precision: 0.018489 NDCG: 0.060153 HR: 0.092446
Top-10 Recall: 0.142102 Precision: 0.014210 NDCG: 0.076155 HR: 0.142102
Eval costs: 0.176630 s
Iter 11...	Training loss: 144271.343750 (5974.182489, 138297.157715) in 3.02s 
Iter 12...	Training loss: 131852.859375 (5149.652104, 126703.205688) in 3.11s 
Iter 13...	Training loss: 120405.867188 (4459.716941, 115946.151489) in 3.03s 
Iter 14...	Training loss: 109031.015625 (3872.026737, 105158.995667) in 3.10s 
Iter 15...	Training loss: 98560.125000 (3390.584472, 95169.549927) in 3.03s 
Top-1 Recall: 0.037507 Precision: 0.037507 NDCG: 0.037507 HR: 0.037507
Top-5 Recall: 0.114633 Precision: 0.022927 NDCG: 0.077662 HR: 0.114633
Top-10 Recall: 0.176440 Precision: 0.017644 NDCG: 0.097550 HR: 0.176440
Eval costs: 0.185034 s
Iter 16...	Training loss: 89000.953125 (2984.631076, 86016.314880) in 3.09s 
Iter 17...	Training loss: 79571.421875 (2652.478765, 76918.932312) in 3.06s 
Iter 18...	Training loss: 70384.859375 (2396.520997, 67988.337036) in 3.10s 
Iter 19...	Training loss: 62752.484375 (2181.062810, 60571.427185) in 3.02s 
Iter 20...	Training loss: 55788.316406 (2002.072809, 53786.244354) in 3.10s 
Top-1 Recall: 0.051770 Precision: 0.051770 NDCG: 0.051770 HR: 0.051770
Top-5 Recall: 0.137348 Precision: 0.027470 NDCG: 0.095421 HR: 0.137348
Top-10 Recall: 0.201796 Precision: 0.020180 NDCG: 0.116084 HR: 0.201796
Eval costs: 0.194374 s
Iter 21...	Training loss: 49647.769531 (1858.352314, 47789.412506) in 3.03s 
Iter 22...	Training loss: 41526.101562 (0.000000, 41526.099213) in 2.63s 
Iter 23...	Training loss: 41622.273438 (3104.031790, 38518.245758) in 3.52s 
Iter 24...	Training loss: 33630.265625 (0.000000, 33630.266357) in 2.62s 
Iter 25...	Training loss: 34409.234375 (2851.351537, 31557.880310) in 3.52s 
Top-1 Recall: 0.057052 Precision: 0.057052 NDCG: 0.057052 HR: 0.057052
Top-5 Recall: 0.152668 Precision: 0.030534 NDCG: 0.105342 HR: 0.152668
Top-10 Recall: 0.207079 Precision: 0.020708 NDCG: 0.123060 HR: 0.207079
Eval costs: 0.202976 s
Iter 26...	Training loss: 29929.691406 (1489.671149, 28440.019104) in 3.15s 
Iter 27...	Training loss: 27480.703125 (1429.663450, 26051.038956) in 3.05s 
Iter 28...	Training loss: 25393.578125 (1385.699928, 24007.879105) in 3.12s 
Iter 29...	Training loss: 23262.804688 (1348.756098, 21914.048813) in 3.06s 
Iter 30...	Training loss: 22072.701172 (1319.164299, 20753.534821) in 3.15s 
Top-1 Recall: 0.059165 Precision: 0.059165 NDCG: 0.059165 HR: 0.059165
Top-5 Recall: 0.161120 Precision: 0.032224 NDCG: 0.111402 HR: 0.161120
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.130037 HR: 0.219229
Eval costs: 0.210297 s
Iter 31...	Training loss: 20502.671875 (1294.033973, 19208.636871) in 3.06s 
Iter 32...	Training loss: 19325.236328 (1270.686918, 18054.547989) in 3.14s 
Iter 33...	Training loss: 18194.689453 (1251.724045, 16942.963882) in 3.06s 
Iter 34...	Training loss: 17237.753906 (1235.978116, 16001.776443) in 3.15s 
Iter 35...	Training loss: 16064.985352 (1224.304118, 14840.681595) in 3.05s 
Top-1 Recall: 0.062863 Precision: 0.062863 NDCG: 0.062863 HR: 0.062863
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.117336 HR: 0.167459
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.135940 HR: 0.225040
Eval costs: 0.308972 s
Iter 36...	Training loss: 15544.226562 (1208.695867, 14335.530571) in 3.04s 
Iter 37...	Training loss: 14783.698242 (1196.628039, 13587.070091) in 3.04s 
Iter 38...	Training loss: 14041.646484 (1188.510749, 12853.137032) in 3.14s 
Iter 39...	Training loss: 13493.871094 (1178.134129, 12315.736557) in 3.04s 
Iter 40...	Training loss: 13042.923828 (1170.386139, 11872.537743) in 3.13s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.161648 Precision: 0.032330 NDCG: 0.116939 HR: 0.161648
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.136571 HR: 0.221870
Eval costs: 0.223104 s
Iter 41...	Training loss: 12426.391602 (1164.649193, 11261.741470) in 3.09s 
Iter 42...	Training loss: 11908.460938 (1159.828447, 10748.631981) in 3.02s 
Iter 43...	Training loss: 11570.088867 (1154.790610, 10415.298630) in 3.09s 
Iter 44...	Training loss: 11103.579102 (1150.063727, 9953.514610) in 3.02s 
Iter 45...	Training loss: 10689.564453 (1145.021586, 9544.542793) in 3.11s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.119450 HR: 0.165874
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.137449 HR: 0.221342
Eval costs: 0.223622 s
Iter 46...	Training loss: 10435.566406 (1140.666570, 9294.900238) in 3.02s 
Iter 47...	Training loss: 9824.136719 (1136.990503, 8687.145660) in 3.09s 
Iter 48...	Training loss: 9895.650391 (1131.470641, 8764.179310) in 3.02s 
Iter 49...	Training loss: 9552.379883 (1130.843011, 8421.536640) in 3.12s 
Iter 50...	Training loss: 9333.517578 (1128.157176, 8205.359562) in 3.02s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.161120 Precision: 0.032224 NDCG: 0.117279 HR: 0.161120
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.137124 HR: 0.222927
Eval costs: 0.226811 s
Iter 51...	Training loss: 8918.840820 (1123.420199, 7795.421219) in 3.09s 
Iter 52...	Training loss: 8719.089844 (1121.113160, 7597.976513) in 3.02s 
Iter 53...	Training loss: 8492.467773 (1117.822089, 7374.645462) in 3.10s 
Iter 54...	Training loss: 8394.277344 (1114.003821, 7280.274044) in 3.02s 
Iter 55...	Training loss: 8130.500000 (1111.324436, 7019.175735) in 3.09s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.118204 HR: 0.163761
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.137071 HR: 0.222398
Eval costs: 0.228599 s
Iter 56...	Training loss: 7850.170898 (1111.303144, 6738.867588) in 3.02s 
Iter 57...	Training loss: 7643.151367 (1107.582331, 6535.567955) in 3.11s 
Iter 58...	Training loss: 7516.637695 (1103.437426, 6413.200008) in 3.05s 
Iter 59...	Training loss: 7395.657227 (1101.324640, 6294.332993) in 3.12s 
Iter 60...	Training loss: 7171.519531 (1101.884737, 6069.634468) in 3.05s 
Top-1 Recall: 0.072372 Precision: 0.072372 NDCG: 0.072372 HR: 0.072372
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.121529 HR: 0.166931
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.140846 HR: 0.226624
Eval costs: 0.235226 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2322020.000000 (118780.087669, 2203240.004883) in 3.23s 
Iter 2...	Training loss: 1098251.375000 (0.000000, 1098251.441895) in 2.63s 
Iter 3...	Training loss: 1119771.750000 (108149.358500, 1011622.501953) in 3.49s 
Iter 4...	Training loss: 726220.125000 (19051.166504, 707169.009766) in 3.06s 
Iter 5...	Training loss: 520310.750000 (11438.601371, 508872.100830) in 3.15s 
Top-1 Recall: 0.008452 Precision: 0.008452 NDCG: 0.008452 HR: 0.008452
Top-5 Recall: 0.027998 Precision: 0.005600 NDCG: 0.018146 HR: 0.027998
Top-10 Recall: 0.052826 Precision: 0.005283 NDCG: 0.026073 HR: 0.052826
Eval costs: 0.167488 s
Iter 6...	Training loss: 391161.468750 (8620.447355, 382541.034912) in 3.10s 
Iter 7...	Training loss: 311695.312500 (7082.141552, 304613.150391) in 3.03s 
Iter 8...	Training loss: 259120.562500 (6027.654888, 253092.918457) in 3.11s 
Iter 9...	Training loss: 205054.656250 (0.000000, 205054.653931) in 2.60s 
Iter 10...	Training loss: 211898.984375 (9424.766752, 202474.243896) in 3.49s 
Top-1 Recall: 0.029583 Precision: 0.029583 NDCG: 0.029583 HR: 0.029583
Top-5 Recall: 0.090861 Precision: 0.018172 NDCG: 0.060131 HR: 0.090861
Top-10 Recall: 0.145800 Precision: 0.014580 NDCG: 0.077693 HR: 0.145800
Eval costs: 0.172547 s
Iter 11...	Training loss: 178131.187500 (4035.816730, 174095.371460) in 3.03s 
Iter 12...	Training loss: 160383.656250 (3515.659910, 156868.024780) in 3.11s 
Iter 13...	Training loss: 145882.515625 (3075.652709, 142806.860107) in 3.03s 
Iter 14...	Training loss: 133714.187500 (2712.847750, 131001.328979) in 3.10s 
Iter 15...	Training loss: 123507.117188 (2398.951730, 121108.156250) in 3.01s 
Top-1 Recall: 0.039620 Precision: 0.039620 NDCG: 0.039620 HR: 0.039620
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.079456 HR: 0.118331
Top-10 Recall: 0.177496 Precision: 0.017750 NDCG: 0.098530 HR: 0.177496
Eval costs: 0.177450 s
Iter 16...	Training loss: 114839.570312 (2142.676015, 112696.884949) in 3.10s 
Iter 17...	Training loss: 107472.476562 (1934.202972, 105538.273682) in 3.02s 
Iter 18...	Training loss: 100959.171875 (1759.076671, 99200.095703) in 3.10s 
Iter 19...	Training loss: 95017.445312 (1619.263518, 93398.183044) in 3.02s 
Iter 20...	Training loss: 89878.921875 (1500.590439, 88378.339233) in 3.09s 
Top-1 Recall: 0.053883 Precision: 0.053883 NDCG: 0.053883 HR: 0.053883
Top-5 Recall: 0.146329 Precision: 0.029266 NDCG: 0.099770 HR: 0.146329
Top-10 Recall: 0.207607 Precision: 0.020761 NDCG: 0.119375 HR: 0.207607
Eval costs: 0.182544 s
Iter 21...	Training loss: 85230.789062 (1403.217100, 83827.569641) in 3.02s 
Iter 22...	Training loss: 80349.640625 (1322.351966, 79027.294495) in 3.12s 
Iter 23...	Training loss: 75992.546875 (1251.632619, 74740.908264) in 3.08s 
Iter 24...	Training loss: 71501.515625 (1191.335081, 70310.188965) in 3.10s 
Iter 25...	Training loss: 67476.109375 (1137.256491, 66338.857300) in 3.02s 
Top-1 Recall: 0.062335 Precision: 0.062335 NDCG: 0.062335 HR: 0.062335
Top-5 Recall: 0.159007 Precision: 0.031801 NDCG: 0.110349 HR: 0.159007
Top-10 Recall: 0.220814 Precision: 0.022081 NDCG: 0.130215 HR: 0.220814
Eval costs: 0.186934 s
Iter 26...	Training loss: 63579.917969 (1091.612193, 62488.302368) in 3.09s 
Iter 27...	Training loss: 59415.023438 (1051.946259, 58363.078796) in 3.05s 
Iter 28...	Training loss: 55196.550781 (1017.569861, 54178.977539) in 3.12s 
Iter 29...	Training loss: 51334.554688 (984.830311, 50349.718719) in 3.03s 
Iter 30...	Training loss: 47105.968750 (955.435126, 46150.535034) in 3.13s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.115717 HR: 0.162176
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.135743 HR: 0.224511
Eval costs: 0.194726 s
Iter 31...	Training loss: 43883.367188 (928.193835, 42955.171539) in 3.05s 
Iter 32...	Training loss: 40354.796875 (906.165745, 39448.627411) in 3.15s 
Iter 33...	Training loss: 34186.218750 (0.000000, 34186.219452) in 2.65s 
Iter 34...	Training loss: 36591.316406 (1702.969441, 34888.345825) in 3.49s 
Iter 35...	Training loss: 31581.357422 (855.671463, 30725.689270) in 3.05s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.122700 HR: 0.170629
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.141293 HR: 0.228209
Eval costs: 0.202085 s
Iter 36...	Training loss: 29031.228516 (835.261355, 28195.968750) in 3.15s 
Iter 37...	Training loss: 26985.187500 (819.320551, 26165.869690) in 3.04s 
Iter 38...	Training loss: 25082.751953 (802.354607, 24280.395370) in 3.14s 
Iter 39...	Training loss: 23501.990234 (788.007828, 22713.981155) in 3.04s 
Iter 40...	Training loss: 21797.117188 (774.927798, 21022.188278) in 3.15s 
Top-1 Recall: 0.072372 Precision: 0.072372 NDCG: 0.072372 HR: 0.072372
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.120450 HR: 0.167987
Top-10 Recall: 0.227681 Precision: 0.022768 NDCG: 0.139846 HR: 0.227681
Eval costs: 0.209345 s
Iter 41...	Training loss: 20416.884766 (764.177325, 19652.709793) in 3.10s 
Iter 42...	Training loss: 19401.947266 (752.241783, 18649.706223) in 3.03s 
Iter 43...	Training loss: 16091.569336 (0.000000, 16091.569092) in 2.66s 
Iter 44...	Training loss: 19749.568359 (1432.547071, 18317.021851) in 3.50s 
Iter 45...	Training loss: 16947.003906 (728.827641, 16218.175613) in 3.10s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.123792 HR: 0.171157
Top-10 Recall: 0.229266 Precision: 0.022927 NDCG: 0.142585 HR: 0.229266
Eval costs: 0.215689 s
Iter 46...	Training loss: 15890.880859 (717.751095, 15173.131134) in 3.02s 
Iter 47...	Training loss: 15690.787109 (706.936403, 14983.851357) in 3.10s 
Iter 48...	Training loss: 14691.404297 (699.697192, 13991.705734) in 3.03s 
Iter 49...	Training loss: 13814.847656 (691.513649, 13123.334084) in 3.11s 
Iter 50...	Training loss: 13581.146484 (682.989466, 12898.156456) in 3.03s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.121622 HR: 0.167987
Top-10 Recall: 0.237190 Precision: 0.023719 NDCG: 0.143723 HR: 0.237190
Eval costs: 0.221195 s
Iter 51...	Training loss: 13072.331055 (675.601910, 12396.730316) in 3.10s 
Iter 52...	Training loss: 12547.130859 (668.940764, 11878.189941) in 3.02s 
Iter 53...	Training loss: 12256.890625 (662.826050, 11594.064026) in 3.10s 
Iter 54...	Training loss: 11826.640625 (657.638757, 11169.000702) in 3.04s 
Iter 55...	Training loss: 11518.056641 (649.827704, 10868.229500) in 3.11s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.121024 HR: 0.169572
Top-10 Recall: 0.228737 Precision: 0.022874 NDCG: 0.140126 HR: 0.228737
Eval costs: 0.225064 s
Iter 56...	Training loss: 11404.791992 (645.458959, 10759.333153) in 3.04s 
Iter 57...	Training loss: 11091.277344 (640.561682, 10450.714531) in 3.10s 
Iter 58...	Training loss: 10611.868164 (634.178929, 9977.689987) in 3.03s 
Iter 59...	Training loss: 10346.564453 (627.899450, 9718.664673) in 3.09s 
Iter 60...	Training loss: 8085.943848 (0.000000, 8085.943680) in 2.60s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.119885 HR: 0.165874
Top-10 Recall: 0.228737 Precision: 0.022874 NDCG: 0.140068 HR: 0.228737
Eval costs: 0.229165 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 587635.625000 (192496.607296, 186193.581571, 208945.459961) in 5.02s 
Iter 2...	Training loss: 236813.828125 (16115.243200, 29154.334571, 191544.258301) in 4.47s 
Iter 3...	Training loss: 218727.187500 (12419.011701, 21708.878874, 184599.304565) in 4.47s 
Iter 4...	Training loss: 208754.812500 (10460.886584, 18756.314697, 179537.609985) in 4.49s 
Iter 5...	Training loss: 183362.015625 (8892.350538, 0.000000, 174469.670898) in 3.95s 
Top-1 Recall: 0.011622 Precision: 0.011622 NDCG: 0.011622 HR: 0.011622
Top-5 Recall: 0.062335 Precision: 0.012467 NDCG: 0.037217 HR: 0.062335
Top-10 Recall: 0.086107 Precision: 0.008611 NDCG: 0.044843 HR: 0.086107
Eval costs: 0.171558 s
Iter 6...	Training loss: 213553.093750 (7625.396470, 36011.275045, 169916.407227) in 4.92s 
Iter 7...	Training loss: 185144.046875 (6623.006780, 14173.948109, 164347.091187) in 4.43s 
Iter 8...	Training loss: 169916.703125 (0.000000, 12716.047079, 157200.686890) in 3.19s 
Iter 9...	Training loss: 171741.921875 (11361.347073, 11097.793936, 149282.796021) in 5.63s 
Iter 10...	Training loss: 153403.156250 (4598.180779, 9624.825586, 139180.157349) in 4.47s 
Top-1 Recall: 0.033809 Precision: 0.033809 NDCG: 0.033809 HR: 0.033809
Top-5 Recall: 0.090333 Precision: 0.018067 NDCG: 0.062104 HR: 0.090333
Top-10 Recall: 0.140518 Precision: 0.014052 NDCG: 0.078273 HR: 0.140518
Eval costs: 0.171364 s
Iter 11...	Training loss: 139946.218750 (4107.827911, 8260.319113, 127578.097046) in 4.48s 
Iter 12...	Training loss: 127385.078125 (3721.257818, 7128.995191, 116534.811768) in 4.48s 
Iter 13...	Training loss: 114941.695312 (3453.808098, 6220.341338, 105267.542664) in 4.48s 
Iter 14...	Training loss: 102457.796875 (3258.504820, 5426.716118, 93772.580078) in 4.48s 
Iter 15...	Training loss: 90896.195312 (3139.524932, 4749.599635, 83007.081238) in 4.49s 
Top-1 Recall: 0.041204 Precision: 0.041204 NDCG: 0.041204 HR: 0.041204
Top-5 Recall: 0.121500 Precision: 0.024300 NDCG: 0.081741 HR: 0.121500
Top-10 Recall: 0.174855 Precision: 0.017485 NDCG: 0.098892 HR: 0.174855
Eval costs: 0.192943 s
Iter 16...	Training loss: 79991.335938 (3079.839491, 4152.100246, 72759.400757) in 4.46s 
Iter 17...	Training loss: 70595.296875 (3064.088710, 3666.291498, 63864.917236) in 4.46s 
Iter 18...	Training loss: 62741.261719 (3091.127889, 3270.068482, 56380.068542) in 4.44s 
Iter 19...	Training loss: 55871.074219 (3145.375102, 2935.933821, 49789.769409) in 4.43s 
Iter 20...	Training loss: 50246.074219 (3217.881447, 2679.668151, 44348.524200) in 4.35s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.138405 Precision: 0.027681 NDCG: 0.094384 HR: 0.138405
Top-10 Recall: 0.193344 Precision: 0.019334 NDCG: 0.112193 HR: 0.193344
Eval costs: 0.200942 s
Iter 21...	Training loss: 45795.539062 (3306.067918, 2474.766020, 40014.711609) in 4.47s 
Iter 22...	Training loss: 41937.730469 (3401.347069, 2322.171921, 36214.209503) in 4.47s 
Iter 23...	Training loss: 38522.671875 (3498.188676, 2200.515765, 32823.963348) in 4.49s 
Iter 24...	Training loss: 35915.601562 (3597.300475, 2102.574602, 30215.727112) in 4.49s 
Iter 25...	Training loss: 33736.773438 (3697.842657, 2026.767902, 28012.159210) in 4.48s 
Top-1 Recall: 0.052826 Precision: 0.052826 NDCG: 0.052826 HR: 0.052826
Top-5 Recall: 0.147913 Precision: 0.029583 NDCG: 0.100884 HR: 0.147913
Top-10 Recall: 0.203381 Precision: 0.020338 NDCG: 0.118848 HR: 0.203381
Eval costs: 0.209031 s
Iter 26...	Training loss: 31539.058594 (3798.708666, 1959.871407, 25780.478043) in 4.48s 
Iter 27...	Training loss: 27743.460938 (3894.813896, 0.000000, 23848.647827) in 3.94s 
Iter 28...	Training loss: 29851.306641 (3988.333063, 3428.920299, 22434.054749) in 4.90s 
Iter 29...	Training loss: 27025.199219 (4078.828660, 1830.457798, 21115.915695) in 4.42s 
Iter 30...	Training loss: 25656.392578 (4170.612223, 1810.422155, 19675.359070) in 4.35s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.161648 Precision: 0.032330 NDCG: 0.111521 HR: 0.161648
Top-10 Recall: 0.210248 Precision: 0.021025 NDCG: 0.127360 HR: 0.210248
Eval costs: 0.214295 s
Iter 31...	Training loss: 24689.921875 (4248.122520, 1791.038476, 18650.762421) in 4.47s 
Iter 32...	Training loss: 23724.046875 (4331.711079, 1775.176607, 17617.157959) in 4.47s 
Iter 33...	Training loss: 22558.822266 (4400.708344, 1758.136031, 16399.980148) in 4.48s 
Iter 34...	Training loss: 22071.357422 (4476.725172, 1742.479414, 15852.153137) in 4.48s 
Iter 35...	Training loss: 21292.339844 (4550.185508, 1734.492941, 15007.661880) in 4.46s 
Top-1 Recall: 0.062863 Precision: 0.062863 NDCG: 0.062863 HR: 0.062863
Top-5 Recall: 0.163233 Precision: 0.032647 NDCG: 0.114362 HR: 0.163233
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.132621 HR: 0.219757
Eval costs: 0.219761 s
Iter 36...	Training loss: 20656.941406 (4625.440392, 1727.181368, 14304.317825) in 4.45s 
Iter 37...	Training loss: 20105.152344 (4682.916045, 1720.437173, 13701.800621) in 4.42s 
Iter 38...	Training loss: 19789.765625 (4750.296561, 1713.779642, 13325.689133) in 4.43s 
Iter 39...	Training loss: 19154.666016 (4810.114645, 1714.276879, 12630.273865) in 4.36s 
Iter 40...	Training loss: 18772.699219 (4863.121639, 1711.992219, 12197.585670) in 4.48s 
Top-1 Recall: 0.062335 Precision: 0.062335 NDCG: 0.062335 HR: 0.062335
Top-5 Recall: 0.166931 Precision: 0.033386 NDCG: 0.116594 HR: 0.166931
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.134762 HR: 0.223455
Eval costs: 0.222641 s
Iter 41...	Training loss: 18159.396484 (4913.994977, 1714.194097, 11531.205406) in 4.48s 
Iter 42...	Training loss: 17891.302734 (4965.307711, 1716.849521, 11209.146255) in 4.49s 
Iter 43...	Training loss: 17561.312500 (5012.949211, 1713.596475, 10834.765701) in 4.48s 
Iter 44...	Training loss: 17321.255859 (5057.915207, 1716.885168, 10546.455475) in 4.49s 
Iter 45...	Training loss: 17091.917969 (5109.256563, 1719.608199, 10263.053429) in 4.48s 
Top-1 Recall: 0.062863 Precision: 0.062863 NDCG: 0.062863 HR: 0.062863
Top-5 Recall: 0.166403 Precision: 0.033281 NDCG: 0.116856 HR: 0.166403
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.134850 HR: 0.222398
Eval costs: 0.226506 s
Iter 46...	Training loss: 16829.390625 (5153.864389, 1726.143486, 9949.381485) in 4.48s 
Iter 47...	Training loss: 16462.902344 (5192.873847, 1729.802871, 9540.224937) in 4.45s 
Iter 48...	Training loss: 16291.928711 (5231.956372, 1733.925545, 9326.046593) in 4.41s 
Iter 49...	Training loss: 15883.671875 (5274.276678, 1740.048785, 8869.347359) in 4.41s 
Iter 50...	Training loss: 15772.689453 (5308.330683, 1746.407670, 8717.951660) in 4.36s 
Top-1 Recall: 0.064448 Precision: 0.064448 NDCG: 0.064448 HR: 0.064448
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.117802 HR: 0.167987
Top-10 Recall: 0.223983 Precision: 0.022398 NDCG: 0.135848 HR: 0.223983
Eval costs: 0.231171 s
Iter 51...	Training loss: 15519.619141 (5336.129543, 1752.608229, 8430.881516) in 4.47s 
Iter 52...	Training loss: 13555.715820 (5369.706154, 0.000000, 8186.010475) in 4.06s 
Iter 53...	Training loss: 16379.007812 (5404.631243, 3052.257540, 7922.118942) in 4.82s 
Iter 54...	Training loss: 15014.001953 (5442.397224, 1752.214802, 7819.391178) in 4.47s 
Iter 55...	Training loss: 14714.576172 (5470.483627, 1765.625442, 7478.466827) in 4.47s 
Top-1 Recall: 0.066561 Precision: 0.066561 NDCG: 0.066561 HR: 0.066561
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.117148 HR: 0.165874
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.134406 HR: 0.219229
Eval costs: 0.231238 s
Iter 56...	Training loss: 14741.253906 (5503.638551, 1774.940823, 7462.674335) in 4.47s 
Iter 57...	Training loss: 14744.106445 (5536.539008, 1787.085016, 7420.482376) in 4.45s 
Iter 58...	Training loss: 14443.261719 (5570.256565, 1791.173324, 7081.831394) in 4.43s 
Iter 59...	Training loss: 14324.519531 (5590.585003, 1800.732937, 6933.201279) in 4.42s 
Iter 60...	Training loss: 14263.505859 (5619.318186, 1807.371313, 6836.816422) in 4.34s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.121771 HR: 0.172742
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.136858 HR: 0.219757
Eval costs: 0.232245 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 540280.375000 (192542.952723, 118710.304291, 229027.128418) in 4.64s 
Iter 2...	Training loss: 301626.718750 (16166.009442, 80517.155607, 204943.536743) in 4.47s 
Iter 3...	Training loss: 258134.015625 (12495.702831, 49393.922049, 196244.386475) in 4.46s 
Iter 4...	Training loss: 233217.156250 (10513.818160, 32793.280727, 189910.043457) in 4.46s 
Iter 5...	Training loss: 217946.812500 (8929.037191, 24997.112767, 184020.647705) in 4.47s 
Top-1 Recall: 0.014791 Precision: 0.014791 NDCG: 0.014791 HR: 0.014791
Top-5 Recall: 0.065504 Precision: 0.013101 NDCG: 0.040080 HR: 0.065504
Top-10 Recall: 0.093502 Precision: 0.009350 NDCG: 0.049061 HR: 0.093502
Eval costs: 0.173254 s
Iter 6...	Training loss: 206337.125000 (7673.971965, 20546.162709, 178116.973267) in 4.46s 
Iter 7...	Training loss: 195390.750000 (6633.456273, 17275.892945, 171481.401367) in 4.47s 
Iter 8...	Training loss: 184205.859375 (5785.299685, 14571.096944, 163849.450195) in 4.48s 
Iter 9...	Training loss: 171933.281250 (5086.501649, 12256.861980, 154589.916748) in 4.43s 
Iter 10...	Training loss: 158343.796875 (4512.941167, 10236.739787, 143594.107300) in 4.41s 
Top-1 Recall: 0.029583 Precision: 0.029583 NDCG: 0.029583 HR: 0.029583
Top-5 Recall: 0.096672 Precision: 0.019334 NDCG: 0.063031 HR: 0.096672
Top-10 Recall: 0.135763 Precision: 0.013576 NDCG: 0.075659 HR: 0.135763
Eval costs: 0.174515 s
Iter 11...	Training loss: 144160.625000 (4037.121647, 8595.400681, 131528.101196) in 4.44s 
Iter 12...	Training loss: 131145.812500 (3667.815142, 7342.832078, 120135.151855) in 4.43s 
Iter 13...	Training loss: 118095.132812 (3412.257362, 6345.879204, 108337.001404) in 4.38s 
Iter 14...	Training loss: 105442.117188 (3233.918697, 5494.457385, 96713.740479) in 4.47s 
Iter 15...	Training loss: 93351.210938 (3125.626216, 4769.216731, 85456.363281) in 4.47s 
Top-1 Recall: 0.042261 Precision: 0.042261 NDCG: 0.042261 HR: 0.042261
Top-5 Recall: 0.117802 Precision: 0.023560 NDCG: 0.080211 HR: 0.117802
Top-10 Recall: 0.175911 Precision: 0.017591 NDCG: 0.098842 HR: 0.175911
Eval costs: 0.191899 s
Iter 16...	Training loss: 82348.523438 (3076.555222, 4166.320790, 75105.643372) in 4.48s 
Iter 17...	Training loss: 73058.500000 (3075.195168, 3683.685481, 66299.611755) in 4.49s 
Iter 18...	Training loss: 61016.593750 (3108.283344, 0.000000, 57908.310913) in 3.95s 
Iter 19...	Training loss: 60416.933594 (3172.296831, 5678.036342, 51566.605255) in 4.92s 
Iter 20...	Training loss: 52208.937500 (3251.239431, 2709.714490, 46247.980316) in 4.41s 
Top-1 Recall: 0.047544 Precision: 0.047544 NDCG: 0.047544 HR: 0.047544
Top-5 Recall: 0.140518 Precision: 0.028104 NDCG: 0.093725 HR: 0.140518
Top-10 Recall: 0.192287 Precision: 0.019229 NDCG: 0.110486 HR: 0.192287
Eval costs: 0.200961 s
Iter 21...	Training loss: 47292.617188 (3345.230687, 2519.045461, 41428.343414) in 4.44s 
Iter 22...	Training loss: 43168.917969 (3452.866811, 2356.862819, 37359.186859) in 4.42s 
Iter 23...	Training loss: 40002.511719 (3553.821976, 2228.328651, 34220.361572) in 4.38s 
Iter 24...	Training loss: 36998.683594 (3664.822893, 2123.405967, 31210.458313) in 4.46s 
Iter 25...	Training loss: 34843.347656 (3775.614445, 2034.696469, 29033.041412) in 4.46s 
Top-1 Recall: 0.053883 Precision: 0.053883 NDCG: 0.053883 HR: 0.053883
Top-5 Recall: 0.153196 Precision: 0.030639 NDCG: 0.104813 HR: 0.153196
Top-10 Recall: 0.206022 Precision: 0.020602 NDCG: 0.121853 HR: 0.206022
Eval costs: 0.208016 s
Iter 26...	Training loss: 32268.417969 (3885.380173, 1963.908642, 26419.127991) in 4.47s 
Iter 27...	Training loss: 30726.710938 (3985.252186, 1903.662038, 24837.798584) in 4.48s 
Iter 28...	Training loss: 29028.898438 (4083.653795, 1850.972762, 23094.270828) in 4.48s 
Iter 29...	Training loss: 27510.607422 (4184.879148, 1811.090161, 21514.639236) in 4.45s 
Iter 30...	Training loss: 26450.484375 (4283.776187, 1782.387722, 20384.320251) in 4.43s 
Top-1 Recall: 0.056524 Precision: 0.056524 NDCG: 0.056524 HR: 0.056524
Top-5 Recall: 0.160592 Precision: 0.032118 NDCG: 0.110187 HR: 0.160592
Top-10 Recall: 0.209192 Precision: 0.020919 NDCG: 0.125783 HR: 0.209192
Eval costs: 0.214735 s
Iter 31...	Training loss: 25016.171875 (4369.802504, 1749.517285, 18896.850372) in 4.42s 
Iter 32...	Training loss: 24284.500000 (4447.953240, 1721.841756, 18114.707123) in 4.43s 
Iter 33...	Training loss: 23393.357422 (4532.337947, 1702.826242, 17158.192825) in 4.34s 
Iter 34...	Training loss: 22215.660156 (4612.880418, 1689.106111, 15913.675095) in 4.47s 
Iter 35...	Training loss: 21960.126953 (4690.585286, 1673.349020, 15596.193817) in 4.47s 
Top-1 Recall: 0.055468 Precision: 0.055468 NDCG: 0.055468 HR: 0.055468
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.111512 HR: 0.162176
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.129986 HR: 0.219757
Eval costs: 0.219771 s
Iter 36...	Training loss: 21222.582031 (4762.945332, 1658.298968, 14801.337936) in 4.46s 
Iter 37...	Training loss: 20494.267578 (4828.172673, 1644.210244, 14021.886398) in 4.47s 
Iter 38...	Training loss: 19886.445312 (4888.579344, 1635.507065, 13362.359337) in 4.47s 
Iter 39...	Training loss: 17855.863281 (4953.310155, 0.000000, 12902.553398) in 3.95s 
Iter 40...	Training loss: 20388.697266 (5010.581191, 2849.148108, 12528.967461) in 4.92s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.118598 HR: 0.167459
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.135833 HR: 0.221342
Eval costs: 0.222538 s
Iter 41...	Training loss: 18275.210938 (5069.457011, 1609.219267, 11596.534073) in 4.44s 
Iter 42...	Training loss: 16433.392578 (5121.255324, 0.000000, 11312.138206) in 4.00s 
Iter 43...	Training loss: 19118.003906 (5177.397647, 2803.499925, 11137.106018) in 4.87s 
Iter 44...	Training loss: 17569.646484 (5225.376823, 1594.673759, 10749.595467) in 4.45s 
Iter 45...	Training loss: 17223.750000 (5277.191905, 1601.737034, 10344.819763) in 4.46s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.121937 HR: 0.171157
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.137188 HR: 0.219229
Eval costs: 0.226313 s
Iter 46...	Training loss: 16904.363281 (5333.553675, 1601.724414, 9969.083977) in 4.47s 
Iter 47...	Training loss: 16638.562500 (5369.522087, 1602.096204, 9666.945747) in 4.46s 
Iter 48...	Training loss: 16342.801758 (5418.212483, 1602.331400, 9322.256493) in 4.47s 
Iter 49...	Training loss: 16151.036133 (5466.946812, 1600.522998, 9083.567795) in 4.46s 
Iter 50...	Training loss: 15775.580078 (5495.130977, 1603.089720, 8677.359024) in 4.42s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.119674 HR: 0.164818
Top-10 Recall: 0.213946 Precision: 0.021395 NDCG: 0.135571 HR: 0.213946
Eval costs: 0.230268 s
Iter 51...	Training loss: 14067.089844 (5547.076793, 0.000000, 8520.012421) in 3.92s 
Iter 52...	Training loss: 16648.261719 (5584.746229, 2771.957316, 8291.559105) in 4.92s 
Iter 53...	Training loss: 15326.541992 (5612.181806, 1597.973104, 8116.387707) in 4.37s 
Iter 54...	Training loss: 15161.813477 (5650.068785, 1602.560923, 7909.183998) in 4.46s 
Iter 55...	Training loss: 15067.991211 (5686.793035, 1603.666596, 7777.531090) in 4.47s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.161648 Precision: 0.032330 NDCG: 0.118091 HR: 0.161648
Top-10 Recall: 0.218700 Precision: 0.021870 NDCG: 0.136391 HR: 0.218700
Eval costs: 0.231925 s
Iter 56...	Training loss: 14934.429688 (5714.762115, 1608.868977, 7610.798771) in 4.47s 
Iter 57...	Training loss: 14646.207031 (5756.270350, 1610.070012, 7279.865891) in 4.46s 
Iter 58...	Training loss: 14447.847656 (5785.410926, 1611.146963, 7051.288826) in 4.46s 
Iter 59...	Training loss: 14418.678711 (5818.378340, 1612.949666, 6987.350094) in 4.46s 
Iter 60...	Training loss: 14227.997070 (5849.312163, 1617.601939, 6761.082787) in 4.46s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.121416 HR: 0.170100
Top-10 Recall: 0.220285 Precision: 0.022029 NDCG: 0.137466 HR: 0.220285
Eval costs: 0.233932 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 728108.500000 (192160.660778, 118695.691036, 417252.123779) in 4.60s 
Iter 2...	Training loss: 405712.125000 (16119.151135, 80015.076002, 309577.864258) in 4.45s 
Iter 3...	Training loss: 262423.625000 (12476.693302, 0.000000, 249946.914795) in 3.96s 
Iter 4...	Training loss: 333476.937500 (10496.645234, 69228.311876, 253751.956787) in 4.92s 
Iter 5...	Training loss: 222269.343750 (8905.495840, 0.000000, 213363.877686) in 3.95s 
Top-1 Recall: 0.017961 Precision: 0.017961 NDCG: 0.017961 HR: 0.017961
Top-5 Recall: 0.075013 Precision: 0.015003 NDCG: 0.046930 HR: 0.075013
Top-10 Recall: 0.107237 Precision: 0.010724 NDCG: 0.057215 HR: 0.107237
Eval costs: 0.174368 s
Iter 6...	Training loss: 259465.562500 (7565.025340, 36890.333499, 215010.206665) in 4.92s 
Iter 7...	Training loss: 217381.015625 (6477.191024, 13352.916419, 197550.902100) in 4.43s 
Iter 8...	Training loss: 198362.718750 (5577.881437, 10675.820242, 182109.025757) in 4.35s 
Iter 9...	Training loss: 180635.406250 (4819.038697, 8814.192284, 167002.209229) in 4.48s 
Iter 10...	Training loss: 164153.796875 (4223.860380, 7341.654277, 152588.276367) in 4.47s 
Top-1 Recall: 0.027470 Precision: 0.027470 NDCG: 0.027470 HR: 0.027470
Top-5 Recall: 0.097200 Precision: 0.019440 NDCG: 0.062546 HR: 0.097200
Top-10 Recall: 0.141046 Precision: 0.014105 NDCG: 0.076571 HR: 0.141046
Eval costs: 0.177096 s
Iter 11...	Training loss: 150085.015625 (3795.768224, 6217.325882, 140071.921997) in 4.47s 
Iter 12...	Training loss: 129559.960938 (3495.336181, 0.000000, 126064.621338) in 4.05s 
Iter 13...	Training loss: 130949.320312 (3301.882872, 9240.482332, 118406.938721) in 4.84s 
Iter 14...	Training loss: 113982.867188 (3187.903381, 4027.620045, 106767.327209) in 4.47s 
Iter 15...	Training loss: 102773.750000 (3131.924460, 3469.641953, 96172.174683) in 4.43s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.111992 Precision: 0.022398 NDCG: 0.079520 HR: 0.111992
Top-10 Recall: 0.174326 Precision: 0.017433 NDCG: 0.099358 HR: 0.174326
Eval costs: 0.185915 s
Iter 16...	Training loss: 92597.992188 (3137.907224, 3037.670810, 86422.420105) in 4.42s 
Iter 17...	Training loss: 83462.359375 (3181.922878, 2693.701855, 77586.726257) in 4.43s 
Iter 18...	Training loss: 74627.296875 (3259.425415, 2415.107024, 68952.765991) in 4.37s 
Iter 19...	Training loss: 66569.039062 (3356.192170, 2193.738629, 61019.100342) in 4.47s 
Iter 20...	Training loss: 59912.476562 (3483.313015, 2006.034604, 54423.134460) in 4.47s 
Top-1 Recall: 0.051770 Precision: 0.051770 NDCG: 0.051770 HR: 0.051770
Top-5 Recall: 0.142631 Precision: 0.028526 NDCG: 0.097410 HR: 0.142631
Top-10 Recall: 0.199683 Precision: 0.019968 NDCG: 0.115722 HR: 0.199683
Eval costs: 0.195000 s
Iter 21...	Training loss: 54110.722656 (3627.582856, 1861.612413, 48621.526093) in 4.46s 
Iter 22...	Training loss: 48870.914062 (3779.545311, 1745.968843, 43345.398773) in 4.47s 
Iter 23...	Training loss: 43871.234375 (3937.568653, 1650.302535, 38283.365265) in 4.47s 
Iter 24...	Training loss: 40315.898438 (4092.562957, 1570.321732, 34653.013092) in 4.45s 
Iter 25...	Training loss: 37470.855469 (4260.738590, 1505.675981, 31704.444519) in 4.44s 
Top-1 Recall: 0.054411 Precision: 0.054411 NDCG: 0.054411 HR: 0.054411
Top-5 Recall: 0.151611 Precision: 0.030322 NDCG: 0.104244 HR: 0.151611
Top-10 Recall: 0.215003 Precision: 0.021500 NDCG: 0.124673 HR: 0.215003
Eval costs: 0.202633 s
Iter 26...	Training loss: 34566.859375 (4410.671328, 1452.243568, 28703.944977) in 4.44s 
Iter 27...	Training loss: 32362.357422 (4567.530391, 1406.166807, 26388.659042) in 4.43s 
Iter 28...	Training loss: 30752.505859 (4706.816797, 1365.090143, 24680.600693) in 4.36s 
Iter 29...	Training loss: 26635.273438 (4846.605781, 0.000000, 21788.665482) in 4.02s 
Iter 30...	Training loss: 28945.050781 (4972.769103, 2416.522576, 21555.760803) in 4.84s 
Top-1 Recall: 0.057581 Precision: 0.057581 NDCG: 0.057581 HR: 0.057581
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.111769 HR: 0.162176
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.130388 HR: 0.219229
Eval costs: 0.215169 s
Iter 31...	Training loss: 26303.660156 (5102.455433, 1295.582312, 19905.621155) in 4.48s 
Iter 32...	Training loss: 25356.447266 (5219.950860, 1266.758617, 18869.734406) in 4.48s 
Iter 33...	Training loss: 24242.410156 (5333.325282, 1247.612711, 17661.471191) in 4.47s 
Iter 34...	Training loss: 23105.378906 (5434.279293, 1232.173048, 16438.928818) in 4.47s 
Iter 35...	Training loss: 22464.318359 (5539.585231, 1216.139407, 15708.593384) in 4.45s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.117424 HR: 0.165346
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.136398 HR: 0.224511
Eval costs: 0.215617 s
Iter 36...	Training loss: 21814.226562 (5642.156242, 1202.389660, 14969.678375) in 4.44s 
Iter 37...	Training loss: 21176.378906 (5735.580288, 1190.707647, 14250.090874) in 4.41s 
Iter 38...	Training loss: 20708.357422 (5830.875692, 1180.289648, 13697.190079) in 4.41s 
Iter 39...	Training loss: 20085.578125 (5910.474576, 1173.385207, 13001.720085) in 4.34s 
Iter 40...	Training loss: 19467.671875 (5997.137998, 1163.647616, 12306.886078) in 4.46s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.122275 HR: 0.173270
Top-10 Recall: 0.217644 Precision: 0.021764 NDCG: 0.136928 HR: 0.217644
Eval costs: 0.219614 s
Iter 41...	Training loss: 19075.875000 (6084.117215, 1158.616681, 11833.139740) in 4.46s 
Iter 42...	Training loss: 18744.085938 (6167.922175, 1150.892621, 11425.270615) in 4.47s 
Iter 43...	Training loss: 18489.050781 (6236.071773, 1143.361220, 11109.617218) in 4.47s 
Iter 44...	Training loss: 18030.173828 (6302.870349, 1141.977537, 10585.325600) in 4.47s 
Iter 45...	Training loss: 16356.467773 (6370.849390, 0.000000, 9985.618866) in 3.92s 
Top-1 Recall: 0.066033 Precision: 0.066033 NDCG: 0.066033 HR: 0.066033
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.118476 HR: 0.167459
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.136042 HR: 0.221342
Eval costs: 0.224147 s
Iter 46...	Training loss: 18745.914062 (6449.136049, 2062.697888, 10234.080971) in 4.93s 
Iter 47...	Training loss: 17231.304688 (6502.876018, 1136.678508, 9591.748909) in 4.41s 
Iter 48...	Training loss: 16770.066406 (6575.730714, 1129.955159, 9064.379448) in 4.44s 
Iter 49...	Training loss: 16692.806641 (6632.348515, 1124.696577, 8935.761177) in 4.36s 
Iter 50...	Training loss: 15078.416016 (6701.022776, 0.000000, 8377.392860) in 4.03s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.116287 HR: 0.162705
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.135919 HR: 0.222927
Eval costs: 0.226969 s
Iter 51...	Training loss: 17632.025391 (6762.171494, 2023.447449, 8846.407829) in 4.85s 
Iter 52...	Training loss: 16125.277344 (6823.991609, 1122.497582, 8178.788795) in 4.46s 
Iter 53...	Training loss: 14322.501953 (6884.102639, 0.000000, 7438.399410) in 4.02s 
Iter 54...	Training loss: 17143.560547 (6937.693527, 2008.260979, 8197.606045) in 4.80s 
Iter 55...	Training loss: 15830.511719 (6992.708434, 1117.774646, 7720.030197) in 4.44s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.117755 HR: 0.162705
Top-10 Recall: 0.222927 Precision: 0.022293 NDCG: 0.137004 HR: 0.222927
Eval costs: 0.231924 s
Iter 56...	Training loss: 15512.412109 (7050.113951, 1111.123543, 7351.174976) in 4.44s 
Iter 57...	Training loss: 15474.511719 (7104.871652, 1105.757695, 7263.881554) in 4.40s 
Iter 58...	Training loss: 15407.234375 (7155.584857, 1102.109456, 7149.540710) in 4.43s 
Iter 59...	Training loss: 15433.125000 (7215.402652, 1097.737003, 7119.985607) in 4.34s 
Iter 60...	Training loss: 15220.945312 (7263.484793, 1094.649650, 6862.812130) in 4.45s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.119529 HR: 0.165874
Top-10 Recall: 0.221342 Precision: 0.022134 NDCG: 0.137341 HR: 0.221342
Eval costs: 0.234011 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0100 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2516620.000000 (192970.115561, 118663.952415, 2204985.899414) in 4.62s 
Iter 2...	Training loss: 1356702.875000 (16083.064520, 78414.122128, 1262205.880859) in 4.47s 
Iter 3...	Training loss: 979971.625000 (12438.393653, 37501.023952, 930032.162109) in 4.48s 
Iter 4...	Training loss: 703082.875000 (10393.383805, 18155.890147, 674533.609863) in 4.47s 
Iter 5...	Training loss: 512424.531250 (8583.801526, 11642.248956, 492198.451904) in 4.49s 
Top-1 Recall: 0.008452 Precision: 0.008452 NDCG: 0.008452 HR: 0.008452
Top-5 Recall: 0.034865 Precision: 0.006973 NDCG: 0.021001 HR: 0.034865
Top-10 Recall: 0.058109 Precision: 0.005811 NDCG: 0.028415 HR: 0.058109
Eval costs: 0.168780 s
Iter 6...	Training loss: 346469.531250 (7036.286241, 0.000000, 339433.248291) in 4.02s 
Iter 7...	Training loss: 341408.500000 (5849.671348, 15925.148895, 319633.650391) in 4.83s 
Iter 8...	Training loss: 271361.125000 (5000.679373, 6423.492513, 259936.992920) in 4.47s 
Iter 9...	Training loss: 231190.062500 (4381.927916, 5370.656494, 221437.481201) in 4.44s 
Iter 10...	Training loss: 202951.000000 (3983.330208, 4625.121404, 194342.538452) in 4.43s 
Top-1 Recall: 0.030639 Precision: 0.030639 NDCG: 0.030639 HR: 0.030639
Top-5 Recall: 0.088220 Precision: 0.017644 NDCG: 0.059103 HR: 0.088220
Top-10 Recall: 0.141046 Precision: 0.014105 NDCG: 0.075946 HR: 0.141046
Eval costs: 0.171597 s
Iter 11...	Training loss: 169254.734375 (3732.713289, 0.000000, 165522.013306) in 3.92s 
Iter 12...	Training loss: 176062.921875 (3579.009003, 7215.204189, 165268.716797) in 4.92s 
Iter 13...	Training loss: 141177.328125 (3495.032065, 0.000000, 137682.276733) in 3.93s 
Iter 14...	Training loss: 147885.671875 (3453.072611, 5569.286648, 138863.305176) in 4.86s 
Iter 15...	Training loss: 128420.148438 (3461.740980, 2433.487345, 122524.916870) in 4.47s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.125198 Precision: 0.025040 NDCG: 0.083546 HR: 0.125198
Top-10 Recall: 0.179609 Precision: 0.017961 NDCG: 0.101008 HR: 0.179609
Eval costs: 0.176915 s
Iter 16...	Training loss: 113758.875000 (3508.452664, 0.000000, 110250.409119) in 4.05s 
Iter 17...	Training loss: 118685.851562 (3573.953354, 3912.567561, 111199.335938) in 4.82s 
Iter 18...	Training loss: 106191.796875 (3634.440359, 1777.911117, 100779.457581) in 4.44s 
Iter 19...	Training loss: 100129.093750 (3727.984015, 1619.978750, 94781.124878) in 4.45s 
Iter 20...	Training loss: 94711.000000 (3828.673382, 1497.703598, 89384.620728) in 4.45s 
Top-1 Recall: 0.054411 Precision: 0.054411 NDCG: 0.054411 HR: 0.054411
Top-5 Recall: 0.144744 Precision: 0.028949 NDCG: 0.099580 HR: 0.144744
Top-10 Recall: 0.205494 Precision: 0.020549 NDCG: 0.119441 HR: 0.205494
Eval costs: 0.181863 s
Iter 21...	Training loss: 89644.726562 (3924.512547, 1399.729644, 84320.490051) in 4.43s 
Iter 22...	Training loss: 85292.937500 (4045.759620, 1313.164371, 79934.028809) in 4.42s 
Iter 23...	Training loss: 80726.226562 (4165.080239, 1246.127895, 75315.025757) in 4.38s 
Iter 24...	Training loss: 76765.015625 (4295.318534, 1186.023186, 71283.671143) in 4.46s 
Iter 25...	Training loss: 72512.367188 (4427.376068, 1136.689549, 66948.305664) in 4.49s 
Top-1 Recall: 0.061278 Precision: 0.061278 NDCG: 0.061278 HR: 0.061278
Top-5 Recall: 0.160592 Precision: 0.032118 NDCG: 0.111217 HR: 0.160592
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.130002 HR: 0.219229
Eval costs: 0.187087 s
Iter 26...	Training loss: 68378.890625 (4554.161336, 1089.041935, 62735.675598) in 4.48s 
Iter 27...	Training loss: 64522.796875 (4690.967819, 1048.503433, 58783.317139) in 4.46s 
Iter 28...	Training loss: 60615.722656 (4832.101177, 1014.143850, 54769.479309) in 4.46s 
Iter 29...	Training loss: 57168.945312 (5000.654722, 983.242177, 51185.052094) in 4.44s 
Iter 30...	Training loss: 50290.609375 (5148.642424, 0.000000, 45141.966736) in 3.94s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.118274 HR: 0.170629
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.136227 HR: 0.226624
Eval costs: 0.194835 s
Iter 31...	Training loss: 52509.660156 (5313.548790, 1832.657162, 45363.457153) in 4.94s 
Iter 32...	Training loss: 43111.453125 (5479.555502, 0.000000, 37631.898590) in 3.92s 
Iter 33...	Training loss: 45964.140625 (5651.767151, 1746.744253, 38565.632294) in 4.88s 
Iter 34...	Training loss: 40793.750000 (5810.905797, 874.994876, 34107.847839) in 4.48s 
Iter 35...	Training loss: 37979.710938 (5983.406133, 851.714150, 31144.589783) in 4.46s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.119834 HR: 0.170629
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.140897 HR: 0.235605
Eval costs: 0.202039 s
Iter 36...	Training loss: 35898.058594 (6169.760233, 831.485769, 28896.810898) in 4.48s 
Iter 37...	Training loss: 33717.226562 (6338.861948, 816.366939, 26561.998672) in 4.46s 
Iter 38...	Training loss: 32026.316406 (6495.591793, 800.975339, 24729.751434) in 4.48s 
Iter 39...	Training loss: 30743.093750 (6652.216527, 787.477013, 23303.402374) in 4.48s 
Iter 40...	Training loss: 29280.382812 (6817.479659, 774.392382, 21688.508911) in 4.44s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.162705 Precision: 0.032541 NDCG: 0.117281 HR: 0.162705
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.140682 HR: 0.234548
Eval costs: 0.209620 s
Iter 41...	Training loss: 28149.775391 (6964.684995, 761.871558, 20423.218445) in 4.45s 
Iter 42...	Training loss: 27217.486328 (7110.021137, 751.689808, 19355.774139) in 4.42s 
Iter 43...	Training loss: 26488.265625 (7245.794289, 741.267880, 18501.206116) in 4.42s 
Iter 44...	Training loss: 25605.593750 (7380.065020, 731.736688, 17493.792343) in 4.35s 
Iter 45...	Training loss: 24500.560547 (7503.479181, 722.161201, 16274.918610) in 4.47s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.120537 HR: 0.173270
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.139658 HR: 0.232435
Eval costs: 0.215922 s
Iter 46...	Training loss: 21923.835938 (7628.872613, 0.000000, 14294.964127) in 4.03s 
Iter 47...	Training loss: 25953.328125 (7758.400825, 1375.891163, 16819.037613) in 4.82s 
Iter 48...	Training loss: 20777.746094 (7860.039223, 0.000000, 12917.706841) in 4.02s 
Iter 49...	Training loss: 24861.636719 (7980.573131, 1352.752356, 15528.309952) in 4.82s 
Iter 50...	Training loss: 22512.968750 (8080.451386, 692.887847, 13739.627594) in 4.45s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.163233 Precision: 0.032647 NDCG: 0.117237 HR: 0.163233
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.139437 HR: 0.232435
Eval costs: 0.220822 s
Iter 51...	Training loss: 21750.421875 (8187.759604, 679.726285, 12882.933823) in 4.43s 
Iter 52...	Training loss: 21350.097656 (8289.644940, 672.471678, 12387.979492) in 4.42s 
Iter 53...	Training loss: 21269.541016 (8389.817456, 664.076191, 12215.646362) in 4.43s 
Iter 54...	Training loss: 20794.398438 (8492.558108, 656.613442, 11645.226524) in 4.35s 
Iter 55...	Training loss: 20548.736328 (8580.780032, 650.359307, 11317.595062) in 4.47s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.164818 Precision: 0.032964 NDCG: 0.120377 HR: 0.164818
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.140944 HR: 0.228209
Eval costs: 0.227811 s
Iter 56...	Training loss: 20376.246094 (8691.610745, 644.421173, 11040.212158) in 4.46s 
Iter 57...	Training loss: 20166.449219 (8769.080681, 638.321727, 10759.045090) in 4.46s 
Iter 58...	Training loss: 20070.804688 (8864.768201, 633.021939, 10573.012558) in 4.47s 
Iter 59...	Training loss: 19971.156250 (8948.337235, 628.055881, 10394.762978) in 4.47s 
Iter 60...	Training loss: 19826.378906 (9047.537497, 622.552879, 10156.288170) in 4.44s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.121717 HR: 0.169572
Top-10 Recall: 0.227681 Precision: 0.022768 NDCG: 0.140737 HR: 0.227681
Eval costs: 0.228159 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 534182.125000 (192653.120017, 118789.692299, 222739.321899) in 4.61s 
Iter 2...	Training loss: 298264.781250 (16011.911673, 80860.609058, 201392.269531) in 4.44s 
Iter 3...	Training loss: 254722.406250 (12301.626793, 50121.733133, 192299.053223) in 4.43s 
Iter 4...	Training loss: 229935.875000 (10251.457160, 33801.108444, 185883.302734) in 4.42s 
Iter 5...	Training loss: 214407.359375 (8595.901315, 26025.232566, 179786.224243) in 4.45s 
Top-1 Recall: 0.017433 Precision: 0.017433 NDCG: 0.017433 HR: 0.017433
Top-5 Recall: 0.069202 Precision: 0.013840 NDCG: 0.044984 HR: 0.069202
Top-10 Recall: 0.108294 Precision: 0.010829 NDCG: 0.057653 HR: 0.108294
Eval costs: 0.174272 s
Iter 6...	Training loss: 201992.656250 (7280.428249, 21384.508636, 173327.733032) in 4.40s 
Iter 7...	Training loss: 189570.453125 (6209.706681, 17749.923801, 165610.816284) in 4.38s 
Iter 8...	Training loss: 175785.421875 (5360.096883, 14667.688372, 155757.645874) in 4.48s 
Iter 9...	Training loss: 161058.625000 (4668.601784, 11974.092978, 144415.953491) in 4.48s 
Iter 10...	Training loss: 147720.796875 (4144.142856, 9799.135660, 133777.508423) in 4.48s 
Top-1 Recall: 0.035394 Precision: 0.035394 NDCG: 0.035394 HR: 0.035394
Top-5 Recall: 0.097200 Precision: 0.019440 NDCG: 0.066708 HR: 0.097200
Top-10 Recall: 0.139461 Precision: 0.013946 NDCG: 0.080496 HR: 0.139461
Eval costs: 0.171952 s
Iter 11...	Training loss: 135356.031250 (3759.697408, 8140.904515, 123455.443237) in 4.48s 
Iter 12...	Training loss: 122965.742188 (3478.156611, 6799.442286, 112688.149353) in 4.47s 
Iter 13...	Training loss: 110981.648438 (3284.577618, 5681.522223, 102015.545227) in 4.44s 
Iter 14...	Training loss: 99280.476562 (3157.458940, 4801.415875, 91321.603455) in 4.43s 
Iter 15...	Training loss: 88473.984375 (3081.336122, 4091.833258, 81300.808533) in 4.42s 
Top-1 Recall: 0.049657 Precision: 0.049657 NDCG: 0.049657 HR: 0.049657
Top-5 Recall: 0.132066 Precision: 0.026413 NDCG: 0.091861 HR: 0.132066
Top-10 Recall: 0.181722 Precision: 0.018172 NDCG: 0.107744 HR: 0.181722
Eval costs: 0.188648 s
Iter 16...	Training loss: 78574.875000 (3051.069245, 3516.908984, 72006.893982) in 4.42s 
Iter 17...	Training loss: 69776.625000 (3061.545805, 3067.630999, 63647.446716) in 4.36s 
Iter 18...	Training loss: 61918.226562 (3102.874084, 2719.719383, 56095.632660) in 4.46s 
Iter 19...	Training loss: 55336.328125 (3166.034181, 2446.188986, 49724.101318) in 4.48s 
Iter 20...	Training loss: 47557.097656 (3245.904553, 0.000000, 44311.197876) in 4.06s 
Top-1 Recall: 0.054939 Precision: 0.054939 NDCG: 0.054939 HR: 0.054939
Top-5 Recall: 0.147913 Precision: 0.029583 NDCG: 0.103172 HR: 0.147913
Top-10 Recall: 0.197570 Precision: 0.019757 NDCG: 0.119345 HR: 0.197570
Eval costs: 0.201688 s
Iter 21...	Training loss: 47372.332031 (3341.034932, 3945.482647, 40085.817139) in 4.83s 
Iter 22...	Training loss: 39569.183594 (3438.544539, 0.000000, 36130.636383) in 4.01s 
Iter 23...	Training loss: 40007.460938 (3543.586639, 3501.866653, 32962.008057) in 4.84s 
Iter 24...	Training loss: 35608.929688 (3639.338988, 1801.881118, 30167.711975) in 4.41s 
Iter 25...	Training loss: 33537.574219 (3736.041042, 1747.722165, 28053.809494) in 4.42s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.117474 HR: 0.167459
Top-10 Recall: 0.212890 Precision: 0.021289 NDCG: 0.132133 HR: 0.212890
Eval costs: 0.208721 s
Iter 26...	Training loss: 31640.248047 (3831.328778, 1693.927175, 26114.992905) in 4.43s 
Iter 27...	Training loss: 28103.513672 (3915.180987, 0.000000, 24188.332062) in 3.93s 
Iter 28...	Training loss: 29794.861328 (3988.777323, 2956.033085, 22850.049164) in 4.86s 
Iter 29...	Training loss: 26971.705078 (4068.698718, 1600.263048, 21302.742157) in 4.44s 
Iter 30...	Training loss: 25947.871094 (4140.767876, 1589.452404, 20217.651688) in 4.46s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.164289 Precision: 0.032858 NDCG: 0.116565 HR: 0.164289
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.136009 HR: 0.224511
Eval costs: 0.217722 s
Iter 31...	Training loss: 25230.433594 (4196.032160, 1579.277387, 19455.123062) in 4.46s 
Iter 32...	Training loss: 24272.464844 (4255.424122, 1562.406694, 18454.632324) in 4.47s 
Iter 33...	Training loss: 23343.041016 (4311.717307, 1556.754964, 17474.567032) in 4.46s 
Iter 34...	Training loss: 22319.083984 (4355.640702, 1543.485872, 16419.957703) in 4.44s 
Iter 35...	Training loss: 21925.302734 (4400.674552, 1538.792839, 15985.835114) in 4.43s 
Top-1 Recall: 0.077655 Precision: 0.077655 NDCG: 0.077655 HR: 0.077655
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.127107 HR: 0.174855
Top-10 Recall: 0.220814 Precision: 0.022081 NDCG: 0.141849 HR: 0.220814
Eval costs: 0.219187 s
Iter 36...	Training loss: 21133.859375 (4434.903404, 1538.646976, 15160.308197) in 4.41s 
Iter 37...	Training loss: 21147.572266 (4466.170106, 1540.007564, 15141.393784) in 4.42s 
Iter 38...	Training loss: 20498.714844 (4498.963884, 1536.967541, 14462.783836) in 4.35s 
Iter 39...	Training loss: 19966.193359 (4530.045588, 1539.484611, 13896.663254) in 4.47s 
Iter 40...	Training loss: 19594.658203 (4558.136127, 1538.434841, 13498.086456) in 4.46s 
Top-1 Recall: 0.080296 Precision: 0.080296 NDCG: 0.080296 HR: 0.080296
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.129117 HR: 0.176440
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.144666 HR: 0.224511
Eval costs: 0.223463 s
Iter 41...	Training loss: 19022.369141 (4583.119348, 1541.106379, 12898.144127) in 4.48s 
Iter 42...	Training loss: 18700.263672 (4599.893441, 1548.364452, 12552.005081) in 4.46s 
Iter 43...	Training loss: 18458.457031 (4621.116991, 1552.154556, 12285.186317) in 4.47s 
Iter 44...	Training loss: 18237.878906 (4638.296460, 1561.176985, 12038.405998) in 4.44s 
Iter 45...	Training loss: 17616.201172 (4651.280201, 1568.829671, 11396.092140) in 4.42s 
Top-1 Recall: 0.082409 Precision: 0.082409 NDCG: 0.082409 HR: 0.082409
Top-5 Recall: 0.186476 Precision: 0.037295 NDCG: 0.134425 HR: 0.186476
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.147353 HR: 0.226624
Eval costs: 0.226833 s
Iter 46...	Training loss: 15908.697266 (4667.034883, 0.000000, 11241.661591) in 3.92s 
Iter 47...	Training loss: 18440.382812 (4673.093949, 2746.801744, 11020.486748) in 4.91s 
Iter 48...	Training loss: 16872.675781 (4678.032648, 1575.267552, 10619.375885) in 4.38s 
Iter 49...	Training loss: 16619.285156 (4690.289687, 1594.849848, 10334.145248) in 4.48s 
Iter 50...	Training loss: 16449.765625 (4688.570046, 1600.286256, 10160.908401) in 4.46s 
Top-1 Recall: 0.078183 Precision: 0.078183 NDCG: 0.078183 HR: 0.078183
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.126784 HR: 0.173798
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.144096 HR: 0.227153
Eval costs: 0.231096 s
Iter 51...	Training loss: 16263.476562 (4699.718707, 1610.429067, 9953.329475) in 4.48s 
Iter 52...	Training loss: 16195.773438 (4704.183724, 1622.724554, 9868.864326) in 4.47s 
Iter 53...	Training loss: 14276.423828 (4706.435771, 0.000000, 9569.986946) in 4.04s 
Iter 54...	Training loss: 17002.822266 (4709.493421, 2819.417306, 9473.912125) in 4.80s 
Iter 55...	Training loss: 15657.837891 (4712.824474, 1644.075854, 9300.939102) in 4.44s 
Top-1 Recall: 0.078183 Precision: 0.078183 NDCG: 0.078183 HR: 0.078183
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.127515 HR: 0.174326
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.143754 HR: 0.224511
Eval costs: 0.233392 s
Iter 56...	Training loss: 15434.285156 (4710.022638, 1656.957808, 9067.303757) in 4.44s 
Iter 57...	Training loss: 15169.388672 (4710.743360, 1675.478063, 8783.166840) in 4.41s 
Iter 58...	Training loss: 15193.144531 (4710.646977, 1691.355103, 8791.141396) in 4.40s 
Iter 59...	Training loss: 13144.531250 (4709.329252, 0.000000, 8435.203350) in 3.92s 
Iter 60...	Training loss: 16086.583984 (4701.599396, 2917.640872, 8467.343521) in 4.83s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.126992 HR: 0.172742
Top-10 Recall: 0.227681 Precision: 0.022768 NDCG: 0.144667 HR: 0.227681
Eval costs: 0.234660 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 555366.312500 (193304.871084, 118798.441944, 243263.036011) in 4.63s 
Iter 2...	Training loss: 312002.000000 (16037.195643, 80801.558702, 215163.213989) in 4.46s 
Iter 3...	Training loss: 266268.312500 (12306.654934, 49624.035822, 204337.667480) in 4.46s 
Iter 4...	Training loss: 239768.953125 (10226.317611, 33090.425041, 196452.213745) in 4.47s 
Iter 5...	Training loss: 222711.718750 (8593.554434, 24959.004540, 189159.169556) in 4.46s 
Top-1 Recall: 0.017961 Precision: 0.017961 NDCG: 0.017961 HR: 0.017961
Top-5 Recall: 0.075541 Precision: 0.015108 NDCG: 0.047696 HR: 0.075541
Top-10 Recall: 0.108822 Precision: 0.010882 NDCG: 0.058426 HR: 0.108822
Eval costs: 0.173865 s
Iter 6...	Training loss: 208934.812500 (7245.002907, 20090.310316, 181599.508911) in 4.47s 
Iter 7...	Training loss: 195059.968750 (6184.043562, 16491.997086, 172383.921997) in 4.48s 
Iter 8...	Training loss: 180420.921875 (5328.868585, 13442.170450, 161649.878906) in 4.47s 
Iter 9...	Training loss: 164986.609375 (4643.913216, 10860.216163, 149482.485596) in 4.44s 
Iter 10...	Training loss: 151081.859375 (4112.010562, 8882.319200, 138087.541016) in 4.41s 
Top-1 Recall: 0.038563 Precision: 0.038563 NDCG: 0.038563 HR: 0.038563
Top-5 Recall: 0.100898 Precision: 0.020180 NDCG: 0.069545 HR: 0.100898
Top-10 Recall: 0.150026 Precision: 0.015003 NDCG: 0.085484 HR: 0.150026
Eval costs: 0.173704 s
Iter 11...	Training loss: 138431.171875 (3730.616310, 7442.474775, 127258.067749) in 4.42s 
Iter 12...	Training loss: 118900.843750 (3459.873279, 0.000000, 115440.968994) in 3.94s 
Iter 13...	Training loss: 118742.125000 (3275.407710, 10626.968091, 104839.750854) in 4.88s 
Iter 14...	Training loss: 101880.062500 (3148.735284, 4546.982665, 94184.343506) in 4.45s 
Iter 15...	Training loss: 90534.851562 (3080.644377, 3907.215926, 83546.983337) in 4.47s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.128896 Precision: 0.025779 NDCG: 0.087460 HR: 0.128896
Top-10 Recall: 0.183307 Precision: 0.018331 NDCG: 0.105171 HR: 0.183307
Eval costs: 0.189700 s
Iter 16...	Training loss: 80342.132812 (3060.328515, 3362.185589, 73919.622925) in 4.48s 
Iter 17...	Training loss: 71476.984375 (3077.707550, 2954.581788, 65444.688721) in 4.47s 
Iter 18...	Training loss: 63531.582031 (3124.816347, 2636.997871, 57769.771393) in 4.45s 
Iter 19...	Training loss: 57177.625000 (3200.572188, 2378.267598, 51598.788300) in 4.43s 
Iter 20...	Training loss: 51558.542969 (3291.705266, 2182.742696, 46084.094360) in 4.42s 
Top-1 Recall: 0.057052 Precision: 0.057052 NDCG: 0.057052 HR: 0.057052
Top-5 Recall: 0.150555 Precision: 0.030111 NDCG: 0.104272 HR: 0.150555
Top-10 Recall: 0.203381 Precision: 0.020338 NDCG: 0.121358 HR: 0.203381
Eval costs: 0.199507 s
Iter 21...	Training loss: 44582.609375 (3386.721105, 0.000000, 41195.887665) in 3.93s 
Iter 22...	Training loss: 44621.558594 (3495.299747, 3563.430337, 37562.824066) in 4.86s 
Iter 23...	Training loss: 39520.183594 (3601.449140, 1815.667088, 34103.061554) in 4.49s 
Iter 24...	Training loss: 36763.746094 (3706.447531, 1745.934917, 31311.364655) in 4.49s 
Iter 25...	Training loss: 34406.800781 (3807.042186, 1678.211729, 28921.550354) in 4.47s 
Top-1 Recall: 0.061278 Precision: 0.061278 NDCG: 0.061278 HR: 0.061278
Top-5 Recall: 0.168516 Precision: 0.033703 NDCG: 0.115079 HR: 0.168516
Top-10 Recall: 0.217116 Precision: 0.021712 NDCG: 0.130912 HR: 0.217116
Eval costs: 0.207778 s
Iter 26...	Training loss: 32376.117188 (3902.139909, 1628.336342, 26845.638672) in 4.47s 
Iter 27...	Training loss: 30911.625000 (3990.223911, 1586.918593, 25334.483047) in 4.46s 
Iter 28...	Training loss: 29163.822266 (4078.613278, 1554.743542, 23530.464432) in 4.45s 
Iter 29...	Training loss: 27890.521484 (4153.685387, 1526.947872, 22209.889893) in 4.44s 
Iter 30...	Training loss: 26626.714844 (4230.299105, 1503.764390, 20892.653076) in 4.43s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.122367 HR: 0.174855
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.139571 HR: 0.228209
Eval costs: 0.218302 s
Iter 31...	Training loss: 25641.865234 (4292.197963, 1486.798024, 19862.868073) in 4.44s 
Iter 32...	Training loss: 24721.570312 (4355.340814, 1473.565782, 18892.664749) in 4.42s 
Iter 33...	Training loss: 23889.566406 (4412.728444, 1469.819873, 18007.017319) in 4.36s 
Iter 34...	Training loss: 22916.253906 (4454.787359, 1459.427126, 17002.041840) in 4.46s 
Iter 35...	Training loss: 22443.302734 (4511.283092, 1448.331331, 16483.690399) in 4.47s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.180666 Precision: 0.036133 NDCG: 0.127511 HR: 0.180666
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.143631 HR: 0.230851
Eval costs: 0.218930 s
Iter 36...	Training loss: 21739.294922 (4545.257509, 1440.270649, 15753.769150) in 4.47s 
Iter 37...	Training loss: 21147.615234 (4579.499873, 1440.121572, 15127.992264) in 4.46s 
Iter 38...	Training loss: 20557.455078 (4622.028766, 1436.174162, 14499.251884) in 4.47s 
Iter 39...	Training loss: 14420.423828 (0.000000, 1432.018005, 12988.406113) in 3.20s 
Iter 40...	Training loss: 24161.015625 (8662.727345, 1430.905285, 14067.382317) in 5.67s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.127422 HR: 0.176968
Top-10 Recall: 0.228737 Precision: 0.022874 NDCG: 0.144199 HR: 0.228737
Eval costs: 0.223062 s
Iter 41...	Training loss: 11784.849609 (0.000000, 0.000000, 11784.850281) in 2.82s 
Iter 42...	Training loss: 24703.607422 (8604.984469, 2517.759740, 13580.863152) in 6.08s 
Iter 43...	Training loss: 17002.714844 (4526.929499, 0.000000, 12475.785576) in 3.95s 
Iter 44...	Training loss: 19455.486328 (4715.155871, 2513.769132, 12226.562050) in 4.84s 
Iter 45...	Training loss: 18037.955078 (4765.919083, 1435.122926, 11836.913536) in 4.46s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.128594 HR: 0.176440
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.145684 HR: 0.229794
Eval costs: 0.227010 s
Iter 46...	Training loss: 17823.625000 (4800.994279, 1444.992922, 11577.638718) in 4.48s 
Iter 47...	Training loss: 16022.532227 (4824.468218, 0.000000, 11198.063034) in 4.03s 
Iter 48...	Training loss: 18308.828125 (4835.536369, 2518.122481, 10955.169632) in 4.82s 
Iter 49...	Training loss: 17006.945312 (4843.149598, 1458.049053, 10705.747238) in 4.44s 
Iter 50...	Training loss: 16703.970703 (4844.057561, 1464.960176, 10394.954941) in 4.43s 
Top-1 Recall: 0.080296 Precision: 0.080296 NDCG: 0.080296 HR: 0.080296
Top-5 Recall: 0.178553 Precision: 0.035711 NDCG: 0.129687 HR: 0.178553
Top-10 Recall: 0.236661 Precision: 0.023666 NDCG: 0.148426 HR: 0.236661
Eval costs: 0.229609 s
Iter 51...	Training loss: 16721.037109 (4851.838835, 1469.984267, 10399.214157) in 4.43s 
Iter 52...	Training loss: 16415.986328 (4837.649306, 1476.910557, 10101.426125) in 4.42s 
Iter 53...	Training loss: 16047.443359 (4852.177784, 1482.744779, 9712.522690) in 4.35s 
Iter 54...	Training loss: 16072.052734 (4844.728744, 1493.392956, 9733.930557) in 4.47s 
Iter 55...	Training loss: 15820.963867 (4846.184260, 1502.743552, 9472.035339) in 4.46s 
Top-1 Recall: 0.080824 Precision: 0.080824 NDCG: 0.080824 HR: 0.080824
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.130950 HR: 0.177496
Top-10 Recall: 0.235077 Precision: 0.023508 NDCG: 0.149709 HR: 0.235077
Eval costs: 0.233593 s
Iter 56...	Training loss: 15512.655273 (4843.486735, 1510.039216, 9159.127762) in 4.47s 
Iter 57...	Training loss: 15471.549805 (4843.163517, 1520.667618, 9107.719337) in 4.48s 
Iter 58...	Training loss: 15136.964844 (4840.366400, 1527.149126, 8769.449554) in 4.46s 
Iter 59...	Training loss: 15125.730469 (4842.776482, 1538.086338, 8744.868256) in 4.44s 
Iter 60...	Training loss: 14878.208008 (4836.433976, 1546.336020, 8495.438866) in 4.40s 
Top-1 Recall: 0.080824 Precision: 0.080824 NDCG: 0.080824 HR: 0.080824
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.129258 HR: 0.174855
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.147435 HR: 0.230851
Eval costs: 0.236021 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 742561.250000 (192869.694956, 118818.617500, 430872.956543) in 4.61s 
Iter 2...	Training loss: 415009.531250 (16078.080399, 80138.071655, 318793.399170) in 4.42s 
Iter 3...	Training loss: 269611.718750 (12299.261620, 0.000000, 257312.458252) in 3.95s 
Iter 4...	Training loss: 338790.437500 (10216.982853, 68798.751791, 259774.718750) in 4.92s 
Iter 5...	Training loss: 264491.718750 (8543.833799, 20405.060082, 235542.849609) in 4.38s 
Top-1 Recall: 0.024828 Precision: 0.024828 NDCG: 0.024828 HR: 0.024828
Top-5 Recall: 0.080824 Precision: 0.016165 NDCG: 0.053390 HR: 0.080824
Top-10 Recall: 0.109878 Precision: 0.010988 NDCG: 0.062750 HR: 0.109878
Eval costs: 0.268335 s
Iter 6...	Training loss: 237312.359375 (7158.988493, 14911.269166, 215242.115845) in 4.40s 
Iter 7...	Training loss: 214258.031250 (6026.316448, 11698.594906, 196533.119507) in 4.39s 
Iter 8...	Training loss: 193297.250000 (5123.752283, 9504.540519, 178668.945435) in 4.46s 
Iter 9...	Training loss: 174474.000000 (4448.279118, 7802.727144, 162222.996338) in 4.47s 
Iter 10...	Training loss: 159011.843750 (3964.153539, 6470.994613, 148576.683228) in 4.47s 
Top-1 Recall: 0.034865 Precision: 0.034865 NDCG: 0.034865 HR: 0.034865
Top-5 Recall: 0.109350 Precision: 0.021870 NDCG: 0.072184 HR: 0.109350
Top-10 Recall: 0.156894 Precision: 0.015689 NDCG: 0.087724 HR: 0.156894
Eval costs: 0.175822 s
Iter 11...	Training loss: 145415.500000 (3632.425552, 5466.435841, 136316.662231) in 4.47s 
Iter 12...	Training loss: 132997.750000 (3401.380607, 4605.182664, 124991.187378) in 4.46s 
Iter 13...	Training loss: 121672.976562 (3256.935387, 3907.615263, 114508.433228) in 4.44s 
Iter 14...	Training loss: 106703.664062 (3170.228564, 0.000000, 103533.449890) in 3.92s 
Iter 15...	Training loss: 105964.953125 (3135.071743, 5795.863546, 97034.002563) in 4.92s 
Top-1 Recall: 0.045959 Precision: 0.045959 NDCG: 0.045959 HR: 0.045959
Top-5 Recall: 0.129424 Precision: 0.025885 NDCG: 0.089355 HR: 0.129424
Top-10 Recall: 0.191759 Precision: 0.019176 NDCG: 0.109464 HR: 0.191759
Eval costs: 0.184722 s
Iter 16...	Training loss: 93602.085938 (3134.524147, 2648.344596, 87819.212708) in 4.44s 
Iter 17...	Training loss: 85175.140625 (3163.193244, 2341.587278, 79670.359314) in 4.37s 
Iter 18...	Training loss: 77628.070312 (3218.516282, 2113.782357, 72295.768188) in 4.47s 
Iter 19...	Training loss: 69889.656250 (3300.567378, 1930.751696, 64658.340637) in 4.48s 
Iter 20...	Training loss: 63421.230469 (3396.543144, 1782.232336, 58242.456970) in 4.46s 
Top-1 Recall: 0.054939 Precision: 0.054939 NDCG: 0.054939 HR: 0.054939
Top-5 Recall: 0.155309 Precision: 0.031062 NDCG: 0.105400 HR: 0.155309
Top-10 Recall: 0.217116 Precision: 0.021712 NDCG: 0.125075 HR: 0.217116
Eval costs: 0.193914 s
Iter 21...	Training loss: 57067.710938 (3509.746917, 1666.676949, 51891.286346) in 4.46s 
Iter 22...	Training loss: 51472.292969 (3635.932863, 1569.672791, 46266.687164) in 4.47s 
Iter 23...	Training loss: 47242.714844 (3770.247119, 1490.689580, 41981.781586) in 4.44s 
Iter 24...	Training loss: 43117.492188 (3901.067762, 1427.490176, 37788.933807) in 4.44s 
Iter 25...	Training loss: 40043.914062 (4041.177455, 1374.120151, 34628.618256) in 4.42s 
Top-1 Recall: 0.061278 Precision: 0.061278 NDCG: 0.061278 HR: 0.061278
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.116144 HR: 0.167987
Top-10 Recall: 0.221870 Precision: 0.022187 NDCG: 0.133409 HR: 0.221870
Eval costs: 0.202866 s
Iter 26...	Training loss: 37124.042969 (4163.491974, 1333.881517, 31626.671097) in 4.42s 
Iter 27...	Training loss: 34758.074219 (4294.194515, 1295.048028, 29168.832764) in 4.37s 
Iter 28...	Training loss: 32916.660156 (4401.071452, 1266.016858, 27249.574615) in 4.48s 
Iter 29...	Training loss: 30818.845703 (4508.432127, 1235.599343, 25074.818329) in 4.47s 
Iter 30...	Training loss: 29400.396484 (4601.545189, 1211.052238, 23587.799149) in 4.49s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.125347 HR: 0.172742
Top-10 Recall: 0.225568 Precision: 0.022557 NDCG: 0.142411 HR: 0.225568
Eval costs: 0.211978 s
Iter 31...	Training loss: 27991.773438 (4687.412094, 1192.772577, 22111.587936) in 4.48s 
Iter 32...	Training loss: 26775.470703 (4760.709692, 1173.803295, 20840.960815) in 4.47s 
Iter 33...	Training loss: 25635.791016 (4838.925409, 1161.248759, 19635.617493) in 4.45s 
Iter 34...	Training loss: 25057.263672 (4903.691074, 1150.177031, 19003.397751) in 4.45s 
Iter 35...	Training loss: 22316.449219 (4959.555682, 0.000000, 17356.893280) in 3.96s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.123955 HR: 0.171157
Top-10 Recall: 0.229794 Precision: 0.022979 NDCG: 0.142973 HR: 0.229794
Eval costs: 0.216385 s
Iter 36...	Training loss: 24738.437500 (5015.399071, 2083.805495, 17639.232513) in 4.93s 
Iter 37...	Training loss: 22739.451172 (5069.024218, 1133.812291, 16536.614807) in 4.43s 
Iter 38...	Training loss: 22047.203125 (5112.345890, 1124.304006, 15810.552979) in 4.34s 
Iter 39...	Training loss: 21585.671875 (5162.474456, 1114.683659, 15308.512230) in 4.66s 
Iter 40...	Training loss: 20894.390625 (5197.300359, 1106.902686, 14590.184364) in 4.47s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.127742 HR: 0.174855
Top-10 Recall: 0.227681 Precision: 0.022768 NDCG: 0.144799 HR: 0.227681
Eval costs: 0.221347 s
Iter 41...	Training loss: 20618.433594 (5226.231109, 1099.601354, 14292.600838) in 4.47s 
Iter 42...	Training loss: 20040.966797 (5254.103298, 1096.688273, 13690.175911) in 4.47s 
Iter 43...	Training loss: 19747.720703 (5290.607194, 1091.227917, 13365.885567) in 4.52s 
Iter 44...	Training loss: 19146.224609 (5319.523057, 1087.437778, 12739.264366) in 4.45s 
Iter 45...	Training loss: 18976.867188 (5343.463587, 1084.884946, 12548.521118) in 4.45s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.128216 HR: 0.176968
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.146121 HR: 0.232435
Eval costs: 0.224818 s
Iter 46...	Training loss: 18643.941406 (5367.720035, 1079.051118, 12197.168785) in 4.46s 
Iter 47...	Training loss: 18597.171875 (5389.672834, 1078.428585, 12129.069221) in 4.41s 
Iter 48...	Training loss: 18166.000000 (5410.890654, 1078.269926, 11676.839012) in 4.34s 
Iter 49...	Training loss: 17931.900391 (5425.577429, 1076.442375, 11429.879440) in 4.45s 
Iter 50...	Training loss: 17539.550781 (5433.624113, 1075.743934, 11030.181519) in 4.49s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.125095 HR: 0.171157
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.145018 HR: 0.232435
Eval costs: 0.229253 s
Iter 51...	Training loss: 17546.740234 (5448.877272, 1076.577557, 11021.284538) in 4.51s 
Iter 52...	Training loss: 17184.531250 (5480.252569, 1072.597160, 10631.683456) in 4.49s 
Iter 53...	Training loss: 15215.605469 (5485.312021, 0.000000, 9730.294289) in 4.06s 
Iter 54...	Training loss: 17960.812500 (5501.061940, 1930.972657, 10528.775970) in 4.85s 
Iter 55...	Training loss: 16567.732422 (5508.803727, 1081.788932, 9977.138565) in 4.43s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.127916 HR: 0.174326
Top-10 Recall: 0.223983 Precision: 0.022398 NDCG: 0.143747 HR: 0.223983
Eval costs: 0.234280 s
Iter 56...	Training loss: 16369.297852 (5511.578633, 1076.606306, 9781.113464) in 4.43s 
Iter 57...	Training loss: 14648.451172 (5517.936701, 0.000000, 9130.514938) in 3.93s 
Iter 58...	Training loss: 17359.326172 (5522.429765, 1926.823565, 9910.072136) in 5.04s 
Iter 59...	Training loss: 15819.666016 (5529.000261, 1087.958698, 9202.705994) in 4.37s 
Iter 60...	Training loss: 15717.888672 (5531.935889, 1083.480035, 9102.472713) in 4.50s 
Top-1 Recall: 0.078183 Precision: 0.078183 NDCG: 0.078183 HR: 0.078183
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.124650 HR: 0.167459
Top-10 Recall: 0.219229 Precision: 0.021923 NDCG: 0.141240 HR: 0.219229
Eval costs: 0.235044 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.1000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2526438.250000 (192414.095190, 118814.946068, 2215209.397461) in 4.63s 
Iter 2...	Training loss: 1358926.750000 (16037.077892, 78602.988712, 1264286.697266) in 4.49s 
Iter 3...	Training loss: 983519.500000 (12294.925347, 37620.805620, 933603.704102) in 4.47s 
Iter 4...	Training loss: 707651.875000 (10204.874781, 18183.663563, 679263.351562) in 4.49s 
Iter 5...	Training loss: 519274.468750 (8339.662076, 11602.927415, 499331.851074) in 4.45s 
Top-1 Recall: 0.011094 Precision: 0.011094 NDCG: 0.011094 HR: 0.011094
Top-5 Recall: 0.040148 Precision: 0.008030 NDCG: 0.024641 HR: 0.040148
Top-10 Recall: 0.063391 Precision: 0.006339 NDCG: 0.032035 HR: 0.063391
Eval costs: 0.169492 s
Iter 6...	Training loss: 401570.187500 (6793.628340, 8833.424482, 385943.106934) in 4.49s 
Iter 7...	Training loss: 323092.218750 (5634.658726, 7244.830157, 310212.686768) in 4.46s 
Iter 8...	Training loss: 245987.781250 (4814.990393, 0.000000, 241172.787109) in 3.99s 
Iter 9...	Training loss: 249602.734375 (4274.577151, 10865.190008, 234462.957520) in 4.92s 
Iter 10...	Training loss: 207553.015625 (3914.196809, 4546.474956, 199092.356934) in 4.43s 
Top-1 Recall: 0.034337 Precision: 0.034337 NDCG: 0.034337 HR: 0.034337
Top-5 Recall: 0.099842 Precision: 0.019968 NDCG: 0.067188 HR: 0.099842
Top-10 Recall: 0.145800 Precision: 0.014580 NDCG: 0.081991 HR: 0.145800
Eval costs: 0.172487 s
Iter 11...	Training loss: 183575.265625 (3685.605184, 3864.768582, 176024.889771) in 4.46s 
Iter 12...	Training loss: 165024.593750 (3542.498046, 3332.360237, 158149.703613) in 4.38s 
Iter 13...	Training loss: 141550.406250 (3473.379622, 0.000000, 138077.054077) in 4.06s 
Iter 14...	Training loss: 147116.937500 (3439.618838, 5201.261583, 138476.055542) in 4.86s 
Iter 15...	Training loss: 129242.328125 (3431.514192, 2289.715584, 123521.093628) in 4.55s 
Top-1 Recall: 0.045959 Precision: 0.045959 NDCG: 0.045959 HR: 0.045959
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.090716 HR: 0.136820
Top-10 Recall: 0.181194 Precision: 0.018119 NDCG: 0.104933 HR: 0.181194
Eval costs: 0.177699 s
Iter 16...	Training loss: 120757.421875 (3464.787172, 2042.452404, 115250.183838) in 4.48s 
Iter 17...	Training loss: 113522.156250 (3501.566572, 1852.711563, 108167.881470) in 4.47s 
Iter 18...	Training loss: 107452.281250 (3556.845701, 1693.913779, 102201.525085) in 4.48s 
Iter 19...	Training loss: 102246.242188 (3609.779819, 1565.262224, 97071.196594) in 4.55s 
Iter 20...	Training loss: 97626.406250 (3680.462435, 1456.630370, 92489.300110) in 4.44s 
Top-1 Recall: 0.059694 Precision: 0.059694 NDCG: 0.059694 HR: 0.059694
Top-5 Recall: 0.149498 Precision: 0.029900 NDCG: 0.104017 HR: 0.149498
Top-10 Recall: 0.208663 Precision: 0.020866 NDCG: 0.123209 HR: 0.208663
Eval costs: 0.183103 s
Iter 21...	Training loss: 92890.406250 (3756.792248, 1365.419264, 87768.187256) in 4.50s 
Iter 22...	Training loss: 88225.750000 (3832.991133, 1289.656001, 83103.106995) in 4.42s 
Iter 23...	Training loss: 84309.437500 (3907.859328, 1225.067030, 79176.511902) in 4.40s 
Iter 24...	Training loss: 80332.562500 (3983.241467, 1166.521195, 75182.800598) in 4.46s 
Iter 25...	Training loss: 76182.164062 (4073.788311, 1113.625147, 70994.751526) in 4.49s 
Top-1 Recall: 0.062863 Precision: 0.062863 NDCG: 0.062863 HR: 0.062863
Top-5 Recall: 0.162176 Precision: 0.032435 NDCG: 0.113590 HR: 0.162176
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.133875 HR: 0.225040
Eval costs: 0.192473 s
Iter 26...	Training loss: 72598.835938 (4153.425699, 1071.416311, 67373.989685) in 4.47s 
Iter 27...	Training loss: 68569.468750 (4252.804383, 1033.607603, 63283.061401) in 4.50s 
Iter 28...	Training loss: 64894.207031 (4356.498239, 998.379929, 59539.330750) in 4.48s 
Iter 29...	Training loss: 58244.605469 (4455.730258, 0.000000, 53788.874878) in 3.95s 
Iter 30...	Training loss: 60436.804688 (4573.775588, 1853.302459, 54009.726440) in 5.08s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.121859 HR: 0.170100
Top-10 Recall: 0.234548 Precision: 0.023455 NDCG: 0.142635 HR: 0.234548
Eval costs: 0.194275 s
Iter 31...	Training loss: 54455.585938 (4692.212175, 920.465956, 48842.916718) in 4.43s 
Iter 32...	Training loss: 50956.582031 (4801.574943, 891.229653, 45263.776489) in 4.72s 
Iter 33...	Training loss: 44906.902344 (4917.842710, 0.000000, 39989.059479) in 3.92s 
Iter 34...	Training loss: 47375.542969 (5038.418989, 1667.933149, 40669.190491) in 4.83s 
Iter 35...	Training loss: 42354.664062 (5163.510968, 836.488492, 36354.665405) in 4.46s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.124023 HR: 0.173270
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.144245 HR: 0.235605
Eval costs: 0.202512 s
Iter 36...	Training loss: 39588.386719 (5306.206741, 815.796028, 33466.383759) in 4.54s 
Iter 37...	Training loss: 37291.996094 (5435.880876, 798.860599, 31057.250061) in 4.46s 
Iter 38...	Training loss: 35609.828125 (5558.532626, 782.722002, 29268.573608) in 4.47s 
Iter 39...	Training loss: 33688.062500 (5677.797893, 770.191621, 27240.070877) in 4.43s 
Iter 40...	Training loss: 32167.244141 (5781.096325, 756.416801, 25629.734650) in 4.41s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.126059 HR: 0.173798
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.146151 HR: 0.235605
Eval costs: 0.211156 s
Iter 41...	Training loss: 30999.541016 (5884.432211, 744.677733, 24370.430588) in 4.43s 
Iter 42...	Training loss: 29741.156250 (5993.220212, 734.445417, 23013.491272) in 4.42s 
Iter 43...	Training loss: 28864.578125 (6066.160579, 723.731550, 22074.686447) in 4.36s 
Iter 44...	Training loss: 27791.009766 (6165.739359, 714.506711, 20910.764832) in 4.48s 
Iter 45...	Training loss: 26926.582031 (6255.767103, 706.926689, 19963.890762) in 4.46s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.126688 HR: 0.173270
Top-10 Recall: 0.240887 Precision: 0.024089 NDCG: 0.148730 HR: 0.240887
Eval costs: 0.218412 s
Iter 46...	Training loss: 26208.339844 (6335.584805, 697.490265, 19175.264175) in 4.49s 
Iter 47...	Training loss: 25815.376953 (6400.639934, 690.386642, 18724.351974) in 4.45s 
Iter 48...	Training loss: 25230.333984 (6471.360327, 684.570264, 18074.404068) in 4.75s 
Iter 49...	Training loss: 24659.656250 (6526.556508, 675.789395, 17457.312012) in 4.49s 
Iter 50...	Training loss: 24173.990234 (6584.588764, 668.845467, 16920.557449) in 4.44s 
Top-1 Recall: 0.075541 Precision: 0.075541 NDCG: 0.075541 HR: 0.075541
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.124304 HR: 0.169044
Top-10 Recall: 0.237190 Precision: 0.023719 NDCG: 0.146618 HR: 0.237190
Eval costs: 0.226136 s
Iter 51...	Training loss: 23619.882812 (6629.575189, 661.398623, 16328.906937) in 4.54s 
Iter 52...	Training loss: 23253.535156 (6685.047573, 656.037760, 15912.449310) in 4.51s 
Iter 53...	Training loss: 22942.531250 (6730.367147, 650.004773, 15562.157845) in 4.43s 
Iter 54...	Training loss: 22456.716797 (6773.717695, 644.909741, 15038.088905) in 4.39s 
Iter 55...	Training loss: 22311.814453 (6816.376566, 639.004572, 14856.432938) in 4.48s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.125906 HR: 0.171157
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.147312 HR: 0.238246
Eval costs: 0.228043 s
Iter 56...	Training loss: 22059.835938 (6855.335909, 634.333211, 14570.166542) in 4.47s 
Iter 57...	Training loss: 21753.511719 (6873.428424, 629.607457, 14250.473579) in 4.46s 
Iter 58...	Training loss: 19157.539062 (6909.461466, 0.000000, 12248.077431) in 4.12s 
Iter 59...	Training loss: 23186.589844 (6932.983947, 1201.582820, 15052.022934) in 5.09s 
Iter 60...	Training loss: 18655.609375 (6964.109914, 0.000000, 11691.500793) in 3.95s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.125741 HR: 0.172742
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.144387 HR: 0.230851
Eval costs: 0.231857 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 727189.500000 (193065.907569, 185913.139854, 348210.448242) in 5.13s 
Iter 2...	Training loss: 314030.343750 (15827.690590, 29044.695299, 269157.983154) in 4.46s 
Iter 3...	Training loss: 262635.437500 (11614.177400, 21594.428870, 229426.847778) in 4.43s 
Iter 4...	Training loss: 229864.921875 (9153.650905, 18015.755539, 202695.500488) in 4.46s 
Iter 5...	Training loss: 202542.140625 (7265.941982, 15107.717406, 180168.492676) in 4.44s 
Top-1 Recall: 0.033281 Precision: 0.033281 NDCG: 0.033281 HR: 0.033281
Top-5 Recall: 0.098257 Precision: 0.019651 NDCG: 0.067098 HR: 0.098257
Top-10 Recall: 0.133122 Precision: 0.013312 NDCG: 0.078204 HR: 0.133122
Eval costs: 0.174906 s
Iter 6...	Training loss: 179667.906250 (5875.366537, 12326.981830, 161465.566895) in 4.47s 
Iter 7...	Training loss: 162183.093750 (4919.374398, 10100.582478, 147163.125610) in 4.38s 
Iter 8...	Training loss: 148265.187500 (4244.899896, 8410.451786, 135609.838257) in 4.54s 
Iter 9...	Training loss: 136974.812500 (3766.846218, 7045.110513, 126162.861938) in 4.49s 
Iter 10...	Training loss: 120596.203125 (3428.916206, 0.000000, 117167.285706) in 4.05s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.127311 Precision: 0.025462 NDCG: 0.089281 HR: 0.127311
Top-10 Recall: 0.178553 Precision: 0.017855 NDCG: 0.105832 HR: 0.178553
Eval costs: 0.177854 s
Iter 11...	Training loss: 122726.742188 (3184.287433, 10375.557938, 109166.903687) in 4.82s 
Iter 12...	Training loss: 108781.539062 (3004.944118, 4353.432687, 101423.150452) in 4.52s 
Iter 13...	Training loss: 100754.718750 (2874.989181, 3669.370931, 94210.354248) in 4.49s 
Iter 14...	Training loss: 92237.289062 (2783.522818, 3129.378326, 86324.388733) in 4.43s 
Iter 15...	Training loss: 84367.507812 (2720.119291, 2706.647163, 78940.731567) in 4.47s 
Top-1 Recall: 0.058109 Precision: 0.058109 NDCG: 0.058109 HR: 0.058109
Top-5 Recall: 0.159535 Precision: 0.031907 NDCG: 0.109228 HR: 0.159535
Top-10 Recall: 0.212361 Precision: 0.021236 NDCG: 0.126265 HR: 0.212361
Eval costs: 0.188075 s
Iter 16...	Training loss: 77268.117188 (2679.513915, 2381.669327, 72206.938477) in 4.43s 
Iter 17...	Training loss: 70206.281250 (2662.078785, 2128.286668, 65415.915833) in 4.43s 
Iter 18...	Training loss: 63907.476562 (2656.016230, 1926.369504, 59325.089813) in 4.40s 
Iter 19...	Training loss: 58208.816406 (2666.986444, 1774.368634, 53767.460876) in 4.47s 
Iter 20...	Training loss: 53166.593750 (2682.195293, 1659.871105, 48824.526581) in 4.59s 
Top-1 Recall: 0.068674 Precision: 0.068674 NDCG: 0.068674 HR: 0.068674
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.118874 HR: 0.167987
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.137883 HR: 0.227153
Eval costs: 0.201952 s
Iter 21...	Training loss: 48539.929688 (2704.680627, 1569.981646, 44265.267578) in 4.51s 
Iter 22...	Training loss: 45023.640625 (2728.275104, 1504.022878, 40791.343811) in 4.49s 
Iter 23...	Training loss: 41774.226562 (2751.342185, 1455.571335, 37567.315796) in 4.53s 
Iter 24...	Training loss: 38918.500000 (2771.569908, 1419.143189, 34727.787506) in 4.44s 
Iter 25...	Training loss: 36698.300781 (2789.359380, 1386.482418, 32522.457886) in 4.43s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.121390 HR: 0.170629
Top-10 Recall: 0.229266 Precision: 0.022927 NDCG: 0.140475 HR: 0.229266
Eval costs: 0.210809 s
Iter 26...	Training loss: 34587.148438 (2799.924127, 1367.195186, 30420.030731) in 4.42s 
Iter 27...	Training loss: 32977.632812 (2810.017477, 1350.121487, 28817.495483) in 4.42s 
Iter 28...	Training loss: 31320.621094 (2814.497196, 1337.119487, 27169.002502) in 4.36s 
Iter 29...	Training loss: 29921.541016 (2815.642576, 1330.385251, 25775.514816) in 4.51s 
Iter 30...	Training loss: 28589.519531 (2816.067172, 1322.724820, 24450.724564) in 4.50s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.126188 HR: 0.177496
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.143245 HR: 0.230322
Eval costs: 0.221014 s
Iter 31...	Training loss: 27242.062500 (2814.914155, 1321.497722, 23105.651917) in 4.48s 
Iter 32...	Training loss: 26329.615234 (2807.628106, 1319.694105, 22202.291977) in 4.48s 
Iter 33...	Training loss: 25355.050781 (2800.197018, 1324.638488, 21230.213470) in 4.47s 
Iter 34...	Training loss: 24536.074219 (2791.132440, 1329.464630, 20415.478210) in 4.47s 
Iter 35...	Training loss: 23983.199219 (2779.245447, 1333.893456, 19870.061432) in 4.44s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.126558 HR: 0.175911
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.144357 HR: 0.230851
Eval costs: 0.222623 s
Iter 36...	Training loss: 21512.513672 (2767.721663, 0.000000, 18744.790451) in 4.01s 
Iter 37...	Training loss: 23362.980469 (2754.173814, 2397.345042, 18211.461609) in 4.91s 
Iter 38...	Training loss: 21766.115234 (2741.356090, 1358.530858, 17666.227325) in 4.42s 
Iter 39...	Training loss: 21074.167969 (2728.028281, 1369.274362, 16976.864563) in 4.36s 
Iter 40...	Training loss: 15495.718750 (0.000000, 1377.698439, 14118.021095) in 3.26s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.126130 HR: 0.174855
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.142149 HR: 0.224511
Eval costs: 0.227547 s
Iter 41...	Training loss: 23911.447266 (4860.263236, 1396.395995, 17654.789818) in 5.64s 
Iter 42...	Training loss: 19713.988281 (2727.356232, 1411.385098, 15575.247192) in 4.64s 
Iter 43...	Training loss: 17786.015625 (2710.472849, 0.000000, 15075.542557) in 4.05s 
Iter 44...	Training loss: 19726.826172 (2687.688698, 2497.811825, 14541.327087) in 4.80s 
Iter 45...	Training loss: 18274.470703 (2664.683721, 1455.539459, 14154.248161) in 4.45s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.126843 HR: 0.173270
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.143504 HR: 0.224511
Eval costs: 0.231624 s
Iter 46...	Training loss: 17842.675781 (2647.727147, 1478.349667, 13716.597824) in 4.53s 
Iter 47...	Training loss: 17627.925781 (2630.927125, 1496.849612, 13500.146095) in 4.41s 
Iter 48...	Training loss: 17344.625000 (2614.187480, 1522.502558, 13207.934113) in 4.43s 
Iter 49...	Training loss: 16836.371094 (2599.734640, 1542.399767, 12694.235413) in 4.35s 
Iter 50...	Training loss: 16774.025391 (2587.184889, 1562.920535, 12623.918716) in 4.47s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.126262 HR: 0.176968
Top-10 Recall: 0.231907 Precision: 0.023191 NDCG: 0.143547 HR: 0.231907
Eval costs: 0.233784 s
Iter 51...	Training loss: 16551.402344 (2572.184510, 1586.663423, 12392.553955) in 4.48s 
Iter 52...	Training loss: 16179.767578 (2558.895750, 1608.906804, 12011.964111) in 4.47s 
Iter 53...	Training loss: 15903.816406 (2546.638660, 1633.592866, 11723.582840) in 4.47s 
Iter 54...	Training loss: 15645.064453 (2534.692061, 1657.428701, 11452.943283) in 4.47s 
Iter 55...	Training loss: 15240.715820 (2524.900581, 1683.747863, 11032.067390) in 4.44s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.179081 Precision: 0.035816 NDCG: 0.128165 HR: 0.179081
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.144795 HR: 0.230851
Eval costs: 0.235830 s
Iter 56...	Training loss: 15138.448242 (2509.677253, 1704.526760, 10924.242973) in 4.44s 
Iter 57...	Training loss: 13074.321289 (2498.294669, 0.000000, 10576.026817) in 3.91s 
Iter 58...	Training loss: 15984.093750 (2489.493476, 2915.124514, 10579.475197) in 4.92s 
Iter 59...	Training loss: 14635.015625 (2479.087703, 1772.683261, 10383.243935) in 4.42s 
Iter 60...	Training loss: 12590.236328 (2472.284351, 0.000000, 10117.953354) in 4.01s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.125535 HR: 0.173270
Top-10 Recall: 0.226096 Precision: 0.022610 NDCG: 0.142682 HR: 0.226096
Eval costs: 0.238583 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 750290.625000 (192421.997286, 185938.069931, 371930.488525) in 5.08s 
Iter 2...	Training loss: 331369.843750 (15809.511411, 29025.047774, 286535.252441) in 4.48s 
Iter 3...	Training loss: 276951.437500 (11604.577499, 21371.929728, 243974.951294) in 4.47s 
Iter 4...	Training loss: 221042.875000 (9127.348368, 0.000000, 211915.509399) in 4.05s 
Iter 5...	Training loss: 231826.687500 (7243.039941, 34015.541318, 190568.089722) in 4.84s 
Top-1 Recall: 0.032752 Precision: 0.032752 NDCG: 0.032752 HR: 0.032752
Top-5 Recall: 0.098785 Precision: 0.019757 NDCG: 0.066559 HR: 0.098785
Top-10 Recall: 0.131009 Precision: 0.013101 NDCG: 0.076900 HR: 0.131009
Eval costs: 0.174939 s
Iter 6...	Training loss: 188318.640625 (5860.273926, 12451.589010, 170006.793701) in 4.47s 
Iter 7...	Training loss: 169209.109375 (4901.910577, 9899.926810, 154407.271851) in 4.55s 
Iter 8...	Training loss: 153839.968750 (4232.056928, 8063.328222, 141544.577759) in 4.47s 
Iter 9...	Training loss: 141316.359375 (3755.762589, 6644.821488, 130915.774780) in 4.45s 
Iter 10...	Training loss: 130730.000000 (3417.403339, 5543.670290, 121768.934570) in 4.45s 
Top-1 Recall: 0.053354 Precision: 0.053354 NDCG: 0.053354 HR: 0.053354
Top-5 Recall: 0.132066 Precision: 0.026413 NDCG: 0.093176 HR: 0.132066
Top-10 Recall: 0.173798 Precision: 0.017380 NDCG: 0.106480 HR: 0.173798
Eval costs: 0.176706 s
Iter 11...	Training loss: 120817.500000 (3175.410112, 4675.089105, 112966.989197) in 4.42s 
Iter 12...	Training loss: 111920.632812 (2996.496017, 3964.792303, 104959.336792) in 4.43s 
Iter 13...	Training loss: 103228.203125 (2866.910534, 3399.353222, 96961.942261) in 4.38s 
Iter 14...	Training loss: 95494.968750 (2778.613269, 2948.031514, 89768.337830) in 4.48s 
Iter 15...	Training loss: 87133.625000 (2711.904148, 2576.299563, 81845.419312) in 4.48s 
Top-1 Recall: 0.057052 Precision: 0.057052 NDCG: 0.057052 HR: 0.057052
Top-5 Recall: 0.152139 Precision: 0.030428 NDCG: 0.105213 HR: 0.152139
Top-10 Recall: 0.208135 Precision: 0.020814 NDCG: 0.123410 HR: 0.208135
Eval costs: 0.186778 s
Iter 16...	Training loss: 79506.992188 (2672.274634, 2280.236850, 74554.486816) in 4.49s 
Iter 17...	Training loss: 72520.031250 (2655.523568, 2048.453742, 67816.056519) in 4.56s 
Iter 18...	Training loss: 65987.859375 (2651.943245, 1863.401584, 61472.522217) in 4.55s 
Iter 19...	Training loss: 60041.906250 (2660.383144, 1721.668571, 55659.855774) in 4.46s 
Iter 20...	Training loss: 54830.113281 (2676.354871, 1613.594817, 50540.157013) in 4.45s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.119125 HR: 0.167987
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.139585 HR: 0.230851
Eval costs: 0.198862 s
Iter 21...	Training loss: 50432.117188 (2702.368052, 1523.525804, 46206.224274) in 4.46s 
Iter 22...	Training loss: 46104.742188 (2725.810473, 1454.297760, 41924.633759) in 4.44s 
Iter 23...	Training loss: 43076.203125 (2750.007233, 1406.882554, 38919.310242) in 4.46s 
Iter 24...	Training loss: 40488.675781 (2771.722167, 1366.365741, 36350.588867) in 4.46s 
Iter 25...	Training loss: 38007.773438 (2790.296504, 1334.317755, 33883.161621) in 4.47s 
Top-1 Recall: 0.075013 Precision: 0.075013 NDCG: 0.075013 HR: 0.075013
Top-5 Recall: 0.179609 Precision: 0.035922 NDCG: 0.126936 HR: 0.179609
Top-10 Recall: 0.237190 Precision: 0.023719 NDCG: 0.145427 HR: 0.237190
Eval costs: 0.211259 s
Iter 26...	Training loss: 35644.492188 (2800.941575, 1306.724782, 31536.830536) in 4.48s 
Iter 27...	Training loss: 33740.019531 (2814.526018, 1291.240882, 29634.255005) in 4.48s 
Iter 28...	Training loss: 30748.566406 (2818.372847, 0.000000, 27930.193848) in 4.03s 
Iter 29...	Training loss: 31769.761719 (2823.697214, 2314.939126, 26631.124435) in 4.91s 
Iter 30...	Training loss: 29145.294922 (2825.054202, 1260.214152, 25060.028076) in 4.44s 
Top-1 Recall: 0.076070 Precision: 0.076070 NDCG: 0.076070 HR: 0.076070
Top-5 Recall: 0.180666 Precision: 0.036133 NDCG: 0.129747 HR: 0.180666
Top-10 Recall: 0.241416 Precision: 0.024142 NDCG: 0.149327 HR: 0.241416
Eval costs: 0.218919 s
Iter 31...	Training loss: 28010.937500 (2820.664264, 1253.502469, 23936.769241) in 4.44s 
Iter 32...	Training loss: 27110.005859 (2812.934659, 1251.314361, 23045.756592) in 4.44s 
Iter 33...	Training loss: 26074.865234 (2810.689500, 1249.576316, 22014.599899) in 4.42s 
Iter 34...	Training loss: 25128.121094 (2801.310425, 1249.091890, 21077.718460) in 4.42s 
Iter 35...	Training loss: 22971.804688 (2789.563277, 0.000000, 20182.241318) in 4.11s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.179609 Precision: 0.035922 NDCG: 0.129858 HR: 0.179609
Top-10 Recall: 0.241944 Precision: 0.024194 NDCG: 0.149899 HR: 0.241944
Eval costs: 0.222129 s
Iter 36...	Training loss: 24588.453125 (2780.884191, 2232.834862, 19574.734558) in 4.83s 
Iter 37...	Training loss: 22906.089844 (2768.571151, 1259.219314, 18878.298309) in 4.47s 
Iter 38...	Training loss: 21957.355469 (2757.075461, 1265.437922, 17934.843262) in 4.50s 
Iter 39...	Training loss: 21460.714844 (2748.239058, 1271.318578, 17441.158447) in 4.46s 
Iter 40...	Training loss: 21086.103516 (2732.277638, 1280.443582, 17073.380997) in 4.46s 
Top-1 Recall: 0.079768 Precision: 0.079768 NDCG: 0.079768 HR: 0.079768
Top-5 Recall: 0.181722 Precision: 0.036344 NDCG: 0.132145 HR: 0.181722
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.149502 HR: 0.235605
Eval costs: 0.225568 s
Iter 41...	Training loss: 20362.052734 (2719.156639, 1291.631944, 16351.265381) in 4.46s 
Iter 42...	Training loss: 19862.533203 (2703.555600, 1301.268813, 15857.710320) in 4.44s 
Iter 43...	Training loss: 19370.658203 (2695.028749, 1310.282949, 15365.345192) in 4.43s 
Iter 44...	Training loss: 19139.753906 (2679.786647, 1323.526655, 15136.440086) in 4.33s 
Iter 45...	Training loss: 18627.136719 (2666.797993, 1335.600252, 14624.739052) in 4.46s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.128623 HR: 0.173798
Top-10 Recall: 0.232964 Precision: 0.023296 NDCG: 0.147661 HR: 0.232964
Eval costs: 0.229611 s
Iter 46...	Training loss: 18291.703125 (2657.777296, 1351.630024, 14282.295036) in 4.46s 
Iter 47...	Training loss: 17853.324219 (2643.225315, 1365.789793, 13844.308586) in 4.46s 
Iter 48...	Training loss: 17415.355469 (2630.334318, 1379.654388, 13405.365799) in 4.46s 
Iter 49...	Training loss: 17166.865234 (2617.205907, 1396.661933, 13152.997490) in 4.46s 
Iter 50...	Training loss: 15365.617188 (2605.822721, 0.000000, 12759.793617) in 4.04s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.128592 HR: 0.177496
Top-10 Recall: 0.238774 Precision: 0.023877 NDCG: 0.148376 HR: 0.238774
Eval costs: 0.234411 s
Iter 51...	Training loss: 17670.472656 (2596.055684, 2435.613515, 12638.804077) in 4.92s 
Iter 52...	Training loss: 16118.339844 (2584.262437, 1450.268081, 12083.809738) in 4.43s 
Iter 53...	Training loss: 15909.258789 (2574.478321, 1468.460018, 11866.319252) in 4.41s 
Iter 54...	Training loss: 15782.911133 (2562.788525, 1488.039813, 11732.083153) in 4.35s 
Iter 55...	Training loss: 15516.908203 (2551.361718, 1505.674102, 11459.872688) in 4.47s 
Top-1 Recall: 0.077655 Precision: 0.077655 NDCG: 0.077655 HR: 0.077655
Top-5 Recall: 0.175383 Precision: 0.035077 NDCG: 0.128636 HR: 0.175383
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.146504 HR: 0.230322
Eval costs: 0.235752 s
Iter 56...	Training loss: 15340.116211 (2543.369998, 1526.117218, 11270.628723) in 4.48s 
Iter 57...	Training loss: 15030.552734 (2533.165342, 1550.310162, 10947.076370) in 4.47s 
Iter 58...	Training loss: 13100.541992 (2524.003118, 0.000000, 10576.539421) in 4.03s 
Iter 59...	Training loss: 15710.397461 (2514.723355, 2643.119663, 10552.555061) in 4.81s 
Iter 60...	Training loss: 14476.500000 (2504.128041, 1602.073491, 10370.298256) in 4.45s 
Top-1 Recall: 0.077126 Precision: 0.077126 NDCG: 0.077126 HR: 0.077126
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.124284 HR: 0.169044
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.144160 HR: 0.230322
Eval costs: 0.239734 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 866356.625000 (193273.834085, 118711.972301, 554370.814209) in 4.66s 
Iter 2...	Training loss: 479314.562500 (15816.979740, 79890.552792, 383607.031982) in 4.49s 
Iter 3...	Training loss: 305481.125000 (11599.710218, 0.000000, 293881.405029) in 3.95s 
Iter 4...	Training loss: 349882.937500 (9108.802670, 65155.751580, 275618.388184) in 4.92s 
Iter 5...	Training loss: 226153.203125 (7214.113144, 0.000000, 218939.063232) in 4.32s 
Top-1 Recall: 0.033809 Precision: 0.033809 NDCG: 0.033809 HR: 0.033809
Top-5 Recall: 0.101426 Precision: 0.020285 NDCG: 0.069268 HR: 0.101426
Top-10 Recall: 0.135763 Precision: 0.013576 NDCG: 0.080271 HR: 0.135763
Eval costs: 0.175161 s
Iter 6...	Training loss: 239396.812500 (5809.921410, 29389.828274, 204197.068237) in 4.91s 
Iter 7...	Training loss: 192806.031250 (4844.813707, 10175.004842, 177786.213745) in 4.43s 
Iter 8...	Training loss: 157233.937500 (4185.376467, 0.000000, 153048.542603) in 3.94s 
Iter 9...	Training loss: 162163.875000 (3728.571306, 12535.433599, 145899.883423) in 4.85s 
Iter 10...	Training loss: 141652.406250 (3412.374828, 5127.206788, 133112.808716) in 4.48s 
Top-1 Recall: 0.048600 Precision: 0.048600 NDCG: 0.048600 HR: 0.048600
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.092724 HR: 0.136820
Top-10 Recall: 0.181722 Precision: 0.018172 NDCG: 0.107279 HR: 0.181722
Eval costs: 0.176573 s
Iter 11...	Training loss: 130513.414062 (3186.228016, 4161.258935, 123165.921875) in 4.59s 
Iter 12...	Training loss: 121017.406250 (3024.920900, 3481.117412, 114511.371704) in 4.62s 
Iter 13...	Training loss: 112806.828125 (2905.794561, 3017.250919, 106883.781982) in 4.48s 
Iter 14...	Training loss: 105362.710938 (2815.211717, 2637.886990, 99909.602600) in 4.48s 
Iter 15...	Training loss: 98290.992188 (2750.846905, 2336.926291, 93203.214905) in 4.53s 
Top-1 Recall: 0.060222 Precision: 0.060222 NDCG: 0.060222 HR: 0.060222
Top-5 Recall: 0.157950 Precision: 0.031590 NDCG: 0.109483 HR: 0.157950
Top-10 Recall: 0.216059 Precision: 0.021606 NDCG: 0.128198 HR: 0.216059
Eval costs: 0.184961 s
Iter 16...	Training loss: 91763.445312 (2701.395032, 2096.954772, 86965.098938) in 4.47s 
Iter 17...	Training loss: 77531.656250 (0.000000, 0.000000, 77531.659424) in 2.78s 
Iter 18...	Training loss: 85250.914062 (5004.529807, 3409.277442, 76837.107910) in 6.10s 
Iter 19...	Training loss: 71147.906250 (2703.782046, 0.000000, 68444.124939) in 3.97s 
Iter 20...	Training loss: 63801.828125 (0.000000, 2967.260214, 60834.568848) in 3.68s 
Top-1 Recall: 0.062335 Precision: 0.062335 NDCG: 0.062335 HR: 0.062335
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.117724 HR: 0.171157
Top-10 Recall: 0.237190 Precision: 0.023719 NDCG: 0.138934 HR: 0.237190
Eval costs: 0.193499 s
Iter 21...	Training loss: 66091.976562 (5002.338122, 1469.988384, 59619.649719) in 5.63s 
Iter 22...	Training loss: 58055.718750 (2774.831817, 1386.751728, 53894.136139) in 4.48s 
Iter 23...	Training loss: 53292.558594 (2774.148383, 1317.799453, 49200.614166) in 4.48s 
Iter 24...	Training loss: 49121.039062 (2776.421983, 1263.243964, 45081.375458) in 4.47s 
Iter 25...	Training loss: 45930.242188 (2785.197732, 1222.999392, 41922.038361) in 4.45s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.124231 HR: 0.173270
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.144757 HR: 0.237718
Eval costs: 0.204697 s
Iter 26...	Training loss: 43132.167969 (2801.427688, 1187.753859, 39142.988037) in 4.47s 
Iter 27...	Training loss: 39727.882812 (2810.685248, 1160.216926, 35756.980927) in 4.43s 
Iter 28...	Training loss: 35870.144531 (2824.872128, 0.000000, 33045.276947) in 3.94s 
Iter 29...	Training loss: 37198.539062 (2834.953456, 2071.181877, 32292.402557) in 4.87s 
Iter 30...	Training loss: 32073.929688 (2838.861861, 0.000000, 29235.064865) in 4.03s 
Top-1 Recall: 0.080824 Precision: 0.080824 NDCG: 0.080824 HR: 0.080824
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.127085 HR: 0.170629
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.148515 HR: 0.237718
Eval costs: 0.214744 s
Iter 31...	Training loss: 33413.406250 (2845.308463, 2009.963895, 28558.132065) in 4.85s 
Iter 32...	Training loss: 30820.203125 (2848.842176, 1084.712522, 26886.647995) in 4.49s 
Iter 33...	Training loss: 29688.419922 (2849.335822, 1069.461935, 25769.618484) in 4.50s 
Iter 34...	Training loss: 28190.708984 (2848.143283, 1052.161551, 24290.405914) in 4.48s 
Iter 35...	Training loss: 21668.273438 (0.000000, 1040.155470, 20628.117844) in 3.23s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.128181 HR: 0.176440
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.145541 HR: 0.230851
Eval costs: 0.316983 s
Iter 36...	Training loss: 30068.070312 (5117.502939, 1033.236239, 23917.331177) in 5.61s 
Iter 37...	Training loss: 25461.339844 (2888.295294, 1025.568697, 21547.477249) in 4.43s 
Iter 38...	Training loss: 22742.832031 (2878.846895, 0.000000, 19863.985657) in 3.98s 
Iter 39...	Training loss: 25017.806641 (2857.498685, 1849.022649, 20311.284775) in 4.89s 
Iter 40...	Training loss: 23200.632812 (2838.713521, 1024.503292, 19337.416779) in 4.47s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.175383 Precision: 0.035077 NDCG: 0.128931 HR: 0.175383
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.147823 HR: 0.234020
Eval costs: 0.225634 s
Iter 41...	Training loss: 20689.916016 (2818.932992, 0.000000, 17870.982803) in 4.04s 
Iter 42...	Training loss: 23013.404297 (2801.170948, 1826.323627, 18385.909302) in 4.82s 
Iter 43...	Training loss: 21255.707031 (2787.850739, 1023.813320, 17444.043472) in 4.44s 
Iter 44...	Training loss: 20525.589844 (2773.408028, 1017.701145, 16734.480820) in 4.47s 
Iter 45...	Training loss: 20344.890625 (2760.270217, 1015.000644, 16569.620651) in 4.44s 
Top-1 Recall: 0.075541 Precision: 0.075541 NDCG: 0.075541 HR: 0.075541
Top-5 Recall: 0.178024 Precision: 0.035605 NDCG: 0.128648 HR: 0.178024
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.145633 HR: 0.231379
Eval costs: 0.230334 s
Iter 46...	Training loss: 19582.796875 (2750.293397, 1013.569435, 15818.933853) in 4.46s 
Iter 47...	Training loss: 19176.636719 (2734.245410, 1013.086957, 15429.304993) in 4.42s 
Iter 48...	Training loss: 18891.433594 (2725.464939, 1012.993920, 15152.972641) in 4.41s 
Iter 49...	Training loss: 18461.589844 (2713.282543, 1013.749782, 14734.556396) in 4.43s 
Iter 50...	Training loss: 16580.195312 (2705.427039, 0.000000, 13874.766830) in 3.93s 
Top-1 Recall: 0.075541 Precision: 0.075541 NDCG: 0.075541 HR: 0.075541
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.125346 HR: 0.171157
Top-10 Recall: 0.228737 Precision: 0.022874 NDCG: 0.143877 HR: 0.228737
Eval costs: 0.232641 s
Iter 51...	Training loss: 18824.199219 (2696.263503, 1810.648251, 14317.287422) in 4.87s 
Iter 52...	Training loss: 17273.064453 (2686.046129, 1033.071870, 13553.943947) in 4.46s 
Iter 53...	Training loss: 17210.537109 (2674.519580, 1033.415294, 13502.601311) in 4.48s 
Iter 54...	Training loss: 16840.242188 (2669.045489, 1037.192103, 13134.003578) in 4.49s 
Iter 55...	Training loss: 16513.125000 (2660.901402, 1039.981607, 12812.242172) in 4.47s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.170100 Precision: 0.034020 NDCG: 0.123715 HR: 0.170100
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.142161 HR: 0.227153
Eval costs: 0.236020 s
Iter 56...	Training loss: 16287.144531 (2651.909090, 1043.415837, 12591.821259) in 4.47s 
Iter 57...	Training loss: 15805.823242 (2643.151916, 1048.749258, 12113.921806) in 4.45s 
Iter 58...	Training loss: 15738.570312 (2634.013038, 1049.097106, 12055.461639) in 4.43s 
Iter 59...	Training loss: 15537.392578 (2624.490054, 1051.995660, 11860.907707) in 4.40s 
Iter 60...	Training loss: 15332.593750 (2615.267637, 1056.996110, 11660.329437) in 4.35s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.169572 Precision: 0.033914 NDCG: 0.122421 HR: 0.169572
Top-10 Recall: 0.222398 Precision: 0.022240 NDCG: 0.139223 HR: 0.222398
Eval costs: 0.334361 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2635811.750000 (192382.112445, 118802.944847, 2324626.473633) in 4.65s 
Iter 2...	Training loss: 1401529.375000 (15761.603612, 78381.814590, 1307386.134766) in 4.48s 
Iter 3...	Training loss: 1021771.750000 (11592.798672, 37254.462341, 972924.506836) in 4.47s 
Iter 4...	Training loss: 753361.187500 (9131.963487, 17860.105154, 726369.239258) in 4.47s 
Iter 5...	Training loss: 555499.875000 (7234.733298, 11334.763309, 536930.328369) in 4.47s 
Top-1 Recall: 0.013735 Precision: 0.013735 NDCG: 0.013735 HR: 0.013735
Top-5 Recall: 0.058109 Precision: 0.011622 NDCG: 0.036464 HR: 0.058109
Top-10 Recall: 0.093502 Precision: 0.009350 NDCG: 0.048029 HR: 0.093502
Eval costs: 0.167711 s
Iter 6...	Training loss: 422615.843750 (5832.456324, 8451.473862, 408331.895996) in 4.48s 
Iter 7...	Training loss: 331507.937500 (4883.068030, 6751.610789, 319873.265625) in 4.47s 
Iter 8...	Training loss: 270959.125000 (4277.916742, 5555.467226, 261125.760986) in 4.48s 
Iter 9...	Training loss: 228373.203125 (3884.023368, 4657.239966, 219831.906372) in 4.44s 
Iter 10...	Training loss: 197942.984375 (3609.815259, 3955.070935, 190378.095337) in 4.46s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.099842 Precision: 0.019968 NDCG: 0.070300 HR: 0.099842
Top-10 Recall: 0.152139 Precision: 0.015214 NDCG: 0.086924 HR: 0.152139
Eval costs: 0.167820 s
Iter 11...	Training loss: 175752.281250 (3416.925641, 3398.962354, 168936.413330) in 4.43s 
Iter 12...	Training loss: 158635.218750 (3280.218278, 2955.006679, 152399.996338) in 4.44s 
Iter 13...	Training loss: 145174.796875 (3164.198219, 2605.428596, 139405.169067) in 4.38s 
Iter 14...	Training loss: 135534.765625 (3078.329373, 2320.370375, 130136.075317) in 4.48s 
Iter 15...	Training loss: 127149.984375 (3002.686898, 2089.066607, 122058.238159) in 4.49s 
Top-1 Recall: 0.049128 Precision: 0.049128 NDCG: 0.049128 HR: 0.049128
Top-5 Recall: 0.137348 Precision: 0.027470 NDCG: 0.093709 HR: 0.137348
Top-10 Recall: 0.199155 Precision: 0.019915 NDCG: 0.113580 HR: 0.199155
Eval costs: 0.175659 s
Iter 16...	Training loss: 115165.640625 (2944.572336, 0.000000, 112221.067566) in 4.05s 
Iter 17...	Training loss: 119334.429688 (2885.745329, 3513.666937, 112935.006165) in 4.81s 
Iter 18...	Training loss: 109545.148438 (2835.954167, 1623.218975, 105085.990234) in 4.48s 
Iter 19...	Training loss: 104962.500000 (2804.202339, 1501.591810, 100656.709351) in 4.44s 
Iter 20...	Training loss: 100336.937500 (2774.744387, 1401.088549, 96161.107300) in 4.42s 
Top-1 Recall: 0.057052 Precision: 0.057052 NDCG: 0.057052 HR: 0.057052
Top-5 Recall: 0.156366 Precision: 0.031273 NDCG: 0.107371 HR: 0.156366
Top-10 Recall: 0.219757 Precision: 0.021976 NDCG: 0.127983 HR: 0.219757
Eval costs: 0.185588 s
Iter 21...	Training loss: 96490.515625 (2756.034004, 1315.392122, 92419.098450) in 4.42s 
Iter 22...	Training loss: 92652.210938 (2740.114298, 1240.119468, 88671.976624) in 4.42s 
Iter 23...	Training loss: 89351.140625 (2728.126067, 1178.014336, 85444.985107) in 4.37s 
Iter 24...	Training loss: 85631.757812 (2726.157503, 1122.537132, 81783.065796) in 4.47s 
Iter 25...	Training loss: 82561.164062 (2721.257395, 1073.090164, 78766.823364) in 4.46s 
Top-1 Recall: 0.062863 Precision: 0.062863 NDCG: 0.062863 HR: 0.062863
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.116410 HR: 0.167459
Top-10 Recall: 0.242472 Precision: 0.024247 NDCG: 0.140507 HR: 0.242472
Eval costs: 0.187313 s
Iter 26...	Training loss: 78732.335938 (2715.545370, 1027.189362, 74989.608093) in 4.47s 
Iter 27...	Training loss: 72782.109375 (2726.399347, 0.000000, 70055.706909) in 4.04s 
Iter 28...	Training loss: 75670.468750 (2734.017369, 1891.820711, 71044.637695) in 4.83s 
Iter 29...	Training loss: 69702.500000 (2744.449370, 931.739274, 66026.317444) in 4.44s 
Iter 30...	Training loss: 66299.726562 (2762.700130, 898.464253, 62638.565491) in 4.45s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.126989 HR: 0.177496
Top-10 Recall: 0.239303 Precision: 0.023930 NDCG: 0.146806 HR: 0.239303
Eval costs: 0.193949 s
Iter 31...	Training loss: 63066.906250 (2779.841664, 870.301858, 59416.767975) in 4.43s 
Iter 32...	Training loss: 59814.683594 (2804.411902, 845.136103, 56165.127350) in 4.43s 
Iter 33...	Training loss: 54170.058594 (2832.234990, 0.000000, 51337.824890) in 4.36s 
Iter 34...	Training loss: 56685.269531 (2857.052743, 1573.640206, 52254.581787) in 4.87s 
Iter 35...	Training loss: 48580.113281 (2882.565388, 0.000000, 45697.546326) in 4.04s 
Top-1 Recall: 0.077655 Precision: 0.077655 NDCG: 0.077655 HR: 0.077655
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.128658 HR: 0.176968
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.146013 HR: 0.230851
Eval costs: 0.202945 s
Iter 36...	Training loss: 51232.332031 (2916.367586, 1509.695654, 46806.267120) in 4.85s 
Iter 37...	Training loss: 42950.859375 (2947.948981, 0.000000, 40002.904816) in 4.00s 
Iter 38...	Training loss: 46162.792969 (2980.006198, 1447.964923, 41734.822632) in 4.82s 
Iter 39...	Training loss: 41772.843750 (3011.642573, 731.372800, 38029.824524) in 4.45s 
Iter 40...	Training loss: 39415.058594 (3046.550280, 711.003762, 35657.501251) in 4.43s 
Top-1 Recall: 0.081352 Precision: 0.081352 NDCG: 0.081352 HR: 0.081352
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.131001 HR: 0.176968
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.149195 HR: 0.234020
Eval costs: 0.212306 s
Iter 41...	Training loss: 37604.292969 (3076.252758, 697.901543, 33830.136078) in 4.44s 
Iter 42...	Training loss: 36041.773438 (3098.006674, 682.163097, 32261.602509) in 4.43s 
Iter 43...	Training loss: 34626.230469 (3122.725154, 671.379581, 30832.127869) in 4.41s 
Iter 44...	Training loss: 33160.445312 (3140.733445, 660.988179, 29358.722794) in 4.35s 
Iter 45...	Training loss: 31792.005859 (3155.200178, 653.448066, 27983.356567) in 4.47s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.180666 Precision: 0.036133 NDCG: 0.130850 HR: 0.180666
Top-10 Recall: 0.237190 Precision: 0.023719 NDCG: 0.148726 HR: 0.237190
Eval costs: 0.218609 s
Iter 46...	Training loss: 30495.625000 (3168.545697, 642.547986, 26684.531281) in 4.52s 
Iter 47...	Training loss: 23178.820312 (0.000000, 634.805809, 22544.014526) in 3.26s 
Iter 48...	Training loss: 32760.458984 (5615.482917, 628.360067, 26516.613480) in 5.63s 
Iter 49...	Training loss: 27836.222656 (3245.949100, 619.413717, 23970.864365) in 4.48s 
Iter 50...	Training loss: 27393.146484 (3246.938003, 614.607750, 23531.601440) in 4.45s 
Top-1 Recall: 0.081881 Precision: 0.081881 NDCG: 0.081881 HR: 0.081881
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.129415 HR: 0.175911
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.147477 HR: 0.232435
Eval costs: 0.224102 s
Iter 51...	Training loss: 24048.642578 (3234.265566, 0.000000, 20814.376892) in 3.94s 
Iter 52...	Training loss: 28018.816406 (3224.333204, 1169.881344, 23624.601120) in 4.94s 
Iter 53...	Training loss: 25236.828125 (3213.265923, 605.332453, 21418.228897) in 4.42s 
Iter 54...	Training loss: 22118.613281 (3199.700013, 0.000000, 18918.911652) in 3.94s 
Iter 55...	Training loss: 25923.777344 (3194.210361, 1140.787644, 21588.778778) in 4.87s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.178553 Precision: 0.035711 NDCG: 0.127610 HR: 0.178553
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.143626 HR: 0.228209
Eval costs: 0.228269 s
Iter 56...	Training loss: 23655.691406 (3180.648165, 592.697359, 19882.345947) in 4.50s 
Iter 57...	Training loss: 23085.076172 (3173.169908, 583.423658, 19328.483368) in 4.47s 
Iter 58...	Training loss: 20253.777344 (3163.769233, 0.000000, 17090.005386) in 4.02s 
Iter 59...	Training loss: 23965.603516 (3154.113723, 1104.838593, 19706.652176) in 4.81s 
Iter 60...	Training loss: 19513.173828 (3143.623427, 0.000000, 16369.551239) in 3.93s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.125262 HR: 0.172742
Top-10 Recall: 0.227153 Precision: 0.022715 NDCG: 0.142610 HR: 0.227153
Eval costs: 0.230188 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.0100 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1955653.250000 (192938.804840, 185714.729938, 1576999.788086) in 5.12s 
Iter 2...	Training loss: 947783.687500 (15573.678883, 28963.834679, 903246.172363) in 4.45s 
Iter 3...	Training loss: 585190.187500 (10831.733914, 0.000000, 574358.510498) in 3.95s 
Iter 4...	Training loss: 446195.437500 (8184.428898, 44034.238157, 393976.752930) in 4.93s 
Iter 5...	Training loss: 306237.250000 (6335.305478, 15436.671531, 284465.272339) in 4.42s 
Top-1 Recall: 0.036450 Precision: 0.036450 NDCG: 0.036450 HR: 0.036450
Top-5 Recall: 0.106181 Precision: 0.021236 NDCG: 0.071963 HR: 0.106181
Top-10 Recall: 0.143687 Precision: 0.014369 NDCG: 0.083965 HR: 0.143687
Eval costs: 0.173503 s
Iter 6...	Training loss: 235240.156250 (5070.488212, 12253.050291, 217916.625610) in 4.45s 
Iter 7...	Training loss: 192535.734375 (4199.847878, 9888.043665, 178447.842163) in 4.42s 
Iter 8...	Training loss: 165231.812500 (3588.816213, 8154.982066, 153487.988770) in 4.39s 
Iter 9...	Training loss: 146782.750000 (3155.844323, 6788.769994, 136838.132324) in 4.48s 
Iter 10...	Training loss: 133582.968750 (2837.444365, 5686.122331, 125059.398193) in 4.47s 
Top-1 Recall: 0.059165 Precision: 0.059165 NDCG: 0.059165 HR: 0.059165
Top-5 Recall: 0.137876 Precision: 0.027575 NDCG: 0.098983 HR: 0.137876
Top-10 Recall: 0.195457 Precision: 0.019546 NDCG: 0.117560 HR: 0.195457
Eval costs: 0.174639 s
Iter 11...	Training loss: 123479.765625 (2596.640079, 4775.859195, 116107.259277) in 4.47s 
Iter 12...	Training loss: 114709.289062 (2408.026395, 4033.569291, 108267.701782) in 4.48s 
Iter 13...	Training loss: 107153.656250 (2254.051586, 3445.244505, 101454.357544) in 4.47s 
Iter 14...	Training loss: 100014.382812 (2125.464362, 2952.966036, 94935.954102) in 4.45s 
Iter 15...	Training loss: 93740.203125 (2020.653682, 2574.419568, 89145.132385) in 4.43s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.117056 HR: 0.165346
Top-10 Recall: 0.225040 Precision: 0.022504 NDCG: 0.136352 HR: 0.225040
Eval costs: 0.184206 s
Iter 16...	Training loss: 87869.187500 (1930.965799, 2261.005175, 83677.211487) in 4.43s 
Iter 17...	Training loss: 82180.921875 (1857.595947, 2018.976337, 78304.351624) in 4.43s 
Iter 18...	Training loss: 76500.203125 (1793.256193, 1822.837795, 72884.108704) in 4.38s 
Iter 19...	Training loss: 71479.460938 (1741.349378, 1676.242500, 68061.875366) in 4.46s 
Iter 20...	Training loss: 66099.484375 (1695.826433, 1559.480369, 62844.179260) in 4.47s 
Top-1 Recall: 0.067618 Precision: 0.067618 NDCG: 0.067618 HR: 0.067618
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.121607 HR: 0.172213
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.142779 HR: 0.238246
Eval costs: 0.195417 s
Iter 21...	Training loss: 60460.562500 (1657.954619, 0.000000, 58802.605286) in 4.04s 
Iter 22...	Training loss: 59314.464844 (1628.532818, 2665.510278, 55020.421509) in 4.81s 
Iter 23...	Training loss: 54287.292969 (1601.917494, 1367.913279, 51317.460175) in 4.47s 
Iter 24...	Training loss: 49314.070312 (1580.611680, 0.000000, 47733.458710) in 3.95s 
Iter 25...	Training loss: 48935.382812 (1561.174504, 2398.417750, 44975.788971) in 4.91s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.124275 HR: 0.176968
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.144103 HR: 0.237718
Eval costs: 0.204710 s
Iter 26...	Training loss: 43352.222656 (1543.352273, 0.000000, 41808.870361) in 3.97s 
Iter 27...	Training loss: 43730.062500 (1528.005800, 2301.917945, 39900.139435) in 4.92s 
Iter 28...	Training loss: 40329.601562 (1514.364372, 1245.578480, 37569.660828) in 4.36s 
Iter 29...	Training loss: 38534.160156 (1499.583089, 1231.606226, 35802.970154) in 4.47s 
Iter 30...	Training loss: 36612.781250 (1488.606989, 1225.955386, 33898.219238) in 4.46s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.179081 Precision: 0.035816 NDCG: 0.125921 HR: 0.179081
Top-10 Recall: 0.239831 Precision: 0.023983 NDCG: 0.145491 HR: 0.239831
Eval costs: 0.214103 s
Iter 31...	Training loss: 35168.140625 (1476.441547, 1221.032155, 32470.670074) in 4.49s 
Iter 32...	Training loss: 33975.968750 (1466.703995, 1222.836847, 31286.423523) in 4.48s 
Iter 33...	Training loss: 32357.992188 (1455.436568, 1223.444815, 29679.108765) in 4.48s 
Iter 34...	Training loss: 31191.248047 (1444.829342, 1232.628407, 28513.790512) in 4.47s 
Iter 35...	Training loss: 29803.421875 (1436.702105, 1236.129181, 27130.589020) in 4.43s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.122823 HR: 0.174326
Top-10 Recall: 0.239303 Precision: 0.023930 NDCG: 0.143798 HR: 0.239303
Eval costs: 0.218685 s
Iter 36...	Training loss: 29038.833984 (1429.012841, 1244.852382, 26364.970581) in 4.46s 
Iter 37...	Training loss: 27925.794922 (1420.472470, 1257.966717, 25247.356628) in 4.42s 
Iter 38...	Training loss: 26886.416016 (1413.875289, 1266.043213, 24206.496216) in 4.42s 
Iter 39...	Training loss: 26326.839844 (1405.575162, 1278.579285, 23642.684143) in 4.33s 
Iter 40...	Training loss: 25667.425781 (1399.051934, 1291.051222, 22977.324234) in 4.45s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.178024 Precision: 0.035605 NDCG: 0.124736 HR: 0.178024
Top-10 Recall: 0.237718 Precision: 0.023772 NDCG: 0.144333 HR: 0.237718
Eval costs: 0.223620 s
Iter 41...	Training loss: 24778.880859 (1391.907899, 1302.319612, 22084.651016) in 4.56s 
Iter 42...	Training loss: 24148.458984 (1386.241177, 1319.208609, 21443.008453) in 4.47s 
Iter 43...	Training loss: 23640.777344 (1381.482186, 1341.318939, 20917.973602) in 4.46s 
Iter 44...	Training loss: 22940.615234 (1374.208394, 1357.344227, 20209.061722) in 4.47s 
Iter 45...	Training loss: 22203.173828 (1369.011269, 1377.796340, 19456.368347) in 4.45s 
Top-1 Recall: 0.071315 Precision: 0.071315 NDCG: 0.071315 HR: 0.071315
Top-5 Recall: 0.173270 Precision: 0.034654 NDCG: 0.123586 HR: 0.173270
Top-10 Recall: 0.236133 Precision: 0.023613 NDCG: 0.143868 HR: 0.236133
Eval costs: 0.228002 s
Iter 46...	Training loss: 21735.585938 (1365.300394, 1395.116894, 18975.168579) in 4.44s 
Iter 47...	Training loss: 21296.478516 (1360.023939, 1417.882256, 18518.573349) in 4.42s 
Iter 48...	Training loss: 20722.355469 (1356.074719, 1438.989929, 17927.292618) in 4.42s 
Iter 49...	Training loss: 20602.328125 (1352.541237, 1458.860066, 17790.929214) in 4.33s 
Iter 50...	Training loss: 19984.580078 (1347.474759, 1485.473874, 17151.631691) in 4.47s 
Top-1 Recall: 0.064448 Precision: 0.064448 NDCG: 0.064448 HR: 0.064448
Top-5 Recall: 0.174855 Precision: 0.034971 NDCG: 0.122262 HR: 0.174855
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.141842 HR: 0.235605
Eval costs: 0.230197 s
Iter 51...	Training loss: 19767.951172 (1344.337582, 1512.719176, 16910.896500) in 4.46s 
Iter 52...	Training loss: 19258.886719 (1341.182464, 1533.194805, 16384.513412) in 4.47s 
Iter 53...	Training loss: 18970.011719 (1336.931288, 1559.431436, 16073.647659) in 4.47s 
Iter 54...	Training loss: 18563.714844 (1334.279487, 1584.076860, 15645.357018) in 4.47s 
Iter 55...	Training loss: 18199.396484 (1331.223822, 1613.840309, 15254.332352) in 4.44s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.122395 HR: 0.171157
Top-10 Recall: 0.239303 Precision: 0.023930 NDCG: 0.144413 HR: 0.239303
Eval costs: 0.231931 s
Iter 56...	Training loss: 17882.486328 (1328.372028, 1636.420225, 14917.694176) in 4.45s 
Iter 57...	Training loss: 17712.869141 (1325.500503, 1661.778819, 14725.590515) in 4.43s 
Iter 58...	Training loss: 17225.480469 (1321.822534, 1683.144004, 14220.516197) in 4.42s 
Iter 59...	Training loss: 13462.386719 (0.000000, 1714.037648, 11748.349197) in 3.19s 
Iter 60...	Training loss: 20135.326172 (2590.030238, 1741.020880, 15804.274986) in 5.64s 
Top-1 Recall: 0.064976 Precision: 0.064976 NDCG: 0.064976 HR: 0.064976
Top-5 Recall: 0.172742 Precision: 0.034548 NDCG: 0.121066 HR: 0.172742
Top-10 Recall: 0.228209 Precision: 0.022821 NDCG: 0.139099 HR: 0.228209
Eval costs: 0.235555 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=0.1000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1904964.250000 (192927.481441, 118772.770660, 1593263.891602) in 4.62s 
Iter 2...	Training loss: 928912.125000 (15490.604629, 0.000000, 913421.532227) in 4.05s 
Iter 3...	Training loss: 712304.812500 (10791.761062, 114473.022900, 587040.027588) in 4.85s 
Iter 4...	Training loss: 348253.125000 (0.000000, 26303.049319, 321950.118164) in 3.28s 
Iter 5...	Training loss: 354136.625000 (14390.712474, 18294.785187, 321451.104004) in 5.64s 
Top-1 Recall: 0.035394 Precision: 0.035394 NDCG: 0.035394 HR: 0.035394
Top-5 Recall: 0.104596 Precision: 0.020919 NDCG: 0.071217 HR: 0.104596
Top-10 Recall: 0.142631 Precision: 0.014263 NDCG: 0.083362 HR: 0.142631
Eval costs: 0.173622 s
Iter 6...	Training loss: 254687.171875 (5183.016654, 13582.168004, 235921.985107) in 4.48s 
Iter 7...	Training loss: 203700.703125 (4209.922189, 10531.069276, 188959.726440) in 4.49s 
Iter 8...	Training loss: 172706.812500 (3580.352091, 8465.377482, 160661.090332) in 4.48s 
Iter 9...	Training loss: 138801.718750 (0.000000, 6967.995802, 131833.730469) in 3.22s 
Iter 10...	Training loss: 154249.828125 (5784.532424, 5821.718956, 142643.582153) in 5.71s 
Top-1 Recall: 0.056524 Precision: 0.056524 NDCG: 0.056524 HR: 0.056524
Top-5 Recall: 0.136292 Precision: 0.027258 NDCG: 0.097104 HR: 0.136292
Top-10 Recall: 0.188061 Precision: 0.018806 NDCG: 0.113794 HR: 0.188061
Eval costs: 0.175546 s
Iter 11...	Training loss: 129038.992188 (2598.893455, 4922.876983, 121517.219238) in 4.42s 
Iter 12...	Training loss: 119190.398438 (2400.188472, 4189.230584, 112600.980652) in 4.45s 
Iter 13...	Training loss: 110446.343750 (2239.902899, 3605.619907, 104600.822693) in 4.36s 
Iter 14...	Training loss: 99867.773438 (2111.461051, 0.000000, 97756.319763) in 4.03s 
Iter 15...	Training loss: 99236.007812 (2003.992029, 5511.012438, 91721.008789) in 4.82s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.163761 Precision: 0.032752 NDCG: 0.115726 HR: 0.163761
Top-10 Recall: 0.223455 Precision: 0.022345 NDCG: 0.135049 HR: 0.223455
Eval costs: 0.187243 s
Iter 16...	Training loss: 90100.492188 (1913.570443, 2467.526527, 85719.395569) in 4.46s 
Iter 17...	Training loss: 84138.703125 (1839.782279, 2207.472759, 80091.436218) in 4.47s 
Iter 18...	Training loss: 78796.085938 (1776.962173, 1986.526460, 75032.595886) in 4.48s 
Iter 19...	Training loss: 73440.351562 (1724.066946, 1802.214955, 69914.062866) in 4.48s 
Iter 20...	Training loss: 68083.703125 (1680.285203, 1662.587865, 64740.840515) in 4.45s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.121856 HR: 0.172213
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.141837 HR: 0.234020
Eval costs: 0.194848 s
Iter 21...	Training loss: 63815.980469 (1644.407309, 1555.631395, 60615.944366) in 4.45s 
Iter 22...	Training loss: 59402.042969 (1613.732736, 1471.551018, 56316.764069) in 4.43s 
Iter 23...	Training loss: 55782.269531 (1589.028565, 1409.186940, 52784.061035) in 4.42s 
Iter 24...	Training loss: 52109.175781 (1566.977738, 1350.468989, 49191.731201) in 4.34s 
Iter 25...	Training loss: 47579.402344 (1547.864195, 0.000000, 46031.539673) in 4.02s 
Top-1 Recall: 0.070259 Precision: 0.070259 NDCG: 0.070259 HR: 0.070259
Top-5 Recall: 0.173798 Precision: 0.034760 NDCG: 0.124399 HR: 0.173798
Top-10 Recall: 0.241944 Precision: 0.024194 NDCG: 0.146315 HR: 0.241944
Eval costs: 0.205986 s
Iter 26...	Training loss: 47344.828125 (1531.008643, 2340.953040, 43472.862946) in 4.86s 
Iter 27...	Training loss: 43795.562500 (1515.501715, 1261.733934, 41018.327209) in 4.47s 
Iter 28...	Training loss: 41384.625000 (1502.339026, 1235.671646, 38646.613983) in 4.46s 
Iter 29...	Training loss: 39437.839844 (1489.911101, 1220.567518, 36727.357971) in 4.47s 
Iter 30...	Training loss: 37405.875000 (1479.216569, 1205.881535, 34720.779480) in 4.45s 
Top-1 Recall: 0.068146 Precision: 0.068146 NDCG: 0.068146 HR: 0.068146
Top-5 Recall: 0.180666 Precision: 0.036133 NDCG: 0.125729 HR: 0.180666
Top-10 Recall: 0.236661 Precision: 0.023666 NDCG: 0.143829 HR: 0.236661
Eval costs: 0.214517 s
Iter 31...	Training loss: 36065.429688 (1468.691639, 1198.188669, 33398.555725) in 4.43s 
Iter 32...	Training loss: 34627.589844 (1456.444239, 1189.254480, 31981.890930) in 4.44s 
Iter 33...	Training loss: 33109.546875 (1448.136540, 1189.269767, 30472.139832) in 4.45s 
Iter 34...	Training loss: 31920.550781 (1439.986762, 1188.585781, 29291.979126) in 4.36s 
Iter 35...	Training loss: 29453.605469 (1430.426396, 0.000000, 28023.179489) in 4.02s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.126538 HR: 0.176968
Top-10 Recall: 0.238246 Precision: 0.023825 NDCG: 0.146233 HR: 0.238246
Eval costs: 0.219589 s
Iter 36...	Training loss: 30524.685547 (1421.688863, 2091.704938, 27011.291458) in 4.84s 
Iter 37...	Training loss: 28675.964844 (1414.997346, 1195.124243, 26065.846085) in 4.46s 
Iter 38...	Training loss: 26317.117188 (1407.129463, 0.000000, 24909.986877) in 4.04s 
Iter 39...	Training loss: 27816.376953 (1400.753349, 2099.337062, 24316.287872) in 4.81s 
Iter 40...	Training loss: 25884.904297 (1393.129294, 1228.065378, 23263.706512) in 4.44s 
Top-1 Recall: 0.072900 Precision: 0.072900 NDCG: 0.072900 HR: 0.072900
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.125520 HR: 0.175911
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.144804 HR: 0.235605
Eval costs: 0.225055 s
Iter 41...	Training loss: 23777.980469 (1387.295847, 0.000000, 22390.684753) in 3.95s 
Iter 42...	Training loss: 25660.449219 (1382.558229, 2127.312118, 22150.579239) in 4.90s 
Iter 43...	Training loss: 23805.437500 (1376.920632, 1261.840358, 21166.675507) in 4.45s 
Iter 44...	Training loss: 23302.816406 (1370.354823, 1274.164780, 20658.297028) in 4.34s 
Iter 45...	Training loss: 22633.394531 (1366.032001, 1288.214235, 19979.149414) in 4.48s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.175911 Precision: 0.035182 NDCG: 0.123486 HR: 0.175911
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.141508 HR: 0.232435
Eval costs: 0.226262 s
Iter 46...	Training loss: 22214.400391 (1361.469610, 1301.737389, 19551.193436) in 4.47s 
Iter 47...	Training loss: 21724.500000 (1357.685358, 1319.008286, 19047.805481) in 4.47s 
Iter 48...	Training loss: 21083.582031 (1353.007795, 1334.194647, 18396.378189) in 4.47s 
Iter 49...	Training loss: 20948.330078 (1349.993926, 1351.550254, 18246.787842) in 4.45s 
Iter 50...	Training loss: 20356.681641 (1345.814537, 1370.472948, 17640.393494) in 4.47s 
Top-1 Recall: 0.069731 Precision: 0.069731 NDCG: 0.069731 HR: 0.069731
Top-5 Recall: 0.176440 Precision: 0.035288 NDCG: 0.125545 HR: 0.176440
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.143328 HR: 0.231379
Eval costs: 0.230914 s
Iter 51...	Training loss: 19912.162109 (1343.251170, 1387.804126, 17181.106323) in 4.44s 
Iter 52...	Training loss: 19552.708984 (1339.563483, 1405.265246, 16807.881790) in 4.43s 
Iter 53...	Training loss: 19073.441406 (1337.157824, 1423.875752, 16312.404724) in 4.42s 
Iter 54...	Training loss: 18917.789062 (1333.166229, 1442.703139, 16141.920509) in 4.45s 
Iter 55...	Training loss: 18332.769531 (1329.409356, 1466.487306, 15536.873337) in 4.34s 
Top-1 Recall: 0.067089 Precision: 0.067089 NDCG: 0.067089 HR: 0.067089
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.121084 HR: 0.172213
Top-10 Recall: 0.230322 Precision: 0.023032 NDCG: 0.139891 HR: 0.230322
Eval costs: 0.233572 s
Iter 56...	Training loss: 18249.921875 (1326.946195, 1484.290199, 15438.684242) in 4.49s 
Iter 57...	Training loss: 17856.210938 (1324.251959, 1507.487573, 15024.473351) in 4.48s 
Iter 58...	Training loss: 17474.634766 (1321.988517, 1525.009092, 14627.640114) in 4.47s 
Iter 59...	Training loss: 17360.804688 (1318.867204, 1546.577779, 14495.358978) in 4.47s 
Iter 60...	Training loss: 17204.128906 (1317.160442, 1571.406603, 14315.561775) in 4.45s 
Top-1 Recall: 0.071844 Precision: 0.071844 NDCG: 0.071844 HR: 0.071844
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.122665 HR: 0.170629
Top-10 Recall: 0.232435 Precision: 0.023244 NDCG: 0.142460 HR: 0.232435
Eval costs: 0.234435 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 1974577.125000 (192354.832943, 0.000000, 1782222.108398) in 4.10s 
Iter 2...	Training loss: 1222277.375000 (15502.216839, 164492.231778, 1042282.904297) in 4.96s 
Iter 3...	Training loss: 654613.875000 (10797.755191, 0.000000, 643816.117188) in 3.96s 
Iter 4...	Training loss: 521637.500000 (8171.906663, 43264.253742, 470201.372314) in 4.93s 
Iter 5...	Training loss: 361821.281250 (6320.393310, 12987.013839, 342513.856445) in 4.43s 
Top-1 Recall: 0.038035 Precision: 0.038035 NDCG: 0.038035 HR: 0.038035
Top-5 Recall: 0.101955 Precision: 0.020391 NDCG: 0.070960 HR: 0.101955
Top-10 Recall: 0.143159 Precision: 0.014316 NDCG: 0.084164 HR: 0.143159
Eval costs: 0.176554 s
Iter 6...	Training loss: 276736.062500 (5053.376111, 9607.130604, 262075.564941) in 4.43s 
Iter 7...	Training loss: 223293.296875 (4184.513198, 7525.680239, 211583.090820) in 4.45s 
Iter 8...	Training loss: 189426.312500 (3587.546732, 6133.923671, 179704.826294) in 4.35s 
Iter 9...	Training loss: 166845.546875 (3162.658726, 5104.455439, 158578.406372) in 4.48s 
Iter 10...	Training loss: 151220.781250 (2852.279282, 4333.851488, 144034.645752) in 4.49s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.137876 Precision: 0.027575 NDCG: 0.093888 HR: 0.137876
Top-10 Recall: 0.192816 Precision: 0.019282 NDCG: 0.111601 HR: 0.192816
Eval costs: 0.179164 s
Iter 11...	Training loss: 139028.500000 (2616.541230, 3722.242456, 132689.723389) in 4.47s 
Iter 12...	Training loss: 129282.671875 (2427.586449, 3250.173148, 123604.915039) in 4.48s 
Iter 13...	Training loss: 121274.039062 (2274.658099, 2871.319152, 116128.058167) in 4.49s 
Iter 14...	Training loss: 109721.578125 (2143.038794, 0.000000, 107578.540405) in 3.95s 
Iter 15...	Training loss: 103478.328125 (0.000000, 4570.761619, 98907.576416) in 3.67s 
Top-1 Recall: 0.059694 Precision: 0.059694 NDCG: 0.059694 HR: 0.059694
Top-5 Recall: 0.159007 Precision: 0.031801 NDCG: 0.110007 HR: 0.159007
Top-10 Recall: 0.224511 Precision: 0.022451 NDCG: 0.131170 HR: 0.224511
Eval costs: 0.185219 s
Iter 16...	Training loss: 109801.093750 (3882.332840, 2138.440175, 103780.330933) in 5.68s 
Iter 17...	Training loss: 96253.804688 (1880.238395, 1935.572332, 92437.993469) in 4.43s 
Iter 18...	Training loss: 90733.796875 (1805.130704, 1771.359246, 87157.304932) in 4.38s 
Iter 19...	Training loss: 82943.820312 (1742.476083, 0.000000, 81201.345337) in 4.05s 
Iter 20...	Training loss: 82595.234375 (1692.374176, 2957.918696, 77944.944702) in 4.83s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.170629 Precision: 0.034126 NDCG: 0.119502 HR: 0.170629
Top-10 Recall: 0.239831 Precision: 0.023983 NDCG: 0.141873 HR: 0.239831
Eval costs: 0.194804 s
Iter 21...	Training loss: 73394.359375 (1649.478470, 0.000000, 71744.880920) in 4.03s 
Iter 22...	Training loss: 73036.679688 (1616.123166, 2649.827174, 68770.730286) in 4.82s 
Iter 23...	Training loss: 67452.007812 (1587.390384, 1345.765317, 64518.863464) in 4.47s 
Iter 24...	Training loss: 63245.582031 (1562.799239, 1272.121970, 60410.663269) in 4.47s 
Iter 25...	Training loss: 59516.656250 (1545.408670, 1216.915896, 56754.331055) in 4.47s 
Top-1 Recall: 0.069202 Precision: 0.069202 NDCG: 0.069202 HR: 0.069202
Top-5 Recall: 0.174326 Precision: 0.034865 NDCG: 0.122940 HR: 0.174326
Top-10 Recall: 0.243001 Precision: 0.024300 NDCG: 0.144995 HR: 0.243001
Eval costs: 0.203273 s
Iter 26...	Training loss: 55980.171875 (1527.655834, 1165.004753, 53287.505737) in 4.43s 
Iter 27...	Training loss: 52847.617188 (1514.980590, 1127.800419, 50204.832214) in 4.45s 
Iter 28...	Training loss: 49776.687500 (1501.935537, 1098.328292, 47176.420471) in 4.42s 
Iter 29...	Training loss: 47211.300781 (1492.160451, 1073.054765, 44646.081390) in 4.34s 
Iter 30...	Training loss: 44937.789062 (1479.918421, 1047.661840, 42410.209412) in 4.51s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.127423 HR: 0.177496
Top-10 Recall: 0.239303 Precision: 0.023930 NDCG: 0.147576 HR: 0.239303
Eval costs: 0.212672 s
Iter 31...	Training loss: 42563.207031 (1473.053900, 1023.196010, 40066.954529) in 4.48s 
Iter 32...	Training loss: 40664.246094 (1462.341260, 1004.411823, 38197.493652) in 4.47s 
Iter 33...	Training loss: 38737.613281 (1454.104615, 990.812528, 36292.697174) in 4.48s 
Iter 34...	Training loss: 35209.230469 (1445.643169, 0.000000, 33763.589539) in 3.95s 
Iter 35...	Training loss: 36866.765625 (1437.923540, 1761.041913, 33667.804138) in 4.92s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.129195 HR: 0.176968
Top-10 Recall: 0.234020 Precision: 0.023402 NDCG: 0.147606 HR: 0.234020
Eval costs: 0.220846 s
Iter 36...	Training loss: 34111.070312 (1432.183696, 970.571614, 31708.312103) in 4.44s 
Iter 37...	Training loss: 32782.097656 (1423.294492, 957.783420, 30401.020889) in 4.43s 
Iter 38...	Training loss: 31680.511719 (1418.209551, 948.434462, 29313.870483) in 4.37s 
Iter 39...	Training loss: 30590.171875 (1411.837408, 937.354270, 28240.979874) in 4.48s 
Iter 40...	Training loss: 29523.423828 (1405.949316, 929.668229, 27187.805099) in 4.48s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.127208 HR: 0.177496
Top-10 Recall: 0.230851 Precision: 0.023085 NDCG: 0.144299 HR: 0.230851
Eval costs: 0.225076 s
Iter 41...	Training loss: 28469.056641 (1400.749579, 928.176156, 26140.133713) in 4.49s 
Iter 42...	Training loss: 27930.912109 (1395.253126, 923.169087, 25612.490265) in 4.54s 
Iter 43...	Training loss: 26875.552734 (1389.884093, 919.131377, 24566.538132) in 4.53s 
Iter 44...	Training loss: 26054.382812 (1384.360106, 919.425356, 23750.596008) in 4.56s 
Iter 45...	Training loss: 25652.486328 (1378.883025, 917.460444, 23356.140305) in 4.50s 
Top-1 Recall: 0.073957 Precision: 0.073957 NDCG: 0.073957 HR: 0.073957
Top-5 Recall: 0.167987 Precision: 0.033597 NDCG: 0.122637 HR: 0.167987
Top-10 Recall: 0.231379 Precision: 0.023138 NDCG: 0.143144 HR: 0.231379
Eval costs: 0.229808 s
Iter 46...	Training loss: 24867.820312 (1376.555793, 918.923421, 22572.340271) in 4.48s 
Iter 47...	Training loss: 22501.011719 (1371.818732, 0.000000, 21129.195786) in 3.96s 
Iter 48...	Training loss: 24796.488281 (1367.995948, 1629.324947, 21799.167603) in 4.93s 
Iter 49...	Training loss: 22925.289062 (1364.408371, 937.878168, 20623.000809) in 4.39s 
Iter 50...	Training loss: 22440.919922 (1360.473163, 935.558581, 20144.888840) in 4.49s 
Top-1 Recall: 0.076598 Precision: 0.076598 NDCG: 0.076598 HR: 0.076598
Top-5 Recall: 0.167459 Precision: 0.033492 NDCG: 0.123886 HR: 0.167459
Top-10 Recall: 0.236661 Precision: 0.023666 NDCG: 0.146173 HR: 0.236661
Eval costs: 0.235704 s
Iter 51...	Training loss: 17851.679688 (0.000000, 934.737233, 16916.943512) in 3.29s 
Iter 52...	Training loss: 25001.398438 (2659.794327, 938.044019, 21403.560471) in 5.64s 
Iter 53...	Training loss: 19687.716797 (1369.793762, 0.000000, 18317.920334) in 4.05s 
Iter 54...	Training loss: 21775.384766 (1358.492169, 1650.286855, 18766.607178) in 4.86s 
Iter 55...	Training loss: 20126.167969 (1349.120316, 960.758741, 17816.286774) in 4.45s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.171157 Precision: 0.034231 NDCG: 0.124583 HR: 0.171157
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.142534 HR: 0.226624
Eval costs: 0.235420 s
Iter 56...	Training loss: 19814.957031 (1343.641655, 961.549448, 17509.762772) in 4.45s 
Iter 57...	Training loss: 19462.730469 (1339.486507, 961.433606, 17161.810318) in 4.43s 
Iter 58...	Training loss: 18942.253906 (1335.349469, 964.076091, 16642.829269) in 4.43s 
Iter 59...	Training loss: 18665.085938 (1333.105353, 972.121707, 16359.855804) in 4.37s 
Iter 60...	Training loss: 18574.167969 (1328.206317, 973.699051, 16272.266426) in 4.49s 
Top-1 Recall: 0.070787 Precision: 0.070787 NDCG: 0.070787 HR: 0.070787
Top-5 Recall: 0.172213 Precision: 0.034443 NDCG: 0.123015 HR: 0.172213
Top-10 Recall: 0.223983 Precision: 0.022398 NDCG: 0.139629 HR: 0.223983
Eval costs: 0.239688 s
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=10.0000 
beta=10.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 3862230.250000 (192877.464714, 118750.066528, 3550603.044922) in 4.64s 
Iter 2...	Training loss: 2043571.250000 (15500.149788, 78530.815918, 1949540.227539) in 4.48s 
Iter 3...	Training loss: 1391923.250000 (10818.215495, 37430.337372, 1343674.604492) in 4.49s 
Iter 4...	Training loss: 980773.500000 (8197.963480, 17982.484661, 954592.991699) in 4.47s 
Iter 5...	Training loss: 702818.937500 (6348.978004, 11379.660559, 685090.330566) in 4.48s 
Top-1 Recall: 0.014791 Precision: 0.014791 NDCG: 0.014791 HR: 0.014791
Top-5 Recall: 0.059694 Precision: 0.011939 NDCG: 0.036640 HR: 0.059694
Top-10 Recall: 0.094559 Precision: 0.009456 NDCG: 0.047980 HR: 0.094559
Eval costs: 0.169863 s
Iter 6...	Training loss: 513088.656250 (5091.157232, 8524.620842, 499472.903564) in 4.48s 
Iter 7...	Training loss: 384975.531250 (4225.215512, 6912.605104, 373837.674561) in 4.47s 
Iter 8...	Training loss: 302174.312500 (3630.746475, 5738.119720, 292805.465332) in 4.48s 
Iter 9...	Training loss: 248025.046875 (3219.537993, 4849.951974, 239955.546509) in 4.47s 
Iter 10...	Training loss: 212887.453125 (2919.394848, 4151.268108, 205816.800171) in 4.45s 
Top-1 Recall: 0.026941 Precision: 0.026941 NDCG: 0.026941 HR: 0.026941
Top-5 Recall: 0.099313 Precision: 0.019863 NDCG: 0.063744 HR: 0.099313
Top-10 Recall: 0.143687 Precision: 0.014369 NDCG: 0.077863 HR: 0.143687
Eval costs: 0.170075 s
Iter 11...	Training loss: 188496.296875 (2691.085876, 3587.468875, 182217.753418) in 4.42s 
Iter 12...	Training loss: 171064.359375 (2509.774700, 3135.133232, 165419.443115) in 4.44s 
Iter 13...	Training loss: 148519.921875 (2354.551050, 0.000000, 146165.400024) in 3.93s 
Iter 14...	Training loss: 155024.562500 (2221.294027, 5035.170022, 147768.125122) in 4.85s 
Iter 15...	Training loss: 139285.421875 (2109.181907, 2262.706347, 134913.545654) in 4.49s 
Top-1 Recall: 0.048072 Precision: 0.048072 NDCG: 0.048072 HR: 0.048072
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.092633 HR: 0.136820
Top-10 Recall: 0.196513 Precision: 0.019651 NDCG: 0.111644 HR: 0.196513
Eval costs: 0.179739 s
Iter 16...	Training loss: 132297.640625 (2017.794262, 2026.592066, 128253.251099) in 4.49s 
Iter 17...	Training loss: 125873.804688 (1936.583908, 1845.539861, 122091.690186) in 4.47s 
Iter 18...	Training loss: 120637.648438 (1865.178780, 1691.174785, 117081.292786) in 4.48s 
Iter 19...	Training loss: 115614.117188 (1805.135586, 1563.154370, 112245.842163) in 4.46s 
Iter 20...	Training loss: 111245.085938 (1751.557669, 1456.440747, 108037.092957) in 4.46s 
Top-1 Recall: 0.054939 Precision: 0.054939 NDCG: 0.054939 HR: 0.054939
Top-5 Recall: 0.151083 Precision: 0.030217 NDCG: 0.103683 HR: 0.151083
Top-10 Recall: 0.223983 Precision: 0.022398 NDCG: 0.127189 HR: 0.223983
Eval costs: 0.184925 s
Iter 21...	Training loss: 107343.578125 (1705.886941, 1363.000653, 104274.690491) in 4.45s 
Iter 22...	Training loss: 100043.242188 (1668.087156, 0.000000, 98375.156616) in 3.95s 
Iter 23...	Training loss: 103879.109375 (1628.776394, 2414.011168, 99836.329224) in 4.87s 
Iter 24...	Training loss: 96746.695312 (1597.308776, 1167.339924, 93982.045471) in 4.49s 
Iter 25...	Training loss: 93606.875000 (1572.264727, 1100.295629, 90934.328003) in 4.50s 
Top-1 Recall: 0.061278 Precision: 0.061278 NDCG: 0.061278 HR: 0.061278
Top-5 Recall: 0.169044 Precision: 0.033809 NDCG: 0.116015 HR: 0.169044
Top-10 Recall: 0.235605 Precision: 0.023560 NDCG: 0.137436 HR: 0.235605
Eval costs: 0.191283 s
Iter 26...	Training loss: 87403.695312 (1549.693500, 0.000000, 85853.994507) in 4.07s 
Iter 27...	Training loss: 85724.000000 (0.000000, 1983.079265, 83740.918091) in 3.69s 
Iter 28...	Training loss: 89022.507812 (2994.241250, 974.020882, 85054.251526) in 5.63s 
Iter 29...	Training loss: 82149.734375 (1523.229291, 929.561282, 79696.945618) in 4.46s 
Iter 30...	Training loss: 79404.601562 (1498.854890, 894.691545, 77011.062012) in 4.45s 
Top-1 Recall: 0.073428 Precision: 0.073428 NDCG: 0.073428 HR: 0.073428
Top-5 Recall: 0.177496 Precision: 0.035499 NDCG: 0.125704 HR: 0.177496
Top-10 Recall: 0.246698 Precision: 0.024670 NDCG: 0.147818 HR: 0.246698
Eval costs: 0.196274 s
Iter 31...	Training loss: 76576.593750 (1479.733585, 862.988715, 74233.876770) in 4.42s 
Iter 32...	Training loss: 73682.210938 (1466.637762, 835.501643, 71380.068542) in 4.46s 
Iter 33...	Training loss: 71036.640625 (1457.031250, 808.074148, 68771.526978) in 4.45s 
Iter 34...	Training loss: 68551.382812 (1448.656986, 784.940318, 66317.790283) in 4.35s 
Iter 35...	Training loss: 65838.437500 (1441.112932, 762.344668, 63634.975891) in 4.48s 
Top-1 Recall: 0.078711 Precision: 0.078711 NDCG: 0.078711 HR: 0.078711
Top-5 Recall: 0.179609 Precision: 0.035922 NDCG: 0.129924 HR: 0.179609
Top-10 Recall: 0.242472 Precision: 0.024247 NDCG: 0.149869 HR: 0.242472
Eval costs: 0.204742 s
Iter 36...	Training loss: 63380.015625 (1435.817797, 743.682996, 61200.515442) in 4.47s 
Iter 37...	Training loss: 60591.855469 (1432.159270, 726.321222, 58433.379242) in 4.48s 
Iter 38...	Training loss: 58304.847656 (1429.751747, 706.934074, 56168.165222) in 4.48s 
Iter 39...	Training loss: 55779.070312 (1428.565602, 689.664276, 53660.842438) in 4.49s 
Iter 40...	Training loss: 53636.367188 (1426.801882, 673.419405, 51536.136505) in 4.48s 
Top-1 Recall: 0.083465 Precision: 0.083465 NDCG: 0.083465 HR: 0.083465
Top-5 Recall: 0.182250 Precision: 0.036450 NDCG: 0.132862 HR: 0.182250
Top-10 Recall: 0.243001 Precision: 0.024300 NDCG: 0.152412 HR: 0.243001
Eval costs: 0.211866 s
Iter 41...	Training loss: 48853.617188 (1424.931682, 0.000000, 47428.687225) in 3.92s 
Iter 42...	Training loss: 51948.105469 (1420.286458, 1256.795622, 49271.023041) in 4.92s 
Iter 43...	Training loss: 44572.117188 (1421.514799, 0.000000, 43150.602417) in 3.93s 
Iter 44...	Training loss: 47752.121094 (1421.582246, 1213.770663, 45116.769257) in 4.86s 
Iter 45...	Training loss: 43952.761719 (1420.151660, 622.355524, 41910.251434) in 4.47s 
Top-1 Recall: 0.078183 Precision: 0.078183 NDCG: 0.078183 HR: 0.078183
Top-5 Recall: 0.176968 Precision: 0.035394 NDCG: 0.128437 HR: 0.176968
Top-10 Recall: 0.243001 Precision: 0.024300 NDCG: 0.149588 HR: 0.243001
Eval costs: 0.218580 s
Iter 46...	Training loss: 42158.925781 (1421.216601, 603.186976, 40134.523956) in 4.48s 
Iter 47...	Training loss: 37969.718750 (1420.002033, 0.000000, 36549.711609) in 4.03s 
Iter 48...	Training loss: 41227.925781 (1417.445601, 1125.911150, 38684.565125) in 4.82s 
Iter 49...	Training loss: 38178.039062 (1418.974219, 579.943630, 36179.122589) in 4.47s 
Iter 50...	Training loss: 36639.691406 (1417.115577, 565.671342, 34656.901550) in 4.46s 
Top-1 Recall: 0.074485 Precision: 0.074485 NDCG: 0.074485 HR: 0.074485
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.121316 HR: 0.165346
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.143204 HR: 0.233492
Eval costs: 0.223969 s
Iter 51...	Training loss: 35378.296875 (1415.651478, 556.063581, 33406.586090) in 4.46s 
Iter 52...	Training loss: 34467.117188 (1414.794243, 547.999982, 32504.323059) in 4.43s 
Iter 53...	Training loss: 33479.800781 (1413.545377, 539.485691, 31526.769714) in 4.43s 
Iter 54...	Training loss: 32470.910156 (1412.023937, 534.820063, 30524.063446) in 4.37s 
Iter 55...	Training loss: 31655.574219 (1410.067208, 528.750972, 29716.753952) in 4.46s 
Top-1 Recall: 0.080824 Precision: 0.080824 NDCG: 0.080824 HR: 0.080824
Top-5 Recall: 0.165346 Precision: 0.033069 NDCG: 0.124434 HR: 0.165346
Top-10 Recall: 0.233492 Precision: 0.023349 NDCG: 0.146470 HR: 0.233492
Eval costs: 0.226250 s
Iter 56...	Training loss: 28476.107422 (1408.315690, 0.000000, 27067.787781) in 4.04s 
Iter 57...	Training loss: 32075.416016 (1406.416413, 1004.857216, 29664.142929) in 4.83s 
Iter 58...	Training loss: 29720.382812 (1404.288947, 521.415116, 27794.679626) in 4.47s 
Iter 59...	Training loss: 26110.023438 (1402.925230, 0.000000, 24707.099731) in 3.95s 
Iter 60...	Training loss: 29794.953125 (1400.298907, 978.406944, 27416.245514) in 4.91s 
Top-1 Recall: 0.077655 Precision: 0.077655 NDCG: 0.077655 HR: 0.077655
Top-5 Recall: 0.165874 Precision: 0.033175 NDCG: 0.122511 HR: 0.165874
Top-10 Recall: 0.226624 Precision: 0.022662 NDCG: 0.142367 HR: 0.226624
Eval costs: 0.231298 s
<<<<<<< HEAD
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2122957.250000 (192283.530212, 1930673.689453) in 18.49s 
Iter 2...	Training loss: 1872194.375000 (15791.880298, 1856402.429688) in 18.36s 
Iter 3...	Training loss: 1805872.750000 (0.000000, 1805872.908203) in 14.85s 
Iter 4...	Training loss: 1750157.875000 (20594.929605, 1729562.870117) in 23.75s 
Iter 5...	Training loss: 1557474.125000 (0.000000, 1557474.178711) in 16.50s 
Top-1 Recall: 0.012150 Precision: 0.012150 NDCG: 0.012150 HR: 0.012150
Top-5 Recall: 0.054411 Precision: 0.010882 NDCG: 0.032723 HR: 0.054411
Top-10 Recall: 0.093502 Precision: 0.009350 NDCG: 0.045184 HR: 0.093502
Eval costs: 16.384567 s
Iter 6...	Training loss: 1446506.875000 (12043.189768, 1434463.598633) in 22.53s 
Iter 7...	Training loss: 1331655.750000 (4923.751138, 1326732.030273) in 22.20s 
Iter 8...	Training loss: 1250518.125000 (4440.697420, 1246077.405273) in 28.15s 
Iter 9...	Training loss: 1184282.500000 (4119.010787, 1180163.504883) in 21.62s 
Iter 10...	Training loss: 1128851.875000 (3900.765617, 1124951.172852) in 20.14s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.109350 Precision: 0.021870 NDCG: 0.074915 HR: 0.109350
Top-10 Recall: 0.163233 Precision: 0.016323 NDCG: 0.092427 HR: 0.163233
Eval costs: 15.914721 s
Iter 11...	Training loss: 1063889.250000 (0.000000, 1063889.195312) in 15.46s 
Iter 12...	Training loss: 1024613.750000 (7054.923112, 1017558.776367) in 23.23s 
Iter 13...	Training loss: 957049.125000 (0.000000, 957049.152344) in 15.00s 
Iter 14...	Training loss: 912045.875000 (6743.680815, 905302.268555) in 22.05s 
Iter 15...	Training loss: 835761.125000 (0.000000, 835761.186523) in 15.01s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.127311 Precision: 0.025462 NDCG: 0.085666 HR: 0.127311
Top-10 Recall: 0.178024 Precision: 0.017802 NDCG: 0.101916 HR: 0.178024
Eval costs: 16.105826 s
Iter 16...	Training loss: 787794.562500 (6585.681070, 781208.900391) in 22.39s 
Iter 17...	Training loss: 716017.312500 (3408.748775, 712608.607910) in 19.06s 
Iter 18...	Training loss: 661067.437500 (3443.461876, 657623.989258) in 25.57s 
Iter 19...	Training loss: 607011.437500 (3437.473007, 603574.021973) in 25.83s 
Iter 20...	Training loss: 550053.625000 (0.000000, 550053.627930) in 16.03s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.128896 Precision: 0.025779 NDCG: 0.086232 HR: 0.128896
Top-10 Recall: 0.189646 Precision: 0.018965 NDCG: 0.105849 HR: 0.189646
Eval costs: 17.127544 s
Iter 21...	Training loss: 518327.062500 (6447.657316, 511879.401855) in 24.33s 
Iter 22...	Training loss: 478443.343750 (3380.705672, 475062.637695) in 22.92s 
Iter 23...	Training loss: 442967.218750 (3418.812610, 439548.398438) in 22.26s 
Iter 24...	Training loss: 412140.593750 (3421.609190, 408719.045654) in 19.55s 
Iter 25...	Training loss: 386436.375000 (3421.237254, 383015.073730) in 19.18s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.132594 Precision: 0.026519 NDCG: 0.090755 HR: 0.132594
Top-10 Recall: 0.195985 Precision: 0.019599 NDCG: 0.111401 HR: 0.195985
Eval costs: 16.259234 s
Iter 26...	Training loss: 358385.781250 (0.000000, 358385.785156) in 16.44s 
Iter 27...	Training loss: 353198.156250 (6364.319044, 346833.875244) in 24.93s 
Iter 28...	Training loss: 319428.750000 (0.000000, 319428.755859) in 15.43s 
Iter 29...	Training loss: 316055.937500 (6306.301592, 309749.652344) in 22.17s 
Iter 30...	Training loss: 299347.125000 (3353.494772, 295993.608398) in 18.79s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.135763 Precision: 0.027153 NDCG: 0.090308 HR: 0.135763
Top-10 Recall: 0.193872 Precision: 0.019387 NDCG: 0.109107 HR: 0.193872
Eval costs: 17.795813 s
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2159116.500000 (105224.026443, 2053892.675781) in 60.43s 
Iter 2...	Training loss: 1964800.625000 (18858.008080, 1945942.767578) in 47.76s 
Iter 3...	Training loss: 1863355.500000 (0.000000, 1863355.517578) in 17.31s 
Iter 4...	Training loss: 1884105.250000 (17287.569280, 1866817.626953) in 74.37s 
Iter 5...	Training loss: 1845727.750000 (5101.310627, 1840626.468750) in 55.95s 
Top-1 Recall: 0.016904 Precision: 0.016904 NDCG: 0.016904 HR: 0.016904
Top-5 Recall: 0.053883 Precision: 0.010777 NDCG: 0.035602 HR: 0.053883
Top-10 Recall: 0.083465 Precision: 0.008347 NDCG: 0.045196 HR: 0.083465
Eval costs: 16.624172 s
Iter 6...	Training loss: 1827928.250000 (4047.279186, 1823881.039062) in 51.34s 
Iter 7...	Training loss: 1804396.500000 (0.000000, 1804396.498047) in 17.83s 
Iter 8...	Training loss: 1813304.750000 (6453.623109, 1806850.908203) in 73.74s 
Iter 9...	Training loss: 1670452.375000 (0.000000, 1670452.414062) in 17.38s 
Iter 10...	Training loss: 1480474.750000 (5525.722538, 1474948.953125) in 74.58s 
Top-1 Recall: 0.025357 Precision: 0.025357 NDCG: 0.025357 HR: 0.025357
Top-5 Recall: 0.090861 Precision: 0.018172 NDCG: 0.057913 HR: 0.090861
Top-10 Recall: 0.135763 Precision: 0.013576 NDCG: 0.072336 HR: 0.135763
Eval costs: 17.625188 s
Iter 11...	Training loss: 1257299.625000 (2740.496742, 1254559.233398) in 54.93s 
Iter 12...	Training loss: 1084674.875000 (0.000000, 1084674.880859) in 17.35s 
Iter 13...	Training loss: 952263.375000 (5242.598017, 947020.748047) in 78.22s 
Iter 14...	Training loss: 799917.062500 (0.000000, 799917.060547) in 17.89s 
Iter 15...	Training loss: 693053.812500 (5168.238486, 687885.653809) in 83.84s 
Top-1 Recall: 0.037507 Precision: 0.037507 NDCG: 0.037507 HR: 0.037507
Top-5 Recall: 0.125198 Precision: 0.025040 NDCG: 0.082215 HR: 0.125198
Top-10 Recall: 0.190703 Precision: 0.019070 NDCG: 0.103315 HR: 0.190703
Eval costs: 25.057628 s
Iter 16...	Training loss: 586726.000000 (0.000000, 586726.008789) in 20.61s 
Iter 17...	Training loss: 534482.625000 (5127.593737, 529355.110352) in 99.63s 
Iter 18...	Training loss: 465981.250000 (0.000000, 465981.270508) in 24.99s 
Iter 19...	Training loss: 435743.093750 (5115.188625, 430627.895020) in 91.10s 
Iter 20...	Training loss: 400651.156250 (2633.265991, 398017.868896) in 53.78s 
Top-1 Recall: 0.039091 Precision: 0.039091 NDCG: 0.039091 HR: 0.039091
Top-5 Recall: 0.128896 Precision: 0.025779 NDCG: 0.085138 HR: 0.128896
Top-10 Recall: 0.192287 Precision: 0.019229 NDCG: 0.105249 HR: 0.192287
Eval costs: 19.235443 s
Iter 21...	Training loss: 364254.562500 (0.000000, 364254.578857) in 19.36s 
Iter 22...	Training loss: 359456.500000 (5106.291760, 354350.267334) in 85.82s 
Iter 23...	Training loss: 335445.656250 (2633.562986, 332812.077393) in 52.20s 
Iter 24...	Training loss: 321255.281250 (2651.075372, 318604.232422) in 49.82s 
Iter 25...	Training loss: 307432.156250 (2656.425374, 304775.740723) in 50.41s 
Top-1 Recall: 0.036450 Precision: 0.036450 NDCG: 0.036450 HR: 0.036450
Top-5 Recall: 0.132066 Precision: 0.026413 NDCG: 0.085110 HR: 0.132066
Top-10 Recall: 0.193344 Precision: 0.019334 NDCG: 0.104715 HR: 0.193344
Eval costs: 20.208687 s
Iter 26...	Training loss: 297748.312500 (2654.066837, 295094.205078) in 47.88s 
Iter 27...	Training loss: 289006.781250 (2654.530681, 286352.238525) in 46.79s 
Iter 28...	Training loss: 272571.250000 (0.000000, 272571.272705) in 19.65s 
Iter 29...	Training loss: 280408.625000 (5091.209229, 275317.423584) in 74.83s 
Iter 30...	Training loss: 254956.031250 (0.000000, 254956.020996) in 21.59s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.135763 Precision: 0.027153 NDCG: 0.088536 HR: 0.135763
Top-10 Recall: 0.194400 Precision: 0.019440 NDCG: 0.107699 HR: 0.194400
Eval costs: 17.494519 s
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2293870.000000 (0.000000, 121265.554167, 2172603.828125) in 88.02s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=20 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 544218.250000 (253837.437790, 290380.822266) in 6.28s 
Iter 2...	Training loss: 241635.359375 (0.000000, 241635.354004) in 4.05s 
Iter 3...	Training loss: 351078.625000 (107990.853990, 243087.756836) in 8.62s 
Iter 4...	Training loss: 212833.703125 (0.000000, 212833.700562) in 4.24s 
Iter 5...	Training loss: 237727.265625 (25574.701598, 212152.568115) in 7.93s 
Top-1 Recall: 0.000528 Precision: 0.000528 NDCG: 0.000528 HR: 0.000528
Top-5 Recall: 0.003170 Precision: 0.000634 NDCG: 0.001854 HR: 0.003170
Top-10 Recall: 0.007924 Precision: 0.000792 NDCG: 0.003362 HR: 0.007924
Eval costs: 4.445480 s
Iter 6...	Training loss: 211504.812500 (8679.826370, 202824.994873) in 6.01s 
Iter 7...	Training loss: 204336.296875 (7245.171386, 197091.128662) in 5.99s 
Iter 8...	Training loss: 199362.906250 (6191.417195, 193171.494751) in 6.06s 
Iter 9...	Training loss: 187374.687500 (0.000000, 187374.686401) in 4.11s 
Iter 10...	Training loss: 199865.921875 (10227.973163, 189637.958252) in 7.99s 
Top-1 Recall: 0.002113 Precision: 0.002113 NDCG: 0.002113 HR: 0.002113
Top-5 Recall: 0.008452 Precision: 0.001690 NDCG: 0.005118 HR: 0.008452
Top-10 Recall: 0.017433 Precision: 0.001743 NDCG: 0.007958 HR: 0.017433
Eval costs: 4.378025 s
Iter 11...	Training loss: 184936.468750 (0.000000, 184936.469604) in 4.41s 
Iter 12...	Training loss: 195442.359375 (8548.503780, 186893.859985) in 8.54s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=50 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 184095.546875  in 7.63s 
Iter 2...	Training loss: 182416.531250  in 7.57s 
Iter 3...	Training loss: 182088.796875  in 7.57s 
Iter 4...	Training loss: 181982.421875  in 7.65s 
Iter 5...	Training loss: 181936.593750  in 7.66s 
Top-1 Recall: 0.006339 Precision: 0.006339 NDCG: 0.006339 HR: 0.006339
Top-5 Recall: 0.021659 Precision: 0.004332 NDCG: 0.013500 HR: 0.021659
Top-10 Recall: 0.036450 Precision: 0.003645 NDCG: 0.018297 HR: 0.036450
Eval costs: 9.600529 s
Iter 6...	Training loss: 181914.640625  in 7.77s 
Iter 7...	Training loss: 181902.093750  in 8.38s 
Iter 8...	Training loss: 181895.234375  in 11.72s 
Iter 9...	Training loss: 181890.734375  in 13.07s 
Iter 10...	Training loss: 181887.953125  in 8.43s 
Top-1 Recall: 0.006867 Precision: 0.006867 NDCG: 0.006867 HR: 0.006867
Top-5 Recall: 0.031696 Precision: 0.006339 NDCG: 0.018936 HR: 0.031696
Top-10 Recall: 0.051241 Precision: 0.005124 NDCG: 0.025282 HR: 0.051241
Eval costs: 9.917371 s
Iter 11...	Training loss: 181886.000000  in 7.78s 
Iter 12...	Training loss: 181884.906250  in 7.80s 
Iter 13...	Training loss: 181884.156250  in 8.72s 
Iter 14...	Training loss: 181883.531250  in 9.55s 
Iter 15...	Training loss: 181883.015625  in 8.29s 
Top-1 Recall: 0.008452 Precision: 0.008452 NDCG: 0.008452 HR: 0.008452
Top-5 Recall: 0.032224 Precision: 0.006445 NDCG: 0.020227 HR: 0.032224
Top-10 Recall: 0.054939 Precision: 0.005494 NDCG: 0.027623 HR: 0.054939
Eval costs: 10.461754 s
Iter 16...	Training loss: 181882.640625  in 8.05s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 183215.890625  in 16.18s 
Iter 2...	Training loss: 182114.421875  in 15.08s 
Iter 3...	Training loss: 181946.734375  in 14.53s 
Iter 4...	Training loss: 181856.703125  in 14.44s 
Iter 5...	Training loss: 181762.750000  in 14.81s 
Top-1 Recall: 0.014791 Precision: 0.014791 NDCG: 0.014791 HR: 0.014791
Top-5 Recall: 0.061278 Precision: 0.012256 NDCG: 0.038146 HR: 0.061278
Top-10 Recall: 0.098257 Precision: 0.009826 NDCG: 0.050195 HR: 0.098257
Eval costs: 16.174920 s
Iter 6...	Training loss: 181499.718750  in 15.75s 
Iter 7...	Training loss: 178066.015625  in 18.55s 
Iter 8...	Training loss: 160611.343750  in 18.71s 
Iter 9...	Training loss: 145534.828125  in 17.07s 
Iter 10...	Training loss: 122021.734375  in 20.42s 
Top-1 Recall: 0.023772 Precision: 0.023772 NDCG: 0.023772 HR: 0.023772
Top-5 Recall: 0.093502 Precision: 0.018700 NDCG: 0.059327 HR: 0.093502
Top-10 Recall: 0.142631 Precision: 0.014263 NDCG: 0.075209 HR: 0.142631
Eval costs: 19.408562 s
Iter 11...	Training loss: 97356.867188  in 15.23s 
Iter 12...	Training loss: 78019.343750  in 15.82s 
Iter 13...	Training loss: 63420.453125  in 15.74s 
Iter 14...	Training loss: 52954.183594  in 15.39s 
Iter 15...	Training loss: 45893.781250  in 22.98s 
Top-1 Recall: 0.033809 Precision: 0.033809 NDCG: 0.033809 HR: 0.033809
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.076460 HR: 0.118331
Top-10 Recall: 0.174855 Precision: 0.017485 NDCG: 0.094569 HR: 0.174855
Eval costs: 30.394868 s
Iter 16...	Training loss: 40167.109375  in 23.71s 
Iter 17...	Training loss: 36217.093750  in 23.50s 
Iter 18...	Training loss: 32728.529297  in 18.13s 
Iter 19...	Training loss: 30323.894531  in 19.23s 
Iter 20...	Training loss: 28759.878906  in 23.14s 
Top-1 Recall: 0.041204 Precision: 0.041204 NDCG: 0.041204 HR: 0.041204
Top-5 Recall: 0.124142 Precision: 0.024828 NDCG: 0.083793 HR: 0.124142
Top-10 Recall: 0.176968 Precision: 0.017697 NDCG: 0.100924 HR: 0.176968
Eval costs: 16.521003 s
Iter 21...	Training loss: 26417.283203  in 21.34s 
Iter 22...	Training loss: 24967.875000  in 16.51s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 183211.937500  in 21.63s 
Iter 2...	Training loss: 182115.812500  in 22.02s 
Iter 3...	Training loss: 181945.484375  in 18.54s 
Iter 4...	Training loss: 181860.671875  in 14.71s 
Iter 5...	Training loss: 181761.265625  in 15.34s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.069202 Precision: 0.013840 NDCG: 0.043854 HR: 0.069202
Top-10 Recall: 0.096144 Precision: 0.009614 NDCG: 0.052451 HR: 0.096144
Eval costs: 16.729109 s
Iter 6...	Training loss: 181499.937500  in 14.94s 
Iter 7...	Training loss: 177933.421875  in 14.99s 
Iter 8...	Training loss: 160646.250000  in 15.10s 
Iter 9...	Training loss: 145718.437500  in 15.08s 
Iter 10...	Training loss: 122345.945312  in 15.13s 
Top-1 Recall: 0.029054 Precision: 0.029054 NDCG: 0.029054 HR: 0.029054
Top-5 Recall: 0.097200 Precision: 0.019440 NDCG: 0.063891 HR: 0.097200
Top-10 Recall: 0.145272 Precision: 0.014527 NDCG: 0.079558 HR: 0.145272
Eval costs: 17.512502 s
Iter 11...	Training loss: 97331.070312  in 15.50s 
Iter 12...	Training loss: 77293.367188  in 15.69s 
Iter 13...	Training loss: 63219.128906  in 15.16s 
Iter 14...	Training loss: 52811.437500  in 15.29s 
Iter 15...	Training loss: 45610.652344  in 15.64s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.115161 Precision: 0.023032 NDCG: 0.078828 HR: 0.115161
Top-10 Recall: 0.174855 Precision: 0.017485 NDCG: 0.098317 HR: 0.174855
Eval costs: 17.233599 s
Iter 16...	Training loss: 40322.886719  in 15.12s 
Iter 17...	Training loss: 36038.152344  in 15.13s 
Iter 18...	Training loss: 33057.800781  in 15.30s 
Iter 19...	Training loss: 30351.406250  in 15.20s 
Iter 20...	Training loss: 28275.277344  in 15.24s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.127311 Precision: 0.025462 NDCG: 0.086705 HR: 0.127311
Top-10 Recall: 0.182250 Precision: 0.018225 NDCG: 0.104186 HR: 0.182250
Eval costs: 17.297272 s
Iter 21...	Training loss: 26935.914062  in 15.43s 
Iter 22...	Training loss: 25268.876953  in 15.39s 
Iter 23...	Training loss: 23966.300781  in 17.43s 
Iter 24...	Training loss: 22570.867188  in 15.97s 
Iter 25...	Training loss: 21703.449219  in 15.18s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.127311 Precision: 0.025462 NDCG: 0.087284 HR: 0.127311
Top-10 Recall: 0.187533 Precision: 0.018753 NDCG: 0.106420 HR: 0.187533
Eval costs: 17.343403 s
Iter 26...	Training loss: 20918.486328  in 15.25s 
Iter 27...	Training loss: 19709.833984  in 15.25s 
Iter 28...	Training loss: 18950.369141  in 15.26s 
Iter 29...	Training loss: 18730.349609  in 15.23s 
Iter 30...	Training loss: 18032.150391  in 15.31s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.132066 Precision: 0.026413 NDCG: 0.088965 HR: 0.132066
Top-10 Recall: 0.191231 Precision: 0.019123 NDCG: 0.107829 HR: 0.191231
Eval costs: 19.040051 s
Iter 31...	Training loss: 17298.513672  in 15.73s 
Iter 32...	Training loss: 16861.517578  in 15.46s 
Iter 33...	Training loss: 16245.736328  in 15.33s 
Iter 34...	Training loss: 15798.030273  in 15.31s 
Iter 35...	Training loss: 15616.300781  in 15.32s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.134707 Precision: 0.026941 NDCG: 0.091017 HR: 0.134707
Top-10 Recall: 0.181194 Precision: 0.018119 NDCG: 0.106005 HR: 0.181194
Eval costs: 17.752142 s
Iter 36...	Training loss: 15081.076172  in 15.32s 
Iter 37...	Training loss: 14787.050781  in 15.32s 
Iter 38...	Training loss: 14604.796875  in 15.66s 
Iter 39...	Training loss: 14097.081055  in 21.14s 
Iter 40...	Training loss: 13921.606445  in 22.98s 
Top-1 Recall: 0.049128 Precision: 0.049128 NDCG: 0.049128 HR: 0.049128
Top-5 Recall: 0.126783 Precision: 0.025357 NDCG: 0.088813 HR: 0.126783
Top-10 Recall: 0.185948 Precision: 0.018595 NDCG: 0.108000 HR: 0.185948
Eval costs: 30.613601 s
Iter 41...	Training loss: 13516.662109  in 21.64s 
Iter 42...	Training loss: 13053.586914  in 17.83s 
Iter 43...	Training loss: 13067.270508  in 25.33s 
Iter 44...	Training loss: 12817.761719  in 23.38s 
Iter 45...	Training loss: 12487.911133  in 15.06s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.134179 Precision: 0.026836 NDCG: 0.094050 HR: 0.134179
Top-10 Recall: 0.181194 Precision: 0.018119 NDCG: 0.109046 HR: 0.181194
Eval costs: 16.537013 s
Iter 46...	Training loss: 12446.134766  in 15.07s 
Iter 47...	Training loss: 11958.503906  in 15.05s 
Iter 48...	Training loss: 11929.258789  in 15.09s 
Iter 49...	Training loss: 11623.661133  in 15.80s 
Iter 50...	Training loss: 11676.984375  in 15.63s 
Top-1 Recall: 0.047544 Precision: 0.047544 NDCG: 0.047544 HR: 0.047544
Top-5 Recall: 0.131009 Precision: 0.026202 NDCG: 0.091105 HR: 0.131009
Top-10 Recall: 0.181722 Precision: 0.018172 NDCG: 0.107532 HR: 0.181722
Eval costs: 17.699117 s
Iter 51...	Training loss: 11309.020508  in 22.63s 
Iter 52...	Training loss: 11533.697266  in 24.56s 
Iter 53...	Training loss: 10709.293945  in 25.16s 
Iter 54...	Training loss: 10866.066406  in 18.37s 
Iter 55...	Training loss: 10546.465820  in 14.50s 
Top-1 Recall: 0.051770 Precision: 0.051770 NDCG: 0.051770 HR: 0.051770
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.094780 HR: 0.136820
Top-10 Recall: 0.184363 Precision: 0.018436 NDCG: 0.109894 HR: 0.184363
Eval costs: 16.564332 s
Iter 56...	Training loss: 10443.413086  in 14.76s 
Iter 57...	Training loss: 10709.101562  in 14.84s 
Iter 58...	Training loss: 10244.080078  in 15.01s 
Iter 59...	Training loss: 10326.438477  in 15.17s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=0.50 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 46801.933594  in 14.68s 
Iter 2...	Training loss: 45704.308594  in 14.69s 
Iter 3...	Training loss: 45535.421875  in 14.79s 
Iter 4...	Training loss: 45450.785156  in 14.87s 
Iter 5...	Training loss: 45354.351562  in 14.90s 
Top-1 Recall: 0.015320 Precision: 0.015320 NDCG: 0.015320 HR: 0.015320
Top-5 Recall: 0.062863 Precision: 0.012573 NDCG: 0.038709 HR: 0.062863
Top-10 Recall: 0.096144 Precision: 0.009614 NDCG: 0.049335 HR: 0.096144
Eval costs: 16.934961 s
Iter 6...	Training loss: 45115.097656  in 14.81s 
Iter 7...	Training loss: 43138.273438  in 15.87s 
Iter 8...	Training loss: 37649.976562  in 15.95s 
Iter 9...	Training loss: 30096.994141  in 15.00s 
Iter 10...	Training loss: 21156.115234  in 14.98s 
Top-1 Recall: 0.030111 Precision: 0.030111 NDCG: 0.030111 HR: 0.030111
Top-5 Recall: 0.100898 Precision: 0.020180 NDCG: 0.065693 HR: 0.100898
Top-10 Recall: 0.155837 Precision: 0.015584 NDCG: 0.083391 HR: 0.155837
Eval costs: 17.368837 s
Iter 11...	Training loss: 14953.316406  in 15.67s 
Iter 12...	Training loss: 11287.727539  in 20.54s 
Iter 13...	Training loss: 9043.348633  in 18.09s 
Iter 14...	Training loss: 7660.603516  in 16.15s 
Iter 15...	Training loss: 6610.914551  in 24.89s 
Top-1 Recall: 0.035922 Precision: 0.035922 NDCG: 0.035922 HR: 0.035922
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.077284 HR: 0.118331
Top-10 Recall: 0.180137 Precision: 0.018014 NDCG: 0.097055 HR: 0.180137
Eval costs: 18.002639 s
Iter 16...	Training loss: 5899.706543  in 21.68s 
Iter 17...	Training loss: 5379.200195  in 14.72s 
Iter 18...	Training loss: 4848.499023  in 14.61s 
Iter 19...	Training loss: 4475.398926  in 14.74s 
Iter 20...	Training loss: 4196.228516  in 14.93s 
Top-1 Recall: 0.039620 Precision: 0.039620 NDCG: 0.039620 HR: 0.039620
Top-5 Recall: 0.124142 Precision: 0.024828 NDCG: 0.082749 HR: 0.124142
Top-10 Recall: 0.172213 Precision: 0.017221 NDCG: 0.098309 HR: 0.172213
Eval costs: 22.258917 s
Iter 21...	Training loss: 3984.873291  in 21.38s 
Iter 22...	Training loss: 3748.572510  in 15.90s 
Iter 23...	Training loss: 3607.154541  in 18.50s 
Iter 24...	Training loss: 3455.560791  in 23.16s 
Iter 25...	Training loss: 3182.979004  in 24.28s 
Top-1 Recall: 0.035394 Precision: 0.035394 NDCG: 0.035394 HR: 0.035394
Top-5 Recall: 0.120444 Precision: 0.024089 NDCG: 0.079122 HR: 0.120444
Top-10 Recall: 0.177496 Precision: 0.017750 NDCG: 0.097662 HR: 0.177496
Eval costs: 29.154798 s
Iter 26...	Training loss: 3149.697998  in 24.19s 
Iter 27...	Training loss: 3021.621338  in 24.37s 
Iter 28...	Training loss: 2898.120605  in 24.42s 
Iter 29...	Training loss: 2787.419189  in 24.60s 
Iter 30...	Training loss: 2679.871582  in 24.73s 
Top-1 Recall: 0.035922 Precision: 0.035922 NDCG: 0.035922 HR: 0.035922
Top-5 Recall: 0.126783 Precision: 0.025357 NDCG: 0.081442 HR: 0.126783
Top-10 Recall: 0.183307 Precision: 0.018331 NDCG: 0.099849 HR: 0.183307
Eval costs: 31.123757 s
Iter 31...	Training loss: 2613.173340  in 24.56s 
Iter 32...	Training loss: 2584.183350  in 24.63s 
Iter 33...	Training loss: 2492.713135  in 24.33s 
Iter 34...	Training loss: 2408.413574  in 85.67s 
Iter 35...	Training loss: 2365.268066  in 16.40s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.080477 HR: 0.118331
Top-10 Recall: 0.170629 Precision: 0.017063 NDCG: 0.097375 HR: 0.170629
Eval costs: 15.625546 s
Iter 36...	Training loss: 2333.544434  in 14.41s 
Iter 37...	Training loss: 2245.378174  in 14.64s 
Iter 38...	Training loss: 2244.770508  in 17.27s 
Iter 39...	Training loss: 2145.597168  in 14.92s 
Iter 40...	Training loss: 2129.770996  in 14.67s 
Top-1 Recall: 0.035922 Precision: 0.035922 NDCG: 0.035922 HR: 0.035922
Top-5 Recall: 0.124142 Precision: 0.024828 NDCG: 0.081065 HR: 0.124142
Top-10 Recall: 0.170629 Precision: 0.017063 NDCG: 0.096092 HR: 0.170629
Eval costs: 16.844791 s
Iter 41...	Training loss: 2082.817139  in 14.84s 
Iter 42...	Training loss: 2040.567749  in 14.78s 
Iter 43...	Training loss: 1992.021973  in 15.92s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=50 
margin=0.50 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 47676.769531  in 8.80s 
Iter 2...	Training loss: 46005.464844  in 9.48s 
Iter 3...	Training loss: 45678.164062  in 13.56s 
Iter 4...	Training loss: 45570.906250  in 10.41s 
Iter 5...	Training loss: 45525.632812  in 8.40s 
Top-1 Recall: 0.003170 Precision: 0.003170 NDCG: 0.003170 HR: 0.003170
Top-5 Recall: 0.019546 Precision: 0.003909 NDCG: 0.011319 HR: 0.019546
Top-10 Recall: 0.036978 Precision: 0.003698 NDCG: 0.017027 HR: 0.036978
Eval costs: 9.969510 s
Iter 6...	Training loss: 45502.972656  in 8.22s 
Iter 7...	Training loss: 45490.328125  in 8.83s 
Iter 8...	Training loss: 45483.589844  in 8.82s 
Iter 9...	Training loss: 45479.253906  in 8.24s 
Iter 10...	Training loss: 45476.617188  in 8.53s 
Top-1 Recall: 0.004754 Precision: 0.004754 NDCG: 0.004754 HR: 0.004754
Top-5 Recall: 0.028526 Precision: 0.005705 NDCG: 0.016391 HR: 0.028526
Top-10 Recall: 0.052826 Precision: 0.005283 NDCG: 0.024148 HR: 0.052826
Eval costs: 11.676047 s
Iter 11...	Training loss: 45474.695312  in 9.25s 
Iter 12...	Training loss: 45473.468750  in 9.68s 
Iter 13...	Training loss: 45472.687500  in 8.50s 
Iter 14...	Training loss: 45471.882812  in 8.51s 
Iter 15...	Training loss: 45471.531250  in 8.80s 
Top-1 Recall: 0.006867 Precision: 0.006867 NDCG: 0.006867 HR: 0.006867
Top-5 Recall: 0.033809 Precision: 0.006762 NDCG: 0.020361 HR: 0.033809
Top-10 Recall: 0.057052 Precision: 0.005705 NDCG: 0.027815 HR: 0.057052
Eval costs: 10.627259 s
Iter 16...	Training loss: 45471.148438  in 8.68s 
Iter 17...	Training loss: 45470.859375  in 8.40s 
Iter 18...	Training loss: 45470.550781  in 8.74s 
Iter 19...	Training loss: 45470.125000  in 8.83s 
Iter 20...	Training loss: 45469.863281  in 8.72s 
Top-1 Recall: 0.006339 Precision: 0.006339 NDCG: 0.006339 HR: 0.006339
Top-5 Recall: 0.035394 Precision: 0.007079 NDCG: 0.020701 HR: 0.035394
Top-10 Recall: 0.069202 Precision: 0.006920 NDCG: 0.031455 HR: 0.069202
Eval costs: 10.722513 s
Iter 21...	Training loss: 45469.242188  in 8.90s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=200 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 182650.765625  in 31.84s 
Iter 2...	Training loss: 181851.593750  in 34.64s 
Iter 3...	Training loss: 181358.453125  in 35.12s 
Iter 4...	Training loss: 172893.000000  in 32.58s 
Iter 5...	Training loss: 155347.015625  in 32.71s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.075013 Precision: 0.015003 NDCG: 0.046949 HR: 0.075013
Top-10 Recall: 0.122557 Precision: 0.012256 NDCG: 0.062253 HR: 0.122557
Eval costs: 31.436605 s
Iter 6...	Training loss: 128569.742188  in 32.82s 
Iter 7...	Training loss: 91908.320312  in 33.93s 
Iter 8...	Training loss: 61984.179688  in 33.68s 
Iter 9...	Training loss: 44332.289062  in 33.24s 
Iter 10...	Training loss: 34410.375000  in 32.86s 
Top-1 Recall: 0.040148 Precision: 0.040148 NDCG: 0.040148 HR: 0.040148
Top-5 Recall: 0.137348 Precision: 0.027470 NDCG: 0.088997 HR: 0.137348
Top-10 Recall: 0.194929 Precision: 0.019493 NDCG: 0.107408 HR: 0.194929
Eval costs: 32.141937 s
Iter 11...	Training loss: 28844.849609  in 34.49s 
Iter 12...	Training loss: 24959.953125  in 33.78s 
Iter 13...	Training loss: 22128.421875  in 35.11s 
Iter 14...	Training loss: 19632.507812  in 40.02s 
Iter 15...	Training loss: 18228.826172  in 37.19s 
Top-1 Recall: 0.047015 Precision: 0.047015 NDCG: 0.047015 HR: 0.047015
Top-5 Recall: 0.130481 Precision: 0.026096 NDCG: 0.090448 HR: 0.130481
Top-10 Recall: 0.194400 Precision: 0.019440 NDCG: 0.110897 HR: 0.194400
Eval costs: 35.180928 s
Iter 16...	Training loss: 16844.482422  in 35.68s 
Iter 17...	Training loss: 15802.406250  in 33.04s 
Iter 18...	Training loss: 14849.641602  in 32.77s 
Iter 19...	Training loss: 14178.004883  in 33.18s 
Iter 20...	Training loss: 13419.960938  in 32.85s 
Top-1 Recall: 0.045959 Precision: 0.045959 NDCG: 0.045959 HR: 0.045959
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.092312 HR: 0.136820
Top-10 Recall: 0.200211 Precision: 0.020021 NDCG: 0.112566 HR: 0.200211
Eval costs: 40.951217 s
Iter 21...	Training loss: 12554.257812  in 38.70s 
Iter 22...	Training loss: 12383.935547  in 37.98s 
Iter 23...	Training loss: 11635.295898  in 37.01s 
Iter 24...	Training loss: 11012.916016  in 36.82s 
Iter 25...	Training loss: 10844.911133  in 34.00s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.126783 Precision: 0.025357 NDCG: 0.091566 HR: 0.126783
Top-10 Recall: 0.192287 Precision: 0.019229 NDCG: 0.112597 HR: 0.192287
Eval costs: 30.872993 s
Iter 26...	Training loss: 10234.351562  in 32.11s 
Iter 27...	Training loss: 9810.323242  in 32.54s 
Iter 28...	Training loss: 9558.279297  in 33.16s 
Iter 29...	Training loss: 9468.560547  in 32.67s 
Iter 30...	Training loss: 9021.250000  in 33.08s 
Top-1 Recall: 0.046487 Precision: 0.046487 NDCG: 0.046487 HR: 0.046487
Top-5 Recall: 0.140518 Precision: 0.028104 NDCG: 0.093927 HR: 0.140518
Top-10 Recall: 0.185420 Precision: 0.018542 NDCG: 0.108330 HR: 0.185420
Eval costs: 31.492693 s
Iter 31...	Training loss: 8907.821289  in 32.47s 
Iter 32...	Training loss: 8502.871094  in 32.71s 
Iter 33...	Training loss: 8219.655273  in 32.92s 
Iter 34...	Training loss: 8160.638672  in 32.81s 
Iter 35...	Training loss: 8075.164062  in 32.73s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.138405 Precision: 0.027681 NDCG: 0.094756 HR: 0.138405
Top-10 Recall: 0.188590 Precision: 0.018859 NDCG: 0.110940 HR: 0.188590
Eval costs: 31.717532 s
Iter 36...	Training loss: 7756.766113  in 32.61s 
Iter 37...	Training loss: 7816.855957  in 33.94s 
Iter 38...	Training loss: 7169.281738  in 39.69s 
Iter 39...	Training loss: 6977.392578  in 37.70s 
Iter 40...	Training loss: 7037.612305  in 37.25s 
Top-1 Recall: 0.047015 Precision: 0.047015 NDCG: 0.047015 HR: 0.047015
Top-5 Recall: 0.129952 Precision: 0.025990 NDCG: 0.089010 HR: 0.129952
Top-10 Recall: 0.176440 Precision: 0.017644 NDCG: 0.104087 HR: 0.176440
Eval costs: 37.830457 s
Iter 41...	Training loss: 6861.132812  in 36.56s 
Iter 42...	Training loss: 6679.729980  in 35.74s 
Iter 43...	Training loss: 6688.131348  in 31.49s 
Iter 44...	Training loss: 6472.295410  in 32.11s 
Iter 45...	Training loss: 6360.039551  in 32.21s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.131009 Precision: 0.026202 NDCG: 0.091298 HR: 0.131009
Top-10 Recall: 0.190703 Precision: 0.019070 NDCG: 0.110523 HR: 0.190703
Eval costs: 31.146630 s
Iter 46...	Training loss: 6310.093750  in 32.26s 
Iter 47...	Training loss: 6188.167969  in 32.48s 
Iter 48...	Training loss: 5967.390625  in 32.68s 
Iter 49...	Training loss: 5924.523438  in 32.92s 
Iter 50...	Training loss: 5791.046875  in 33.93s 
Top-1 Recall: 0.042789 Precision: 0.042789 NDCG: 0.042789 HR: 0.042789
Top-5 Recall: 0.133122 Precision: 0.026624 NDCG: 0.089161 HR: 0.133122
Top-10 Recall: 0.183307 Precision: 0.018331 NDCG: 0.105435 HR: 0.183307
Eval costs: 41.744758 s
Iter 51...	Training loss: 5572.010254  in 46.07s 
Iter 52...	Training loss: 5632.314941  in 39.33s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 183215.671875  in 15.09s 
Iter 2...	Training loss: 182116.921875  in 15.55s 
Iter 3...	Training loss: 181946.937500  in 14.80s 
Iter 4...	Training loss: 181861.156250  in 14.82s 
Iter 5...	Training loss: 181766.359375  in 14.87s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.062335 Precision: 0.012467 NDCG: 0.040797 HR: 0.062335
Top-10 Recall: 0.096672 Precision: 0.009667 NDCG: 0.051908 HR: 0.096672
Eval costs: 16.980152 s
Iter 6...	Training loss: 181527.953125  in 14.89s 
Iter 7...	Training loss: 178887.234375  in 14.95s 
Iter 8...	Training loss: 161220.765625  in 15.41s 
Iter 9...	Training loss: 146470.500000  in 15.01s 
Iter 10...	Training loss: 123680.500000  in 16.36s 
Top-1 Recall: 0.031696 Precision: 0.031696 NDCG: 0.031696 HR: 0.031696
Top-5 Recall: 0.092446 Precision: 0.018489 NDCG: 0.061810 HR: 0.092446
Top-10 Recall: 0.144216 Precision: 0.014422 NDCG: 0.078400 HR: 0.144216
Eval costs: 18.867170 s
Iter 11...	Training loss: 98130.539062  in 15.92s 
Iter 12...	Training loss: 77933.093750  in 16.67s 
Iter 13...	Training loss: 63380.687500  in 17.09s 
Iter 14...	Training loss: 52943.261719  in 15.91s 
Iter 15...	Training loss: 45677.011719  in 15.97s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.116746 Precision: 0.023349 NDCG: 0.078159 HR: 0.116746
Top-10 Recall: 0.176440 Precision: 0.017644 NDCG: 0.097466 HR: 0.176440
Eval costs: 18.018912 s
Iter 16...	Training loss: 39925.593750  in 17.31s 
Iter 17...	Training loss: 36170.757812  in 15.40s 
Iter 18...	Training loss: 32751.619141  in 15.20s 
Iter 19...	Training loss: 30079.953125  in 15.14s 
Iter 20...	Training loss: 28119.255859  in 15.15s 
Top-1 Recall: 0.043317 Precision: 0.043317 NDCG: 0.043317 HR: 0.043317
Top-5 Recall: 0.122557 Precision: 0.024511 NDCG: 0.083523 HR: 0.122557
Top-10 Recall: 0.178024 Precision: 0.017802 NDCG: 0.101262 HR: 0.178024
Eval costs: 17.574839 s
Iter 21...	Training loss: 26546.667969  in 16.02s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 204393.968750  in 10.87s 
Iter 2...	Training loss: 188107.906250  in 10.95s 
Iter 3...	Training loss: 181794.093750  in 11.10s 
Iter 4...	Training loss: 177176.796875  in 11.06s 
Iter 5...	Training loss: 172703.718750  in 11.47s 
Top-1 Recall: 0.007924 Precision: 0.007924 NDCG: 0.007924 HR: 0.007924
Top-5 Recall: 0.045959 Precision: 0.009192 NDCG: 0.026644 HR: 0.045959
Top-10 Recall: 0.076598 Precision: 0.007660 NDCG: 0.036427 HR: 0.076598
Eval costs: 16.956181 s
Iter 6...	Training loss: 168391.390625  in 11.47s 
Iter 7...	Training loss: 162999.328125  in 11.38s 
Iter 8...	Training loss: 157169.968750  in 11.20s 
Iter 9...	Training loss: 149765.484375  in 11.14s 
Iter 10...	Training loss: 140495.171875  in 11.19s 
Top-1 Recall: 0.033809 Precision: 0.033809 NDCG: 0.033809 HR: 0.033809
Top-5 Recall: 0.099313 Precision: 0.019863 NDCG: 0.065785 HR: 0.099313
Top-10 Recall: 0.138933 Precision: 0.013893 NDCG: 0.078794 HR: 0.138933
Eval costs: 17.103479 s
Iter 11...	Training loss: 129306.414062  in 11.15s 
Iter 12...	Training loss: 117486.156250  in 11.18s 
Iter 13...	Training loss: 105947.664062  in 11.39s 
Iter 14...	Training loss: 94489.851562  in 13.15s 
Iter 15...	Training loss: 83219.937500  in 11.92s 
Top-1 Recall: 0.039091 Precision: 0.039091 NDCG: 0.039091 HR: 0.039091
Top-5 Recall: 0.118859 Precision: 0.023772 NDCG: 0.079307 HR: 0.118859
Top-10 Recall: 0.169572 Precision: 0.016957 NDCG: 0.095548 HR: 0.169572
Eval costs: 24.511177 s
Iter 16...	Training loss: 73063.093750  in 16.54s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 180562.531250  in 10.57s 
Iter 2...	Training loss: 163551.203125  in 10.14s 
Iter 3...	Training loss: 82587.789062  in 9.38s 
Iter 4...	Training loss: 45.537373  in 9.34s 
Iter 5...	Training loss: 5.488846  in 9.40s 
Top-1 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-5 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-10 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Eval costs: 8.982321 s
Iter 6...	Training loss: 2.443766  in 9.53s 
Iter 7...	Training loss: 1.379137  in 9.45s 
Iter 8...	Training loss: 1.315991  in 9.46s 
Iter 9...	Training loss: 0.915346  in 9.47s 
Iter 10...	Training loss: 0.976226  in 9.54s 
Top-1 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-5 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-10 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Eval costs: 9.274245 s
Iter 11...	Training loss: 0.824287  in 9.60s 
Iter 12...	Training loss: 0.512418  in 10.04s 
Iter 13...	Training loss: 0.198298  in 10.25s 
Iter 14...	Training loss: 0.520249  in 9.67s 
Iter 15...	Training loss: 0.401426  in 9.69s 
Top-1 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-5 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-10 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Eval costs: 9.627414 s
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 182749.187500  in 9.89s 
Iter 2...	Training loss: 181919.031250  in 9.88s 
Iter 3...	Training loss: 181431.125000  in 9.56s 
Iter 4...	Training loss: 170507.984375  in 9.49s 
Iter 5...	Training loss: 154278.156250  in 9.54s 
Top-1 Recall: 0.029583 Precision: 0.029583 NDCG: 0.029583 HR: 0.029583
Top-5 Recall: 0.065504 Precision: 0.013101 NDCG: 0.048425 HR: 0.065504
Top-10 Recall: 0.081881 Precision: 0.008188 NDCG: 0.053620 HR: 0.081881
Eval costs: 9.302450 s
Iter 6...	Training loss: 151638.265625  in 9.61s 
Iter 7...	Training loss: 149911.437500  in 11.10s 
Iter 8...	Training loss: 147790.687500  in 10.00s 
Iter 9...	Training loss: 143415.031250  in 10.13s 
Iter 10...	Training loss: 138739.812500  in 9.64s 
Top-1 Recall: 0.032224 Precision: 0.032224 NDCG: 0.032224 HR: 0.032224
Top-5 Recall: 0.087691 Precision: 0.017538 NDCG: 0.060861 HR: 0.087691
Top-10 Recall: 0.115689 Precision: 0.011569 NDCG: 0.069818 HR: 0.115689
Eval costs: 9.495498 s
Iter 11...	Training loss: 136192.734375  in 10.32s 
Iter 12...	Training loss: 133264.968750  in 10.49s 
Iter 13...	Training loss: 130079.140625  in 9.73s 
Iter 14...	Training loss: 126557.070312  in 9.70s 
Iter 15...	Training loss: 123076.460938  in 9.70s 
Top-1 Recall: 0.048600 Precision: 0.048600 NDCG: 0.048600 HR: 0.048600
Top-5 Recall: 0.110935 Precision: 0.022187 NDCG: 0.080110 HR: 0.110935
Top-10 Recall: 0.144216 Precision: 0.014422 NDCG: 0.090796 HR: 0.144216
Eval costs: 9.633061 s
Iter 16...	Training loss: 119535.648438  in 10.00s 
Iter 17...	Training loss: 116217.226562  in 10.00s 
Iter 18...	Training loss: 112658.195312  in 9.77s 
Iter 19...	Training loss: 109084.992188  in 9.75s 
Iter 20...	Training loss: 105380.000000  in 9.76s 
Top-1 Recall: 0.050713 Precision: 0.050713 NDCG: 0.050713 HR: 0.050713
Top-5 Recall: 0.119915 Precision: 0.023983 NDCG: 0.084750 HR: 0.119915
Top-10 Recall: 0.160063 Precision: 0.016006 NDCG: 0.097654 HR: 0.160063
Eval costs: 9.655542 s
Iter 21...	Training loss: 101292.703125  in 10.03s 
Iter 22...	Training loss: 96856.507812  in 10.73s 
Iter 23...	Training loss: 92121.460938  in 10.34s 
Iter 24...	Training loss: 87611.656250  in 10.24s 
Iter 25...	Training loss: 83220.156250  in 9.94s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.120972 Precision: 0.024194 NDCG: 0.083271 HR: 0.120972
Top-10 Recall: 0.178553 Precision: 0.017855 NDCG: 0.101722 HR: 0.178553
Eval costs: 9.760741 s
Iter 26...	Training loss: 78538.882812  in 10.33s 
Iter 27...	Training loss: 75036.351562  in 10.79s 
Iter 28...	Training loss: 71337.601562  in 10.48s 
Iter 29...	Training loss: 67389.414062  in 10.09s 
Iter 30...	Training loss: 64624.128906  in 10.49s 
Top-1 Recall: 0.042789 Precision: 0.042789 NDCG: 0.042789 HR: 0.042789
Top-5 Recall: 0.125198 Precision: 0.025040 NDCG: 0.084522 HR: 0.125198
Top-10 Recall: 0.178024 Precision: 0.017802 NDCG: 0.101504 HR: 0.178024
Eval costs: 10.242426 s
Iter 31...	Training loss: 61575.351562  in 10.22s 
Iter 32...	Training loss: 58669.667969  in 10.08s 
Iter 33...	Training loss: 56775.093750  in 9.90s 
Iter 34...	Training loss: 54402.140625  in 9.86s 
Iter 35...	Training loss: 52533.660156  in 9.85s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.125726 Precision: 0.025145 NDCG: 0.082710 HR: 0.125726
Top-10 Recall: 0.175911 Precision: 0.017591 NDCG: 0.098861 HR: 0.175911
Eval costs: 10.673213 s
Iter 36...	Training loss: 51362.648438  in 10.66s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 195567.171875  in 13.99s 
Iter 2...	Training loss: 179206.875000  in 14.17s 
Iter 3...	Training loss: 167230.921875  in 14.27s 
Iter 4...	Training loss: 161667.109375  in 14.37s 
Iter 5...	Training loss: 156462.296875  in 14.44s 
Top-1 Recall: 0.027470 Precision: 0.027470 NDCG: 0.027470 HR: 0.027470
Top-5 Recall: 0.076070 Precision: 0.015214 NDCG: 0.051618 HR: 0.076070
Top-10 Recall: 0.104596 Precision: 0.010460 NDCG: 0.060857 HR: 0.104596
Eval costs: 16.724459 s
Iter 6...	Training loss: 148207.828125  in 14.45s 
Iter 7...	Training loss: 142590.953125  in 15.70s 
Iter 8...	Training loss: 135813.453125  in 16.48s 
Iter 9...	Training loss: 126516.437500  in 15.48s 
Iter 10...	Training loss: 114226.625000  in 15.49s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.108294 Precision: 0.021659 NDCG: 0.078095 HR: 0.108294
Top-10 Recall: 0.157950 Precision: 0.015795 NDCG: 0.094176 HR: 0.157950
Eval costs: 17.398633 s
Iter 11...	Training loss: 98749.539062  in 16.18s 
Iter 12...	Training loss: 80448.953125  in 15.94s 
Iter 13...	Training loss: 63158.117188  in 14.64s 
Iter 14...	Training loss: 49480.453125  in 14.69s 
Iter 15...	Training loss: 40793.734375  in 14.77s 
Top-1 Recall: 0.042789 Precision: 0.042789 NDCG: 0.042789 HR: 0.042789
Top-5 Recall: 0.121500 Precision: 0.024300 NDCG: 0.083796 HR: 0.121500
Top-10 Recall: 0.163761 Precision: 0.016376 NDCG: 0.097506 HR: 0.163761
Eval costs: 16.954103 s
Iter 16...	Training loss: 33904.769531  in 14.93s 
Iter 17...	Training loss: 30004.841797  in 15.44s 
Iter 18...	Training loss: 26922.574219  in 14.92s 
Iter 19...	Training loss: 24451.494141  in 15.61s 
Iter 20...	Training loss: 22196.267578  in 14.73s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.122029 Precision: 0.024406 NDCG: 0.084275 HR: 0.122029
Top-10 Recall: 0.165874 Precision: 0.016587 NDCG: 0.098186 HR: 0.165874
Eval costs: 18.676581 s
Iter 21...	Training loss: 20350.285156  in 15.11s 
Iter 22...	Training loss: 19327.937500  in 15.05s 
Iter 23...	Training loss: 17474.650391  in 14.80s 
Iter 24...	Training loss: 17050.306641  in 16.07s 
Iter 25...	Training loss: 16276.680664  in 15.03s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.120444 Precision: 0.024089 NDCG: 0.085688 HR: 0.120444
Top-10 Recall: 0.161648 Precision: 0.016165 NDCG: 0.099007 HR: 0.161648
Eval costs: 23.621813 s
Iter 26...	Training loss: 15216.171875  in 18.52s 
Iter 27...	Training loss: 14779.725586  in 15.44s 
Iter 28...	Training loss: 13907.449219  in 15.13s 
Iter 29...	Training loss: 13549.021484  in 14.88s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 218201.218750  in 14.45s 
Iter 2...	Training loss: 207577.546875  in 14.57s 
Iter 3...	Training loss: 200050.078125  in 14.84s 
Iter 4...	Training loss: 194528.984375  in 15.06s 
Iter 5...	Training loss: 190741.015625  in 14.84s 
Top-1 Recall: 0.008452 Precision: 0.008452 NDCG: 0.008452 HR: 0.008452
Top-5 Recall: 0.032752 Precision: 0.006550 NDCG: 0.021219 HR: 0.032752
Top-10 Recall: 0.052826 Precision: 0.005283 NDCG: 0.027715 HR: 0.052826
Eval costs: 16.947064 s
Iter 6...	Training loss: 187782.203125  in 14.78s 
Iter 7...	Training loss: 185503.593750  in 14.90s 
Iter 8...	Training loss: 183662.765625  in 14.89s 
Iter 9...	Training loss: 182084.375000  in 14.87s 
Iter 10...	Training loss: 180734.578125  in 15.14s 
Top-1 Recall: 0.012150 Precision: 0.012150 NDCG: 0.012150 HR: 0.012150
Top-5 Recall: 0.042261 Precision: 0.008452 NDCG: 0.027538 HR: 0.042261
Top-10 Recall: 0.059165 Precision: 0.005917 NDCG: 0.033060 HR: 0.059165
Eval costs: 17.393251 s
Iter 11...	Training loss: 179403.500000  in 15.20s 
Iter 12...	Training loss: 177918.937500  in 14.95s 
Iter 13...	Training loss: 176599.015625  in 14.93s 
Iter 14...	Training loss: 175167.296875  in 16.03s 
Iter 15...	Training loss: 173401.078125  in 15.88s 
Top-1 Recall: 0.014791 Precision: 0.014791 NDCG: 0.014791 HR: 0.014791
Top-5 Recall: 0.044902 Precision: 0.008980 NDCG: 0.029741 HR: 0.044902
Top-10 Recall: 0.066033 Precision: 0.006603 NDCG: 0.036616 HR: 0.066033
Eval costs: 17.992843 s
Iter 16...	Training loss: 171454.234375  in 15.40s 
Iter 17...	Training loss: 169387.953125  in 15.18s 
Iter 18...	Training loss: 166349.625000  in 15.08s 
Iter 19...	Training loss: 162849.546875  in 15.05s 
Iter 20...	Training loss: 160501.781250  in 15.02s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.044374 Precision: 0.008875 NDCG: 0.031292 HR: 0.044374
Top-10 Recall: 0.069202 Precision: 0.006920 NDCG: 0.039429 HR: 0.069202
Eval costs: 17.280952 s
Iter 21...	Training loss: 159684.093750  in 15.33s 
Iter 22...	Training loss: 158912.953125  in 17.23s 
Iter 23...	Training loss: 158643.890625  in 19.54s 
Iter 24...	Training loss: 158642.453125  in 15.79s 
Iter 25...	Training loss: 157740.640625  in 15.41s 
Top-1 Recall: 0.016904 Precision: 0.016904 NDCG: 0.016904 HR: 0.016904
Top-5 Recall: 0.044374 Precision: 0.008875 NDCG: 0.030309 HR: 0.044374
Top-10 Recall: 0.073428 Precision: 0.007343 NDCG: 0.039635 HR: 0.073428
Eval costs: 17.508555 s
Iter 26...	Training loss: 157685.546875  in 15.58s 
Iter 27...	Training loss: 157524.578125  in 16.01s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 218233.406250  in 11.77s 
Iter 2...	Training loss: 209651.140625  in 14.55s 
Iter 3...	Training loss: 204013.093750  in 15.50s 
Iter 4...	Training loss: 199964.781250  in 13.72s 
Iter 5...	Training loss: 196902.328125  in 14.19s 
Top-1 Recall: 0.012150 Precision: 0.012150 NDCG: 0.012150 HR: 0.012150
Top-5 Recall: 0.039091 Precision: 0.007818 NDCG: 0.025934 HR: 0.039091
Top-10 Recall: 0.055996 Precision: 0.005600 NDCG: 0.031356 HR: 0.055996
Eval costs: 21.977438 s
Iter 6...	Training loss: 194413.531250  in 13.74s 
Iter 7...	Training loss: 192450.218750  in 13.30s 
Iter 8...	Training loss: 190845.687500  in 13.55s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 199910.750000  in 12.25s 
Iter 2...	Training loss: 186586.234375  in 12.67s 
Iter 3...	Training loss: 184002.750000  in 12.58s 
Iter 4...	Training loss: 182241.906250  in 12.62s 
Iter 5...	Training loss: 179324.453125  in 12.51s 
Top-1 Recall: 0.022715 Precision: 0.022715 NDCG: 0.022715 HR: 0.022715
Top-5 Recall: 0.042789 Precision: 0.008558 NDCG: 0.032944 HR: 0.042789
Top-10 Recall: 0.070259 Precision: 0.007026 NDCG: 0.041860 HR: 0.070259
Eval costs: 17.365165 s
Iter 6...	Training loss: 172077.437500  in 12.52s 
Iter 7...	Training loss: 167912.171875  in 12.65s 
Iter 8...	Training loss: 165635.171875  in 13.03s 
Iter 9...	Training loss: 163778.875000  in 13.14s 
Iter 10...	Training loss: 162654.046875  in 12.87s 
Top-1 Recall: 0.007924 Precision: 0.007924 NDCG: 0.007924 HR: 0.007924
Top-5 Recall: 0.046487 Precision: 0.009297 NDCG: 0.026908 HR: 0.046487
Top-10 Recall: 0.072372 Precision: 0.007237 NDCG: 0.035206 HR: 0.072372
Eval costs: 18.540303 s
Iter 11...	Training loss: 161760.984375  in 12.58s 
Iter 12...	Training loss: 160524.640625  in 13.56s 
Iter 13...	Training loss: 159872.750000  in 14.42s 
Iter 14...	Training loss: 159190.609375  in 14.53s 
Iter 15...	Training loss: 158826.421875  in 13.82s 
Top-1 Recall: 0.007924 Precision: 0.007924 NDCG: 0.007924 HR: 0.007924
Top-5 Recall: 0.045959 Precision: 0.009192 NDCG: 0.026538 HR: 0.045959
Top-10 Recall: 0.070787 Precision: 0.007079 NDCG: 0.034546 HR: 0.070787
Eval costs: 18.283617 s
Iter 16...	Training loss: 158230.343750  in 13.24s 
Iter 17...	Training loss: 157526.015625  in 12.88s 
Iter 18...	Training loss: 157320.921875  in 13.94s 
Iter 19...	Training loss: 156777.140625  in 13.78s 
Iter 20...	Training loss: 156183.156250  in 14.52s 
Top-1 Recall: 0.013207 Precision: 0.013207 NDCG: 0.013207 HR: 0.013207
Top-5 Recall: 0.050185 Precision: 0.010037 NDCG: 0.032056 HR: 0.050185
Top-10 Recall: 0.076070 Precision: 0.007607 NDCG: 0.040260 HR: 0.076070
Eval costs: 18.723787 s
Iter 21...	Training loss: 155603.531250  in 13.31s 
Iter 22...	Training loss: 154983.390625  in 12.53s 
Iter 23...	Training loss: 153776.812500  in 12.87s 
Iter 24...	Training loss: 153478.109375  in 12.41s 
Iter 25...	Training loss: 153288.703125  in 12.40s 
Top-1 Recall: 0.020602 Precision: 0.020602 NDCG: 0.020602 HR: 0.020602
Top-5 Recall: 0.054411 Precision: 0.010882 NDCG: 0.038051 HR: 0.054411
Top-10 Recall: 0.080824 Precision: 0.008082 NDCG: 0.046468 HR: 0.080824
Eval costs: 18.326731 s
Iter 26...	Training loss: 152596.921875  in 12.92s 
Iter 27...	Training loss: 151951.609375  in 13.59s 
Iter 28...	Training loss: 151637.671875  in 12.84s 
Iter 29...	Training loss: 151105.843750  in 13.48s 
Iter 30...	Training loss: 151049.375000  in 12.61s 
Top-1 Recall: 0.026941 Precision: 0.026941 NDCG: 0.026941 HR: 0.026941
Top-5 Recall: 0.064976 Precision: 0.012995 NDCG: 0.046250 HR: 0.064976
Top-10 Recall: 0.089276 Precision: 0.008928 NDCG: 0.054024 HR: 0.089276
Eval costs: 17.175668 s
Iter 31...	Training loss: 150546.218750  in 14.29s 
Iter 32...	Training loss: 150108.390625  in 14.57s 
Iter 33...	Training loss: 149611.937500  in 15.26s 
Iter 34...	Training loss: 149376.921875  in 14.83s 
Iter 35...	Training loss: 149190.531250  in 14.69s 
Top-1 Recall: 0.027470 Precision: 0.027470 NDCG: 0.027470 HR: 0.027470
Top-5 Recall: 0.066033 Precision: 0.013207 NDCG: 0.047135 HR: 0.066033
Top-10 Recall: 0.093502 Precision: 0.009350 NDCG: 0.056057 HR: 0.093502
Eval costs: 21.528246 s
Iter 36...	Training loss: 149166.312500  in 14.50s 
Iter 37...	Training loss: 148442.562500  in 14.95s 
Iter 38...	Training loss: 147725.859375  in 14.66s 
Iter 39...	Training loss: 147480.437500  in 14.58s 
Iter 40...	Training loss: 146752.796875  in 14.62s 
Top-1 Recall: 0.025885 Precision: 0.025885 NDCG: 0.025885 HR: 0.025885
Top-5 Recall: 0.062863 Precision: 0.012573 NDCG: 0.044823 HR: 0.062863
Top-10 Recall: 0.096672 Precision: 0.009667 NDCG: 0.055768 HR: 0.096672
Eval costs: 22.198025 s
Iter 41...	Training loss: 146289.609375  in 14.57s 
Iter 42...	Training loss: 145901.078125  in 15.42s 
Iter 43...	Training loss: 144987.015625  in 15.71s 
Iter 44...	Training loss: 144332.656250  in 15.90s 
Iter 45...	Training loss: 143708.625000  in 15.30s 
Top-1 Recall: 0.023772 Precision: 0.023772 NDCG: 0.023772 HR: 0.023772
Top-5 Recall: 0.074485 Precision: 0.014897 NDCG: 0.049786 HR: 0.074485
Top-10 Recall: 0.105652 Precision: 0.010565 NDCG: 0.059867 HR: 0.105652
Eval costs: 19.897910 s
Iter 46...	Training loss: 143260.859375  in 15.57s 
Iter 47...	Training loss: 142917.046875  in 13.35s 
Iter 48...	Training loss: 142108.265625  in 13.35s 
Iter 49...	Training loss: 141798.156250  in 13.50s 
Iter 50...	Training loss: 140979.734375  in 14.07s 
Top-1 Recall: 0.025885 Precision: 0.025885 NDCG: 0.025885 HR: 0.025885
Top-5 Recall: 0.078183 Precision: 0.015637 NDCG: 0.053235 HR: 0.078183
Top-10 Recall: 0.103539 Precision: 0.010354 NDCG: 0.061351 HR: 0.103539
Eval costs: 18.427999 s
Iter 51...	Training loss: 140616.281250  in 12.60s 
Iter 52...	Training loss: 140619.093750  in 12.66s 
Iter 53...	Training loss: 140032.609375  in 12.56s 
Iter 54...	Training loss: 140180.734375  in 12.58s 
Iter 55...	Training loss: 139506.890625  in 12.56s 
Top-1 Recall: 0.031167 Precision: 0.031167 NDCG: 0.031167 HR: 0.031167
Top-5 Recall: 0.079768 Precision: 0.015954 NDCG: 0.055627 HR: 0.079768
Top-10 Recall: 0.117802 Precision: 0.011780 NDCG: 0.067943 HR: 0.117802
Eval costs: 17.618849 s
Iter 56...	Training loss: 138996.312500  in 12.57s 
Iter 57...	Training loss: 138777.859375  in 12.96s 
Iter 58...	Training loss: 138201.406250  in 13.28s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 247246.000000  in 12.52s 
Iter 2...	Training loss: 165896.718750  in 12.67s 
Iter 3...	Training loss: 164635.687500  in 12.50s 
Iter 4...	Training loss: 165658.968750  in 12.50s 
Iter 5...	Training loss: 164628.578125  in 12.65s 
Top-1 Recall: 0.006867 Precision: 0.006867 NDCG: 0.006867 HR: 0.006867
Top-5 Recall: 0.035394 Precision: 0.007079 NDCG: 0.021540 HR: 0.035394
Top-10 Recall: 0.052298 Precision: 0.005230 NDCG: 0.027067 HR: 0.052298
Eval costs: 17.601803 s
Iter 6...	Training loss: 163613.015625  in 12.76s 
Iter 7...	Training loss: 162209.031250  in 13.62s 
Iter 8...	Training loss: 159633.062500  in 13.30s 
Iter 9...	Training loss: 158015.093750  in 12.84s 
Iter 10...	Training loss: 157758.812500  in 12.65s 
Top-1 Recall: 0.005811 Precision: 0.005811 NDCG: 0.005811 HR: 0.005811
Top-5 Recall: 0.031696 Precision: 0.006339 NDCG: 0.018575 HR: 0.031696
Top-10 Recall: 0.051241 Precision: 0.005124 NDCG: 0.025037 HR: 0.051241
Eval costs: 17.359158 s
Iter 11...	Training loss: 157092.406250  in 13.21s 
Iter 12...	Training loss: 158624.968750  in 14.35s 
Iter 13...	Training loss: 161947.484375  in 14.57s 
Iter 14...	Training loss: 160549.171875  in 12.48s 
Iter 15...	Training loss: 157818.218750  in 12.82s 
Top-1 Recall: 0.008980 Precision: 0.008980 NDCG: 0.008980 HR: 0.008980
Top-5 Recall: 0.036978 Precision: 0.007396 NDCG: 0.023063 HR: 0.036978
Top-10 Recall: 0.054411 Precision: 0.005441 NDCG: 0.028590 HR: 0.054411
Eval costs: 21.203380 s
=======
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2122957.250000 (192283.530212, 1930673.689453) in 18.49s 
Iter 2...	Training loss: 1872194.375000 (15791.880298, 1856402.429688) in 18.36s 
Iter 3...	Training loss: 1805872.750000 (0.000000, 1805872.908203) in 14.85s 
Iter 4...	Training loss: 1750157.875000 (20594.929605, 1729562.870117) in 23.75s 
Iter 5...	Training loss: 1557474.125000 (0.000000, 1557474.178711) in 16.50s 
Top-1 Recall: 0.012150 Precision: 0.012150 NDCG: 0.012150 HR: 0.012150
Top-5 Recall: 0.054411 Precision: 0.010882 NDCG: 0.032723 HR: 0.054411
Top-10 Recall: 0.093502 Precision: 0.009350 NDCG: 0.045184 HR: 0.093502
Eval costs: 16.384567 s
Iter 6...	Training loss: 1446506.875000 (12043.189768, 1434463.598633) in 22.53s 
Iter 7...	Training loss: 1331655.750000 (4923.751138, 1326732.030273) in 22.20s 
Iter 8...	Training loss: 1250518.125000 (4440.697420, 1246077.405273) in 28.15s 
Iter 9...	Training loss: 1184282.500000 (4119.010787, 1180163.504883) in 21.62s 
Iter 10...	Training loss: 1128851.875000 (3900.765617, 1124951.172852) in 20.14s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.109350 Precision: 0.021870 NDCG: 0.074915 HR: 0.109350
Top-10 Recall: 0.163233 Precision: 0.016323 NDCG: 0.092427 HR: 0.163233
Eval costs: 15.914721 s
Iter 11...	Training loss: 1063889.250000 (0.000000, 1063889.195312) in 15.46s 
Iter 12...	Training loss: 1024613.750000 (7054.923112, 1017558.776367) in 23.23s 
Iter 13...	Training loss: 957049.125000 (0.000000, 957049.152344) in 15.00s 
Iter 14...	Training loss: 912045.875000 (6743.680815, 905302.268555) in 22.05s 
Iter 15...	Training loss: 835761.125000 (0.000000, 835761.186523) in 15.01s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.127311 Precision: 0.025462 NDCG: 0.085666 HR: 0.127311
Top-10 Recall: 0.178024 Precision: 0.017802 NDCG: 0.101916 HR: 0.178024
Eval costs: 16.105826 s
Iter 16...	Training loss: 787794.562500 (6585.681070, 781208.900391) in 22.39s 
Iter 17...	Training loss: 716017.312500 (3408.748775, 712608.607910) in 19.06s 
Iter 18...	Training loss: 661067.437500 (3443.461876, 657623.989258) in 25.57s 
Iter 19...	Training loss: 607011.437500 (3437.473007, 603574.021973) in 25.83s 
Iter 20...	Training loss: 550053.625000 (0.000000, 550053.627930) in 16.03s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.128896 Precision: 0.025779 NDCG: 0.086232 HR: 0.128896
Top-10 Recall: 0.189646 Precision: 0.018965 NDCG: 0.105849 HR: 0.189646
Eval costs: 17.127544 s
Iter 21...	Training loss: 518327.062500 (6447.657316, 511879.401855) in 24.33s 
Iter 22...	Training loss: 478443.343750 (3380.705672, 475062.637695) in 22.92s 
Iter 23...	Training loss: 442967.218750 (3418.812610, 439548.398438) in 22.26s 
Iter 24...	Training loss: 412140.593750 (3421.609190, 408719.045654) in 19.55s 
Iter 25...	Training loss: 386436.375000 (3421.237254, 383015.073730) in 19.18s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.132594 Precision: 0.026519 NDCG: 0.090755 HR: 0.132594
Top-10 Recall: 0.195985 Precision: 0.019599 NDCG: 0.111401 HR: 0.195985
Eval costs: 16.259234 s
Iter 26...	Training loss: 358385.781250 (0.000000, 358385.785156) in 16.44s 
Iter 27...	Training loss: 353198.156250 (6364.319044, 346833.875244) in 24.93s 
Iter 28...	Training loss: 319428.750000 (0.000000, 319428.755859) in 15.43s 
Iter 29...	Training loss: 316055.937500 (6306.301592, 309749.652344) in 22.17s 
Iter 30...	Training loss: 299347.125000 (3353.494772, 295993.608398) in 18.79s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.135763 Precision: 0.027153 NDCG: 0.090308 HR: 0.135763
Top-10 Recall: 0.193872 Precision: 0.019387 NDCG: 0.109107 HR: 0.193872
Eval costs: 17.795813 s
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2159116.500000 (105224.026443, 2053892.675781) in 60.43s 
Iter 2...	Training loss: 1964800.625000 (18858.008080, 1945942.767578) in 47.76s 
Iter 3...	Training loss: 1863355.500000 (0.000000, 1863355.517578) in 17.31s 
Iter 4...	Training loss: 1884105.250000 (17287.569280, 1866817.626953) in 74.37s 
Iter 5...	Training loss: 1845727.750000 (5101.310627, 1840626.468750) in 55.95s 
Top-1 Recall: 0.016904 Precision: 0.016904 NDCG: 0.016904 HR: 0.016904
Top-5 Recall: 0.053883 Precision: 0.010777 NDCG: 0.035602 HR: 0.053883
Top-10 Recall: 0.083465 Precision: 0.008347 NDCG: 0.045196 HR: 0.083465
Eval costs: 16.624172 s
Iter 6...	Training loss: 1827928.250000 (4047.279186, 1823881.039062) in 51.34s 
Iter 7...	Training loss: 1804396.500000 (0.000000, 1804396.498047) in 17.83s 
Iter 8...	Training loss: 1813304.750000 (6453.623109, 1806850.908203) in 73.74s 
Iter 9...	Training loss: 1670452.375000 (0.000000, 1670452.414062) in 17.38s 
Iter 10...	Training loss: 1480474.750000 (5525.722538, 1474948.953125) in 74.58s 
Top-1 Recall: 0.025357 Precision: 0.025357 NDCG: 0.025357 HR: 0.025357
Top-5 Recall: 0.090861 Precision: 0.018172 NDCG: 0.057913 HR: 0.090861
Top-10 Recall: 0.135763 Precision: 0.013576 NDCG: 0.072336 HR: 0.135763
Eval costs: 17.625188 s
Iter 11...	Training loss: 1257299.625000 (2740.496742, 1254559.233398) in 54.93s 
Iter 12...	Training loss: 1084674.875000 (0.000000, 1084674.880859) in 17.35s 
Iter 13...	Training loss: 952263.375000 (5242.598017, 947020.748047) in 78.22s 
Iter 14...	Training loss: 799917.062500 (0.000000, 799917.060547) in 17.89s 
Iter 15...	Training loss: 693053.812500 (5168.238486, 687885.653809) in 83.84s 
Top-1 Recall: 0.037507 Precision: 0.037507 NDCG: 0.037507 HR: 0.037507
Top-5 Recall: 0.125198 Precision: 0.025040 NDCG: 0.082215 HR: 0.125198
Top-10 Recall: 0.190703 Precision: 0.019070 NDCG: 0.103315 HR: 0.190703
Eval costs: 25.057628 s
Iter 16...	Training loss: 586726.000000 (0.000000, 586726.008789) in 20.61s 
Iter 17...	Training loss: 534482.625000 (5127.593737, 529355.110352) in 99.63s 
Iter 18...	Training loss: 465981.250000 (0.000000, 465981.270508) in 24.99s 
Iter 19...	Training loss: 435743.093750 (5115.188625, 430627.895020) in 91.10s 
Iter 20...	Training loss: 400651.156250 (2633.265991, 398017.868896) in 53.78s 
Top-1 Recall: 0.039091 Precision: 0.039091 NDCG: 0.039091 HR: 0.039091
Top-5 Recall: 0.128896 Precision: 0.025779 NDCG: 0.085138 HR: 0.128896
Top-10 Recall: 0.192287 Precision: 0.019229 NDCG: 0.105249 HR: 0.192287
Eval costs: 19.235443 s
Iter 21...	Training loss: 364254.562500 (0.000000, 364254.578857) in 19.36s 
Iter 22...	Training loss: 359456.500000 (5106.291760, 354350.267334) in 85.82s 
Iter 23...	Training loss: 335445.656250 (2633.562986, 332812.077393) in 52.20s 
Iter 24...	Training loss: 321255.281250 (2651.075372, 318604.232422) in 49.82s 
Iter 25...	Training loss: 307432.156250 (2656.425374, 304775.740723) in 50.41s 
Top-1 Recall: 0.036450 Precision: 0.036450 NDCG: 0.036450 HR: 0.036450
Top-5 Recall: 0.132066 Precision: 0.026413 NDCG: 0.085110 HR: 0.132066
Top-10 Recall: 0.193344 Precision: 0.019334 NDCG: 0.104715 HR: 0.193344
Eval costs: 20.208687 s
Iter 26...	Training loss: 297748.312500 (2654.066837, 295094.205078) in 47.88s 
Iter 27...	Training loss: 289006.781250 (2654.530681, 286352.238525) in 46.79s 
Iter 28...	Training loss: 272571.250000 (0.000000, 272571.272705) in 19.65s 
Iter 29...	Training loss: 280408.625000 (5091.209229, 275317.423584) in 74.83s 
Iter 30...	Training loss: 254956.031250 (0.000000, 254956.020996) in 21.59s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.135763 Precision: 0.027153 NDCG: 0.088536 HR: 0.135763
Top-10 Recall: 0.194400 Precision: 0.019440 NDCG: 0.107699 HR: 0.194400
Eval costs: 17.494519 s
embed_dim=100 
margin=2.00 
alpha=1.0000 
beta=1.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 2293870.000000 (0.000000, 121265.554167, 2172603.828125) in 88.02s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=20 
margin=2.00 
alpha=1.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 544218.250000 (253837.437790, 290380.822266) in 6.28s 
Iter 2...	Training loss: 241635.359375 (0.000000, 241635.354004) in 4.05s 
Iter 3...	Training loss: 351078.625000 (107990.853990, 243087.756836) in 8.62s 
Iter 4...	Training loss: 212833.703125 (0.000000, 212833.700562) in 4.24s 
Iter 5...	Training loss: 237727.265625 (25574.701598, 212152.568115) in 7.93s 
Top-1 Recall: 0.000528 Precision: 0.000528 NDCG: 0.000528 HR: 0.000528
Top-5 Recall: 0.003170 Precision: 0.000634 NDCG: 0.001854 HR: 0.003170
Top-10 Recall: 0.007924 Precision: 0.000792 NDCG: 0.003362 HR: 0.007924
Eval costs: 4.445480 s
Iter 6...	Training loss: 211504.812500 (8679.826370, 202824.994873) in 6.01s 
Iter 7...	Training loss: 204336.296875 (7245.171386, 197091.128662) in 5.99s 
Iter 8...	Training loss: 199362.906250 (6191.417195, 193171.494751) in 6.06s 
Iter 9...	Training loss: 187374.687500 (0.000000, 187374.686401) in 4.11s 
Iter 10...	Training loss: 199865.921875 (10227.973163, 189637.958252) in 7.99s 
Top-1 Recall: 0.002113 Precision: 0.002113 NDCG: 0.002113 HR: 0.002113
Top-5 Recall: 0.008452 Precision: 0.001690 NDCG: 0.005118 HR: 0.008452
Top-10 Recall: 0.017433 Precision: 0.001743 NDCG: 0.007958 HR: 0.017433
Eval costs: 4.378025 s
Iter 11...	Training loss: 184936.468750 (0.000000, 184936.469604) in 4.41s 
Iter 12...	Training loss: 195442.359375 (8548.503780, 186893.859985) in 8.54s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=50 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 184095.546875  in 7.63s 
Iter 2...	Training loss: 182416.531250  in 7.57s 
Iter 3...	Training loss: 182088.796875  in 7.57s 
Iter 4...	Training loss: 181982.421875  in 7.65s 
Iter 5...	Training loss: 181936.593750  in 7.66s 
Top-1 Recall: 0.006339 Precision: 0.006339 NDCG: 0.006339 HR: 0.006339
Top-5 Recall: 0.021659 Precision: 0.004332 NDCG: 0.013500 HR: 0.021659
Top-10 Recall: 0.036450 Precision: 0.003645 NDCG: 0.018297 HR: 0.036450
Eval costs: 9.600529 s
Iter 6...	Training loss: 181914.640625  in 7.77s 
Iter 7...	Training loss: 181902.093750  in 8.38s 
Iter 8...	Training loss: 181895.234375  in 11.72s 
Iter 9...	Training loss: 181890.734375  in 13.07s 
Iter 10...	Training loss: 181887.953125  in 8.43s 
Top-1 Recall: 0.006867 Precision: 0.006867 NDCG: 0.006867 HR: 0.006867
Top-5 Recall: 0.031696 Precision: 0.006339 NDCG: 0.018936 HR: 0.031696
Top-10 Recall: 0.051241 Precision: 0.005124 NDCG: 0.025282 HR: 0.051241
Eval costs: 9.917371 s
Iter 11...	Training loss: 181886.000000  in 7.78s 
Iter 12...	Training loss: 181884.906250  in 7.80s 
Iter 13...	Training loss: 181884.156250  in 8.72s 
Iter 14...	Training loss: 181883.531250  in 9.55s 
Iter 15...	Training loss: 181883.015625  in 8.29s 
Top-1 Recall: 0.008452 Precision: 0.008452 NDCG: 0.008452 HR: 0.008452
Top-5 Recall: 0.032224 Precision: 0.006445 NDCG: 0.020227 HR: 0.032224
Top-10 Recall: 0.054939 Precision: 0.005494 NDCG: 0.027623 HR: 0.054939
Eval costs: 10.461754 s
Iter 16...	Training loss: 181882.640625  in 8.05s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 183215.890625  in 16.18s 
Iter 2...	Training loss: 182114.421875  in 15.08s 
Iter 3...	Training loss: 181946.734375  in 14.53s 
Iter 4...	Training loss: 181856.703125  in 14.44s 
Iter 5...	Training loss: 181762.750000  in 14.81s 
Top-1 Recall: 0.014791 Precision: 0.014791 NDCG: 0.014791 HR: 0.014791
Top-5 Recall: 0.061278 Precision: 0.012256 NDCG: 0.038146 HR: 0.061278
Top-10 Recall: 0.098257 Precision: 0.009826 NDCG: 0.050195 HR: 0.098257
Eval costs: 16.174920 s
Iter 6...	Training loss: 181499.718750  in 15.75s 
Iter 7...	Training loss: 178066.015625  in 18.55s 
Iter 8...	Training loss: 160611.343750  in 18.71s 
Iter 9...	Training loss: 145534.828125  in 17.07s 
Iter 10...	Training loss: 122021.734375  in 20.42s 
Top-1 Recall: 0.023772 Precision: 0.023772 NDCG: 0.023772 HR: 0.023772
Top-5 Recall: 0.093502 Precision: 0.018700 NDCG: 0.059327 HR: 0.093502
Top-10 Recall: 0.142631 Precision: 0.014263 NDCG: 0.075209 HR: 0.142631
Eval costs: 19.408562 s
Iter 11...	Training loss: 97356.867188  in 15.23s 
Iter 12...	Training loss: 78019.343750  in 15.82s 
Iter 13...	Training loss: 63420.453125  in 15.74s 
Iter 14...	Training loss: 52954.183594  in 15.39s 
Iter 15...	Training loss: 45893.781250  in 22.98s 
Top-1 Recall: 0.033809 Precision: 0.033809 NDCG: 0.033809 HR: 0.033809
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.076460 HR: 0.118331
Top-10 Recall: 0.174855 Precision: 0.017485 NDCG: 0.094569 HR: 0.174855
Eval costs: 30.394868 s
Iter 16...	Training loss: 40167.109375  in 23.71s 
Iter 17...	Training loss: 36217.093750  in 23.50s 
Iter 18...	Training loss: 32728.529297  in 18.13s 
Iter 19...	Training loss: 30323.894531  in 19.23s 
Iter 20...	Training loss: 28759.878906  in 23.14s 
Top-1 Recall: 0.041204 Precision: 0.041204 NDCG: 0.041204 HR: 0.041204
Top-5 Recall: 0.124142 Precision: 0.024828 NDCG: 0.083793 HR: 0.124142
Top-10 Recall: 0.176968 Precision: 0.017697 NDCG: 0.100924 HR: 0.176968
Eval costs: 16.521003 s
Iter 21...	Training loss: 26417.283203  in 21.34s 
Iter 22...	Training loss: 24967.875000  in 16.51s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 183211.937500  in 21.63s 
Iter 2...	Training loss: 182115.812500  in 22.02s 
Iter 3...	Training loss: 181945.484375  in 18.54s 
Iter 4...	Training loss: 181860.671875  in 14.71s 
Iter 5...	Training loss: 181761.265625  in 15.34s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.069202 Precision: 0.013840 NDCG: 0.043854 HR: 0.069202
Top-10 Recall: 0.096144 Precision: 0.009614 NDCG: 0.052451 HR: 0.096144
Eval costs: 16.729109 s
Iter 6...	Training loss: 181499.937500  in 14.94s 
Iter 7...	Training loss: 177933.421875  in 14.99s 
Iter 8...	Training loss: 160646.250000  in 15.10s 
Iter 9...	Training loss: 145718.437500  in 15.08s 
Iter 10...	Training loss: 122345.945312  in 15.13s 
Top-1 Recall: 0.029054 Precision: 0.029054 NDCG: 0.029054 HR: 0.029054
Top-5 Recall: 0.097200 Precision: 0.019440 NDCG: 0.063891 HR: 0.097200
Top-10 Recall: 0.145272 Precision: 0.014527 NDCG: 0.079558 HR: 0.145272
Eval costs: 17.512502 s
Iter 11...	Training loss: 97331.070312  in 15.50s 
Iter 12...	Training loss: 77293.367188  in 15.69s 
Iter 13...	Training loss: 63219.128906  in 15.16s 
Iter 14...	Training loss: 52811.437500  in 15.29s 
Iter 15...	Training loss: 45610.652344  in 15.64s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.115161 Precision: 0.023032 NDCG: 0.078828 HR: 0.115161
Top-10 Recall: 0.174855 Precision: 0.017485 NDCG: 0.098317 HR: 0.174855
Eval costs: 17.233599 s
Iter 16...	Training loss: 40322.886719  in 15.12s 
Iter 17...	Training loss: 36038.152344  in 15.13s 
Iter 18...	Training loss: 33057.800781  in 15.30s 
Iter 19...	Training loss: 30351.406250  in 15.20s 
Iter 20...	Training loss: 28275.277344  in 15.24s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.127311 Precision: 0.025462 NDCG: 0.086705 HR: 0.127311
Top-10 Recall: 0.182250 Precision: 0.018225 NDCG: 0.104186 HR: 0.182250
Eval costs: 17.297272 s
Iter 21...	Training loss: 26935.914062  in 15.43s 
Iter 22...	Training loss: 25268.876953  in 15.39s 
Iter 23...	Training loss: 23966.300781  in 17.43s 
Iter 24...	Training loss: 22570.867188  in 15.97s 
Iter 25...	Training loss: 21703.449219  in 15.18s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.127311 Precision: 0.025462 NDCG: 0.087284 HR: 0.127311
Top-10 Recall: 0.187533 Precision: 0.018753 NDCG: 0.106420 HR: 0.187533
Eval costs: 17.343403 s
Iter 26...	Training loss: 20918.486328  in 15.25s 
Iter 27...	Training loss: 19709.833984  in 15.25s 
Iter 28...	Training loss: 18950.369141  in 15.26s 
Iter 29...	Training loss: 18730.349609  in 15.23s 
Iter 30...	Training loss: 18032.150391  in 15.31s 
Top-1 Recall: 0.043846 Precision: 0.043846 NDCG: 0.043846 HR: 0.043846
Top-5 Recall: 0.132066 Precision: 0.026413 NDCG: 0.088965 HR: 0.132066
Top-10 Recall: 0.191231 Precision: 0.019123 NDCG: 0.107829 HR: 0.191231
Eval costs: 19.040051 s
Iter 31...	Training loss: 17298.513672  in 15.73s 
Iter 32...	Training loss: 16861.517578  in 15.46s 
Iter 33...	Training loss: 16245.736328  in 15.33s 
Iter 34...	Training loss: 15798.030273  in 15.31s 
Iter 35...	Training loss: 15616.300781  in 15.32s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.134707 Precision: 0.026941 NDCG: 0.091017 HR: 0.134707
Top-10 Recall: 0.181194 Precision: 0.018119 NDCG: 0.106005 HR: 0.181194
Eval costs: 17.752142 s
Iter 36...	Training loss: 15081.076172  in 15.32s 
Iter 37...	Training loss: 14787.050781  in 15.32s 
Iter 38...	Training loss: 14604.796875  in 15.66s 
Iter 39...	Training loss: 14097.081055  in 21.14s 
Iter 40...	Training loss: 13921.606445  in 22.98s 
Top-1 Recall: 0.049128 Precision: 0.049128 NDCG: 0.049128 HR: 0.049128
Top-5 Recall: 0.126783 Precision: 0.025357 NDCG: 0.088813 HR: 0.126783
Top-10 Recall: 0.185948 Precision: 0.018595 NDCG: 0.108000 HR: 0.185948
Eval costs: 30.613601 s
Iter 41...	Training loss: 13516.662109  in 21.64s 
Iter 42...	Training loss: 13053.586914  in 17.83s 
Iter 43...	Training loss: 13067.270508  in 25.33s 
Iter 44...	Training loss: 12817.761719  in 23.38s 
Iter 45...	Training loss: 12487.911133  in 15.06s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.134179 Precision: 0.026836 NDCG: 0.094050 HR: 0.134179
Top-10 Recall: 0.181194 Precision: 0.018119 NDCG: 0.109046 HR: 0.181194
Eval costs: 16.537013 s
Iter 46...	Training loss: 12446.134766  in 15.07s 
Iter 47...	Training loss: 11958.503906  in 15.05s 
Iter 48...	Training loss: 11929.258789  in 15.09s 
Iter 49...	Training loss: 11623.661133  in 15.80s 
Iter 50...	Training loss: 11676.984375  in 15.63s 
Top-1 Recall: 0.047544 Precision: 0.047544 NDCG: 0.047544 HR: 0.047544
Top-5 Recall: 0.131009 Precision: 0.026202 NDCG: 0.091105 HR: 0.131009
Top-10 Recall: 0.181722 Precision: 0.018172 NDCG: 0.107532 HR: 0.181722
Eval costs: 17.699117 s
Iter 51...	Training loss: 11309.020508  in 22.63s 
Iter 52...	Training loss: 11533.697266  in 24.56s 
Iter 53...	Training loss: 10709.293945  in 25.16s 
Iter 54...	Training loss: 10866.066406  in 18.37s 
Iter 55...	Training loss: 10546.465820  in 14.50s 
Top-1 Recall: 0.051770 Precision: 0.051770 NDCG: 0.051770 HR: 0.051770
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.094780 HR: 0.136820
Top-10 Recall: 0.184363 Precision: 0.018436 NDCG: 0.109894 HR: 0.184363
Eval costs: 16.564332 s
Iter 56...	Training loss: 10443.413086  in 14.76s 
Iter 57...	Training loss: 10709.101562  in 14.84s 
Iter 58...	Training loss: 10244.080078  in 15.01s 
Iter 59...	Training loss: 10326.438477  in 15.17s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=0.50 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 46801.933594  in 14.68s 
Iter 2...	Training loss: 45704.308594  in 14.69s 
Iter 3...	Training loss: 45535.421875  in 14.79s 
Iter 4...	Training loss: 45450.785156  in 14.87s 
Iter 5...	Training loss: 45354.351562  in 14.90s 
Top-1 Recall: 0.015320 Precision: 0.015320 NDCG: 0.015320 HR: 0.015320
Top-5 Recall: 0.062863 Precision: 0.012573 NDCG: 0.038709 HR: 0.062863
Top-10 Recall: 0.096144 Precision: 0.009614 NDCG: 0.049335 HR: 0.096144
Eval costs: 16.934961 s
Iter 6...	Training loss: 45115.097656  in 14.81s 
Iter 7...	Training loss: 43138.273438  in 15.87s 
Iter 8...	Training loss: 37649.976562  in 15.95s 
Iter 9...	Training loss: 30096.994141  in 15.00s 
Iter 10...	Training loss: 21156.115234  in 14.98s 
Top-1 Recall: 0.030111 Precision: 0.030111 NDCG: 0.030111 HR: 0.030111
Top-5 Recall: 0.100898 Precision: 0.020180 NDCG: 0.065693 HR: 0.100898
Top-10 Recall: 0.155837 Precision: 0.015584 NDCG: 0.083391 HR: 0.155837
Eval costs: 17.368837 s
Iter 11...	Training loss: 14953.316406  in 15.67s 
Iter 12...	Training loss: 11287.727539  in 20.54s 
Iter 13...	Training loss: 9043.348633  in 18.09s 
Iter 14...	Training loss: 7660.603516  in 16.15s 
Iter 15...	Training loss: 6610.914551  in 24.89s 
Top-1 Recall: 0.035922 Precision: 0.035922 NDCG: 0.035922 HR: 0.035922
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.077284 HR: 0.118331
Top-10 Recall: 0.180137 Precision: 0.018014 NDCG: 0.097055 HR: 0.180137
Eval costs: 18.002639 s
Iter 16...	Training loss: 5899.706543  in 21.68s 
Iter 17...	Training loss: 5379.200195  in 14.72s 
Iter 18...	Training loss: 4848.499023  in 14.61s 
Iter 19...	Training loss: 4475.398926  in 14.74s 
Iter 20...	Training loss: 4196.228516  in 14.93s 
Top-1 Recall: 0.039620 Precision: 0.039620 NDCG: 0.039620 HR: 0.039620
Top-5 Recall: 0.124142 Precision: 0.024828 NDCG: 0.082749 HR: 0.124142
Top-10 Recall: 0.172213 Precision: 0.017221 NDCG: 0.098309 HR: 0.172213
Eval costs: 22.258917 s
Iter 21...	Training loss: 3984.873291  in 21.38s 
Iter 22...	Training loss: 3748.572510  in 15.90s 
Iter 23...	Training loss: 3607.154541  in 18.50s 
Iter 24...	Training loss: 3455.560791  in 23.16s 
Iter 25...	Training loss: 3182.979004  in 24.28s 
Top-1 Recall: 0.035394 Precision: 0.035394 NDCG: 0.035394 HR: 0.035394
Top-5 Recall: 0.120444 Precision: 0.024089 NDCG: 0.079122 HR: 0.120444
Top-10 Recall: 0.177496 Precision: 0.017750 NDCG: 0.097662 HR: 0.177496
Eval costs: 29.154798 s
Iter 26...	Training loss: 3149.697998  in 24.19s 
Iter 27...	Training loss: 3021.621338  in 24.37s 
Iter 28...	Training loss: 2898.120605  in 24.42s 
Iter 29...	Training loss: 2787.419189  in 24.60s 
Iter 30...	Training loss: 2679.871582  in 24.73s 
Top-1 Recall: 0.035922 Precision: 0.035922 NDCG: 0.035922 HR: 0.035922
Top-5 Recall: 0.126783 Precision: 0.025357 NDCG: 0.081442 HR: 0.126783
Top-10 Recall: 0.183307 Precision: 0.018331 NDCG: 0.099849 HR: 0.183307
Eval costs: 31.123757 s
Iter 31...	Training loss: 2613.173340  in 24.56s 
Iter 32...	Training loss: 2584.183350  in 24.63s 
Iter 33...	Training loss: 2492.713135  in 24.33s 
Iter 34...	Training loss: 2408.413574  in 85.67s 
Iter 35...	Training loss: 2365.268066  in 16.40s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.118331 Precision: 0.023666 NDCG: 0.080477 HR: 0.118331
Top-10 Recall: 0.170629 Precision: 0.017063 NDCG: 0.097375 HR: 0.170629
Eval costs: 15.625546 s
Iter 36...	Training loss: 2333.544434  in 14.41s 
Iter 37...	Training loss: 2245.378174  in 14.64s 
Iter 38...	Training loss: 2244.770508  in 17.27s 
Iter 39...	Training loss: 2145.597168  in 14.92s 
Iter 40...	Training loss: 2129.770996  in 14.67s 
Top-1 Recall: 0.035922 Precision: 0.035922 NDCG: 0.035922 HR: 0.035922
Top-5 Recall: 0.124142 Precision: 0.024828 NDCG: 0.081065 HR: 0.124142
Top-10 Recall: 0.170629 Precision: 0.017063 NDCG: 0.096092 HR: 0.170629
Eval costs: 16.844791 s
Iter 41...	Training loss: 2082.817139  in 14.84s 
Iter 42...	Training loss: 2040.567749  in 14.78s 
Iter 43...	Training loss: 1992.021973  in 15.92s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=50 
margin=0.50 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 47676.769531  in 8.80s 
Iter 2...	Training loss: 46005.464844  in 9.48s 
Iter 3...	Training loss: 45678.164062  in 13.56s 
Iter 4...	Training loss: 45570.906250  in 10.41s 
Iter 5...	Training loss: 45525.632812  in 8.40s 
Top-1 Recall: 0.003170 Precision: 0.003170 NDCG: 0.003170 HR: 0.003170
Top-5 Recall: 0.019546 Precision: 0.003909 NDCG: 0.011319 HR: 0.019546
Top-10 Recall: 0.036978 Precision: 0.003698 NDCG: 0.017027 HR: 0.036978
Eval costs: 9.969510 s
Iter 6...	Training loss: 45502.972656  in 8.22s 
Iter 7...	Training loss: 45490.328125  in 8.83s 
Iter 8...	Training loss: 45483.589844  in 8.82s 
Iter 9...	Training loss: 45479.253906  in 8.24s 
Iter 10...	Training loss: 45476.617188  in 8.53s 
Top-1 Recall: 0.004754 Precision: 0.004754 NDCG: 0.004754 HR: 0.004754
Top-5 Recall: 0.028526 Precision: 0.005705 NDCG: 0.016391 HR: 0.028526
Top-10 Recall: 0.052826 Precision: 0.005283 NDCG: 0.024148 HR: 0.052826
Eval costs: 11.676047 s
Iter 11...	Training loss: 45474.695312  in 9.25s 
Iter 12...	Training loss: 45473.468750  in 9.68s 
Iter 13...	Training loss: 45472.687500  in 8.50s 
Iter 14...	Training loss: 45471.882812  in 8.51s 
Iter 15...	Training loss: 45471.531250  in 8.80s 
Top-1 Recall: 0.006867 Precision: 0.006867 NDCG: 0.006867 HR: 0.006867
Top-5 Recall: 0.033809 Precision: 0.006762 NDCG: 0.020361 HR: 0.033809
Top-10 Recall: 0.057052 Precision: 0.005705 NDCG: 0.027815 HR: 0.057052
Eval costs: 10.627259 s
Iter 16...	Training loss: 45471.148438  in 8.68s 
Iter 17...	Training loss: 45470.859375  in 8.40s 
Iter 18...	Training loss: 45470.550781  in 8.74s 
Iter 19...	Training loss: 45470.125000  in 8.83s 
Iter 20...	Training loss: 45469.863281  in 8.72s 
Top-1 Recall: 0.006339 Precision: 0.006339 NDCG: 0.006339 HR: 0.006339
Top-5 Recall: 0.035394 Precision: 0.007079 NDCG: 0.020701 HR: 0.035394
Top-10 Recall: 0.069202 Precision: 0.006920 NDCG: 0.031455 HR: 0.069202
Eval costs: 10.722513 s
Iter 21...	Training loss: 45469.242188  in 8.90s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=200 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 182650.765625  in 31.84s 
Iter 2...	Training loss: 181851.593750  in 34.64s 
Iter 3...	Training loss: 181358.453125  in 35.12s 
Iter 4...	Training loss: 172893.000000  in 32.58s 
Iter 5...	Training loss: 155347.015625  in 32.71s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.075013 Precision: 0.015003 NDCG: 0.046949 HR: 0.075013
Top-10 Recall: 0.122557 Precision: 0.012256 NDCG: 0.062253 HR: 0.122557
Eval costs: 31.436605 s
Iter 6...	Training loss: 128569.742188  in 32.82s 
Iter 7...	Training loss: 91908.320312  in 33.93s 
Iter 8...	Training loss: 61984.179688  in 33.68s 
Iter 9...	Training loss: 44332.289062  in 33.24s 
Iter 10...	Training loss: 34410.375000  in 32.86s 
Top-1 Recall: 0.040148 Precision: 0.040148 NDCG: 0.040148 HR: 0.040148
Top-5 Recall: 0.137348 Precision: 0.027470 NDCG: 0.088997 HR: 0.137348
Top-10 Recall: 0.194929 Precision: 0.019493 NDCG: 0.107408 HR: 0.194929
Eval costs: 32.141937 s
Iter 11...	Training loss: 28844.849609  in 34.49s 
Iter 12...	Training loss: 24959.953125  in 33.78s 
Iter 13...	Training loss: 22128.421875  in 35.11s 
Iter 14...	Training loss: 19632.507812  in 40.02s 
Iter 15...	Training loss: 18228.826172  in 37.19s 
Top-1 Recall: 0.047015 Precision: 0.047015 NDCG: 0.047015 HR: 0.047015
Top-5 Recall: 0.130481 Precision: 0.026096 NDCG: 0.090448 HR: 0.130481
Top-10 Recall: 0.194400 Precision: 0.019440 NDCG: 0.110897 HR: 0.194400
Eval costs: 35.180928 s
Iter 16...	Training loss: 16844.482422  in 35.68s 
Iter 17...	Training loss: 15802.406250  in 33.04s 
Iter 18...	Training loss: 14849.641602  in 32.77s 
Iter 19...	Training loss: 14178.004883  in 33.18s 
Iter 20...	Training loss: 13419.960938  in 32.85s 
Top-1 Recall: 0.045959 Precision: 0.045959 NDCG: 0.045959 HR: 0.045959
Top-5 Recall: 0.136820 Precision: 0.027364 NDCG: 0.092312 HR: 0.136820
Top-10 Recall: 0.200211 Precision: 0.020021 NDCG: 0.112566 HR: 0.200211
Eval costs: 40.951217 s
Iter 21...	Training loss: 12554.257812  in 38.70s 
Iter 22...	Training loss: 12383.935547  in 37.98s 
Iter 23...	Training loss: 11635.295898  in 37.01s 
Iter 24...	Training loss: 11012.916016  in 36.82s 
Iter 25...	Training loss: 10844.911133  in 34.00s 
Top-1 Recall: 0.051241 Precision: 0.051241 NDCG: 0.051241 HR: 0.051241
Top-5 Recall: 0.126783 Precision: 0.025357 NDCG: 0.091566 HR: 0.126783
Top-10 Recall: 0.192287 Precision: 0.019229 NDCG: 0.112597 HR: 0.192287
Eval costs: 30.872993 s
Iter 26...	Training loss: 10234.351562  in 32.11s 
Iter 27...	Training loss: 9810.323242  in 32.54s 
Iter 28...	Training loss: 9558.279297  in 33.16s 
Iter 29...	Training loss: 9468.560547  in 32.67s 
Iter 30...	Training loss: 9021.250000  in 33.08s 
Top-1 Recall: 0.046487 Precision: 0.046487 NDCG: 0.046487 HR: 0.046487
Top-5 Recall: 0.140518 Precision: 0.028104 NDCG: 0.093927 HR: 0.140518
Top-10 Recall: 0.185420 Precision: 0.018542 NDCG: 0.108330 HR: 0.185420
Eval costs: 31.492693 s
Iter 31...	Training loss: 8907.821289  in 32.47s 
Iter 32...	Training loss: 8502.871094  in 32.71s 
Iter 33...	Training loss: 8219.655273  in 32.92s 
Iter 34...	Training loss: 8160.638672  in 32.81s 
Iter 35...	Training loss: 8075.164062  in 32.73s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.138405 Precision: 0.027681 NDCG: 0.094756 HR: 0.138405
Top-10 Recall: 0.188590 Precision: 0.018859 NDCG: 0.110940 HR: 0.188590
Eval costs: 31.717532 s
Iter 36...	Training loss: 7756.766113  in 32.61s 
Iter 37...	Training loss: 7816.855957  in 33.94s 
Iter 38...	Training loss: 7169.281738  in 39.69s 
Iter 39...	Training loss: 6977.392578  in 37.70s 
Iter 40...	Training loss: 7037.612305  in 37.25s 
Top-1 Recall: 0.047015 Precision: 0.047015 NDCG: 0.047015 HR: 0.047015
Top-5 Recall: 0.129952 Precision: 0.025990 NDCG: 0.089010 HR: 0.129952
Top-10 Recall: 0.176440 Precision: 0.017644 NDCG: 0.104087 HR: 0.176440
Eval costs: 37.830457 s
Iter 41...	Training loss: 6861.132812  in 36.56s 
Iter 42...	Training loss: 6679.729980  in 35.74s 
Iter 43...	Training loss: 6688.131348  in 31.49s 
Iter 44...	Training loss: 6472.295410  in 32.11s 
Iter 45...	Training loss: 6360.039551  in 32.21s 
Top-1 Recall: 0.050185 Precision: 0.050185 NDCG: 0.050185 HR: 0.050185
Top-5 Recall: 0.131009 Precision: 0.026202 NDCG: 0.091298 HR: 0.131009
Top-10 Recall: 0.190703 Precision: 0.019070 NDCG: 0.110523 HR: 0.190703
Eval costs: 31.146630 s
Iter 46...	Training loss: 6310.093750  in 32.26s 
Iter 47...	Training loss: 6188.167969  in 32.48s 
Iter 48...	Training loss: 5967.390625  in 32.68s 
Iter 49...	Training loss: 5924.523438  in 32.92s 
Iter 50...	Training loss: 5791.046875  in 33.93s 
Top-1 Recall: 0.042789 Precision: 0.042789 NDCG: 0.042789 HR: 0.042789
Top-5 Recall: 0.133122 Precision: 0.026624 NDCG: 0.089161 HR: 0.133122
Top-10 Recall: 0.183307 Precision: 0.018331 NDCG: 0.105435 HR: 0.183307
Eval costs: 41.744758 s
Iter 51...	Training loss: 5572.010254  in 46.07s 
Iter 52...	Training loss: 5632.314941  in 39.33s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 183215.671875  in 15.09s 
Iter 2...	Training loss: 182116.921875  in 15.55s 
Iter 3...	Training loss: 181946.937500  in 14.80s 
Iter 4...	Training loss: 181861.156250  in 14.82s 
Iter 5...	Training loss: 181766.359375  in 14.87s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.062335 Precision: 0.012467 NDCG: 0.040797 HR: 0.062335
Top-10 Recall: 0.096672 Precision: 0.009667 NDCG: 0.051908 HR: 0.096672
Eval costs: 16.980152 s
Iter 6...	Training loss: 181527.953125  in 14.89s 
Iter 7...	Training loss: 178887.234375  in 14.95s 
Iter 8...	Training loss: 161220.765625  in 15.41s 
Iter 9...	Training loss: 146470.500000  in 15.01s 
Iter 10...	Training loss: 123680.500000  in 16.36s 
Top-1 Recall: 0.031696 Precision: 0.031696 NDCG: 0.031696 HR: 0.031696
Top-5 Recall: 0.092446 Precision: 0.018489 NDCG: 0.061810 HR: 0.092446
Top-10 Recall: 0.144216 Precision: 0.014422 NDCG: 0.078400 HR: 0.144216
Eval costs: 18.867170 s
Iter 11...	Training loss: 98130.539062  in 15.92s 
Iter 12...	Training loss: 77933.093750  in 16.67s 
Iter 13...	Training loss: 63380.687500  in 17.09s 
Iter 14...	Training loss: 52943.261719  in 15.91s 
Iter 15...	Training loss: 45677.011719  in 15.97s 
Top-1 Recall: 0.041733 Precision: 0.041733 NDCG: 0.041733 HR: 0.041733
Top-5 Recall: 0.116746 Precision: 0.023349 NDCG: 0.078159 HR: 0.116746
Top-10 Recall: 0.176440 Precision: 0.017644 NDCG: 0.097466 HR: 0.176440
Eval costs: 18.018912 s
Iter 16...	Training loss: 39925.593750  in 17.31s 
Iter 17...	Training loss: 36170.757812  in 15.40s 
Iter 18...	Training loss: 32751.619141  in 15.20s 
Iter 19...	Training loss: 30079.953125  in 15.14s 
Iter 20...	Training loss: 28119.255859  in 15.15s 
Top-1 Recall: 0.043317 Precision: 0.043317 NDCG: 0.043317 HR: 0.043317
Top-5 Recall: 0.122557 Precision: 0.024511 NDCG: 0.083523 HR: 0.122557
Top-10 Recall: 0.178024 Precision: 0.017802 NDCG: 0.101262 HR: 0.178024
Eval costs: 17.574839 s
Iter 21...	Training loss: 26546.667969  in 16.02s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 204393.968750  in 10.87s 
Iter 2...	Training loss: 188107.906250  in 10.95s 
Iter 3...	Training loss: 181794.093750  in 11.10s 
Iter 4...	Training loss: 177176.796875  in 11.06s 
Iter 5...	Training loss: 172703.718750  in 11.47s 
Top-1 Recall: 0.007924 Precision: 0.007924 NDCG: 0.007924 HR: 0.007924
Top-5 Recall: 0.045959 Precision: 0.009192 NDCG: 0.026644 HR: 0.045959
Top-10 Recall: 0.076598 Precision: 0.007660 NDCG: 0.036427 HR: 0.076598
Eval costs: 16.956181 s
Iter 6...	Training loss: 168391.390625  in 11.47s 
Iter 7...	Training loss: 162999.328125  in 11.38s 
Iter 8...	Training loss: 157169.968750  in 11.20s 
Iter 9...	Training loss: 149765.484375  in 11.14s 
Iter 10...	Training loss: 140495.171875  in 11.19s 
Top-1 Recall: 0.033809 Precision: 0.033809 NDCG: 0.033809 HR: 0.033809
Top-5 Recall: 0.099313 Precision: 0.019863 NDCG: 0.065785 HR: 0.099313
Top-10 Recall: 0.138933 Precision: 0.013893 NDCG: 0.078794 HR: 0.138933
Eval costs: 17.103479 s
Iter 11...	Training loss: 129306.414062  in 11.15s 
Iter 12...	Training loss: 117486.156250  in 11.18s 
Iter 13...	Training loss: 105947.664062  in 11.39s 
Iter 14...	Training loss: 94489.851562  in 13.15s 
Iter 15...	Training loss: 83219.937500  in 11.92s 
Top-1 Recall: 0.039091 Precision: 0.039091 NDCG: 0.039091 HR: 0.039091
Top-5 Recall: 0.118859 Precision: 0.023772 NDCG: 0.079307 HR: 0.118859
Top-10 Recall: 0.169572 Precision: 0.016957 NDCG: 0.095548 HR: 0.169572
Eval costs: 24.511177 s
Iter 16...	Training loss: 73063.093750  in 16.54s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 180562.531250  in 10.57s 
Iter 2...	Training loss: 163551.203125  in 10.14s 
Iter 3...	Training loss: 82587.789062  in 9.38s 
Iter 4...	Training loss: 45.537373  in 9.34s 
Iter 5...	Training loss: 5.488846  in 9.40s 
Top-1 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-5 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-10 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Eval costs: 8.982321 s
Iter 6...	Training loss: 2.443766  in 9.53s 
Iter 7...	Training loss: 1.379137  in 9.45s 
Iter 8...	Training loss: 1.315991  in 9.46s 
Iter 9...	Training loss: 0.915346  in 9.47s 
Iter 10...	Training loss: 0.976226  in 9.54s 
Top-1 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-5 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-10 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Eval costs: 9.274245 s
Iter 11...	Training loss: 0.824287  in 9.60s 
Iter 12...	Training loss: 0.512418  in 10.04s 
Iter 13...	Training loss: 0.198298  in 10.25s 
Iter 14...	Training loss: 0.520249  in 9.67s 
Iter 15...	Training loss: 0.401426  in 9.69s 
Top-1 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-5 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Top-10 Recall: 0.000000 Precision: 0.000000 NDCG: 0.000000 HR: 0.000000
Eval costs: 9.627414 s
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 182749.187500  in 9.89s 
Iter 2...	Training loss: 181919.031250  in 9.88s 
Iter 3...	Training loss: 181431.125000  in 9.56s 
Iter 4...	Training loss: 170507.984375  in 9.49s 
Iter 5...	Training loss: 154278.156250  in 9.54s 
Top-1 Recall: 0.029583 Precision: 0.029583 NDCG: 0.029583 HR: 0.029583
Top-5 Recall: 0.065504 Precision: 0.013101 NDCG: 0.048425 HR: 0.065504
Top-10 Recall: 0.081881 Precision: 0.008188 NDCG: 0.053620 HR: 0.081881
Eval costs: 9.302450 s
Iter 6...	Training loss: 151638.265625  in 9.61s 
Iter 7...	Training loss: 149911.437500  in 11.10s 
Iter 8...	Training loss: 147790.687500  in 10.00s 
Iter 9...	Training loss: 143415.031250  in 10.13s 
Iter 10...	Training loss: 138739.812500  in 9.64s 
Top-1 Recall: 0.032224 Precision: 0.032224 NDCG: 0.032224 HR: 0.032224
Top-5 Recall: 0.087691 Precision: 0.017538 NDCG: 0.060861 HR: 0.087691
Top-10 Recall: 0.115689 Precision: 0.011569 NDCG: 0.069818 HR: 0.115689
Eval costs: 9.495498 s
Iter 11...	Training loss: 136192.734375  in 10.32s 
Iter 12...	Training loss: 133264.968750  in 10.49s 
Iter 13...	Training loss: 130079.140625  in 9.73s 
Iter 14...	Training loss: 126557.070312  in 9.70s 
Iter 15...	Training loss: 123076.460938  in 9.70s 
Top-1 Recall: 0.048600 Precision: 0.048600 NDCG: 0.048600 HR: 0.048600
Top-5 Recall: 0.110935 Precision: 0.022187 NDCG: 0.080110 HR: 0.110935
Top-10 Recall: 0.144216 Precision: 0.014422 NDCG: 0.090796 HR: 0.144216
Eval costs: 9.633061 s
Iter 16...	Training loss: 119535.648438  in 10.00s 
Iter 17...	Training loss: 116217.226562  in 10.00s 
Iter 18...	Training loss: 112658.195312  in 9.77s 
Iter 19...	Training loss: 109084.992188  in 9.75s 
Iter 20...	Training loss: 105380.000000  in 9.76s 
Top-1 Recall: 0.050713 Precision: 0.050713 NDCG: 0.050713 HR: 0.050713
Top-5 Recall: 0.119915 Precision: 0.023983 NDCG: 0.084750 HR: 0.119915
Top-10 Recall: 0.160063 Precision: 0.016006 NDCG: 0.097654 HR: 0.160063
Eval costs: 9.655542 s
Iter 21...	Training loss: 101292.703125  in 10.03s 
Iter 22...	Training loss: 96856.507812  in 10.73s 
Iter 23...	Training loss: 92121.460938  in 10.34s 
Iter 24...	Training loss: 87611.656250  in 10.24s 
Iter 25...	Training loss: 83220.156250  in 9.94s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.120972 Precision: 0.024194 NDCG: 0.083271 HR: 0.120972
Top-10 Recall: 0.178553 Precision: 0.017855 NDCG: 0.101722 HR: 0.178553
Eval costs: 9.760741 s
Iter 26...	Training loss: 78538.882812  in 10.33s 
Iter 27...	Training loss: 75036.351562  in 10.79s 
Iter 28...	Training loss: 71337.601562  in 10.48s 
Iter 29...	Training loss: 67389.414062  in 10.09s 
Iter 30...	Training loss: 64624.128906  in 10.49s 
Top-1 Recall: 0.042789 Precision: 0.042789 NDCG: 0.042789 HR: 0.042789
Top-5 Recall: 0.125198 Precision: 0.025040 NDCG: 0.084522 HR: 0.125198
Top-10 Recall: 0.178024 Precision: 0.017802 NDCG: 0.101504 HR: 0.178024
Eval costs: 10.242426 s
Iter 31...	Training loss: 61575.351562  in 10.22s 
Iter 32...	Training loss: 58669.667969  in 10.08s 
Iter 33...	Training loss: 56775.093750  in 9.90s 
Iter 34...	Training loss: 54402.140625  in 9.86s 
Iter 35...	Training loss: 52533.660156  in 9.85s 
Top-1 Recall: 0.040676 Precision: 0.040676 NDCG: 0.040676 HR: 0.040676
Top-5 Recall: 0.125726 Precision: 0.025145 NDCG: 0.082710 HR: 0.125726
Top-10 Recall: 0.175911 Precision: 0.017591 NDCG: 0.098861 HR: 0.175911
Eval costs: 10.673213 s
Iter 36...	Training loss: 51362.648438  in 10.66s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 195567.171875  in 13.99s 
Iter 2...	Training loss: 179206.875000  in 14.17s 
Iter 3...	Training loss: 167230.921875  in 14.27s 
Iter 4...	Training loss: 161667.109375  in 14.37s 
Iter 5...	Training loss: 156462.296875  in 14.44s 
Top-1 Recall: 0.027470 Precision: 0.027470 NDCG: 0.027470 HR: 0.027470
Top-5 Recall: 0.076070 Precision: 0.015214 NDCG: 0.051618 HR: 0.076070
Top-10 Recall: 0.104596 Precision: 0.010460 NDCG: 0.060857 HR: 0.104596
Eval costs: 16.724459 s
Iter 6...	Training loss: 148207.828125  in 14.45s 
Iter 7...	Training loss: 142590.953125  in 15.70s 
Iter 8...	Training loss: 135813.453125  in 16.48s 
Iter 9...	Training loss: 126516.437500  in 15.48s 
Iter 10...	Training loss: 114226.625000  in 15.49s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.108294 Precision: 0.021659 NDCG: 0.078095 HR: 0.108294
Top-10 Recall: 0.157950 Precision: 0.015795 NDCG: 0.094176 HR: 0.157950
Eval costs: 17.398633 s
Iter 11...	Training loss: 98749.539062  in 16.18s 
Iter 12...	Training loss: 80448.953125  in 15.94s 
Iter 13...	Training loss: 63158.117188  in 14.64s 
Iter 14...	Training loss: 49480.453125  in 14.69s 
Iter 15...	Training loss: 40793.734375  in 14.77s 
Top-1 Recall: 0.042789 Precision: 0.042789 NDCG: 0.042789 HR: 0.042789
Top-5 Recall: 0.121500 Precision: 0.024300 NDCG: 0.083796 HR: 0.121500
Top-10 Recall: 0.163761 Precision: 0.016376 NDCG: 0.097506 HR: 0.163761
Eval costs: 16.954103 s
Iter 16...	Training loss: 33904.769531  in 14.93s 
Iter 17...	Training loss: 30004.841797  in 15.44s 
Iter 18...	Training loss: 26922.574219  in 14.92s 
Iter 19...	Training loss: 24451.494141  in 15.61s 
Iter 20...	Training loss: 22196.267578  in 14.73s 
Top-1 Recall: 0.044374 Precision: 0.044374 NDCG: 0.044374 HR: 0.044374
Top-5 Recall: 0.122029 Precision: 0.024406 NDCG: 0.084275 HR: 0.122029
Top-10 Recall: 0.165874 Precision: 0.016587 NDCG: 0.098186 HR: 0.165874
Eval costs: 18.676581 s
Iter 21...	Training loss: 20350.285156  in 15.11s 
Iter 22...	Training loss: 19327.937500  in 15.05s 
Iter 23...	Training loss: 17474.650391  in 14.80s 
Iter 24...	Training loss: 17050.306641  in 16.07s 
Iter 25...	Training loss: 16276.680664  in 15.03s 
Top-1 Recall: 0.045431 Precision: 0.045431 NDCG: 0.045431 HR: 0.045431
Top-5 Recall: 0.120444 Precision: 0.024089 NDCG: 0.085688 HR: 0.120444
Top-10 Recall: 0.161648 Precision: 0.016165 NDCG: 0.099007 HR: 0.161648
Eval costs: 23.621813 s
Iter 26...	Training loss: 15216.171875  in 18.52s 
Iter 27...	Training loss: 14779.725586  in 15.44s 
Iter 28...	Training loss: 13907.449219  in 15.13s 
Iter 29...	Training loss: 13549.021484  in 14.88s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 218201.218750  in 14.45s 
Iter 2...	Training loss: 207577.546875  in 14.57s 
Iter 3...	Training loss: 200050.078125  in 14.84s 
Iter 4...	Training loss: 194528.984375  in 15.06s 
Iter 5...	Training loss: 190741.015625  in 14.84s 
Top-1 Recall: 0.008452 Precision: 0.008452 NDCG: 0.008452 HR: 0.008452
Top-5 Recall: 0.032752 Precision: 0.006550 NDCG: 0.021219 HR: 0.032752
Top-10 Recall: 0.052826 Precision: 0.005283 NDCG: 0.027715 HR: 0.052826
Eval costs: 16.947064 s
Iter 6...	Training loss: 187782.203125  in 14.78s 
Iter 7...	Training loss: 185503.593750  in 14.90s 
Iter 8...	Training loss: 183662.765625  in 14.89s 
Iter 9...	Training loss: 182084.375000  in 14.87s 
Iter 10...	Training loss: 180734.578125  in 15.14s 
Top-1 Recall: 0.012150 Precision: 0.012150 NDCG: 0.012150 HR: 0.012150
Top-5 Recall: 0.042261 Precision: 0.008452 NDCG: 0.027538 HR: 0.042261
Top-10 Recall: 0.059165 Precision: 0.005917 NDCG: 0.033060 HR: 0.059165
Eval costs: 17.393251 s
Iter 11...	Training loss: 179403.500000  in 15.20s 
Iter 12...	Training loss: 177918.937500  in 14.95s 
Iter 13...	Training loss: 176599.015625  in 14.93s 
Iter 14...	Training loss: 175167.296875  in 16.03s 
Iter 15...	Training loss: 173401.078125  in 15.88s 
Top-1 Recall: 0.014791 Precision: 0.014791 NDCG: 0.014791 HR: 0.014791
Top-5 Recall: 0.044902 Precision: 0.008980 NDCG: 0.029741 HR: 0.044902
Top-10 Recall: 0.066033 Precision: 0.006603 NDCG: 0.036616 HR: 0.066033
Eval costs: 17.992843 s
Iter 16...	Training loss: 171454.234375  in 15.40s 
Iter 17...	Training loss: 169387.953125  in 15.18s 
Iter 18...	Training loss: 166349.625000  in 15.08s 
Iter 19...	Training loss: 162849.546875  in 15.05s 
Iter 20...	Training loss: 160501.781250  in 15.02s 
Top-1 Recall: 0.019546 Precision: 0.019546 NDCG: 0.019546 HR: 0.019546
Top-5 Recall: 0.044374 Precision: 0.008875 NDCG: 0.031292 HR: 0.044374
Top-10 Recall: 0.069202 Precision: 0.006920 NDCG: 0.039429 HR: 0.069202
Eval costs: 17.280952 s
Iter 21...	Training loss: 159684.093750  in 15.33s 
Iter 22...	Training loss: 158912.953125  in 17.23s 
Iter 23...	Training loss: 158643.890625  in 19.54s 
Iter 24...	Training loss: 158642.453125  in 15.79s 
Iter 25...	Training loss: 157740.640625  in 15.41s 
Top-1 Recall: 0.016904 Precision: 0.016904 NDCG: 0.016904 HR: 0.016904
Top-5 Recall: 0.044374 Precision: 0.008875 NDCG: 0.030309 HR: 0.044374
Top-10 Recall: 0.073428 Precision: 0.007343 NDCG: 0.039635 HR: 0.073428
Eval costs: 17.508555 s
Iter 26...	Training loss: 157685.546875  in 15.58s 
Iter 27...	Training loss: 157524.578125  in 16.01s 
############################################### 
n_negative=20  
batch_size=1024 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 218233.406250  in 11.77s 
Iter 2...	Training loss: 209651.140625  in 14.55s 
Iter 3...	Training loss: 204013.093750  in 15.50s 
Iter 4...	Training loss: 199964.781250  in 13.72s 
Iter 5...	Training loss: 196902.328125  in 14.19s 
Top-1 Recall: 0.012150 Precision: 0.012150 NDCG: 0.012150 HR: 0.012150
Top-5 Recall: 0.039091 Precision: 0.007818 NDCG: 0.025934 HR: 0.039091
Top-10 Recall: 0.055996 Precision: 0.005600 NDCG: 0.031356 HR: 0.055996
Eval costs: 21.977438 s
Iter 6...	Training loss: 194413.531250  in 13.74s 
Iter 7...	Training loss: 192450.218750  in 13.30s 
Iter 8...	Training loss: 190845.687500  in 13.55s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 199910.750000  in 12.25s 
Iter 2...	Training loss: 186586.234375  in 12.67s 
Iter 3...	Training loss: 184002.750000  in 12.58s 
Iter 4...	Training loss: 182241.906250  in 12.62s 
Iter 5...	Training loss: 179324.453125  in 12.51s 
Top-1 Recall: 0.022715 Precision: 0.022715 NDCG: 0.022715 HR: 0.022715
Top-5 Recall: 0.042789 Precision: 0.008558 NDCG: 0.032944 HR: 0.042789
Top-10 Recall: 0.070259 Precision: 0.007026 NDCG: 0.041860 HR: 0.070259
Eval costs: 17.365165 s
Iter 6...	Training loss: 172077.437500  in 12.52s 
Iter 7...	Training loss: 167912.171875  in 12.65s 
Iter 8...	Training loss: 165635.171875  in 13.03s 
Iter 9...	Training loss: 163778.875000  in 13.14s 
Iter 10...	Training loss: 162654.046875  in 12.87s 
Top-1 Recall: 0.007924 Precision: 0.007924 NDCG: 0.007924 HR: 0.007924
Top-5 Recall: 0.046487 Precision: 0.009297 NDCG: 0.026908 HR: 0.046487
Top-10 Recall: 0.072372 Precision: 0.007237 NDCG: 0.035206 HR: 0.072372
Eval costs: 18.540303 s
Iter 11...	Training loss: 161760.984375  in 12.58s 
Iter 12...	Training loss: 160524.640625  in 13.56s 
Iter 13...	Training loss: 159872.750000  in 14.42s 
Iter 14...	Training loss: 159190.609375  in 14.53s 
Iter 15...	Training loss: 158826.421875  in 13.82s 
Top-1 Recall: 0.007924 Precision: 0.007924 NDCG: 0.007924 HR: 0.007924
Top-5 Recall: 0.045959 Precision: 0.009192 NDCG: 0.026538 HR: 0.045959
Top-10 Recall: 0.070787 Precision: 0.007079 NDCG: 0.034546 HR: 0.070787
Eval costs: 18.283617 s
Iter 16...	Training loss: 158230.343750  in 13.24s 
Iter 17...	Training loss: 157526.015625  in 12.88s 
Iter 18...	Training loss: 157320.921875  in 13.94s 
Iter 19...	Training loss: 156777.140625  in 13.78s 
Iter 20...	Training loss: 156183.156250  in 14.52s 
Top-1 Recall: 0.013207 Precision: 0.013207 NDCG: 0.013207 HR: 0.013207
Top-5 Recall: 0.050185 Precision: 0.010037 NDCG: 0.032056 HR: 0.050185
Top-10 Recall: 0.076070 Precision: 0.007607 NDCG: 0.040260 HR: 0.076070
Eval costs: 18.723787 s
Iter 21...	Training loss: 155603.531250  in 13.31s 
Iter 22...	Training loss: 154983.390625  in 12.53s 
Iter 23...	Training loss: 153776.812500  in 12.87s 
Iter 24...	Training loss: 153478.109375  in 12.41s 
Iter 25...	Training loss: 153288.703125  in 12.40s 
Top-1 Recall: 0.020602 Precision: 0.020602 NDCG: 0.020602 HR: 0.020602
Top-5 Recall: 0.054411 Precision: 0.010882 NDCG: 0.038051 HR: 0.054411
Top-10 Recall: 0.080824 Precision: 0.008082 NDCG: 0.046468 HR: 0.080824
Eval costs: 18.326731 s
Iter 26...	Training loss: 152596.921875  in 12.92s 
Iter 27...	Training loss: 151951.609375  in 13.59s 
Iter 28...	Training loss: 151637.671875  in 12.84s 
Iter 29...	Training loss: 151105.843750  in 13.48s 
Iter 30...	Training loss: 151049.375000  in 12.61s 
Top-1 Recall: 0.026941 Precision: 0.026941 NDCG: 0.026941 HR: 0.026941
Top-5 Recall: 0.064976 Precision: 0.012995 NDCG: 0.046250 HR: 0.064976
Top-10 Recall: 0.089276 Precision: 0.008928 NDCG: 0.054024 HR: 0.089276
Eval costs: 17.175668 s
Iter 31...	Training loss: 150546.218750  in 14.29s 
Iter 32...	Training loss: 150108.390625  in 14.57s 
Iter 33...	Training loss: 149611.937500  in 15.26s 
Iter 34...	Training loss: 149376.921875  in 14.83s 
Iter 35...	Training loss: 149190.531250  in 14.69s 
Top-1 Recall: 0.027470 Precision: 0.027470 NDCG: 0.027470 HR: 0.027470
Top-5 Recall: 0.066033 Precision: 0.013207 NDCG: 0.047135 HR: 0.066033
Top-10 Recall: 0.093502 Precision: 0.009350 NDCG: 0.056057 HR: 0.093502
Eval costs: 21.528246 s
Iter 36...	Training loss: 149166.312500  in 14.50s 
Iter 37...	Training loss: 148442.562500  in 14.95s 
Iter 38...	Training loss: 147725.859375  in 14.66s 
Iter 39...	Training loss: 147480.437500  in 14.58s 
Iter 40...	Training loss: 146752.796875  in 14.62s 
Top-1 Recall: 0.025885 Precision: 0.025885 NDCG: 0.025885 HR: 0.025885
Top-5 Recall: 0.062863 Precision: 0.012573 NDCG: 0.044823 HR: 0.062863
Top-10 Recall: 0.096672 Precision: 0.009667 NDCG: 0.055768 HR: 0.096672
Eval costs: 22.198025 s
Iter 41...	Training loss: 146289.609375  in 14.57s 
Iter 42...	Training loss: 145901.078125  in 15.42s 
Iter 43...	Training loss: 144987.015625  in 15.71s 
Iter 44...	Training loss: 144332.656250  in 15.90s 
Iter 45...	Training loss: 143708.625000  in 15.30s 
Top-1 Recall: 0.023772 Precision: 0.023772 NDCG: 0.023772 HR: 0.023772
Top-5 Recall: 0.074485 Precision: 0.014897 NDCG: 0.049786 HR: 0.074485
Top-10 Recall: 0.105652 Precision: 0.010565 NDCG: 0.059867 HR: 0.105652
Eval costs: 19.897910 s
Iter 46...	Training loss: 143260.859375  in 15.57s 
Iter 47...	Training loss: 142917.046875  in 13.35s 
Iter 48...	Training loss: 142108.265625  in 13.35s 
Iter 49...	Training loss: 141798.156250  in 13.50s 
Iter 50...	Training loss: 140979.734375  in 14.07s 
Top-1 Recall: 0.025885 Precision: 0.025885 NDCG: 0.025885 HR: 0.025885
Top-5 Recall: 0.078183 Precision: 0.015637 NDCG: 0.053235 HR: 0.078183
Top-10 Recall: 0.103539 Precision: 0.010354 NDCG: 0.061351 HR: 0.103539
Eval costs: 18.427999 s
Iter 51...	Training loss: 140616.281250  in 12.60s 
Iter 52...	Training loss: 140619.093750  in 12.66s 
Iter 53...	Training loss: 140032.609375  in 12.56s 
Iter 54...	Training loss: 140180.734375  in 12.58s 
Iter 55...	Training loss: 139506.890625  in 12.56s 
Top-1 Recall: 0.031167 Precision: 0.031167 NDCG: 0.031167 HR: 0.031167
Top-5 Recall: 0.079768 Precision: 0.015954 NDCG: 0.055627 HR: 0.079768
Top-10 Recall: 0.117802 Precision: 0.011780 NDCG: 0.067943 HR: 0.117802
Eval costs: 17.618849 s
Iter 56...	Training loss: 138996.312500  in 12.57s 
Iter 57...	Training loss: 138777.859375  in 12.96s 
Iter 58...	Training loss: 138201.406250  in 13.28s 
############################################### 
n_negative=20  
batch_size=1024 
embed_dim=100 
margin=2.00 
alpha=0.0000 
beta=0.0000 
cooccurrence_cap=100 
############################################### 
Iter 1...	Training loss: 247246.000000  in 12.52s 
Iter 2...	Training loss: 165896.718750  in 12.67s 
Iter 3...	Training loss: 164635.687500  in 12.50s 
Iter 4...	Training loss: 165658.968750  in 12.50s 
Iter 5...	Training loss: 164628.578125  in 12.65s 
Top-1 Recall: 0.006867 Precision: 0.006867 NDCG: 0.006867 HR: 0.006867
Top-5 Recall: 0.035394 Precision: 0.007079 NDCG: 0.021540 HR: 0.035394
Top-10 Recall: 0.052298 Precision: 0.005230 NDCG: 0.027067 HR: 0.052298
Eval costs: 17.601803 s
Iter 6...	Training loss: 163613.015625  in 12.76s 
Iter 7...	Training loss: 162209.031250  in 13.62s 
Iter 8...	Training loss: 159633.062500  in 13.30s 
Iter 9...	Training loss: 158015.093750  in 12.84s 
Iter 10...	Training loss: 157758.812500  in 12.65s 
Top-1 Recall: 0.005811 Precision: 0.005811 NDCG: 0.005811 HR: 0.005811
Top-5 Recall: 0.031696 Precision: 0.006339 NDCG: 0.018575 HR: 0.031696
Top-10 Recall: 0.051241 Precision: 0.005124 NDCG: 0.025037 HR: 0.051241
Eval costs: 17.359158 s
Iter 11...	Training loss: 157092.406250  in 13.21s 
Iter 12...	Training loss: 158624.968750  in 14.35s 
Iter 13...	Training loss: 161947.484375  in 14.57s 
Iter 14...	Training loss: 160549.171875  in 12.48s 
Iter 15...	Training loss: 157818.218750  in 12.82s 
Top-1 Recall: 0.008980 Precision: 0.008980 NDCG: 0.008980 HR: 0.008980
Top-5 Recall: 0.036978 Precision: 0.007396 NDCG: 0.023063 HR: 0.036978
Top-10 Recall: 0.054411 Precision: 0.005441 NDCG: 0.028590 HR: 0.054411
Eval costs: 21.203380 s
>>>>>>> 0fce27345cedc18c1b94ea16f39966eda8d097a9
